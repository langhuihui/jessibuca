(function (global, factory) {
    typeof exports === 'object' && typeof module !== 'undefined' ? module.exports = factory() :
    typeof define === 'function' && define.amd ? define(factory) :
    (global = typeof globalThis !== 'undefined' ? globalThis : global || self, global["jessibuca-demo"] = factory());
})(this, (function () { 'use strict';

    // 播放协议
    const PLAYER_PLAY_PROTOCOL = {
      websocket: 1,
      fetch: 2,
      hls: 3,
      webrtc: 4,
      webTransport: 5
    }; // 播放

    const PLAY_TYPE = {
      player: "player",
      playbackTF: 'playbackTF'
    };
    const FILE_SUFFIX = {
      mp4: 'mp4',
      webm: 'webm'
    };
    const DEMUX_TYPE = {
      flv: 'flv',
      m7s: 'm7s',
      hls: 'hls',
      webrtc: 'webrtc',
      webTransport: 'webTransport',
      nakedFlow: 'nakedFlow'
    };
    const DEMUX_TYPE_SHOW = {
      flv: 'FLV',
      m7s: 'm7s',
      hls: 'HLS',
      webrtc: 'Webrtc',
      webTransport: 'WebTransport',
      nakedFlow: '裸流'
    };
    const DECODE_TYPE = {
      mse: 'mse',
      wcs: 'wcs',
      offscreen: 'offscreen',
      wasm: 'wasm',
      simd: 'simd',
      webrtc: 'webrtc',
      hls: 'hls'
    };
    const RENDER_TYPE = {
      canvas: 'canvas',
      video: 'video'
    };
    const DEFAULT_PLAYBACK_FORWARD_MAX_RATE_DECODE_IFRAME = 8;
    const DOCUMENT_ONE_SECOND_BUFFER_LENGTH = 60; // default one second buffer length (fps is 25 - 30)

    const MSE_MAX_DELAY_TIME = 5; // 单位 秒

    const MSE_DELAY_INCREASE_TIME = 3; // 单位 秒

    const DEFAULT_JESSIBUCA_OPTIONS = {
      url: '',
      playbackConfig: {},
      playType: PLAY_TYPE.player,
      playbackForwardMaxRateDecodeIFrame: DEFAULT_PLAYBACK_FORWARD_MAX_RATE_DECODE_IFRAME,
      playOptions: {},
      isLive: true
    }; // default player options

    const DEFAULT_PLAYER_OPTIONS = {
      playType: PLAY_TYPE.player,
      //
      container: '',
      //
      videoBuffer: 1 * 1000,
      // 1* 1000ms == 1 second
      videoBufferDelay: 1 * 1000,
      // 1 * 1000ms
      networkDelay: 10 * 1000,
      //  10 * 1000ms
      isResize: true,
      //
      isFullResize: false,
      // full resize
      isFlv: false,
      // flv
      isHls: false,
      // hls
      isWebrtc: false,
      // webrtc
      isWebrtcForZLM: false,
      // webrtc for ZLM
      isNakedFlow: false,
      // 是否是裸流（264、265）
      debug: false,
      hotKey: false,
      // 快捷键
      loadingTimeout: 10,
      // loading timeout
      heartTimeout: 10,
      // heart timeout
      timeout: 10,
      // second
      loadingTimeoutReplay: true,
      // loading timeout replay
      heartTimeoutReplay: true,
      // heart timeout replay。
      loadingTimeoutReplayTimes: 3,
      // loading timeout replay fail times
      heartTimeoutReplayTimes: 3,
      // heart timeout replay fail times
      supportDblclickFullscreen: false,
      showBandwidth: false,
      //
      showPerformance: false,
      // 是否显示性能面板
      keepScreenOn: false,
      isNotMute: false,
      hasAudio: true,
      hasVideo: true,
      operateBtns: {
        fullscreen: false,
        screenshot: false,
        play: false,
        audio: false,
        record: false,
        ptz: false,
        quality: false,
        zoom: false,
        close: false,
        scale: false,
        performance: false,
        face: false,
        fullscreenFn: null,
        fullscreenExitFn: null,
        screenshotFn: null,
        playFn: null,
        pauseFn: null,
        recordFn: null,
        recordStopFn: null
      },
      watermarkConfig: {},
      controlAutoHide: false,
      hasControl: false,
      loadingIcon: true,
      loadingText: '',
      background: '',
      decoder: 'decoder-pro.js',
      decoderWASM: '',
      url: '',
      //
      rotate: 0,
      mirrorRotate: 'none',
      // 镜像xx
      playbackConfig: {
        playList: [],
        // {start:xx,end:xx}
        fps: '',
        // fps值
        showControl: true,
        isCacheBeforeDecodeForFpsRender: false,
        // rfs渲染时，是否在解码前缓存数据
        uiUsePlaybackPause: false,
        // ui上面是否使用 playbackPause 方法
        isUseFpsRender: false,
        // 是否使用固定的fps渲染，如果设置的fps小于流推过来的，会造成内存堆积甚至溢出
        isUseLocalCalculateTime: false,
        // 是否使用本地时间来计算playback时间
        localOneFrameTimestamp: 40 // 一帧 40ms, isUseLocalCalculateTime 为 true 生效。

      },
      qualityConfig: [],
      // 支持 ['高清','超清','4K']
      defaultStreamQuality: '',
      scaleConfig: ['拉伸', '缩放', '正常'],
      // text: '',
      forceNoOffscreen: true,
      // 默认是不采用
      hiddenAutoPause: false,
      protocol: PLAYER_PLAY_PROTOCOL.fetch,
      demuxType: DEMUX_TYPE.flv,
      //
      useWasm: false,
      //wasm 解码 默认
      useWCS: false,
      //
      useSIMD: false,
      wcsUseVideoRender: true,
      // wcs 是否使用 video 渲染
      wasmUseVideoRender: true,
      // wasm 用video标签渲染
      mseUseCanvasRender: false,
      //mse 用canvas标签渲染
      hlsUseCanvasRender: false,
      // hls 用canvas标签渲染
      useMSE: false,
      //
      useOffscreen: false,
      //
      autoWasm: true,
      // 自动降级到 wasm 模式
      wasmDecodeErrorReplay: true,
      // 解码失败重新播放。
      openWebglAlignment: false,
      //  https://github.com/langhuihui/jessibuca/issues/152
      wasmDecodeAudioSyncVideo: true,
      // wasm 解码之后音视频同步
      syncAudioAndVideo: false,
      // 音视频同步
      // playback config
      playbackDelayTime: 1000,
      // TF卡流播放延迟时间
      playbackFps: 25,
      playbackForwardMaxRateDecodeIFrame: DEFAULT_PLAYBACK_FORWARD_MAX_RATE_DECODE_IFRAME,
      // max rate render i frame
      playbackCurrentTimeMove: true,
      useVideoRender: true,
      // 使用video标签渲染
      useCanvasRender: false,
      // 使用canvas渲染
      networkDelayTimeoutReplay: false,
      // 网络延迟重连
      recordType: FILE_SUFFIX.mp4,
      checkFirstIFrame: true,
      // 检查第一帧是否是I帧
      nakedFlowFps: 25,
      // 裸流fps
      audioEngine: null,
      // 音频引擎
      isShowRecordingUI: true,
      // 是否显示录制中
      isShowZoomingUI: true,
      // 是否显示缩放中
      useFaceDetector: true //

    };
    const WORKER_CMD_TYPE = {
      init: 'init',
      initVideo: 'initVideo',
      render: 'render',
      playAudio: 'playAudio',
      initAudio: 'initAudio',
      kBps: 'kBps',
      decode: 'decode',
      audioCode: 'audioCode',
      videoCode: 'videoCode',
      videoCodec: 'videoCodec',
      videoNalu: 'videoNalu',
      wasmError: 'wasmError',
      workerFetch: 'workerFetch',
      iframeIntervalTs: 'iframeIntervalTs',
      workerEnd: 'workerEnd',
      networkDelay: 'networkDelay',
      playbackStreamVideoFps: 'playbackStreamVideoFps'
    };
    const WASM_ERROR = {
      invalidNalUnitSize: 'Invalid NAL unit size' // errorSplittingTheInputIntoNALUnits: 'Error splitting the input into NAL units'

    };
    const MEDIA_TYPE = {
      audio: 1,
      video: 2
    };
    const FLV_MEDIA_TYPE = {
      audio: 8,
      video: 9,
      scriptData: 18
    };
    const WORKER_SEND_TYPE = {
      init: 'init',
      decode: 'decode',
      audioDecode: 'audioDecode',
      videoDecode: 'videoDecode',
      initAudioCodec: 'initAudioCodec',
      initVideoCodec: 'initVideoCodec',
      close: 'close',
      updateConfig: 'updateConfig',
      resetDecode: 'resetDecode',
      clearBuffer: 'clearBuffer',
      resetAudioDecode: 'resetAudioDecode',
      resetVideoDecode: 'resetVideoDecode',
      fetchStream: 'fetchStream'
    }; // inner events

    const EVENTS = {
      fullscreen: 'fullscreen$2',
      webFullscreen: 'webFullscreen',
      decoderWorkerInit: 'decoderWorkerInit',
      play: 'play',
      playing: 'playing',
      pause: 'pause',
      mute: 'mute',
      load: 'load',
      loading: 'loading',
      zooming: 'zooming',
      videoInfo: 'videoInfo',
      timeUpdate: 'timeUpdate',
      audioInfo: "audioInfo",
      log: 'log',
      error: "error",
      kBps: 'kBps',
      timeout: 'timeout',
      delayTimeout: 'delayTimeout',
      loadingTimeout: 'loadingTimeout',
      stats: 'stats',
      performance: "performance",
      faceDetectActive: 'faceDetectActive',
      // record
      record: 'record',
      recording: 'recording',
      recordingTimestamp: 'recordingTimestamp',
      recordStart: 'recordStart',
      recordEnd: 'recordEnd',
      recordCreateError: 'recordCreateError',
      recordBlob: 'recordBlob',
      buffer: 'buffer',
      videoFrame: 'videoFrame',
      start: 'start',
      metadata: 'metadata',
      resize: 'resize',
      volumechange: 'volumechange',
      destroy: 'destroy',
      beforeDestroy: 'beforeDestroy',
      // stream
      streamEnd: 'streamEnd',
      streamRate: 'streamRate',
      streamAbps: 'streamAbps',
      streamVbps: 'streamVbps',
      streamDts: 'streamDts',
      streamSuccess: 'streamSuccess',
      streamMessage: 'streamMessage',
      streamError: 'streamError',
      streamStats: 'streamStats',
      // MSE
      mseSourceOpen: 'mseSourceOpen',
      mseSourceClose: 'mseSourceClose',
      mseSourceended: 'mseSourceended',
      mseSourceBufferError: 'mseSourceBufferError',
      mseSourceBufferBusy: 'mseSourceBufferBusy',
      mseSourceBufferFull: 'mseSourceBufferFull',
      // VIDEO
      videoWaiting: 'videoWaiting',
      videoTimeUpdate: 'videoTimeUpdate',
      videoSyncAudio: 'videoSyncAudio',
      //
      playToRenderTimes: 'playToRenderTimes',
      playbackTime: 'playbackTime',
      playbackTimestamp: 'playbackTimestamp',
      playbackPrecision: 'playbackPrecision',
      playbackJustTime: 'playbackJustTime',
      playbackStats: 'playbackStats',
      playbackSeek: 'playbackSeek',
      playbackPause: 'playbackPause',
      playbackPauseOrResume: 'playbackPauseOrResume',
      ptz: 'ptz',
      streamQualityChange: 'streamQualityChange',
      visibilityChange: "visibilityChange",
      netBuf: 'netBuf',
      close: 'close',
      networkDelayTimeout: 'networkDelayTimeout',
      togglePerformancePanel: 'togglePerformancePanel',
      viewResizeChange: 'viewResizeChange',
      // talk
      talkGetUserMediaSuccess: 'talkGetUserMediaSuccess',
      talkGetUserMediaFail: 'talkGetUserMediaFail',
      talkGetUserMediaTimeout: 'talkGetUserMediaTimeout',
      talkStreamStart: 'talkStreamStart',
      talkStreamOpen: 'talkStreamOpen',
      talkStreamClose: 'talkStreamClose',
      talkStreamError: 'talkStreamError',
      talkStreamInactive: 'talkStreamInactive',
      webrtcDisconnect: 'webrtcDisconnect',
      webrtcFailed: 'webrtcFailed',
      webrtcClosed: 'webrtcClosed',
      // crash
      crashLog: 'crashLog'
    };
    const JESSIBUCA_EVENTS = {
      load: EVENTS.load,
      timeUpdate: EVENTS.timeUpdate,
      videoInfo: EVENTS.videoInfo,
      audioInfo: EVENTS.audioInfo,
      error: EVENTS.error,
      kBps: EVENTS.kBps,
      log: EVENTS.log,
      start: EVENTS.start,
      timeout: EVENTS.timeout,
      loadingTimeout: EVENTS.loadingTimeout,
      delayTimeout: EVENTS.delayTimeout,
      fullscreen: 'fullscreen',
      play: EVENTS.play,
      pause: EVENTS.pause,
      mute: EVENTS.mute,
      stats: EVENTS.stats,
      performance: EVENTS.performance,
      recordingTimestamp: EVENTS.recordingTimestamp,
      recordStart: EVENTS.recordStart,
      recordEnd: EVENTS.recordEnd,
      recordBlob: EVENTS.recordBlob,
      playToRenderTimes: EVENTS.playToRenderTimes,
      // playback
      playbackSeek: EVENTS.playbackSeek,
      playbackStats: EVENTS.playbackStats,
      playbackTimestamp: EVENTS.playbackTimestamp,
      playbackPauseOrResume: EVENTS.playbackPauseOrResume,
      ptz: EVENTS.ptz,
      streamQualityChange: EVENTS.streamQualityChange,
      zooming: EVENTS.zooming,
      crashLog: EVENTS.crashLog
    };
    const TALK_EVENTS = {
      talkStreamClose: EVENTS.talkStreamClose,
      talkStreamError: EVENTS.talkStreamError,
      talkStreamInactive: EVENTS.talkStreamInactive,
      talkGetUserMediaTimeout: EVENTS.talkGetUserMediaTimeout
    };
    const EVENTS_ERROR = {
      playError: 'playIsNotPauseOrUrlIsNull',
      fetchError: "fetchError",
      websocketError: 'websocketError',
      webcodecsH265NotSupport: 'webcodecsH265NotSupport',
      webcodecsDecodeError: 'webcodecsDecodeError',
      mediaSourceH265NotSupport: 'mediaSourceH265NotSupport',
      mediaSourceFull: EVENTS.mseSourceBufferFull,
      mseSourceBufferError: EVENTS.mseSourceBufferError,
      mediaSourceAppendBufferError: 'mediaSourceAppendBufferError',
      mediaSourceBufferListLarge: 'mediaSourceBufferListLarge',
      mediaSourceAppendBufferEndTimeout: 'mediaSourceAppendBufferEndTimeout',
      wasmDecodeError: 'wasmDecodeError',
      hlsError: 'hlsError',
      webrtcError: 'webrtcError',
      webglAlignmentError: 'webglAlignmentError',
      webcodecsWidthOrHeightChange: 'webcodecsWidthOrHeightChange',
      tallWebsocketClosedByError: 'tallWebsocketClosedByError'
    };
    const WEBSOCKET_STATUS = {
      notConnect: 'notConnect',
      open: 'open',
      close: 'close',
      error: 'error'
    };
    const SCREENSHOT_TYPE = {
      download: 'download',
      base64: 'base64',
      blob: 'blob'
    };
    const RECORDING_TYPE = {
      download: 'download',
      blob: 'blob'
    };
    const VIDEO_ENC_TYPE = {
      7: 'H264(AVC)',
      //
      12: 'H265(HEVC)' //

    };
    const VIDEO_ENC_CODE = {
      h264: 7,
      h265: 12
    };
    const VIDEO_ENC_TYPE_SHOW = {
      h264: 'H264(AVC)',
      h265: 'H265(HEVC)'
    };
    const AUDIO_ENC_CODE = {
      AAC: 10,
      ALAW: 7,
      MULAW: 8
    };
    const AUDIO_ENC_CODE_SHOW = {
      AAC: 'AAC',
      ALAW: 'ALAW(g711a)',
      MULAW: 'MULAW(g711u)'
    };
    const AUDIO_ENC_TYPE = {
      10: 'AAC',
      7: 'ALAW',
      8: 'MULAW'
    };
    const H264_NAL_TYPE = {
      sps: 7,
      pps: 8,
      iFrame: 5,
      kUnspecified: 0,
      kSliceNonIDR: 1,
      kSliceDPA: 2,
      kSliceDPB: 3,
      kSliceDPC: 4,
      kSliceIDR: 5,
      kSliceSEI: 6,
      kSliceSPS: 7,
      kSlicePPS: 8,
      kSliceAUD: 9,
      kEndOfSequence: 10,
      kEndOfStream: 11,
      kFiller: 12,
      kSPSExt: 13,
      kReserved0: 14
    };
    const H265_NAL_TYPE = {
      vps: 32,
      // 语义为视频参数集
      sps: 33,
      // 语义为序列参数集
      pps: 34,
      // 语义为图像参数集
      sei: 39 //SEI 语义为补充增强信息
      //iFrame: 19, // 语义为可能有RADL图像的IDR图像的SS编码数据 IDR
      //pFrame: 1, //  语义为被参考的后置图像，且非TSA、非STSA的SS编码数据
      //nLp: 20, // kSliceIDR_N_LP

    };
    const CONTROL_HEIGHT = 38;
    const CONTROL_PLAYBACK_HEIGHT = 48;
    const SCALE_MODE_TYPE = {
      full: 0,
      //  视频画面完全填充canvas区域,画面会被拉伸
      auto: 1,
      // 视频画面做等比缩放后,高或宽对齐canvas区域,画面不被拉伸,但有黑边
      fullAuto: 2 // 视频画面做等比缩放后,完全填充canvas区域,画面不被拉伸,没有黑边,但画面显示不全

    };
    const CANVAS_RENDER_TYPE = {
      webcodecs: 'webcodecs',
      webgl: 'webgl',
      offscreen: 'offscreen',
      mse: 'mse',
      hls: 'hls'
    };
    const ENCODED_VIDEO_TYPE = {
      key: 'key',
      delta: 'delta'
    };
    const MP4_CODECS = {
      avc: 'video/mp4; codecs="avc1.64002A"',
      hev: 'video/mp4; codecs="hev1.1.6.L123.b0"'
    };
    const MEDIA_SOURCE_STATE = {
      ended: 'ended',
      open: 'open',
      closed: 'closed'
    }; // frag duration
    const AUDIO_SYNC_VIDEO_DIFF = 1000; // ms
    // renderTimeDay once length

    const PLAYBACK_RENDER_ONCE_LENGTH = 2000;
    const HOT_KEY = {
      esc: 27,
      //
      arrowUp: 38,
      //
      arrowDown: 40 //

    }; // playback control time precision

    const PLAYBACK_CONTROL_TIME_PRECISION = {
      oneHour: 'oneHour',
      // 60min
      halfHour: 'halfHour',
      // 30min
      tenMin: 'tenMin',
      // 10min
      fiveMin: 'fiveMin' // 5min
      // oneMin: "oneMin" // 1min

    };
    const PLAYBACK_CONTROL_TIME_PRECISION_CLASS = {
      oneHour: 'one-hour',
      // 60min
      halfHour: 'half-hour',
      // 30min
      tenMin: 'ten-min',
      // 10min
      fiveMin: 'five-min' // 5min
      // oneMin: 'one-min' // 1min

    };

    const PLAYBACK_CONTROL_TIME_PRECISION_ARRAY = ['oneHour', 'halfHour', 'tenMin', 'fiveMin'];
    const PTZ_ARROW = ['up', 'right', 'down', 'left'];
    const PTZ_OBJ = {
      up: "up",
      right: 'right',
      down: 'down',
      left: 'left',
      stop: 'stop'
    };
    const TALK_ENC_TYPE = {
      g711a: 'g711a',
      g711u: 'g711u'
    };
    const SCREENSHOT_FORMAT_TYPE = {
      png: 'image/png',
      jpeg: 'image/jpeg',
      webp: 'image/webp'
    };
    const MEDIA_SOURCE_EVENTS = {
      sourceClose: 'sourceclose',
      sourceOpen: 'sourceopen',
      sourceended: 'sourceended'
    };
    const VIDEO_ELEMENT_EVENTS = {
      canplay: 'canplay',
      waiting: "waiting",
      timeUpdate: 'timeupdate',
      ratechange: 'ratechange'
    };
    const VIDEO_ENCODE_TYPE = {
      h264: 'avc',
      h265: 'hevc'
    };
    const WCS_ERROR = {
      keyframeIsRequiredError: 'A key frame is required after configure() or flush()',
      canNotDecodeClosedCodec: "Cannot call 'decode' on a closed codec"
    };
    const FETCH_ERROR = {
      abortError: 'The user aborted a request',
      abortError2: 'AbortError',
      abort: 'AbortError'
    };
    const PLAYER_STATUS = {
      loading: 'loading',
      playing: 'playing',
      paused: 'paused',
      destroy: 'destroy'
    };
    const AVC_PACKET_TYPE = {
      sequenceHeader: 0,
      nalu: 1
    };
    //     RTP_PAYLOAD_TYPE_PCMA    = 8,   // g711a
    //     RTP_PAYLOAD_TYPE_JPEG    = 26,
    //     RTP_PAYLOAD_TYPE_H264    = 96,
    //     RTP_PAYLOAD_TYPE_H265    = 97,
    //     RTP_PAYLOAD_TYPE_OPUS    = 98,
    //     RTP_PAYLOAD_TYPE_AAC     = 99,
    //     RTP_PAYLOAD_TYPE_G726    = 100,
    //     RTP_PAYLOAD_TYPE_G726_16 = 101,
    //     RTP_PAYLOAD_TYPE_G726_24 = 102,
    //     RTP_PAYLOAD_TYPE_G726_32 = 103,
    //     RTP_PAYLOAD_TYPE_G726_40 = 104,
    //     RTP_PAYLOAD_TYPE_SPEEX   = 105,

    const RTP_PAYLOAD_TYPE = {
      pcma: 8,
      g711a: 8,
      pcmu: 0,
      g711u: 0,
      jpeg: 26,
      h264: 96,
      h265: 97,
      opus: 98
    };
    const TALK_PACKET_TYPE = {
      rtp: 'rtp',
      opus: 'opus'
    };
    const WEBSOCKET_EVENTS = {
      open: 'open',
      close: 'close',
      error: 'error',
      message: 'message'
    };
    const TALK_ENGINE = {
      worklet: 'worklet',
      script: 'script'
    }; // default talk options

    const DEFAULT_TALK_OPTIONS = {
      encType: TALK_ENC_TYPE.g711a,
      packetType: TALK_PACKET_TYPE.rtp,
      rtpSsrc: '0000000000',
      // 10 位
      numberChannels: 1,
      // 采样通道
      sampleRate: 8000,
      // 采样率
      sampleBitsWidth: 16,
      // 采样精度
      debug: false,
      testMicrophone: false,
      // 测试麦克风获取
      audioBufferLength: 160,
      // 默认走的是 20ms 8000 采样率 16 位精度
      engine: TALK_ENGINE.worklet,
      //
      checkGetUserMediaTimeout: false,
      // 检测 getUserMedia 超时
      getUserMediaTimeout: 10 * 1000 // getUserMedia 超时时间 10s

    };
    const AUDIO_ENGINE_TYPE = {
      worklet: 'worklet',
      script: 'script',
      // default
      active: 'active' //

    };

    class Debug {
      constructor(master) {
        this.log = function (name) {
          if (master._opt.debug) {
            for (var _len = arguments.length, args = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {
              args[_key - 1] = arguments[_key];
            }

            console.log(`JessibucaPro:[log][${name}]`, ...args);
          }
        };

        this.warn = function (name) {
          if (master._opt.debug) {
            for (var _len2 = arguments.length, args = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {
              args[_key2 - 1] = arguments[_key2];
            }

            console.log(`JessibucaPro:[warn][${name}]`, ...args);
          }
        };

        this.error = function (name) {
          for (var _len3 = arguments.length, args = new Array(_len3 > 1 ? _len3 - 1 : 0), _key3 = 1; _key3 < _len3; _key3++) {
            args[_key3 - 1] = arguments[_key3];
          }

          console.error(`JessibucaPro:[error][${name}]`, ...args);
        };
      }

    }

    class Events {
      constructor(master) {
        this.destroys = [];
        this.proxy = this.proxy.bind(this);
        this.master = master;
      }

      proxy(target, name, callback) {
        let option = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};

        if (!target) {
          return;
        }

        if (Array.isArray(name)) {
          return name.map(item => this.proxy(target, item, callback, option));
        }

        target.addEventListener(name, callback, option);

        const destroy = () => target.removeEventListener(name, callback, option);

        this.destroys.push(destroy);
        return destroy;
      }

      destroy() {
        this.master.debug && this.master.debug.log(`Events`, 'destroy');
        this.destroys.forEach(event => event());
      }

    }

    var property$1 = (player => {
      Object.defineProperty(player, 'rect', {
        get: () => {
          const clientRect = player.$container.getBoundingClientRect();
          clientRect.width = Math.max(clientRect.width, player.$container.clientWidth);
          clientRect.height = Math.max(clientRect.height, player.$container.clientHeight);
          return clientRect;
        }
      });
      ['bottom', 'height', 'left', 'right', 'top', 'width'].forEach(key => {
        Object.defineProperty(player, key, {
          get: () => {
            return player.rect[key];
          }
        });
      });
    });

    var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

    function unwrapExports (x) {
    	return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
    }

    function createCommonjsModule(fn, module) {
    	return module = { exports: {} }, fn(module, module.exports), module.exports;
    }

    var screenfull = createCommonjsModule(function (module) {
    /*!
    * screenfull
    * v5.1.0 - 2020-12-24
    * (c) Sindre Sorhus; MIT License
    */
    (function () {

    	var document = typeof window !== 'undefined' && typeof window.document !== 'undefined' ? window.document : {};
    	var isCommonjs = module.exports;

    	var fn = (function () {
    		var val;

    		var fnMap = [
    			[
    				'requestFullscreen',
    				'exitFullscreen',
    				'fullscreenElement',
    				'fullscreenEnabled',
    				'fullscreenchange',
    				'fullscreenerror'
    			],
    			// New WebKit
    			[
    				'webkitRequestFullscreen',
    				'webkitExitFullscreen',
    				'webkitFullscreenElement',
    				'webkitFullscreenEnabled',
    				'webkitfullscreenchange',
    				'webkitfullscreenerror'

    			],
    			// Old WebKit
    			[
    				'webkitRequestFullScreen',
    				'webkitCancelFullScreen',
    				'webkitCurrentFullScreenElement',
    				'webkitCancelFullScreen',
    				'webkitfullscreenchange',
    				'webkitfullscreenerror'

    			],
    			[
    				'mozRequestFullScreen',
    				'mozCancelFullScreen',
    				'mozFullScreenElement',
    				'mozFullScreenEnabled',
    				'mozfullscreenchange',
    				'mozfullscreenerror'
    			],
    			[
    				'msRequestFullscreen',
    				'msExitFullscreen',
    				'msFullscreenElement',
    				'msFullscreenEnabled',
    				'MSFullscreenChange',
    				'MSFullscreenError'
    			]
    		];

    		var i = 0;
    		var l = fnMap.length;
    		var ret = {};

    		for (; i < l; i++) {
    			val = fnMap[i];
    			if (val && val[1] in document) {
    				for (i = 0; i < val.length; i++) {
    					ret[fnMap[0][i]] = val[i];
    				}
    				return ret;
    			}
    		}

    		return false;
    	})();

    	var eventNameMap = {
    		change: fn.fullscreenchange,
    		error: fn.fullscreenerror
    	};

    	var screenfull = {
    		request: function (element, options) {
    			return new Promise(function (resolve, reject) {
    				var onFullScreenEntered = function () {
    					this.off('change', onFullScreenEntered);
    					resolve();
    				}.bind(this);

    				this.on('change', onFullScreenEntered);

    				element = element || document.documentElement;

    				var returnPromise = element[fn.requestFullscreen](options);

    				if (returnPromise instanceof Promise) {
    					returnPromise.then(onFullScreenEntered).catch(reject);
    				}
    			}.bind(this));
    		},
    		exit: function () {
    			return new Promise(function (resolve, reject) {
    				if (!this.isFullscreen) {
    					resolve();
    					return;
    				}

    				var onFullScreenExit = function () {
    					this.off('change', onFullScreenExit);
    					resolve();
    				}.bind(this);

    				this.on('change', onFullScreenExit);

    				var returnPromise = document[fn.exitFullscreen]();

    				if (returnPromise instanceof Promise) {
    					returnPromise.then(onFullScreenExit).catch(reject);
    				}
    			}.bind(this));
    		},
    		toggle: function (element, options) {
    			return this.isFullscreen ? this.exit() : this.request(element, options);
    		},
    		onchange: function (callback) {
    			this.on('change', callback);
    		},
    		onerror: function (callback) {
    			this.on('error', callback);
    		},
    		on: function (event, callback) {
    			var eventName = eventNameMap[event];
    			if (eventName) {
    				document.addEventListener(eventName, callback, false);
    			}
    		},
    		off: function (event, callback) {
    			var eventName = eventNameMap[event];
    			if (eventName) {
    				document.removeEventListener(eventName, callback, false);
    			}
    		},
    		raw: fn
    	};

    	if (!fn) {
    		if (isCommonjs) {
    			module.exports = {isEnabled: false};
    		} else {
    			window.screenfull = {isEnabled: false};
    		}

    		return;
    	}

    	Object.defineProperties(screenfull, {
    		isFullscreen: {
    			get: function () {
    				return Boolean(document[fn.fullscreenElement]);
    			}
    		},
    		element: {
    			enumerable: true,
    			get: function () {
    				return document[fn.fullscreenElement];
    			}
    		},
    		isEnabled: {
    			enumerable: true,
    			get: function () {
    				// Coerce to boolean in case of old WebKit
    				return Boolean(document[fn.fullscreenEnabled]);
    			}
    		}
    	});

    	if (isCommonjs) {
    		module.exports = screenfull;
    	} else {
    		window.screenfull = screenfull;
    	}
    })();
    });
    screenfull.isEnabled;

    /**
     *
     * @param payload
     * @returns {boolean}
     */

    function isAacCodecPacket(payload) {
      return payload[0] >> 4 === AUDIO_ENC_CODE.AAC && payload[1] === AVC_PACKET_TYPE.sequenceHeader;
    }

    function noop$2() {}
    function supportOffscreen($canvas) {
      return typeof $canvas.transferControlToOffscreen === 'function';
    }
    function supportOffscreenV2() {
      return typeof OffscreenCanvas !== "undefined";
    }
    function createContextGL($canvas) {
      let gl = null;
      const validContextNames = ["webgl", "experimental-webgl", "moz-webgl", "webkit-3d"];
      let nameIndex = 0;

      while (!gl && nameIndex < validContextNames.length) {
        const contextName = validContextNames[nameIndex];

        try {
          let contextOptions = {
            preserveDrawingBuffer: true
          };
          gl = $canvas.getContext(contextName, contextOptions);
        } catch (e) {
          gl = null;
        }

        if (!gl || typeof gl.getParameter !== "function") {
          gl = null;
        }

        ++nameIndex;
      }

      return gl;
    }
    function dataURLToFile() {
      let dataURL = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';
      const arr = dataURL.split(",");
      const bstr = atob(arr[1]);
      const type = arr[0].replace("data:", "").replace(";base64", "");
      let n = bstr.length,
          u8arr = new Uint8Array(n);

      while (n--) {
        u8arr[n] = bstr.charCodeAt(n);
      }

      return new File([u8arr], 'file', {
        type
      });
    }
    function now$1() {
      return new Date().getTime();
    }
    (() => {
      try {
        if (typeof WebAssembly === "object" && typeof WebAssembly.instantiate === "function") {
          const module = new WebAssembly.Module(Uint8Array.of(0x0, 0x61, 0x73, 0x6d, 0x01, 0x00, 0x00, 0x00));
          if (module instanceof WebAssembly.Module) return new WebAssembly.Instance(module) instanceof WebAssembly.Instance;
        }
      } catch (e) {}

      return false;
    })();
    function clamp(num, a, b) {
      return Math.max(Math.min(num, Math.max(a, b)), Math.min(a, b));
    }
    function setStyle(element, key, value) {
      if (!element) {
        return;
      }

      if (typeof key === 'object') {
        Object.keys(key).forEach(item => {
          setStyle(element, item, key[item]);
        });
      }

      element.style[key] = value;
      return element;
    }
    function getStyle(element, key) {
      let numberType = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : true;

      if (!element) {
        return 0;
      }

      const value = getComputedStyle(element, null).getPropertyValue(key);
      return numberType ? parseFloat(value) : value;
    }
    function getNowTime() {
      if (performance && typeof performance.now === 'function') {
        return performance.now();
      }

      return Date.now();
    }
    function calculationRate(callback) {
      let totalSize = 0;
      let lastTime = getNowTime();
      return size => {
        if (!isNumber(size)) {
          return;
        }

        totalSize += size;
        const thisTime = getNowTime();
        const diffTime = thisTime - lastTime;

        if (diffTime >= 1000) {
          callback(totalSize / diffTime * 1000);
          lastTime = thisTime;
          totalSize = 0;
        }
      };
    }
    function isMobile() {
      return /iphone|ipod|android.*mobile|windows.*phone|blackberry.*mobile/i.test(window.navigator.userAgent.toLowerCase());
    }
    function isAndroid() {
      const UA = window.navigator.userAgent.toLowerCase();
      return /android/i.test(UA);
    }
    function getBrowser() {
      const UserAgent = navigator.userAgent.toLowerCase();
      const browserInfo = {};
      const browserArray = {
        IE: window.ActiveXObject || "ActiveXObject" in window,
        // IE
        Chrome: UserAgent.indexOf('chrome') > -1 && UserAgent.indexOf('safari') > -1,
        // Chrome浏览器
        Firefox: UserAgent.indexOf('firefox') > -1,
        // 火狐浏览器
        Opera: UserAgent.indexOf('opera') > -1,
        // Opera浏览器
        Safari: UserAgent.indexOf('safari') > -1 && UserAgent.indexOf('chrome') == -1,
        // safari浏览器
        Edge: UserAgent.indexOf('edge') > -1,
        // Edge浏览器
        QQBrowser: /qqbrowser/.test(UserAgent),
        // qq浏览器
        WeixinBrowser: /MicroMessenger/i.test(UserAgent) // 微信浏览器

      }; // console.log(browserArray)

      for (let i in browserArray) {
        if (browserArray[i]) {
          let versions = '';

          if (i === 'IE') {
            versions = UserAgent.match(/(msie\s|trident.*rv:)([\w.]+)/)[2];
          } else if (i === 'Chrome') {
            for (let mt in navigator.mimeTypes) {
              //检测是否是360浏览器(测试只有pc端的360才起作用)
              if (navigator.mimeTypes[mt]['type'] === 'application/360softmgrplugin') {
                i = '360';
              }
            }

            versions = UserAgent.match(/chrome\/([\d.]+)/)[1];
          } else if (i === 'Firefox') {
            versions = UserAgent.match(/firefox\/([\d.]+)/)[1];
          } else if (i === 'Opera') {
            versions = UserAgent.match(/opera\/([\d.]+)/)[1];
          } else if (i === 'Safari') {
            versions = UserAgent.match(/version\/([\d.]+)/)[1];
          } else if (i === 'Edge') {
            versions = UserAgent.match(/edge\/([\d.]+)/)[1];
          } else if (i === 'QQBrowser') {
            versions = UserAgent.match(/qqbrowser\/([\d.]+)/)[1];
          }

          browserInfo.type = i;
          browserInfo.version = parseInt(versions);
        }
      }

      return browserInfo;
    }
    function isIOS() {
      const UA = window.navigator.userAgent.toLowerCase();
      return UA && /iphone|ipad|ipod|ios/.test(UA);
    }
    function isSafari() {
      const ua = window.navigator.userAgent;
      return !ua.match(/Chrome/gi) && !!ua.match(/Safari/gi);
    }
    function parseTime(time, cFormat) {
      if (arguments.length === 0) {
        return null;
      }

      var format = cFormat || '{y}-{m}-{d} {h}:{i}:{s}';
      var date;

      if (typeof time === 'object') {
        date = time;
      } else {
        if (('' + time).length === 10) time = parseInt(time) * 1000;
        time = +time; // 转成int 型

        date = new Date(time);
      }

      var formatObj = {
        y: date.getFullYear(),
        m: date.getMonth() + 1,
        d: date.getDate(),
        h: date.getHours(),
        i: date.getMinutes(),
        s: date.getSeconds(),
        a: date.getDay()
      };
      var time_str = format.replace(/{(y|m|d|h|i|s|a)+}/g, (result, key) => {
        var value = formatObj[key];
        if (key === 'a') return ['一', '二', '三', '四', '五', '六', '日'][value - 1];

        if (result.length > 0 && value < 10) {
          value = '0' + value;
        }

        return value || 0;
      });
      return time_str;
    } // 是否支持 webcodecs

    function supportWCS() {
      return "VideoEncoder" in window;
    }
    function supportWasmUseVideoRender() {
      return 'VideoFrame' in window;
    }
    function toNumber(value) {
      if (typeof value !== 'string') {
        return value;
      } else {
        // 转换成 number 类型
        var parsed = Number(value);
        return isNaN(parsed) ? value : parsed;
      }
    }
    function formatVideoDecoderConfigure(avcC) {
      let codecArray = avcC.subarray(1, 4);
      let codecString = "avc1.";

      for (let j = 0; j < 3; j++) {
        let h = codecArray[j].toString(16);

        if (h.length < 2) {
          h = "0" + h;
        }

        codecString += h;
      }

      return {
        codec: codecString,
        description: avcC
      };
    }
    function formatHevcVideoDecoderConfigure(hecvC) {
      // The codec string begins with the prefix "hev1." or "hvc1.", with a suffix of four dot-separated fields as described
      // 'hvc1.2.4.L93.B0', //'hev1.1.6.H120.B0'
      hecvC.subarray(1, 4); // let codecString = "hvc1.2.4.L93.B0";

      let codecString = 'hev1.1.6.L120.90'; // for (let j = 0; j < 3; j++) {
      //     let h = codecArray[j].toString(16);
      //     if (h.length < 2) {
      //         h = "0" + h
      //     }
      //     codecString += h
      // }

      return {
        codec: codecString,
        description: hecvC
      };
    }
    function isFullScreen() {
      // return document.isFullScreen || document.mozIsFullScreen || document.webkitIsFullScreen;
      return screenfull.isFullscreen;
    } //

    function bpsSize(value) {
      if (null == value || value === '') {
        return "0 KB/s";
      }

      let size = parseFloat(value);
      size = size.toFixed(2);
      return size + 'KB/s';
    }
    function bpsSize$2(value) {
      if (null == value || value === '' || parseFloat(value) === 0 || value === 'NaN') {
        return "0 KB/s";
      }

      const unitArr = ["KB/s", "MB/s", "GB/s", "TB/s", "PB/s", "EB/s", "ZB/s", "YB/s"];
      let index = 0;
      const srcsize = parseFloat(value);
      index = Math.floor(Math.log(srcsize) / Math.log(1024));
      let size = srcsize / Math.pow(1024, index);
      size = size.toFixed(2); //

      return size + (unitArr[index] || unitArr[0]);
    }
    function formatFileSize(value) {
      if (null == value || value == '') {
        return "0 Bytes";
      }

      const unitArr = new Array("Bytes", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB");
      let index = 0;
      const srcsize = parseFloat(value);
      index = Math.floor(Math.log(srcsize) / Math.log(1024));
      var size = srcsize / Math.pow(1024, index);
      size = size.toFixed(2); //保留的小数位数

      return size + unitArr[index];
    }
    function isNumber(value) {
      const toString = Object.prototype.toString;
      return toString.call(value) === "[object Number]";
    }
    function fpsStatus(fps) {
      let result = 0;

      if (fps >= 24) {
        result = 2;
      } else if (fps >= 15) {
        result = 1;
      }

      return result;
    }
    function createEmptyImageBitmap(width, height) {
      const $canvasElement = document.createElement("canvas");
      $canvasElement.width = width;
      $canvasElement.height = height;
      return window.createImageBitmap($canvasElement, 0, 0, width, height);
    }
    function supportMSE() {
      return window.MediaSource && window.MediaSource.isTypeSupported(MP4_CODECS.avc);
    } //

    function supportMSEDecodeHevc() {
      return window.MediaSource && window.MediaSource.isTypeSupported(MP4_CODECS.hev);
    } // 查看是否webcodecs 支持 hevc解码
    // chrome 107

    function supportWCSDecodeHevc() {
      const browserInfo = getBrowser();
      return browserInfo.type.toLowerCase() === 'chrome' && browserInfo.version >= 107;
    }
    function supportMediaStreamTrack() {
      return window.MediaStreamTrackGenerator && typeof window.MediaStreamTrackGenerator === 'function';
    }
    function saveBlobToFile(fileName, blob) {
      let url = window.URL.createObjectURL(blob);
      let aLink = window.document.createElement('a');
      aLink.download = fileName;
      aLink.href = url; //创建内置事件并触发

      let evt = window.document.createEvent('MouseEvents');
      evt.initEvent("click", true, true); //initEvent 不加后两个参数在FF下会报错  事件类型，是否冒泡，是否阻止浏览器的默认行为

      aLink.dispatchEvent(evt);
      setTimeout(() => {
        window.URL.revokeObjectURL(url);
      }, isIOS() ? 1000 : 0);
    }
    function isEmpty(value) {
      return value === null || value === undefined;
    }
    function isBoolean(value) {
      return value === true || value === false;
    }
    function isNotEmpty(value) {
      return !isEmpty(value);
    }
    function initPlayTimes() {
      return {
        playInitStart: '',
        //1
        playStart: '',
        // 2
        streamStart: '',
        //3
        streamResponse: '',
        // 4
        demuxStart: '',
        // 5
        decodeStart: '',
        // 6
        videoStart: '',
        // 7
        playTimestamp: '',
        // playStart- playInitStart
        streamTimestamp: '',
        // streamStart - playStart
        streamResponseTimestamp: '',
        // streamResponse - streamStart
        demuxTimestamp: '',
        // demuxStart - streamResponse
        decodeTimestamp: '',
        // decodeStart - demuxStart
        videoTimestamp: '',
        // videoStart - decodeStart
        allTimestamp: '' // videoStart - playInitStart

      };
    }

    function _formatWatermarkOptions(options) {
      let defaultConfig = {
        container: '',
        left: '',
        right: '',
        top: '',
        bottom: '',
        opacity: 1,
        image: {
          src: '',
          width: '100',
          height: '60'
        },
        text: {
          content: '',
          fontSize: '14',
          color: '#000'
        }
      };
      const imageConfig = Object.assign(defaultConfig.image, options.image || {});
      const textConfig = Object.assign(defaultConfig.text, options.text || {});
      defaultConfig = Object.assign(defaultConfig, options, {
        image: imageConfig,
        text: textConfig
      });
      return defaultConfig;
    } // create watermark


    function createWatermark(options) {
      let defaultConfig = _formatWatermarkOptions(options);

      const $container = defaultConfig.container;

      if (!$container) {
        return;
      }

      let shadowRoot = null;
      const otDiv = document.createElement('div');
      otDiv.setAttribute('style', 'pointer-events: none !important; display: block !important');

      if (typeof otDiv.attachShadow === "function") {
        shadowRoot = otDiv.attachShadow({
          mode: 'open'
        });
      } else if (otDiv.shadowRoot) {
        shadowRoot = otDiv.shadowRoot;
      } else {
        shadowRoot = otDiv;
      }

      const nodeList = $container.children;
      const index = Math.floor(Math.random() * (nodeList.length - 1));

      if (nodeList[index]) {
        $container.insertBefore(otDiv, nodeList[index]);
      } else {
        $container.appendChild(otDiv);
      }

      const maskDiv = document.createElement('div');
      let innerDom = null;

      if (defaultConfig.image && defaultConfig.image.src) {
        innerDom = document.createElement('img');
        innerDom.style.height = '100%';
        innerDom.style.width = '100%';
        innerDom.style.objectFit = 'contain';
        innerDom.src = defaultConfig.image.src;
      } else if (defaultConfig.text && defaultConfig.text.content) {
        innerDom = document.createTextNode(defaultConfig.text.content);
      }

      if (!innerDom) {
        return;
      }

      maskDiv.appendChild(innerDom);
      maskDiv.style.visibility = '';
      maskDiv.style.position = "absolute";
      maskDiv.style.display = 'block';
      maskDiv.style['-ms-user-select'] = "none";
      maskDiv.style['-moz-user-select'] = "none";
      maskDiv.style['-webkit-user-select'] = "none";
      maskDiv.style['-o-user-select'] = "none";
      maskDiv.style['user-select'] = "none";
      maskDiv.style['-webkit-touch-callout'] = "none";
      maskDiv.style['-webkit-tap-highlight-color'] = "rgba(0,0,0,0)";
      maskDiv.style['-webkit-text-size-adjust'] = "none";
      maskDiv.style['-webkit-touch-callout'] = "none";
      maskDiv.style.opacity = defaultConfig.opacity;

      if (isNumber(defaultConfig.left)) {
        maskDiv.style.left = defaultConfig.left + 'px';
      }

      if (isNumber(defaultConfig.right)) {
        maskDiv.style.right = defaultConfig.right + 'px';
      }

      if (isNumber(defaultConfig.top)) {
        maskDiv.style.top = defaultConfig.top + 'px';
      }

      if (isNumber(defaultConfig.bottom)) {
        maskDiv.style.bottom = defaultConfig.bottom + 'px';
      }

      maskDiv.style.overflow = 'hidden';
      maskDiv.style.zIndex = "9999999";

      if (defaultConfig.image && defaultConfig.image.src) {
        maskDiv.style.width = defaultConfig.image.width + 'px';
        maskDiv.style.height = defaultConfig.image.height + 'px';
      } else if (defaultConfig.text && defaultConfig.text.content) {
        maskDiv.style.fontSize = defaultConfig.text.fontSize + 'px';
        maskDiv.style.color = defaultConfig.text.color;
      }

      shadowRoot.appendChild(maskDiv); // remove function

      return () => {
        $container.removeChild(otDiv);
      };
    } // create image watermark

    function createImageWatermark(dataUrl, options) {
      return new Promise((resolve, reject) => {
        let defaultConfig = _formatWatermarkOptions(options);

        if (!defaultConfig.image.src && !defaultConfig.text.content) {
          return resolve(dataUrl);
        }

        let canvas = document.createElement('canvas');
        canvas.width = options.width;
        canvas.height = options.height;
        let ctx = canvas.getContext('2d');
        let x = 0;
        let y = 0;

        if (isNumber(defaultConfig.left)) {
          x = defaultConfig.left;
        } else if (isNumber(defaultConfig.right)) {
          x = canvas.width - defaultConfig.right;
        }

        if (isNumber(defaultConfig.top)) {
          y = defaultConfig.top;
        } else if (isNumber(defaultConfig.bottom)) {
          y = canvas.height - defaultConfig.bottom;
        }

        const imag = new Image();
        imag.src = dataUrl;

        imag.onload = () => {
          ctx.drawImage(imag, 0, 0);

          if (defaultConfig.image && defaultConfig.image.src) {
            const tempImage = new Image();
            tempImage.src = defaultConfig.image.src;
            tempImage.setAttribute("crossOrigin", 'Anonymous');

            tempImage.onload = () => {
              x -= defaultConfig.image.width; // y -= defaultConfig.image.height;

              ctx.drawImage(tempImage, x, y, defaultConfig.image.width, defaultConfig.image.height);
              resolve(canvas.toDataURL(options.format, options.quality));
            };

            tempImage.onerror = e => {
              reject();
            };
          } else if (defaultConfig.text && defaultConfig.text.content) {
            // 设置填充字号和字体，样式
            ctx.font = defaultConfig.text.fontSize + "px 宋体"; // color

            ctx.fillStyle = defaultConfig.text.color; // 设置右对齐

            ctx.textAlign = 'right'; // 在指定位置绘制文字，这里指定距离右下角20坐标的地方

            ctx.fillText(defaultConfig.text.content, x, y);
            resolve(canvas.toDataURL(options.format, options.quality));
          }
        };

        imag.onerror = e => {
          reject(e);
        };
      });
    }
    function formatTimeTips(time) {
      var result; //

      if (time > -1) {
        var hour = Math.floor(time / 3600);
        var min = Math.floor(time / 60) % 60;
        var sec = time % 60;
        sec = Math.round(sec);

        if (hour < 10) {
          result = '0' + hour + ":";
        } else {
          result = hour + ":";
        }

        if (min < 10) {
          result += "0";
        }

        result += min + ":";

        if (sec < 10) {
          result += "0";
        }

        result += sec.toFixed(0);
      }

      return result;
    } //

    function createVideoFrame(arrayBuffer, init) {
      return new VideoFrame(arrayBuffer, init);
    }

    function formatMinTimeTips(time, second) {
      let result = ''; //

      if (time > -1) {
        const hour = Math.floor(time / 60) % 60;
        let min = time % 60;
        min = Math.round(min);

        if (hour < 10) {
          result = '0' + hour + ":";
        } else {
          result = hour + ":";
        }

        if (min < 10) {
          result += "0";
        }

        result += min;

        if (!isEmpty(second)) {
          if (second < 10) {
            second = '0' + second;
          }

          result += ':' + second;
        }
      }

      return result;
    } // second timestamp

    function formatSecondTimeTips(time) {
      let result = '';

      if (time > -1) {
        const hour = Math.floor(time / 60 / 60) % 60;
        let min = Math.floor(time / 60) % 60;
        let second = time % 60;
        min = Math.round(min);

        if (hour < 10) {
          result = '0' + hour + ":";
        } else {
          result = hour + ":";
        }

        if (min < 10) {
          result += "0";
        }

        result += min + ':';

        if (second < 10) {
          result += '0';
        }

        result += second;
      }

      return result;
    }
    function formatSecondTime(time) {
      let result = {};

      if (time > -1) {
        const hour = Math.floor(time / 60 / 60) % 60;
        let min = Math.floor(time / 60) % 60;
        let second = time % 60;
        result = {
          hour,
          min,
          second
        };
      }

      return result;
    }
    /**
     *
     * @param time
     */

    function formatMinuteTimestamp(day, time) {
      const hour = Math.floor(time / 60) % 60;
      const min = Math.floor(time % 60);
      const nowMinuteTimestamp = new Date(day).setHours(hour, min, 0, 0);
      return nowMinuteTimestamp;
    }
    function formatSecondTimestamp(day, time) {
      const hour = Math.floor(time / 60 / 60) % 60;
      const min = Math.floor(time / 60) % 60;
      const second = time % 60;
      const nowSecondTimestamp = new Date(day).setHours(hour, min, second, 0);
      return nowSecondTimestamp;
    }
    function getStrLength(value) {
      return ('' + value).length;
    }
    function isEmptyObject(obj) {
      return obj && Object.keys(obj).length === 0;
    }
    function isNotEmptyObject(obj) {
      return !isEmptyObject(obj);
    }
    function isString(value) {
      return typeof value === "string";
    }
    function isSupportSIMD() {
      return WebAssembly.validate(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 123, 3, 2, 1, 0, 10, 10, 1, 8, 0, 65, 0, 253, 15, 253, 98, 11]));
    }
    const isWeChat = () => {
      const userAgent = window.navigator.userAgent;
      return /MicroMessenger/i.test(userAgent);
    }; //

    const isWeChatInAndroid = () => {
      return isWeChat() && isAndroid();
    };
    function getTarget(e) {
      const event = e || window.event;
      const target = event.target || event.srcElement;
      return target;
    }
    function isFunction$1(fn) {
      return typeof fn === "function";
    }
    function isWebglRenderSupport(width) {
      return width / 2 % 4 === 0;
    }
    /**
     *
     * @param event
     * @returns {{posX: number, posY: number}}
     */

    function getMousePosition(event) {
      let posX = 0;
      let posY = 0;
      const e = event || window.event; //标准化事件对象

      if (e.pageX || e.pageY) {
        //获取鼠标指针的当前坐标值
        posX = e.pageX;
        posY = e.pageY;
      } else if (e.clientX || e.clientY) {
        posX = event.clientX + document.documentElement.scrollLeft + document.body.scrollLeft;
        posY = event.clientY + document.documentElement.scrollTop + document.body.scrollTop;
      }

      return {
        posX,
        posY
      };
    }
    function canPlayAppleMpegurl() {
      let video = document.createElement('video');
      let result = video.canPlayType('application/vnd.apple.mpegurl');
      video = null;
      return result;
    }
    function isSupportGetUserMedia() {
      let result = false;
      const navigator = window.navigator;

      if (navigator) {
        result = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);

        if (!result) {
          result = !!(navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);
        }
      }

      return result;
    }
    function onlyMseOrWcsVideo(opt) {
      return opt.hasAudio === false && (opt.useMSE || opt.useWCS && !opt.useOffscreen);
    }
    function checkNaluType(naluBuffer) {
      let result = null;
      let type = naluBuffer[0] & 0b0001_1111;

      if (type === H264_NAL_TYPE.sps || type === H264_NAL_TYPE.pps) {
        result = VIDEO_ENC_TYPE_SHOW.h264;
      }

      if (!result) {
        type = (naluBuffer[0] & 0x7E) >> 1;

        if (type === H265_NAL_TYPE.vps || type === H265_NAL_TYPE.sps || type === H265_NAL_TYPE.pps) {
          result = VIDEO_ENC_TYPE_SHOW.h265;
        }
      }

      return result;
    }
    function createWorkletModuleUrl(func) {
      function functionToString(str) {
        return str.trim().match(/^function\s*\w*\s*\([\w\s,]*\)\s*{([\w\W]*?)}$/)[1];
      }

      const funcStr = functionToString(func.toString());
      const blob = new Blob([funcStr], {
        type: 'application/javascript'
      });
      return URL.createObjectURL(blob);
    }
    function closeVideoFrame(videoFrame) {
      if (videoFrame.close) {
        videoFrame.close();
      } else if (videoFrame.destroy) {
        videoFrame.destroy();
      }
    }
    function isInHttps() {
      return window.location.protocol === 'https:' || window.location.hostname === 'localhost';
    }
    function errorToString(error) {
      const nativeToString = Object.prototype.toString;

      function isErrorLike(error) {
        switch (nativeToString.call(error)) {
          case '[object Error]':
            return true;

          case '[object Exception]':
            return true;

          case '[object DOMException]':
            return true;

          default:
            try {
              return error instanceof Error;
            } catch (e) {
              return false;
            }

        }
      }

      if (isErrorLike(error)) {
        return error.message;
      } else {
        return error == null ? '' : typeof error === 'object' ? JSON.stringify(error, null, 2) : String(error);
      }
    }
    function calcStreamFpsByBufferList(bufferList, type) {
      if (type) {
        bufferList = bufferList.filter(item => item.type === type);
      }

      let firstItem = bufferList[0];
      let oneSecondLength = null;

      if (firstItem) {
        // next start
        for (let i = 1; i < bufferList.length; i++) {
          let tempItem = bufferList[i];

          if (type && tempItem.type !== type) {
            tempItem = null;
          }

          if (tempItem) {
            const diff = tempItem.ts - firstItem.ts;

            if (diff >= 1000) {
              const prevTempItem = bufferList[i - 1];
              const diff2 = prevTempItem.ts - firstItem.ts;

              if (diff2 < 1000) {
                oneSecondLength = i + 1;
              }
            }
          }
        }
      }

      return oneSecondLength;
    }

    var events$1 = (player => {
      try {
        const screenfullChange = e => {
          if (getTarget(e) === player.$container) {
            player.emit(JESSIBUCA_EVENTS.fullscreen, player.fullscreen); // 如果不是fullscreen,则触发下 resize 方法

            if (!player.fullscreen) {
              player.resize();
            } else {
              if (player._opt.useMSE) {
                player.resize();
              }
            }
          }
        };

        screenfull.on('change', screenfullChange);
        player.events.destroys.push(() => {
          screenfull.off('change', screenfullChange);
        });
      } catch (error) {//
      } //


      player.on(EVENTS.decoderWorkerInit, () => {
        player.debug.log('player', 'has loaded');
        player.loaded = true;
      }); //

      player.on(EVENTS.play, () => {
        player.loading = false;
      }); //

      player.on(EVENTS.fullscreen, value => {
        if (value) {
          try {
            screenfull.request(player.$container).then(() => {}).catch(e => {
              player.debug.error('player', 'fullscreen error', e);

              if (isMobile()) {
                player.webFullscreen = true;
              }
            });
          } catch (e) {
            if (isMobile()) {
              player.webFullscreen = true;
            }
          }
        } else {
          try {
            screenfull.exit().then(() => {
              if (player.webFullscreen) {
                player.webFullscreen = false;
              }
            }).catch(e => {
              player.debug.error('player', 'fullscreen error', e);

              if (isMobile()) {
                player.webFullscreen = false;
              }
            });
          } catch (e) {
            if (isMobile()) {
              player.webFullscreen = false;
            }
          }
        }
      }); // just for mobile check

      if (isMobile()) {
        player.on(EVENTS.webFullscreen, value => {
          if (value) {
            player.$container.classList.add('jessibuca-fullscreen-web');
          } else {
            player.$container.classList.remove('jessibuca-fullscreen-web');
          } //


          player.emit(JESSIBUCA_EVENTS.fullscreen, player.fullscreen);
        });
      } //


      player.on(EVENTS.resize, () => {
        player.video.resize();
      });

      if (player._opt.debug) {
        const ignoreList = [EVENTS.timeUpdate];
        Object.keys(EVENTS).forEach(key => {
          player.on(EVENTS[key], value => {
            if (ignoreList.includes(key)) {
              return;
            }

            player.debug.log('player events', EVENTS[key], value);
          });
        });
        Object.keys(EVENTS_ERROR).forEach(key => {
          player.on(EVENTS_ERROR[key], value => {
            player.debug.log('player event error', EVENTS_ERROR[key], value);
          });
        });
      }
    });

    class Emitter {
      on(name, fn, ctx) {
        const e = this.e || (this.e = {});
        (e[name] || (e[name] = [])).push({
          fn,
          ctx
        });
        return this;
      }

      once(name, fn, ctx) {
        const self = this;

        function listener() {
          self.off(name, listener);

          for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {
            args[_key] = arguments[_key];
          }

          fn.apply(ctx, args);
        }

        listener._ = fn;
        return this.on(name, listener, ctx);
      }

      emit(name) {
        const evtArr = ((this.e || (this.e = {}))[name] || []).slice();

        for (var _len2 = arguments.length, data = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {
          data[_key2 - 1] = arguments[_key2];
        }

        for (let i = 0; i < evtArr.length; i += 1) {
          evtArr[i].fn.apply(evtArr[i].ctx, data);
        }

        return this;
      }

      off(name, callback) {
        const e = this.e || (this.e = {});

        if (!name) {
          Object.keys(e).forEach(key => {
            delete e[key];
          });
          delete this.e;
          return;
        }

        const evts = e[name];
        const liveEvents = [];

        if (evts && callback) {
          for (let i = 0, len = evts.length; i < len; i += 1) {
            if (evts[i].fn !== callback && evts[i].fn._ !== callback) liveEvents.push(evts[i]);
          }
        }

        if (liveEvents.length) {
          e[name] = liveEvents;
        } else {
          delete e[name];
        }

        return this;
      }

    }

    /**
     * Common utilities
     * @module glMatrix
     */
    // Configuration Constants
    var EPSILON = 0.000001;
    var ARRAY_TYPE = typeof Float32Array !== 'undefined' ? Float32Array : Array;
    if (!Math.hypot) Math.hypot = function () {
      var y = 0,
          i = arguments.length;

      while (i--) {
        y += arguments[i] * arguments[i];
      }

      return Math.sqrt(y);
    };

    /**
     * 4x4 Matrix<br>Format: column-major, when typed out it looks like row-major<br>The matrices are being post multiplied.
     * @module mat4
     */

    /**
     * Creates a new identity mat4
     *
     * @returns {mat4} a new 4x4 matrix
     */

    function create$1() {
      var out = new ARRAY_TYPE(16);

      if (ARRAY_TYPE != Float32Array) {
        out[1] = 0;
        out[2] = 0;
        out[3] = 0;
        out[4] = 0;
        out[6] = 0;
        out[7] = 0;
        out[8] = 0;
        out[9] = 0;
        out[11] = 0;
        out[12] = 0;
        out[13] = 0;
        out[14] = 0;
      }

      out[0] = 1;
      out[5] = 1;
      out[10] = 1;
      out[15] = 1;
      return out;
    }
    /**
     * Set a mat4 to the identity matrix
     *
     * @param {mat4} out the receiving matrix
     * @returns {mat4} out
     */

    function identity(out) {
      out[0] = 1;
      out[1] = 0;
      out[2] = 0;
      out[3] = 0;
      out[4] = 0;
      out[5] = 1;
      out[6] = 0;
      out[7] = 0;
      out[8] = 0;
      out[9] = 0;
      out[10] = 1;
      out[11] = 0;
      out[12] = 0;
      out[13] = 0;
      out[14] = 0;
      out[15] = 1;
      return out;
    }
    /**
     * Generates a orthogonal projection matrix with the given bounds.
     * The near/far clip planes correspond to a normalized device coordinate Z range of [-1, 1],
     * which matches WebGL/OpenGL's clip volume.
     *
     * @param {mat4} out mat4 frustum matrix will be written into
     * @param {number} left Left bound of the frustum
     * @param {number} right Right bound of the frustum
     * @param {number} bottom Bottom bound of the frustum
     * @param {number} top Top bound of the frustum
     * @param {number} near Near bound of the frustum
     * @param {number} far Far bound of the frustum
     * @returns {mat4} out
     */

    function orthoNO(out, left, right, bottom, top, near, far) {
      var lr = 1 / (left - right);
      var bt = 1 / (bottom - top);
      var nf = 1 / (near - far);
      out[0] = -2 * lr;
      out[1] = 0;
      out[2] = 0;
      out[3] = 0;
      out[4] = 0;
      out[5] = -2 * bt;
      out[6] = 0;
      out[7] = 0;
      out[8] = 0;
      out[9] = 0;
      out[10] = 2 * nf;
      out[11] = 0;
      out[12] = (left + right) * lr;
      out[13] = (top + bottom) * bt;
      out[14] = (far + near) * nf;
      out[15] = 1;
      return out;
    }
    /**
     * Alias for {@link mat4.orthoNO}
     * @function
     */

    var ortho = orthoNO;
    /**
     * Generates a look-at matrix with the given eye position, focal point, and up axis.
     * If you want a matrix that actually makes an object look at another object, you should use targetTo instead.
     *
     * @param {mat4} out mat4 frustum matrix will be written into
     * @param {ReadonlyVec3} eye Position of the viewer
     * @param {ReadonlyVec3} center Point the viewer is looking at
     * @param {ReadonlyVec3} up vec3 pointing up
     * @returns {mat4} out
     */

    function lookAt(out, eye, center, up) {
      var x0, x1, x2, y0, y1, y2, z0, z1, z2, len;
      var eyex = eye[0];
      var eyey = eye[1];
      var eyez = eye[2];
      var upx = up[0];
      var upy = up[1];
      var upz = up[2];
      var centerx = center[0];
      var centery = center[1];
      var centerz = center[2];

      if (Math.abs(eyex - centerx) < EPSILON && Math.abs(eyey - centery) < EPSILON && Math.abs(eyez - centerz) < EPSILON) {
        return identity(out);
      }

      z0 = eyex - centerx;
      z1 = eyey - centery;
      z2 = eyez - centerz;
      len = 1 / Math.hypot(z0, z1, z2);
      z0 *= len;
      z1 *= len;
      z2 *= len;
      x0 = upy * z2 - upz * z1;
      x1 = upz * z0 - upx * z2;
      x2 = upx * z1 - upy * z0;
      len = Math.hypot(x0, x1, x2);

      if (!len) {
        x0 = 0;
        x1 = 0;
        x2 = 0;
      } else {
        len = 1 / len;
        x0 *= len;
        x1 *= len;
        x2 *= len;
      }

      y0 = z1 * x2 - z2 * x1;
      y1 = z2 * x0 - z0 * x2;
      y2 = z0 * x1 - z1 * x0;
      len = Math.hypot(y0, y1, y2);

      if (!len) {
        y0 = 0;
        y1 = 0;
        y2 = 0;
      } else {
        len = 1 / len;
        y0 *= len;
        y1 *= len;
        y2 *= len;
      }

      out[0] = x0;
      out[1] = y0;
      out[2] = z0;
      out[3] = 0;
      out[4] = x1;
      out[5] = y1;
      out[6] = z1;
      out[7] = 0;
      out[8] = x2;
      out[9] = y2;
      out[10] = z2;
      out[11] = 0;
      out[12] = -(x0 * eyex + x1 * eyey + x2 * eyez);
      out[13] = -(y0 * eyex + y1 * eyey + y2 * eyez);
      out[14] = -(z0 * eyex + z1 * eyey + z2 * eyez);
      out[15] = 1;
      return out;
    }

    /**
     * 3 Dimensional Vector
     * @module vec3
     */

    /**
     * Creates a new, empty vec3
     *
     * @returns {vec3} a new 3D vector
     */

    function create() {
      var out = new ARRAY_TYPE(3);

      if (ARRAY_TYPE != Float32Array) {
        out[0] = 0;
        out[1] = 0;
        out[2] = 0;
      }

      return out;
    }
    /**
     * Creates a new vec3 initialized with the given values
     *
     * @param {Number} x X component
     * @param {Number} y Y component
     * @param {Number} z Z component
     * @returns {vec3} a new 3D vector
     */

    function fromValues(x, y, z) {
      var out = new ARRAY_TYPE(3);
      out[0] = x;
      out[1] = y;
      out[2] = z;
      return out;
    }
    /**
     * Perform some operation over an array of vec3s.
     *
     * @param {Array} a the array of vectors to iterate over
     * @param {Number} stride Number of elements between the start of each vec3. If 0 assumes tightly packed
     * @param {Number} offset Number of elements to skip at the beginning of the array
     * @param {Number} count Number of vec3s to iterate over. If 0 iterates over entire array
     * @param {Function} fn Function to call for each vector in the array
     * @param {Object} [arg] additional argument to pass to fn
     * @returns {Array} a
     * @function
     */

    (function () {
      var vec = create();
      return function (a, stride, offset, count, fn, arg) {
        var i, l;

        if (!stride) {
          stride = 3;
        }

        if (!offset) {
          offset = 0;
        }

        if (count) {
          l = Math.min(count * stride + offset, a.length);
        } else {
          l = a.length;
        }

        for (i = offset; i < l; i += stride) {
          vec[0] = a[i];
          vec[1] = a[i + 1];
          vec[2] = a[i + 2];
          fn(vec, vec, arg);
          a[i] = vec[0];
          a[i + 1] = vec[1];
          a[i + 2] = vec[2];
        }

        return a;
      };
    })();

    var createWebGL = ((gl, openWebglAlignment) => {
      const vertexShaderScript = `
            attribute vec4 aVertexPosition;
            attribute vec2 aTexturePosition;
            uniform mat4 uModelMatrix;
            uniform mat4 uViewMatrix;
            uniform mat4 uProjectionMatrix;
            varying lowp vec2 vTexturePosition;
            void main(void) {
              gl_Position = uProjectionMatrix * uViewMatrix * uModelMatrix * aVertexPosition;
              vTexturePosition = aTexturePosition;
            }
        `;
      const fragmentShaderScript = `
            precision highp float;
            varying highp vec2 vTexturePosition;
            uniform int isyuv;
            uniform sampler2D rgbaTexture;
            uniform sampler2D yTexture;
            uniform sampler2D uTexture;
            uniform sampler2D vTexture;

            const mat4 YUV2RGB = mat4( 1.1643828125, 0, 1.59602734375, -.87078515625,
                                       1.1643828125, -.39176171875, -.81296875, .52959375,
                                       1.1643828125, 2.017234375, 0, -1.081390625,
                                       0, 0, 0, 1);


            void main(void) {

                if (isyuv>0) {

                    highp float y = texture2D(yTexture,  vTexturePosition).r;
                    highp float u = texture2D(uTexture,  vTexturePosition).r;
                    highp float v = texture2D(vTexture,  vTexturePosition).r;
                    gl_FragColor = vec4(y, u, v, 1) * YUV2RGB;

                } else {
                    gl_FragColor =  texture2D(rgbaTexture, vTexturePosition);
                }
            }
        `;

      if (openWebglAlignment) {
        gl.pixelStorei(gl.UNPACK_ALIGNMENT, 1);
      }

      const shaderProgram = _initShaderProgram();

      const _programInfo = {
        program: shaderProgram,
        attribLocations: {
          vertexPosition: gl.getAttribLocation(shaderProgram, 'aVertexPosition'),
          texturePosition: gl.getAttribLocation(shaderProgram, 'aTexturePosition')
        },
        uniformLocations: {
          projectionMatrix: gl.getUniformLocation(shaderProgram, 'uProjectionMatrix'),
          modelMatrix: gl.getUniformLocation(shaderProgram, 'uModelMatrix'),
          viewMatrix: gl.getUniformLocation(shaderProgram, 'uViewMatrix'),
          rgbatexture: gl.getUniformLocation(shaderProgram, 'rgbaTexture'),
          ytexture: gl.getUniformLocation(shaderProgram, 'yTexture'),
          utexture: gl.getUniformLocation(shaderProgram, 'uTexture'),
          vtexture: gl.getUniformLocation(shaderProgram, 'vTexture'),
          isyuv: gl.getUniformLocation(shaderProgram, 'isyuv')
        }
      };

      const _buffers = _initBuffers();

      const _rgbatexture = _createTexture();

      const _ytexture = _createTexture();

      const _utexture = _createTexture();

      const _vtexture = _createTexture();

      function _initBuffers() {
        // Create a buffer for the cube's vertex positions.
        const positionBuffer = gl.createBuffer(); // Select the positionBuffer as the one to apply buffer
        // operations to from here out.

        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer); // Now create an array of positions for the cube.

        const positions = [// Front face
        -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0]; // Now pass the list of positions into WebGL to build the
        // shape. We do this by creating a Float32Array from the
        // JavaScript array, then use it to fill the current buffer.

        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW); // Now set up the colors for the faces. We'll use solid colors
        // for each face.
        //   const facePos = [
        //     [0.0,  0.0],
        //     [1.0,  0.0],
        //     [1.0,  1.0],
        //     [0.0,  1.0]
        //   ];

        const facePos = [[0.0, 1.0], [1.0, 1.0], [1.0, 0.0], [0.0, 0.0]]; // Convert the array of colors into a table for all the vertices.

        var texturePos = [];
        texturePos = texturePos.concat(...facePos);
        const texpositionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, texpositionBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(texturePos), gl.STATIC_DRAW); // Build the element array buffer; this specifies the indices
        // into the vertex arrays for each face's vertices.

        const indexBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer); // This array defines each face as two triangles, using the
        // indices into the vertex array to specify each triangle's
        // position.

        const indices = [0, 1, 2, 0, 2, 3]; // Now send the element array to GL

        gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array(indices), gl.STATIC_DRAW);
        return {
          position: positionBuffer,
          texPosition: texpositionBuffer,
          indices: indexBuffer
        };
      }

      function _createTexture() {
        let texture = gl.createTexture();
        gl.bindTexture(gl.TEXTURE_2D, texture);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
        return texture;
      }

      function _loadShader(type, source) {
        const shader = gl.createShader(type); // Send the source to the shader object

        gl.shaderSource(shader, source); // Compile the shader program

        gl.compileShader(shader); // See if it compiled successfully

        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
          console.log('An error occurred compiling the shaders: ' + gl.getShaderInfoLog(shader));
          gl.deleteShader(shader);
          return null;
        }

        return shader;
      }

      function _initShaderProgram() {
        const vertexShader = _loadShader(gl.VERTEX_SHADER, vertexShaderScript);

        const fragmentShader = _loadShader(gl.FRAGMENT_SHADER, fragmentShaderScript); // Create the shader program


        const shaderProgram = gl.createProgram();
        gl.attachShader(shaderProgram, vertexShader);
        gl.attachShader(shaderProgram, fragmentShader);
        gl.linkProgram(shaderProgram); // If creating the shader program failed, alert

        if (!gl.getProgramParameter(shaderProgram, gl.LINK_STATUS)) {
          console.log('Unable to initialize the shader program: ' + gl.getProgramInfoLog(shaderProgram));
          return null;
        }

        return shaderProgram;
      }

      function _drawScene(w, h) {
        gl.viewport(0, 0, w, h);
        gl.clearColor(0.0, 0.0, 0.0, 0.0); // Clear to black, fully opaque

        gl.clearDepth(1.0); // Clear everything

        gl.enable(gl.DEPTH_TEST); // Enable depth testing

        gl.depthFunc(gl.LEQUAL); // Near things obscure far things
        // Clear the canvas before we start drawing on it.

        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
        const zNear = 0.1;
        const zFar = 100.0;
        const projectionMatrix = create$1();
        ortho(projectionMatrix, -1, 1, -1, 1, zNear, zFar); // Set the drawing position to the "identity" point, which is
        // the center of the scene.

        const modelMatrix = create$1();
        identity(modelMatrix);
        const viewMatrix = create$1();
        lookAt(viewMatrix, fromValues(0, 0, 0), fromValues(0, 0, -1), fromValues(0, 1, 0)); // Tell WebGL how to pull out the positions from the position
        // buffer into the vertexPosition attribute

        {
          const numComponents = 3;
          const type = gl.FLOAT;
          const normalize = false;
          const stride = 0;
          const offset = 0;
          gl.bindBuffer(gl.ARRAY_BUFFER, _buffers.position);
          gl.vertexAttribPointer(_programInfo.attribLocations.vertexPosition, numComponents, type, normalize, stride, offset);
          gl.enableVertexAttribArray(_programInfo.attribLocations.vertexPosition);
        } // Tell WebGL how to pull out the colors from the color buffer
        // into the vertexColor attribute.

        {
          const numComponents = 2;
          const type = gl.FLOAT;
          const normalize = false;
          const stride = 0;
          const offset = 0;
          gl.bindBuffer(gl.ARRAY_BUFFER, _buffers.texPosition);
          gl.vertexAttribPointer(_programInfo.attribLocations.texturePosition, numComponents, type, normalize, stride, offset);
          gl.enableVertexAttribArray(_programInfo.attribLocations.texturePosition);
        }
        let rgbatextunit = 2;
        let ytextunit = rgbatextunit + 1;
        let utextunit = rgbatextunit + 2;
        let vtextunit = rgbatextunit + 3;
        gl.activeTexture(gl.TEXTURE0 + ytextunit);
        gl.bindTexture(gl.TEXTURE_2D, _ytexture);
        gl.activeTexture(gl.TEXTURE0 + utextunit);
        gl.bindTexture(gl.TEXTURE_2D, _utexture);
        gl.activeTexture(gl.TEXTURE0 + vtextunit);
        gl.bindTexture(gl.TEXTURE_2D, _vtexture); // Tell WebGL which indices to use to index the vertices

        gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, _buffers.indices); // Tell WebGL to use our program when drawing

        gl.useProgram(_programInfo.program); // Set the shader uniforms

        gl.uniformMatrix4fv(_programInfo.uniformLocations.projectionMatrix, false, projectionMatrix);
        gl.uniformMatrix4fv(_programInfo.uniformLocations.modelMatrix, false, modelMatrix);
        gl.uniformMatrix4fv(_programInfo.uniformLocations.viewMatrix, false, viewMatrix);
        gl.uniform1i(_programInfo.uniformLocations.rgbatexture, rgbatextunit);
        gl.uniform1i(_programInfo.uniformLocations.ytexture, ytextunit);
        gl.uniform1i(_programInfo.uniformLocations.utexture, utextunit);
        gl.uniform1i(_programInfo.uniformLocations.vtexture, vtextunit);
        gl.uniform1i(_programInfo.uniformLocations.isyuv, 1);
        {
          const vertexCount = 6;
          const type = gl.UNSIGNED_SHORT;
          const offset = 0;
          gl.drawElements(gl.TRIANGLES, vertexCount, type, offset);
        } // Update the rotation for the next draw
      }

      return {
        render: function (width, height, y, u, v) {
          gl.activeTexture(gl.TEXTURE0);
          gl.bindTexture(gl.TEXTURE_2D, _ytexture);
          gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, width, height, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, y);
          gl.activeTexture(gl.TEXTURE1);
          gl.bindTexture(gl.TEXTURE_2D, _utexture);
          gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, width / 2, height / 2, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, u);
          gl.activeTexture(gl.TEXTURE2);
          gl.bindTexture(gl.TEXTURE_2D, _vtexture);
          gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, width / 2, height / 2, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, v);

          _drawScene(width, height);
        },
        renderYUV: function (width, height, data) {
          let y = data.slice(0, width * height);
          let u = data.slice(width * height, width * height * 5 / 4);
          let v = data.slice(width * height * 5 / 4, width * height * 3 / 2);
          gl.activeTexture(gl.TEXTURE0);
          gl.bindTexture(gl.TEXTURE_2D, _ytexture);
          gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, width, height, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, y);
          gl.activeTexture(gl.TEXTURE1);
          gl.bindTexture(gl.TEXTURE_2D, _utexture);
          gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, width / 2, height / 2, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, u);
          gl.activeTexture(gl.TEXTURE2);
          gl.bindTexture(gl.TEXTURE_2D, _vtexture);
          gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, width / 2, height / 2, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, v);

          _drawScene(width, height);
        },
        destroy: function () {
          gl.deleteProgram(_programInfo.program);
          gl.deleteBuffer(_buffers.position);
          gl.deleteBuffer(_buffers.texPosition);
          gl.deleteBuffer(_buffers.indices);
          gl.deleteTexture(_rgbatexture);
          gl.deleteTexture(_ytexture);
          gl.deleteTexture(_utexture);
          gl.deleteTexture(_vtexture);
        }
      };
    });

    class CommonLoader$2 extends Emitter {
      constructor() {
        super();
        this.videoInfo = {
          width: null,
          height: null,
          encType: null
        };
        this.init = false;
      }

      resetInit() {
        this.videoInfo = {
          width: null,
          height: null,
          encType: null
        };
        this.init = false;
      }

      destroy() {
        this.resetInit();
      }

      updateVideoInfo(data) {
        if (isNotEmpty(data.encTypeCode)) {
          this.videoInfo.encType = VIDEO_ENC_TYPE[data.encTypeCode];
        }

        if (isNotEmpty(data.encType)) {
          this.videoInfo.encType = data.encType;
        }

        if (isNotEmpty(data.width)) {
          this.videoInfo.width = data.width;
        }

        if (isNotEmpty(data.height)) {
          this.videoInfo.height = data.height;
        } // video 基本信息


        if (isNotEmpty(this.videoInfo.encType) && isNotEmpty(this.videoInfo.height) && isNotEmpty(this.videoInfo.width) && !this.init) {
          this.player.emit(EVENTS.videoInfo, this.videoInfo);
          this.init = true;
        }
      }

      clearView() {}

      play() {}

      pause() {}

      getType() {}

    }

    /*
    * FileSaver.js
    * A saveAs() FileSaver implementation.
    *
    * By Eli Grey, http://eligrey.com
    *
    * License : https://github.com/eligrey/FileSaver.js/blob/master/LICENSE.md (MIT)
    * source  : http://purl.eligrey.com/github/FileSaver.js
    */
    // The one and only way of getting global scope in all environments
    // https://stackoverflow.com/q/3277182/1008999
    var _global = typeof window === 'object' && window.window === window ? window : typeof self === 'object' && self.self === self ? self : typeof global === 'object' && global.global === global ? global : undefined;

    function bom(blob, opts) {
      if (typeof opts === 'undefined') opts = {
        autoBom: false
      };else if (typeof opts !== 'object') {
        console.warn('Deprecated: Expected third argument to be a object');
        opts = {
          autoBom: !opts
        };
      } // prepend BOM for UTF-8 XML and text/* types (including HTML)
      // note: your browser will automatically convert UTF-16 U+FEFF to EF BB BF

      if (opts.autoBom && /^\s*(?:text\/\S*|application\/xml|\S*\/\S*\+xml)\s*;.*charset\s*=\s*utf-8/i.test(blob.type)) {
        return new Blob([String.fromCharCode(0xFEFF), blob], {
          type: blob.type
        });
      }

      return blob;
    }

    function download(url, name, opts) {
      var xhr = new XMLHttpRequest();
      xhr.open('GET', url);
      xhr.responseType = 'blob';

      xhr.onload = function () {
        saveAs(xhr.response, name, opts);
      };

      xhr.onerror = function () {
        console.error('could not download file');
      };

      xhr.send();
    }

    function corsEnabled(url) {
      var xhr = new XMLHttpRequest(); // use sync to avoid popup blocker

      xhr.open('HEAD', url, false);

      try {
        xhr.send();
      } catch (e) {}

      return xhr.status >= 200 && xhr.status <= 299;
    } // `a.click()` doesn't work for all browsers (#465)


    function click(node) {
      try {
        node.dispatchEvent(new MouseEvent('click'));
      } catch (e) {
        var evt = document.createEvent('MouseEvents');
        evt.initMouseEvent('click', true, true, window, 0, 0, 0, 80, 20, false, false, false, false, 0, null);
        node.dispatchEvent(evt);
      }
    } // Detect WebView inside a native macOS app by ruling out all browsers
    // We just need to check for 'Safari' because all other browsers (besides Firefox) include that too
    // https://www.whatismybrowser.com/guides/the-latest-user-agent/macos


    var isMacOSWebView = _global.navigator && /Macintosh/.test(navigator.userAgent) && /AppleWebKit/.test(navigator.userAgent) && !/Safari/.test(navigator.userAgent);
    var saveAs = // probably in some web worker
    typeof window !== 'object' || window !== _global ? function saveAs() {
      /* noop */
    } // Use download attribute first if possible (#193 Lumia mobile) unless this is a macOS WebView
    : 'download' in HTMLAnchorElement.prototype && !isMacOSWebView ? function saveAs(blob, name, opts) {
      var URL = _global.URL || _global.webkitURL; // Namespace is used to prevent conflict w/ Chrome Poper Blocker extension (Issue #561)

      var a = document.createElementNS('http://www.w3.org/1999/xhtml', 'a');
      name = name || blob.name || 'download';
      a.download = name;
      a.rel = 'noopener'; // tabnabbing
      // TODO: detect chrome extensions & packaged apps
      // a.target = '_blank'

      if (typeof blob === 'string') {
        // Support regular links
        a.href = blob;

        if (a.origin !== location.origin) {
          corsEnabled(a.href) ? download(blob, name, opts) : click(a, a.target = '_blank');
        } else {
          click(a);
        }
      } else {
        // Support blobs
        a.href = URL.createObjectURL(blob);
        setTimeout(function () {
          URL.revokeObjectURL(a.href);
        }, 4E4); // 40s

        setTimeout(function () {
          click(a);
        }, 0);
      }
    } // Use msSaveOrOpenBlob as a second approach
    : 'msSaveOrOpenBlob' in navigator ? function saveAs(blob, name, opts) {
      name = name || blob.name || 'download';

      if (typeof blob === 'string') {
        if (corsEnabled(blob)) {
          download(blob, name, opts);
        } else {
          var a = document.createElement('a');
          a.href = blob;
          a.target = '_blank';
          setTimeout(function () {
            click(a);
          });
        }
      } else {
        navigator.msSaveOrOpenBlob(bom(blob, opts), name);
      }
    } // Fallback to using FileReader and a popup
    : function saveAs(blob, name, opts, popup) {
      // Open a popup immediately do go around popup blocker
      // Mostly only available on user interaction and the fileReader is async so...
      popup = popup || open('', '_blank');

      if (popup) {
        popup.document.title = popup.document.body.innerText = 'downloading...';
      }

      if (typeof blob === 'string') return download(blob, name, opts);
      var force = blob.type === 'application/octet-stream';

      var isSafari = /constructor/i.test(_global.HTMLElement) || _global.safari;

      var isChromeIOS = /CriOS\/[\d]+/.test(navigator.userAgent);

      if ((isChromeIOS || force && isSafari || isMacOSWebView) && typeof FileReader !== 'undefined') {
        // Safari doesn't allow downloading of blob URLs
        var reader = new FileReader();

        reader.onloadend = function () {
          var url = reader.result;
          url = isChromeIOS ? url : url.replace(/^data:[^;]*;/, 'data:attachment/file;');
          if (popup) popup.location.href = url;else location = url;
          popup = null; // reverse-tabnabbing #460
        };

        reader.readAsDataURL(blob);
      } else {
        var URL = _global.URL || _global.webkitURL;
        var url = URL.createObjectURL(blob);
        if (popup) popup.location = url;else location.href = url;
        popup = null; // reverse-tabnabbing #460

        setTimeout(function () {
          URL.revokeObjectURL(url);
        }, 4E4); // 40s
      }
    };

    class CommonCanvasLoader extends CommonLoader$2 {
      constructor(player) {
        super();
        this.player = player;
        const $canvasElement = document.createElement("canvas");
        $canvasElement.style.position = "absolute";
        $canvasElement.style.top = 0;
        $canvasElement.style.left = 0;
        this.$videoElement = $canvasElement;
        player.$container.appendChild(this.$videoElement);
        this.context2D = null;
        this.contextGl = null;
        this.contextGlRender = null;
        this.contextGlDestroy = null;
        this.bitmaprenderer = null;
        this.renderType = null;
        this.controlHeight = 0; //

        this._initCanvasRender();
      }

      destroy() {
        super.destroy();

        if (this.contextGl) {
          this.contextGl = null;
        }

        if (this.context2D) {
          this.context2D = null;
        }

        if (this.contextGlRender) {
          this.contextGlDestroy && this.contextGlDestroy();
          this.contextGlDestroy = null;
          this.contextGlRender = null;
        }

        if (this.bitmaprenderer) {
          this.bitmaprenderer = null;
        }

        this.renderType = null;
        this.videoInfo = {
          width: '',
          height: '',
          encType: '',
          encTypeCode: ''
        };
        this.player.$container.removeChild(this.$videoElement);
        this.init = false;
        this.off();
      }

      _initContextGl() {
        this.contextGl = createContextGL(this.$videoElement);
        const webgl = createWebGL(this.contextGl, this.player._opt.openWebglAlignment); // this.contextGlRender = webgl.render;

        this.contextGlRender = webgl.renderYUV;
        this.contextGlDestroy = webgl.destroy;
      }

      initCanvasViewSize() {
        this.$videoElement.width = this.videoInfo.width;
        this.$videoElement.height = this.videoInfo.height;
        this.resize();
      }

      screenshot(filename, format, quality, type) {
        filename = filename || now$1();
        type = type || SCREENSHOT_TYPE.download;
        let encoderOptions = 0.92;

        if (!SCREENSHOT_FORMAT_TYPE[format] && SCREENSHOT_TYPE[format]) {
          type = format;
          format = 'png';
          quality = undefined;
        }

        if (typeof quality === "string") {
          type = quality;
          quality = undefined;
        }

        if (typeof quality !== 'undefined') {
          encoderOptions = Number(quality);
        }

        const dataURL = this.$videoElement.toDataURL(SCREENSHOT_FORMAT_TYPE[format] || SCREENSHOT_FORMAT_TYPE.png, encoderOptions);
        const file = dataURLToFile(dataURL);

        if (type === SCREENSHOT_TYPE.base64) {
          return dataURL;
        } else if (type === SCREENSHOT_TYPE.blob) {
          return file;
        } else if (type === SCREENSHOT_TYPE.download) {
          // downloadImg(file, filename);
          saveAs(file, filename);
        }
      }

      screenshotWatermark(options) {
        return new Promise((resolve, reject) => {
          if (isString(options)) {
            options = {
              filename: options
            };
          }

          options = options || {};
          options.width = this.videoInfo.width;
          options.height = this.videoInfo.height;
          options.filename = options.filename || now$1();
          options.format = options.format ? SCREENSHOT_FORMAT_TYPE[options.format] : SCREENSHOT_FORMAT_TYPE.png;
          options.quality = Number(options.quality) || 0.92;
          options.type = options.type || SCREENSHOT_TYPE.download;
          const dataURL = this.$videoElement.toDataURL(options.format, options.quality);
          createImageWatermark(dataURL, options).then(dataURL2 => {
            const file = dataURLToFile(dataURL2);

            if (options.type === SCREENSHOT_TYPE.base64) {
              resolve(dataURL);
            } else if (options.type === SCREENSHOT_TYPE.blob) {
              resolve(file);
            } else if (options.type === SCREENSHOT_TYPE.download) {
              resolve(); // downloadImg(file, options.filename);

              saveAs(file, options.filename);
            }
          }).catch(e => {
            reject(e);
          });
        });
      } //


      render() {}

      clearView() {}

      play() {}

      pause() {}

      resize() {
        this.player.debug.log('canvasVideo', 'resize');
        const option = this.player._opt;
        let width = this.player.width;
        let height = this.player.height;

        if (option.hasControl && !option.controlAutoHide) {
          const controlHeight = this.controlHeight;

          if (isMobile() && this.player.fullscreen) {
            width -= controlHeight;
          } else {
            height -= controlHeight;
          }
        }

        let resizeWidth = this.$videoElement.width;
        let resizeHeight = this.$videoElement.height;
        const rotate = option.rotate;
        let left = (width - resizeWidth) / 2;
        let top = (height - resizeHeight) / 2;

        if (rotate === 270 || rotate === 90) {
          resizeWidth = this.$videoElement.height;
          resizeHeight = this.$videoElement.width;
        }

        const wScale = width / resizeWidth;
        const hScale = height / resizeHeight;
        let scale = wScale > hScale ? hScale : wScale; //

        if (!option.isResize) {
          if (wScale !== hScale) {
            scale = wScale + ',' + hScale;
          }
        } //


        if (option.isFullResize) {
          scale = wScale > hScale ? wScale : hScale;
        }

        let transform = "scale(" + scale + ")";

        if (option.mirrorRotate === 'none') {
          if (rotate) {
            transform += ' rotate(' + rotate + 'deg)';
          }
        }

        if (option.mirrorRotate === 'level') {
          transform += ' rotateY(180deg)'; // 水平镜像翻转
        } else if (option.mirrorRotate === 'vertical') {
          transform += ' rotateX(180deg)'; // 垂直镜像翻转
        }

        this.$videoElement.style.transform = transform;
        this.$videoElement.style.left = left + "px";
        this.$videoElement.style.top = top + "px";
      }

      initFps() {}

      setStreamFps() {}

      getStreamFps() {
        return 25;
      }

      getType() {
        return RENDER_TYPE.canvas;
      }

    }

    class CanvasVideoLoader extends CommonCanvasLoader {
      constructor(player) {
        super(player);
        this.yuvList = [];
        this.controlHeight = CONTROL_HEIGHT;
        this.player.debug.log('CanvasVideo', 'init');
      }

      destroy() {
        super.destroy();
        this.yuvList = [];
        this.player.debug.log(`CanvasVideoLoader`, 'destroy');
      }

      _initContext2D() {
        let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
        this.context2D = this.$videoElement.getContext('2d', options);
      } // 渲染类型


      _initCanvasRender() {
        if (this.player._opt.useWCS && !this._supportOffscreen()) {
          this.renderType = CANVAS_RENDER_TYPE.webcodecs; // {alpha: false}

          this._initContext2D();
        } else if (this.player._opt.useMSE && this.player._opt.mseUseCanvasRender) {
          this.renderType = CANVAS_RENDER_TYPE.mse;

          this._initContext2D();
        } else if (this.player._opt.isHls && this.player._opt.useCanvasRender) {
          this.renderType = CANVAS_RENDER_TYPE.hls;

          this._initContext2D();
        } else if (this._supportOffscreen()) {
          this.renderType = CANVAS_RENDER_TYPE.offscreen;

          this._bindOffscreen();
        } else {
          this.renderType = CANVAS_RENDER_TYPE.webgl;

          this._initContextGl();
        }
      }

      _supportOffscreen() {
        return supportOffscreen(this.$videoElement) && this.player._opt.useOffscreen;
      } //


      _bindOffscreen() {
        this.bitmaprenderer = this.$videoElement.getContext('bitmaprenderer');
      }

      render(msg) {
        this.yuvList.push(msg);
        this.startRender();
      }

      startRender() {
        while (true) {
          if (this.yuvList.length <= 0) {
            break;
          }

          const yuv = this.yuvList.shift();
          this.doRender(yuv);
        }
      } //


      doRender(msg) {
        this.player.videoTimestamp = msg.ts || 0;
        this.player.updateStats({
          fps: true,
          ts: msg.ts || 0
        });

        switch (this.renderType) {
          case CANVAS_RENDER_TYPE.offscreen:
            this.bitmaprenderer.transferFromImageBitmap(msg.buffer);
            break;

          case CANVAS_RENDER_TYPE.webgl:
            let yuvData = msg.output;

            if (this.player.faceDetectActive && this.player.ai && this.player.ai.faceDetector) {
              yuvData = this.player.ai.faceDetector.detect({
                width: this.$videoElement.width,
                height: this.$videoElement.height,
                data: msg.output
              });
            }

            this.contextGlRender(this.$videoElement.width, this.$videoElement.height, yuvData);
            break;

          case CANVAS_RENDER_TYPE.webcodecs:
            if (isFunction$1(msg.videoFrame.createImageBitmap)) {
              try {
                msg.videoFrame.createImageBitmap().then(image => {
                  this.context2D.drawImage(image, 0, 0, this.$videoElement.width, this.$videoElement.height);
                  closeVideoFrame(msg.videoFrame);
                });
              } catch (e) {}
            } else {
              this.context2D.drawImage(msg.videoFrame, 0, 0, this.$videoElement.width, this.$videoElement.height);
              closeVideoFrame(msg.videoFrame);
            }

            break;

          case CANVAS_RENDER_TYPE.mse:
            // console.log(msg.$video);
            this.context2D.drawImage(msg.$video, 0, 0, this.$videoElement.width, this.$videoElement.height);
            break;

          case CANVAS_RENDER_TYPE.hls:
            // console.log(msg.$video);
            this.context2D.drawImage(msg.$video, 0, 0, this.$videoElement.width, this.$videoElement.height);
            break;
        }
      } //


      clearView() {
        switch (this.renderType) {
          case CANVAS_RENDER_TYPE.offscreen:
            createEmptyImageBitmap(this.$videoElement.width, this.$videoElement.height).then(imageBitMap => {
              this.bitmaprenderer.transferFromImageBitmap(imageBitMap);
            });
            break;

          case CANVAS_RENDER_TYPE.webgl:
            this.contextGl.clear(this.contextGl.COLOR_BUFFER_BIT);
            break;

          case CANVAS_RENDER_TYPE.webcodecs:
            this.context2D.clearRect(0, 0, this.$videoElement.width, this.$videoElement.height);
            break;

          case CANVAS_RENDER_TYPE.mse:
            this.context2D.clearRect(0, 0, this.$videoElement.width, this.$videoElement.height);
            break;

          case CANVAS_RENDER_TYPE.hls:
            this.context2D.clearRect(0, 0, this.$videoElement.width, this.$videoElement.height);
            break;
        }
      }

    }

    class VideoLoader extends CommonLoader$2 {
      constructor(player) {
        super();
        this.player = player;
        const $videoElement = document.createElement('video');
        $videoElement.muted = true;
        $videoElement.style.position = "absolute";
        $videoElement.style.top = 0;
        $videoElement.style.left = 0;
        this._videoCanPlay = false;
        player.$container.appendChild($videoElement);
        this.$videoElement = $videoElement;
        this.mediaStream = null;

        if (player.canVideoTrackWritter() && supportMediaStreamTrack()) {
          this.trackGenerator = new MediaStreamTrackGenerator({
            kind: 'video'
          });
          this.mediaStream = new MediaStream([this.trackGenerator]);
          $videoElement.srcObject = this.mediaStream;
          this.vwriter = this.trackGenerator.writable.getWriter();
        }

        this.fixChromeVideoFlashBug();
        this.resize();
        this.eventListenList = [];
        const {
          proxy
        } = this.player.events;
        const canplayProxyDestroy = proxy(this.$videoElement, 'canplay', () => {
          this.player.debug.log('Video', 'canplay');
          this._videoCanPlay = true; // this._play();
        });
        const waitingProxyDestroy = proxy(this.$videoElement, 'waiting', () => {
          this._videoCanPlay = false; // this.player.emit(EVENTS.videoWaiting);

          this.player.debug.log('Video', 'waiting');
        });
        const timeupdateProxyDestroy = proxy(this.$videoElement, 'timeupdate', event => {
          // this.player.debug.log('Video', 'timeupdate', event.timeStamp);
          //
          const timeStamp = parseInt(event.timeStamp, 10);

          if (this.player._opt.isWebrtc || this.player._opt.isHls) {
            this.player.emit(EVENTS.timeUpdate, timeStamp);
          } // just for webrtc


          if (player._opt.isWebrtc) {
            player.handleRender();
          }
        });
        const errorProxyDestroy = proxy(this.$videoElement, 'error', () => {
          this.player.debug.log('Video', "Error " + this.$videoElement.error.code + "; details: " + this.$videoElement.error.message);
        });
        this.eventListenList.push(canplayProxyDestroy, waitingProxyDestroy, timeupdateProxyDestroy, errorProxyDestroy);
        this.player.debug.log('Video', 'init');
      }

      destroy() {
        super.destroy();

        if (this.eventListenList) {
          this.eventListenList.forEach(item => {
            item();
          });
          this.eventListenList = [];
        }

        if (this.$videoElement) {
          this.$videoElement.pause();
          this.$videoElement.currentTime = 0;
          this.$videoElement.src = '';
          this.player.$container.removeChild(this.$videoElement);
          this.$videoElement = null;
        }

        if (this.trackGenerator) {
          this.trackGenerator.stop();
          this.trackGenerator = null;
        }

        if (this.vwriter) {
          this.vwriter.close();
          this.vwriter = null;
        }

        this.mediaStream = null;
        this._videoCanPlay = false;
        this.off();
        this.player.debug.log('Video', 'destroy');
      }
      /**
       * 修复chrome系浏览器，在设置video的objectFit属性后，video标签会无缘无故的闪烁，
       * 但是添加了backdropFilter属性之后，就不会闪烁了。
       */


      fixChromeVideoFlashBug() {
        const browser = getBrowser();
        const type = browser.type.toLowerCase();

        if (type === 'chrome' || type === 'edge') {
          const $container = this.player.$container;
          $container.style.backdropFilter = 'blur(0px)';
          $container.style.translateZ = '0';
        }
      }

      isPause() {
        let result = true;

        if (this.$videoElement) {
          result = this.$videoElement.paused;
        }

        return result;
      }

      play() {
        // this.$videoElement && (this.$videoElement.autoplay = true);
        this._play();
      }

      _play() {
        // if (!this._videoCanPlay) {
        //     this.player.debug.warn('Video', 'play _videoCanPlay is false');
        //     return
        // }
        this.$videoElement && this.$videoElement.play().then(() => {
          this.player.debug.log('Video', '_play play');
        }).catch(e => {
          this.player.debug.error('Video', '_play play', e);
        });
      }

      pause(isNow) {
        // 预防
        // https://developer.chrome.com/blog/play-request-was-interrupted/
        // http://alonesuperman.com/?p=23
        if (isNow) {
          this.$videoElement && this.$videoElement.pause();
        } else {
          setTimeout(() => {
            this.$videoElement && this.$videoElement.pause();
          }, 100);
        }
      }

      clearView() {}

      screenshot(filename, format, quality, type) {
        filename = filename || now$1();
        type = type || SCREENSHOT_TYPE.download;
        const formatType = {
          png: 'image/png',
          jpeg: 'image/jpeg',
          webp: 'image/webp'
        };
        let encoderOptions = 0.92;

        if (!formatType[format] && SCREENSHOT_TYPE[format]) {
          type = format;
          format = 'png';
          quality = undefined;
        }

        if (typeof quality === "string") {
          type = quality;
          quality = undefined;
        }

        if (typeof quality !== 'undefined') {
          encoderOptions = Number(quality);
        }

        const $video = this.$videoElement;
        let canvas = document.createElement('canvas');
        canvas.width = $video.videoWidth;
        canvas.height = $video.videoHeight;
        const context = canvas.getContext('2d');
        context.drawImage($video, 0, 0, canvas.width, canvas.height);
        const dataURL = canvas.toDataURL(SCREENSHOT_TYPE[format] || SCREENSHOT_TYPE.png, encoderOptions);
        const file = dataURLToFile(dataURL);

        if (type === SCREENSHOT_TYPE.base64) {
          return dataURL;
        } else if (type === SCREENSHOT_TYPE.blob) {
          return file;
        } else if (type === SCREENSHOT_TYPE.download) {
          // downloadImg(file, filename);
          saveAs(file, filename);
        }
      }

      screenshotWatermark(options) {
        return new Promise((resolve, reject) => {
          if (isString(options)) {
            options = {
              filename: options
            };
          }

          const $video = this.$videoElement;
          options = options || {};
          options.width = $video.videoWidth;
          options.height = $video.videoHeight;
          options.filename = options.filename || now$1();
          options.format = options.format ? SCREENSHOT_FORMAT_TYPE[options.format] : SCREENSHOT_FORMAT_TYPE.png;
          options.quality = Number(options.quality) || 0.92;
          options.type = options.type || SCREENSHOT_TYPE.download;
          let canvas = document.createElement('canvas');
          canvas.width = $video.videoWidth;
          canvas.height = $video.videoHeight;
          const context = canvas.getContext('2d');
          context.drawImage($video, 0, 0, canvas.width, canvas.height);
          const dataURL = canvas.toDataURL(options.format, options.quality);
          createImageWatermark(dataURL, options).then(dataURL2 => {
            const file = dataURLToFile(dataURL2);

            if (options.type === SCREENSHOT_TYPE.base64) {
              resolve(dataURL);
            } else if (options.type === SCREENSHOT_TYPE.blob) {
              resolve(file);
            } else if (options.type === SCREENSHOT_TYPE.download) {
              resolve(); // downloadImg(file, options.filename);

              saveAs(file, options.filename);
            }
          }).catch(e => {
            reject(e);
          });
        });
      }

      initCanvasViewSize() {
        this.resize();
      } //


      render(msg) {
        if (this.vwriter) {
          this.player.videoTimestamp = msg.ts || 0;
          this.player.updateStats({
            fps: true,
            ts: msg.ts || 0
          });

          if (msg.videoFrame) {
            // just for wcs
            this.vwriter.write(msg.videoFrame);
          } else if (msg.output) {
            // just for wasm
            let yuvData = msg.output;

            if (this.player.faceDetectActive && this.player.ai && this.player.ai.faceDetector) {
              yuvData = this.player.ai.faceDetector.detect({
                width: this.videoInfo.width,
                height: this.videoInfo.height,
                data: msg.output
              });
            }

            const videoFrame = createVideoFrame(yuvData, {
              format: 'I420',
              codedWidth: this.videoInfo.width,
              codedHeight: this.videoInfo.height,
              timestamp: msg.ts
            });
            this.vwriter.write(videoFrame);
          }
        } else {
          this.player.debug.warn('Video', 'render and this.vwriter is null');
        }
      }

      resize() {
        let width = this.player.width;
        let height = this.player.height;
        const option = this.player._opt;
        const rotate = option.rotate;

        if (option.hasControl && !option.controlAutoHide) {
          const controlHeight = option.playType === PLAY_TYPE.playbackTF ? CONTROL_PLAYBACK_HEIGHT : CONTROL_HEIGHT;

          if (isMobile() && this.player.fullscreen) {
            width -= controlHeight;
          } else {
            height -= controlHeight;
          }
        }

        this.$videoElement.width = width;
        this.$videoElement.height = height;

        if (rotate === 270 || rotate === 90) {
          this.$videoElement.width = height;
          this.$videoElement.height = width;
        }

        let resizeWidth = this.$videoElement.width;
        let resizeHeight = this.$videoElement.height;
        let left = (width - resizeWidth) / 2;
        let top = (height - resizeHeight) / 2;
        let objectFill = 'contain'; // 默认是true
        // 视频画面做等比缩放后,高或宽对齐canvas区域,画面不被拉伸,但有黑边
        // 视频画面完全填充canvas区域,画面会被拉伸

        if (!option.isResize) {
          objectFill = 'fill';
        } // 视频画面做等比缩放后,完全填充canvas区域,画面不被拉伸,没有黑边,但画面显示不全


        if (option.isFullResize) {
          objectFill = 'none';
        }

        let transform = '';

        if (option.mirrorRotate === 'none') {
          if (rotate) {
            transform += ' rotate(' + rotate + 'deg)';
          }
        }

        if (option.mirrorRotate === 'level') {
          transform += ' rotateY(180deg)'; // 水平镜像翻转
        } else if (option.mirrorRotate === 'vertical') {
          transform += ' rotateX(180deg)'; // 垂直镜像翻转
        }

        this.$videoElement.style.objectFit = objectFill;
        this.$videoElement.style.transform = transform;
        this.$videoElement.style.left = left + "px";
        this.$videoElement.style.top = top + "px";
      }

      getType() {
        return RENDER_TYPE.video;
      }

    }

    class CanvasPlaybackLoader extends CommonCanvasLoader {
      constructor(player) {
        super(player);
        this.controlHeight = CONTROL_PLAYBACK_HEIGHT; // yuvlist

        this.bufferList = []; //

        this.playing = false; //

        this.playInterval = null; //

        this.fps = 1; //

        this.preFps = 1;
        this.streamFps = 0; //

        this.playbackRate = 1; //

        this._firstTimestamp = null; //

        this._renderFps = 0; //

        this._startfpsTime = null; //

        this._startFpsTimestamp = null;
        this._hasCalcFps = false;
        this.player.on(EVENTS.playbackPause, flag => {
          if (flag) {
            this.pause();
            this.clear();
          } else {
            this.resume();
          }
        });
        this.player.debug.log(`CanvasPlaybackLoader`, 'init');
      }

      destroy() {
        this._stopSync();

        this._firstTimestamp = null;
        this.playing = false;
        this.playbackRate = 1;
        this.fps = 1;
        this.preFps = 1;
        this.bufferList = [];
        this._renderFps = 0;
        this._startfpsTime = null;
        this._startFpsTimestamp = null;
        this._hasCalcFps = false;
        super.destroy();
        this.player.debug.log(`CanvasPlaybackLoader`, 'destroy');
      }

      _initCanvasRender() {
        this.renderType = CANVAS_RENDER_TYPE.webgl;

        this._initContextGl();
      }

      _sync() {
        this._stopSync(); // 第一帧


        this._doPlay();

        this.playInterval = setInterval(() => {
          // 后续帧。
          this._doPlay();
        }, this.fragDuration);
      }

      _doPlay() {
        if (this.bufferList.length > 0 && !this.player.seeking) {
          const bufferData = this.bufferList.shift();

          if (bufferData && bufferData.buffer) {
            this._doRender(bufferData.buffer);

            this.player.handleRender(); // this._updateStats(bufferData.ts);

            this.player.playback.updateStats({
              ts: bufferData.ts
            });
          }
        }
      }

      _stopSync() {
        if (this.playInterval) {
          clearInterval(this.playInterval);
          this.playInterval = null;
        }
      } // render method


      _doRender(buffer) {
        this.contextGlRender(this.$videoElement.width, this.$videoElement.height, buffer);
      }

      _updateStats(ts) {
        //
        this.player.updateStats({
          fps: true,
          ts
        });

        if (!this._startfpsTime) {
          this._startfpsTime = ts;
          this._startFpsTimestamp = now$1();
        }

        const _now = ts;
        const dataTimestamp = now$1();
        const timestamp = dataTimestamp - this._startFpsTimestamp; // update fps

        if (timestamp <= 1 * 1000) {
          this._renderFps += 1;
          return;
        }

        this.player.emit(EVENTS.playbackStats, {
          fps: this._renderFps,
          start: this._startfpsTime,
          end: _now,
          timestamp: timestamp,
          dataTimestamp: _now - this._startfpsTime,
          audioBufferSize: this.player.audio ? this.player.audio.bufferSize : 0,
          videoBufferSize: this.player.video ? this.player.video.bufferSize : 0,
          ts
        });
        this._renderFps = 0;
        this._startfpsTime = _now;
        this._startFpsTimestamp = dataTimestamp;
      }

      get rate() {
        return this.playbackRate;
      }

      get fragDuration() {
        return Math.ceil(1000 / (this.fps * this.playbackRate));
      }

      get bufferSize() {
        return this.bufferList.length;
      }

      getStreamFps() {
        return this.streamFps;
      }

      initFps() {
        this.preFps = clamp(this.player.playback.fps, 1, 100);
        this.fps = this.preFps;
      }

      setFps(value) {
        if (value !== this.fps) {
          // 如果fps 超过了，则需要
          if (value > 100) {
            this.player.debug.warn('CanvasPlaybackLoader', 'setFps max', value);
          }

          if (value < 0) {
            this.player.debug.warn('CanvasPlaybackLoader', 'setFps min', value);
          }

          this.fps = clamp(value, 1, 100);

          if (this.player.playback.isUseFpsRender) {
            this._sync();
          }
        }
      }

      setStreamFps(fps) {
        this.player.debug.log(`CanvasPlaybackLoader`, 'setStreamFps', fps);
        this._hasCalcFps = true;
        this.streamFps = fps;
        this.preFps = fps;
        this.fps = fps;
      }

      setRate(value) {
        if (value !== this.playbackRate) {
          // this.player.debug.log(`CanvasPlaybackLoader`, 'setRate', value);
          this.playbackRate = value;

          if (this.player.playback.isUseFpsRender) {
            this._sync();
          }
        }
      }

      render$2(msg) {
        if (this._firstTimestamp === null) {
          this._firstTimestamp = msg.ts;
        }

        const data = {
          ts: msg.ts - this._firstTimestamp,
          buffer: msg.output // yuv 数据

        };
        this.bufferList.push(data);
        this.startRender();
        this.player.handleRender(); // this._updateStats(msg.ts);

        this.player.playback.updateStats({
          ts: msg.ts
        });
      }

      startRender() {
        while (true) {
          if (this.bufferList.length <= 0) {
            break;
          }

          const yuv = this.bufferList.shift();

          this._doRender(yuv.buffer);
        }
      }

      pushData(msg) {
        if (this._firstTimestamp === null) {
          this._firstTimestamp = msg.ts;
        }

        const data = {
          ts: msg.ts - this._firstTimestamp,
          buffer: msg.output // yuv 数据

        };
        const isCacheBeforeDecodeForFpsRender = this.player._opt.playbackConfig.isCacheBeforeDecodeForFpsRender;

        if (!isCacheBeforeDecodeForFpsRender) {
          // 如果缓冲数据超过 2s 直接加速播放掉。
          if (this.bufferSize > this.fps * this.playbackRate * 2) {
            this.player.debug.warn('CanvasPlaybackLoader', `buffer size is ${this.bufferSize}`);

            this._doPlay();
          }
        }

        this.bufferList.push(data);

        if (!this._hasCalcFps) {
          const streamFps = calcStreamFpsByBufferList(this.bufferList);
          console.error('CanvasPlaybackLoader streamFps', streamFps);

          if (streamFps !== null) {
            if (streamFps !== this.preFps) {
              this.player.debug.log('CanvasPlaybackLoader', `calc fps is ${streamFps} pre fps is ${this.preFps} and updatePreFps`);
              this.setStreamFps(streamFps);
            }
          }
        }

        if (!isCacheBeforeDecodeForFpsRender) {
          // this.player.debug.log(`CanvasPlaybackLoader`, 'pushData', this.bufferSize);
          // if buffer length
          const bufferListLength = this.bufferList.length;
          const fps = this.fps * this.playbackRate;
          const rate = bufferListLength / fps;
          this.player.debug.log(`CanvasPlaybackLoader`, 'rate is', rate);

          if (rate <= 1) {
            this.setFps(this.preFps);
          } else {
            this.setFps(this.fps + Math.floor(rate * this.playbackRate));
            this.player.debug.warn('CanvasPlaybackLoader', 'rate is', rate, 'fps is', this.fps, 'bufferListLength is', bufferListLength);
          }
        }
      }

      initVideo() {
        if (this.player.playback.isUseFpsRender) {
          this._sync();
        }

        this.playing = true;
      }

      initVideoDelay() {
        const delayTime = this.player._opt.playbackDelayTime;

        if (delayTime > 0) {
          this.delayTimeout = setTimeout(() => {
            this.initVideo(); // console.error('initVideoDelay , bufferList length', this.bufferList.length);
          }, delayTime);
        } else {
          this.initVideo();
        }
      }

      clearView() {
        this.contextGl.clear(this.contextGl.COLOR_BUFFER_BIT);
      }

      clear() {
        this.bufferList = [];
      }

      resume() {
        if (this.player.playback.isUseFpsRender) {
          this._sync();
        }

        this.playing = true;
      }

      pause() {
        if (this.player.playback.isUseFpsRender) {
          this._stopSync();
        }

        this.playing = false;
      }

    }

    class Video {
      constructor(player) {
        const Loader = Video.getLoaderFactory(player._opt);
        return new Loader(player);
      }

      static getLoaderFactory(opt) {
        if (opt.useMSE) {
          if (opt.mseUseCanvasRender) {
            return CanvasVideoLoader;
          } else {
            return VideoLoader;
          }
        } else if (opt.isHls) {
          if (opt.useCanvasRender) {
            return CanvasVideoLoader;
          } else {
            return VideoLoader;
          }
        } else if (opt.isWebrtc) {
          return VideoLoader;
        } else if (opt.useWCS) {
          if (!opt.useOffscreen && opt.wcsUseVideoRender) {
            return VideoLoader;
          } else {
            return CanvasVideoLoader;
          }
        } else {
          if (opt.playType === PLAY_TYPE.playbackTF) {
            return CanvasPlaybackLoader;
          } else {
            if (opt.wasmUseVideoRender && !opt.useOffscreen) {
              return VideoLoader;
            } else {
              return CanvasVideoLoader;
            }
          }
        }
      }

    }

    class CommonContextLoader extends Emitter {
      constructor(player) {
        super();
        this.bufferList = [];
        this.player = player;
        this.scriptNode = null;
        this.workletProcessorNode = null;
        this.hasInitScriptNode = false;
        this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
          sampleRate: 48000
        }); //

        this.gainNode = this.audioContext.createGain(); // Get an AudioBufferSourceNode.
        // This is the AudioNode to use when we want to play an AudioBuffer

        const source = this.audioContext.createBufferSource(); // set the buffer in the AudioBufferSourceNode

        source.buffer = this.audioContext.createBuffer(1, 1, 22050); // connect the AudioBufferSourceNode to the
        // destination so we can hear the sound

        source.connect(this.audioContext.destination); // noteOn as start
        // start the source playing

        if (source.noteOn) {
          source.noteOn(0);
        } else {
          source.start(0);
        }

        this.audioBufferSourceNode = source; //

        this.mediaStreamAudioDestinationNode = this.audioContext.createMediaStreamDestination(); //

        this.audioEnabled(true); // default setting 0

        this.gainNode.gain.value = 0;
        this.playing = false; //

        this.audioSyncVideoOption = {
          diff: null
        };
        this.audioInfo = {
          encType: '',
          channels: '',
          sampleRate: ''
        };
        this.init = false;
        this.hasAudio = false; // update

        this.on(EVENTS.videoSyncAudio, options => {
          // this.player.debug.log('AudioContext', `videoSyncAudio , audioTimestamp: ${options.audioTimestamp},videoTimestamp: ${options.videoTimestamp},diff:${options.diff}`)
          this.audioSyncVideoOption = options;
        });
      }

      resetInit() {
        this.audioInfo = {
          encType: '',
          channels: '',
          sampleRate: ''
        };
        this.init = false;
      }

      destroy() {
        this.closeAudio();
        this.resetInit();
        this.audioContext.close();
        this.audioContext = null;
        this.gainNode = null;
        this.hasAudio = false;
        this.playing = false;

        if (this.scriptNode) {
          this.scriptNode.onaudioprocess = noop$2;
          this.scriptNode = null;
        }

        if (this.workletProcessorNode) {
          this.workletProcessorNode.port.onmessage = noop$2;
          this.workletProcessorNode = null;
        }

        this.audioBufferSourceNode = null;
        this.mediaStreamAudioDestinationNode = null;
        this.hasInitScriptNode = false;
        this.audioSyncVideoOption = {
          diff: null
        };
        this.off();
      }

      updateAudioInfo(data) {
        if (data.encTypeCode) {
          this.audioInfo.encType = AUDIO_ENC_TYPE[data.encTypeCode];
        }

        if (data.channels) {
          this.audioInfo.channels = data.channels;
        }

        if (data.sampleRate) {
          this.audioInfo.sampleRate = data.sampleRate;
        } // audio 基本信息


        if (this.audioInfo.sampleRate && this.audioInfo.channels && this.audioInfo.encType && !this.init) {
          this.player.emit(EVENTS.audioInfo, this.audioInfo);
          this.init = true;
        }
      } //


      get isPlaying() {
        return this.playing;
      }

      get isMute() {
        return this.gainNode.gain.value === 0;
      }

      get volume() {
        return this.gainNode.gain.value;
      }

      get bufferSize() {
        return this.bufferList.length;
      }

      initScriptNode() {}

      initMobileScriptNode() {}

      initWorkletScriptNode() {}

      getEngineType() {
        return '';
      }

      mute(flag) {
        if (flag) {
          if (!this.isMute) {
            this.player.emit(EVENTS.mute, flag);
          } // this.audioEnabled(false);


          this.setVolume(0);
          this.clear();
        } else {
          if (this.isMute) {
            this.player.emit(EVENTS.mute, flag);
          }

          this.audioEnabled(true);
          this.setVolume(0.5);
        }
      }

      setVolume(volume) {
        volume = parseFloat(volume).toFixed(2);

        if (isNaN(volume)) {
          return;
        }

        this.audioEnabled(true);
        volume = clamp(volume, 0, 1);
        this.gainNode.gain.value = volume; // this.gainNode.gain.setValueAtTime(volume, this.audioContext.currentTime);

        this.player.emit(EVENTS.volumechange, this.player.volume);
      }

      closeAudio() {
        if (this.hasInitScriptNode) {
          this.scriptNode && this.scriptNode.disconnect(this.gainNode);
          this.workletProcessorNode && this.workletProcessorNode.disconnect(this.gainNode);
          this.gainNode && this.gainNode.disconnect(this.audioContext.destination);
          this.gainNode && this.gainNode.disconnect(this.mediaStreamAudioDestinationNode);
        }

        this.clear();
      } // 是否播放。。。


      audioEnabled(flag) {
        if (flag) {
          if (this.isStateSuspended()) {
            // resume
            this.audioContext.resume();
          }
        } else {
          if (this.isStateRunning()) {
            // suspend
            this.audioContext.suspend();
          }
        }
      }

      isStateRunning() {
        return this.audioContext.state === 'running';
      }

      isStateSuspended() {
        return this.audioContext.state === 'suspended';
      }

      clear() {
        this.bufferList = [];
      }

      play(buffer, ts) {// empty
      }

      pause() {
        this.audioSyncVideoOption = {
          diff: null
        };
        this.playing = false;
        this.clear();
      }

      resume() {
        this.playing = true;
      }

      setRate(value) {// empty
      }

      getAudioBufferSize() {
        return 0;
      }

    }

    class Processor {
      constructor(player, audio, buffer, channel, bufferSize) {
        this.player = player;
        this.audio = audio;
        this.buffer = buffer;
        this.channel = channel;
        this.bufferSize = bufferSize;
      } //


      extract(target, numFrames) {
        let data = this.provide(numFrames);

        for (let i = 0; i < data.size; i++) {
          target[i * 2] = data.left[i];
          target[i * 2 + 1] = data.right[i];
        }

        this.audio.tempAudioTimestamp = data.ts;
        return data.size;
      }

      provide(sourceSize) {
        let left = new Float32Array(sourceSize);
        let right = new Float32Array(sourceSize);
        let size = 0;
        let ts = 0;
        let sourcePosition = 0;
        let num = sourceSize / this.bufferSize;

        if (this.buffer.length > num) {
          for (let i = 0; i < num; i++) {
            const bufferItem = this.buffer.shift();

            if (this.channel === 2) {
              left.set(bufferItem.buffer[0], sourcePosition);
              right.set(bufferItem.buffer[1], sourcePosition);
            } else {
              left.set(bufferItem.buffer[0], sourcePosition);
              right.set(bufferItem.buffer[0], sourcePosition);
            }

            sourcePosition += this.bufferSize;
            ts = bufferItem.ts;
          }

          size = left.length;
        }

        return {
          size,
          ts,
          left,
          right
        };
      }

      destroy() {
        this.buffer = null;
        this.channel = null;
      }

    }

    /**
     * sound rate
     */
    class FifoSampleBuffer {
      constructor() {
        this._vector = new Float32Array();
        this._position = 0;
        this._frameCount = 0;
      }

      get vector() {
        return this._vector;
      }

      get position() {
        return this._position;
      }

      get startIndex() {
        return this._position * 2;
      }

      get frameCount() {
        return this._frameCount;
      }

      get endIndex() {
        return (this._position + this._frameCount) * 2;
      }

      clear() {
        this.receive(this._frameCount);
        this.rewind();
      }

      put(numFrames) {
        this._frameCount += numFrames;
      }

      putSamples(samples, position) {
        let numFrames = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
        position = position || 0;
        const sourceOffset = position * 2;

        if (!(numFrames >= 0)) {
          numFrames = (samples.length - sourceOffset) / 2;
        }

        const numSamples = numFrames * 2;
        this.ensureCapacity(numFrames + this._frameCount);
        const destOffset = this.endIndex;
        this.vector.set(samples.subarray(sourceOffset, sourceOffset + numSamples), destOffset);
        this._frameCount += numFrames;
      }

      putBuffer(buffer, position) {
        let numFrames = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
        position = position || 0;

        if (!(numFrames >= 0)) {
          numFrames = buffer.frameCount - position;
        }

        this.putSamples(buffer.vector, buffer.position + position, numFrames);
      }

      receive(numFrames) {
        if (!(numFrames >= 0) || numFrames > this._frameCount) {
          numFrames = this.frameCount;
        }

        this._frameCount -= numFrames;
        this._position += numFrames;
      }

      receiveSamples(output) {
        let numFrames = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
        const numSamples = numFrames * 2;
        const sourceOffset = this.startIndex;
        output.set(this._vector.subarray(sourceOffset, sourceOffset + numSamples));
        this.receive(numFrames);
      }

      extract(output) {
        let position = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
        let numFrames = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
        const sourceOffset = this.startIndex + position * 2;
        const numSamples = numFrames * 2;
        output.set(this._vector.subarray(sourceOffset, sourceOffset + numSamples));
      }

      ensureCapacity() {
        let numFrames = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;
        const minLength = parseInt(numFrames * 2);

        if (this._vector.length < minLength) {
          const newVector = new Float32Array(minLength);
          newVector.set(this._vector.subarray(this.startIndex, this.endIndex));
          this._vector = newVector;
          this._position = 0;
        } else {
          this.rewind();
        }
      }

      ensureAdditionalCapacity() {
        let numFrames = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;
        this.ensureCapacity(this._frameCount + numFrames);
      }

      rewind() {
        if (this._position > 0) {
          this._vector.set(this._vector.subarray(this.startIndex, this.endIndex));

          this._position = 0;
        }
      }

    }

    class AbstractFifoSamplePipe {
      constructor(createBuffers) {
        if (createBuffers) {
          this._inputBuffer = new FifoSampleBuffer();
          this._outputBuffer = new FifoSampleBuffer();
        } else {
          this._inputBuffer = this._outputBuffer = null;
        }
      }

      get inputBuffer() {
        return this._inputBuffer;
      }

      set inputBuffer(inputBuffer) {
        this._inputBuffer = inputBuffer;
      }

      get outputBuffer() {
        return this._outputBuffer;
      }

      set outputBuffer(outputBuffer) {
        this._outputBuffer = outputBuffer;
      }

      clear() {
        this._inputBuffer.clear();

        this._outputBuffer.clear();
      }

    }

    class RateTransposer extends AbstractFifoSamplePipe {
      constructor(createBuffers) {
        super(createBuffers);
        this.reset();
        this._rate = 1;
      }

      set rate(rate) {
        this._rate = rate;
      }

      reset() {
        this.slopeCount = 0;
        this.prevSampleL = 0;
        this.prevSampleR = 0;
      }

      clone() {
        const result = new RateTransposer();
        result.rate = this._rate;
        return result;
      }

      process() {
        const numFrames = this._inputBuffer.frameCount;

        this._outputBuffer.ensureAdditionalCapacity(numFrames / this._rate + 1);

        const numFramesOutput = this.transpose(numFrames);

        this._inputBuffer.receive();

        this._outputBuffer.put(numFramesOutput);
      }

      transpose() {
        let numFrames = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

        if (numFrames === 0) {
          return 0;
        }

        const src = this._inputBuffer.vector;
        const srcOffset = this._inputBuffer.startIndex;
        const dest = this._outputBuffer.vector;
        const destOffset = this._outputBuffer.endIndex;
        let used = 0;
        let i = 0;

        while (this.slopeCount < 1.0) {
          dest[destOffset + 2 * i] = (1.0 - this.slopeCount) * this.prevSampleL + this.slopeCount * src[srcOffset];
          dest[destOffset + 2 * i + 1] = (1.0 - this.slopeCount) * this.prevSampleR + this.slopeCount * src[srcOffset + 1];
          i = i + 1;
          this.slopeCount += this._rate;
        }

        this.slopeCount -= 1.0;

        if (numFrames !== 1) {
          out: while (true) {
            while (this.slopeCount > 1.0) {
              this.slopeCount -= 1.0;
              used = used + 1;

              if (used >= numFrames - 1) {
                break out;
              }
            }

            const srcIndex = srcOffset + 2 * used;
            dest[destOffset + 2 * i] = (1.0 - this.slopeCount) * src[srcIndex] + this.slopeCount * src[srcIndex + 2];
            dest[destOffset + 2 * i + 1] = (1.0 - this.slopeCount) * src[srcIndex + 1] + this.slopeCount * src[srcIndex + 3];
            i = i + 1;
            this.slopeCount += this._rate;
          }
        }

        this.prevSampleL = src[srcOffset + 2 * numFrames - 2];
        this.prevSampleR = src[srcOffset + 2 * numFrames - 1];
        return i;
      }

    }

    class FilterSupport {
      constructor(pipe) {
        this._pipe = pipe;
      }

      get pipe() {
        return this._pipe;
      }

      get inputBuffer() {
        return this._pipe.inputBuffer;
      }

      get outputBuffer() {
        return this._pipe.outputBuffer;
      }

      fillInputBuffer() {
        throw new Error('fillInputBuffer() not overridden');
      }

      fillOutputBuffer() {
        let numFrames = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

        while (this.outputBuffer.frameCount < numFrames) {
          const numInputFrames = 8192 * 2 - this.inputBuffer.frameCount;
          this.fillInputBuffer(numInputFrames);

          if (this.inputBuffer.frameCount < 8192 * 2) {
            break;
          }

          this._pipe.process();
        }
      }

      clear() {
        this._pipe.clear();
      }

    }

    const noop$1 = function () {
      return;
    };

    class SimpleFilter extends FilterSupport {
      constructor(sourceSound, pipe) {
        let callback = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : noop$1;
        super(pipe);
        this.callback = callback;
        this.sourceSound = sourceSound;
        this.historyBufferSize = 22050;
        this._sourcePosition = 0;
        this.outputBufferPosition = 0;
        this._position = 0;
      }

      get position() {
        return this._position;
      }

      set position(position) {
        if (position > this._position) {
          throw new RangeError('New position may not be greater than current position');
        }

        const newOutputBufferPosition = this.outputBufferPosition - (this._position - position);

        if (newOutputBufferPosition < 0) {
          throw new RangeError('New position falls outside of history buffer');
        }

        this.outputBufferPosition = newOutputBufferPosition;
        this._position = position;
      }

      get sourcePosition() {
        return this._sourcePosition;
      }

      set sourcePosition(sourcePosition) {
        this.clear();
        this._sourcePosition = sourcePosition;
      }

      onEnd() {
        this.callback();
      }

      fillInputBuffer() {
        let numFrames = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;
        const samples = new Float32Array(numFrames * 2);
        const numFramesExtracted = this.sourceSound.extract(samples, numFrames, this._sourcePosition);
        this._sourcePosition += numFramesExtracted;
        this.inputBuffer.putSamples(samples, 0, numFramesExtracted);
      }

      extract(target) {
        let numFrames = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
        this.fillOutputBuffer(this.outputBufferPosition + numFrames);
        const numFramesExtracted = Math.min(numFrames, this.outputBuffer.frameCount - this.outputBufferPosition);
        this.outputBuffer.extract(target, this.outputBufferPosition, numFramesExtracted);
        const currentFrames = this.outputBufferPosition + numFramesExtracted;
        this.outputBufferPosition = Math.min(this.historyBufferSize, currentFrames);
        this.outputBuffer.receive(Math.max(currentFrames - this.historyBufferSize, 0));
        this._position += numFramesExtracted;
        return numFramesExtracted;
      }

      handleSampleData(event) {
        this.extract(event.data, 4096);
      }

      clear() {
        super.clear();
        this.outputBufferPosition = 0;
      }

    }

    const USE_AUTO_SEQUENCE_LEN = 0;
    const DEFAULT_SEQUENCE_MS = USE_AUTO_SEQUENCE_LEN;
    const USE_AUTO_SEEKWINDOW_LEN = 0;
    const DEFAULT_SEEKWINDOW_MS = USE_AUTO_SEEKWINDOW_LEN;
    const DEFAULT_OVERLAP_MS = 8;
    const _SCAN_OFFSETS = [[124, 186, 248, 310, 372, 434, 496, 558, 620, 682, 744, 806, 868, 930, 992, 1054, 1116, 1178, 1240, 1302, 1364, 1426, 1488, 0], [-100, -75, -50, -25, 25, 50, 75, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [-20, -15, -10, -5, 5, 10, 15, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [-4, -3, -2, -1, 1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]];
    const AUTOSEQ_TEMPO_LOW = 0.5;
    const AUTOSEQ_TEMPO_TOP = 2.0;
    const AUTOSEQ_AT_MIN = 125.0;
    const AUTOSEQ_AT_MAX = 50.0;
    const AUTOSEQ_K = (AUTOSEQ_AT_MAX - AUTOSEQ_AT_MIN) / (AUTOSEQ_TEMPO_TOP - AUTOSEQ_TEMPO_LOW);
    const AUTOSEQ_C = AUTOSEQ_AT_MIN - AUTOSEQ_K * AUTOSEQ_TEMPO_LOW;
    const AUTOSEEK_AT_MIN = 25.0;
    const AUTOSEEK_AT_MAX = 15.0;
    const AUTOSEEK_K = (AUTOSEEK_AT_MAX - AUTOSEEK_AT_MIN) / (AUTOSEQ_TEMPO_TOP - AUTOSEQ_TEMPO_LOW);
    const AUTOSEEK_C = AUTOSEEK_AT_MIN - AUTOSEEK_K * AUTOSEQ_TEMPO_LOW;

    class Stretch extends AbstractFifoSamplePipe {
      constructor(createBuffers) {
        super(createBuffers);
        this._quickSeek = true;
        this.midBufferDirty = false;
        this.midBuffer = null;
        this.overlapLength = 0;
        this.autoSeqSetting = true;
        this.autoSeekSetting = true;
        this._tempo = 1;
        this.setParameters(44100, DEFAULT_SEQUENCE_MS, DEFAULT_SEEKWINDOW_MS, DEFAULT_OVERLAP_MS);
      }

      clear() {
        super.clear();
        this.clearMidBuffer();
      }

      clearMidBuffer() {
        if (this.midBufferDirty) {
          this.midBufferDirty = false;
          this.midBuffer = null;
        }
      }

      setParameters(sampleRate, sequenceMs, seekWindowMs, overlapMs) {
        if (sampleRate > 0) {
          this.sampleRate = sampleRate;
        }

        if (overlapMs > 0) {
          this.overlapMs = overlapMs;
        }

        if (sequenceMs > 0) {
          this.sequenceMs = sequenceMs;
          this.autoSeqSetting = false;
        } else {
          this.autoSeqSetting = true;
        }

        if (seekWindowMs > 0) {
          this.seekWindowMs = seekWindowMs;
          this.autoSeekSetting = false;
        } else {
          this.autoSeekSetting = true;
        }

        this.calculateSequenceParameters();
        this.calculateOverlapLength(this.overlapMs);
        this.tempo = this._tempo;
      }

      set tempo(newTempo) {
        let intskip;
        this._tempo = newTempo;
        this.calculateSequenceParameters();
        this.nominalSkip = this._tempo * (this.seekWindowLength - this.overlapLength);
        this.skipFract = 0;
        intskip = Math.floor(this.nominalSkip + 0.5);
        this.sampleReq = Math.max(intskip + this.overlapLength, this.seekWindowLength) + this.seekLength;
      }

      get tempo() {
        return this._tempo;
      }

      get inputChunkSize() {
        return this.sampleReq;
      }

      get outputChunkSize() {
        return this.overlapLength + Math.max(0, this.seekWindowLength - 2 * this.overlapLength);
      }

      calculateOverlapLength() {
        let overlapInMsec = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;
        let newOvl;
        newOvl = this.sampleRate * overlapInMsec / 1000;
        newOvl = newOvl < 16 ? 16 : newOvl;
        newOvl -= newOvl % 8;
        this.overlapLength = newOvl;
        this.refMidBuffer = new Float32Array(this.overlapLength * 2);
        this.midBuffer = new Float32Array(this.overlapLength * 2);
      }

      checkLimits(x, mi, ma) {
        return x < mi ? mi : x > ma ? ma : x;
      }

      calculateSequenceParameters() {
        let seq;
        let seek;

        if (this.autoSeqSetting) {
          seq = AUTOSEQ_C + AUTOSEQ_K * this._tempo;
          seq = this.checkLimits(seq, AUTOSEQ_AT_MAX, AUTOSEQ_AT_MIN);
          this.sequenceMs = Math.floor(seq + 0.5);
        }

        if (this.autoSeekSetting) {
          seek = AUTOSEEK_C + AUTOSEEK_K * this._tempo;
          seek = this.checkLimits(seek, AUTOSEEK_AT_MAX, AUTOSEEK_AT_MIN);
          this.seekWindowMs = Math.floor(seek + 0.5);
        }

        this.seekWindowLength = Math.floor(this.sampleRate * this.sequenceMs / 1000);
        this.seekLength = Math.floor(this.sampleRate * this.seekWindowMs / 1000);
      }

      set quickSeek(enable) {
        this._quickSeek = enable;
      }

      clone() {
        const result = new Stretch();
        result.tempo = this._tempo;
        result.setParameters(this.sampleRate, this.sequenceMs, this.seekWindowMs, this.overlapMs);
        return result;
      }

      seekBestOverlapPosition() {
        return this._quickSeek ? this.seekBestOverlapPositionStereoQuick() : this.seekBestOverlapPositionStereo();
      }

      seekBestOverlapPositionStereo() {
        let bestOffset;
        let bestCorrelation;
        let correlation;
        let i = 0;
        this.preCalculateCorrelationReferenceStereo();
        bestOffset = 0;
        bestCorrelation = Number.MIN_VALUE;

        for (; i < this.seekLength; i = i + 1) {
          correlation = this.calculateCrossCorrelationStereo(2 * i, this.refMidBuffer);

          if (correlation > bestCorrelation) {
            bestCorrelation = correlation;
            bestOffset = i;
          }
        }

        return bestOffset;
      }

      seekBestOverlapPositionStereoQuick() {
        let bestOffset;
        let bestCorrelation;
        let correlation;
        let scanCount = 0;
        let correlationOffset;
        let tempOffset;
        this.preCalculateCorrelationReferenceStereo();
        bestCorrelation = Number.MIN_VALUE;
        bestOffset = 0;
        correlationOffset = 0;
        tempOffset = 0;

        for (; scanCount < 4; scanCount = scanCount + 1) {
          let j = 0;

          while (_SCAN_OFFSETS[scanCount][j]) {
            tempOffset = correlationOffset + _SCAN_OFFSETS[scanCount][j];

            if (tempOffset >= this.seekLength) {
              break;
            }

            correlation = this.calculateCrossCorrelationStereo(2 * tempOffset, this.refMidBuffer);

            if (correlation > bestCorrelation) {
              bestCorrelation = correlation;
              bestOffset = tempOffset;
            }

            j = j + 1;
          }

          correlationOffset = bestOffset;
        }

        return bestOffset;
      }

      preCalculateCorrelationReferenceStereo() {
        let i = 0;
        let context;
        let temp;

        for (; i < this.overlapLength; i = i + 1) {
          temp = i * (this.overlapLength - i);
          context = i * 2;
          this.refMidBuffer[context] = this.midBuffer[context] * temp;
          this.refMidBuffer[context + 1] = this.midBuffer[context + 1] * temp;
        }
      }

      calculateCrossCorrelationStereo(mixingPosition, compare) {
        const mixing = this._inputBuffer.vector;
        mixingPosition += this._inputBuffer.startIndex;
        let correlation = 0;
        let i = 2;
        const calcLength = 2 * this.overlapLength;
        let mixingOffset;

        for (; i < calcLength; i = i + 2) {
          mixingOffset = i + mixingPosition;
          correlation += mixing[mixingOffset] * compare[i] + mixing[mixingOffset + 1] * compare[i + 1];
        }

        return correlation;
      }

      overlap(overlapPosition) {
        this.overlapStereo(2 * overlapPosition);
      }

      overlapStereo(inputPosition) {
        const input = this._inputBuffer.vector;
        inputPosition += this._inputBuffer.startIndex;
        const output = this._outputBuffer.vector;
        const outputPosition = this._outputBuffer.endIndex;
        let i = 0;
        let context;
        let tempFrame;
        const frameScale = 1 / this.overlapLength;
        let fi;
        let inputOffset;
        let outputOffset;

        for (; i < this.overlapLength; i = i + 1) {
          tempFrame = (this.overlapLength - i) * frameScale;
          fi = i * frameScale;
          context = 2 * i;
          inputOffset = context + inputPosition;
          outputOffset = context + outputPosition;
          output[outputOffset + 0] = input[inputOffset + 0] * fi + this.midBuffer[context + 0] * tempFrame;
          output[outputOffset + 1] = input[inputOffset + 1] * fi + this.midBuffer[context + 1] * tempFrame;
        }
      }

      process() {
        let offset;
        let temp;
        let overlapSkip;

        if (this.midBuffer === null) {
          if (this._inputBuffer.frameCount < this.overlapLength) {
            return;
          }

          this.midBuffer = new Float32Array(this.overlapLength * 2);

          this._inputBuffer.receiveSamples(this.midBuffer, this.overlapLength);
        }

        while (this._inputBuffer.frameCount >= this.sampleReq) {
          offset = this.seekBestOverlapPosition();

          this._outputBuffer.ensureAdditionalCapacity(this.overlapLength);

          this.overlap(Math.floor(offset));

          this._outputBuffer.put(this.overlapLength);

          temp = this.seekWindowLength - 2 * this.overlapLength;

          if (temp > 0) {
            this._outputBuffer.putBuffer(this._inputBuffer, offset + this.overlapLength, temp);
          }

          const start = this._inputBuffer.startIndex + 2 * (offset + this.seekWindowLength - this.overlapLength);
          this.midBuffer.set(this._inputBuffer.vector.subarray(start, start + 2 * this.overlapLength));
          this.skipFract += this.nominalSkip;
          overlapSkip = Math.floor(this.skipFract);
          this.skipFract -= overlapSkip;

          this._inputBuffer.receive(overlapSkip);
        }
      }

    }

    const testFloatEqual = function (a, b) {
      return (a > b ? a - b : b - a) > 1e-10;
    };

    class SoundTouch {
      constructor() {
        this.transposer = new RateTransposer(false);
        this.stretch = new Stretch(false);
        this._inputBuffer = new FifoSampleBuffer();
        this._intermediateBuffer = new FifoSampleBuffer();
        this._outputBuffer = new FifoSampleBuffer();
        this._rate = 0;
        this._tempo = 0;
        this.virtualPitch = 1.0;
        this.virtualRate = 1.0;
        this.virtualTempo = 1.0;
        this.calculateEffectiveRateAndTempo();
      }

      clear() {
        this.transposer.clear();
        this.stretch.clear();
      }

      clone() {
        const result = new SoundTouch();
        result.rate = this.rate;
        result.tempo = this.tempo;
        return result;
      }

      get rate() {
        return this._rate;
      }

      set rate(rate) {
        this.virtualRate = rate;
        this.calculateEffectiveRateAndTempo();
      }

      set rateChange(rateChange) {
        this._rate = 1.0 + 0.01 * rateChange;
      }

      get tempo() {
        return this._tempo;
      }

      set tempo(tempo) {
        this.virtualTempo = tempo;
        this.calculateEffectiveRateAndTempo();
      }

      set tempoChange(tempoChange) {
        this.tempo = 1.0 + 0.01 * tempoChange;
      }

      set pitch(pitch) {
        this.virtualPitch = pitch;
        this.calculateEffectiveRateAndTempo();
      }

      set pitchOctaves(pitchOctaves) {
        this.pitch = Math.exp(0.69314718056 * pitchOctaves);
        this.calculateEffectiveRateAndTempo();
      }

      set pitchSemitones(pitchSemitones) {
        this.pitchOctaves = pitchSemitones / 12.0;
      }

      get inputBuffer() {
        return this._inputBuffer;
      }

      get outputBuffer() {
        return this._outputBuffer;
      }

      calculateEffectiveRateAndTempo() {
        const previousTempo = this._tempo;
        const previousRate = this._rate;
        this._tempo = this.virtualTempo / this.virtualPitch;
        this._rate = this.virtualRate * this.virtualPitch;

        if (testFloatEqual(this._tempo, previousTempo)) {
          this.stretch.tempo = this._tempo;
        }

        if (testFloatEqual(this._rate, previousRate)) {
          this.transposer.rate = this._rate;
        }

        if (this._rate > 1.0) {
          if (this._outputBuffer != this.transposer.outputBuffer) {
            this.stretch.inputBuffer = this._inputBuffer;
            this.stretch.outputBuffer = this._intermediateBuffer;
            this.transposer.inputBuffer = this._intermediateBuffer;
            this.transposer.outputBuffer = this._outputBuffer;
          }
        } else {
          if (this._outputBuffer != this.stretch.outputBuffer) {
            this.transposer.inputBuffer = this._inputBuffer;
            this.transposer.outputBuffer = this._intermediateBuffer;
            this.stretch.inputBuffer = this._intermediateBuffer;
            this.stretch.outputBuffer = this._outputBuffer;
          }
        }
      }

      process() {
        if (this._rate > 1.0) {
          this.stretch.process();
          this.transposer.process();
        } else {
          this.transposer.process();
          this.stretch.process();
        }
      }

    }

    class RateProcessor {
      constructor(player, audio, source) {
        this.player = player;
        this.audio = audio;
        this.soundTouch = new SoundTouch();
        this.soundTouch.tempo = 1;
        this.soundTouch.rate = 1;
        this.filter = new SimpleFilter(source, this.soundTouch);
      }

      setRate(value) {
        this.soundTouch.tempo = value;
      }

      provide(size) {
        let target = new Float32Array(size * 2);
        let framesExtracted = this.filter.extract(target, size);
        let left = new Float32Array(framesExtracted);
        let right = new Float32Array(framesExtracted); // 缩小

        for (let i = 0; i < framesExtracted; i++) {
          left[i] = target[i * 2];
          right[i] = target[i * 2 + 1];
        } //


        return {
          size: framesExtracted,
          left,
          right,
          ts: this.audio.tempAudioTimestamp || 0
        };
      }

      destroy() {
        if (this.soundTouch) {
          this.soundTouch.clear();
          this.soundTouch = null;
        }

        if (this.filter) {
          this.filter = null;
        }
      }

    }

    class AudioContextLoader extends CommonContextLoader {
      constructor(player) {
        super(player); // default is 1

        this.defaultPlaybackRate = 1;
        this.playbackRate = 1;
        this.rateProcessor = null;
        this.processor = null;
        this.firstTimestamp = null;
        this.scriptNodeInterval = null;
        this.audioBufferSize = 1024;
        this.engineType = player._opt.audioEngine || AUDIO_ENGINE_TYPE.script;

        if (isWeChatInAndroid() && player._opt.audioEngine === null || this.engineType === AUDIO_ENGINE_TYPE.active) {
          this.audioBufferSize = 4800;
        }

        if (this.engineType === AUDIO_ENGINE_TYPE.script) {
          this.audioBufferSize = 4096;
        }

        this.scriptStartTime = 0;
        this.player.debug.log('AudioContext', 'init', {
          audioBufferSize: this.audioBufferSize
        });
      } //


      destroy() {
        super.destroy();

        if (this.processor) {
          this.processor.destroy();
          this.processor = null;
        }

        if (this.rateProcessor) {
          this.rateProcessor.destroy();
          this.rateProcessor = null;
        }

        if (this.scriptNodeInterval) {
          clearInterval(this.scriptNodeInterval);
          this.scriptNodeInterval = null;
        }

        this.scriptStartTime = 0;
        this.engineType = AUDIO_ENGINE_TYPE.script;
        this.player.debug.log('AudioContext', 'destroy');
      }

      getAudioBufferSize() {
        return this.audioBufferSize;
      }

      get oneBufferDuration() {
        return this.audioBufferSize / this.audioContext.sampleRate * 1000; // ms
      }

      get isActiveEngineType() {
        return this.engineType === AUDIO_ENGINE_TYPE.active;
      }

      initProcessor() {
        this.processor = new Processor(this.player, this, this.bufferList, this.audioInfo.channels, this.audioBufferSize);
        this.rateProcessor = new RateProcessor(this.player, this, this.processor);
      } //


      initScriptNode() {
        this.playing = true;

        if (this.hasInitScriptNode) {
          return;
        }

        this.initProcessor();

        if (this.player._opt.audioEngine) {
          if (this.player._opt.audioEngine === AUDIO_ENGINE_TYPE.worklet && isInHttps()) {
            this.initWorkletScriptNode();
          } else if (this.player._opt.audioEngine === AUDIO_ENGINE_TYPE.active) {
            this.initIntervalScriptNode();
          } else if (this.player._opt.audioEngine === AUDIO_ENGINE_TYPE.script) {
            this.initProcessScriptNode();
          } else {
            this.autoInitScriptNode();
          }
        } else {
          this.autoInitScriptNode();
        }
      }

      autoInitScriptNode() {
        // auto select
        if (isWeChatInAndroid()) {
          // wechat android
          this.initIntervalScriptNode();
        } else if (isInHttps()) {
          this.initWorkletScriptNode();
        } else {
          this.initProcessScriptNode();
        }
      }

      getEngineType() {
        return this.engineType;
      }

      isPlaybackRateSpeed() {
        return this.playbackRate > this.defaultPlaybackRate;
      }

      initProcessScriptNode() {
        this.engineType = AUDIO_ENGINE_TYPE.script;
        const scriptNode = this.audioContext.createScriptProcessor(this.audioBufferSize, 0, this.audioInfo.channels); // tips: if audio isStateSuspended  onaudioprocess method not working

        scriptNode.onaudioprocess = audioProcessingEvent => {
          const outputBuffer = audioProcessingEvent.outputBuffer;
          this.handleScriptNodeCallback(outputBuffer);
        };

        scriptNode.connect(this.gainNode);
        this.scriptNode = scriptNode;
        this.gainNode.connect(this.audioContext.destination);
        this.gainNode.connect(this.mediaStreamAudioDestinationNode);
        this.hasInitScriptNode = true;
      }

      initIntervalScriptNode() {
        this.scriptStartTime = 0;
        this.engineType = AUDIO_ENGINE_TYPE.active;
        const intervalTime = 1000 * this.audioBufferSize / this.audioContext.sampleRate;
        this.scriptNodeInterval = setInterval(() => {
          const audioSource = this.audioContext.createBufferSource();
          const outputBuffer = this.audioContext.createBuffer(this.audioInfo.channels, this.audioBufferSize, this.audioContext.sampleRate);
          this.handleScriptNodeCallback(outputBuffer, () => {
            if (this.scriptStartTime < this.audioContext.currentTime) {
              this.scriptStartTime = this.audioContext.currentTime;
            }

            audioSource.buffer = outputBuffer;
            audioSource.connect(this.gainNode);
            audioSource.start(this.scriptStartTime);
            this.scriptStartTime += outputBuffer.duration;
          });
        }, intervalTime);
        this.gainNode.connect(this.audioContext.destination);
        this.gainNode.connect(this.mediaStreamAudioDestinationNode);
        this.hasInitScriptNode = true;
      }

      initWorkletScriptNode() {
        this.engineType = AUDIO_ENGINE_TYPE.worklet;

        function audiWorkletProcessor() {
          class WorkletProcessor extends AudioWorkletProcessor {
            constructor() {
              super();
              this.audioBufferSize = 1024;
              this.start = false;
              this.channels = 1;
              this.samplesArray = [];
              this.offset = 0;
              this.state = 0;

              this.port.onmessage = e => {
                // console.log('WorkletProcessor onmessage', e.data);
                if (e.data.message === "init") {
                  this.audioBufferSize = e.data.audioBufferSize;
                  this.start = e.data.start;
                  this.channels = e.data.channels;
                  this.state = 0;
                  this.offset = 0;
                  this.samplesArray = [];
                } else if (e.data.message === "stop") {
                  this.state = 0;
                  this.start = false;
                  this.offset = 0;
                  this.samplesArray = [];
                } else if (e.data.message === "data") {
                  this.samplesArray.push(e.data.buffer);
                } else if (e.data.message === "zero") {
                  this.samplesArray.push({
                    left: new Float32Array(this.audioBufferSize).fill(0),
                    right: new Float32Array(this.audioBufferSize).fill(0)
                  });
                }
              };
            }

            process(inputs, outputs, parameters) {
              const outputLeft = outputs[0][0];
              const outputRight = outputs[0][1];

              if (this.offset === 0) {
                this.port.postMessage({
                  message: "beep"
                });
              }

              if (this.state === 0) {
                this.state = 1;
              } else if (this.state === 1 && this.samplesArray.length >= 4) {
                this.state = 2;
              } else if (this.state === 2) {
                const bufferItem = this.samplesArray[0];

                for (let i = 0; i < outputLeft.length; i++) {
                  if (this.channels === 1) {
                    outputLeft[i] = bufferItem.left[i + this.offset];
                  } else if (this.channels === 2) {
                    outputLeft[i] = bufferItem.left[i + this.offset];

                    if (outputRight) {
                      outputRight[i] = bufferItem.right[i + this.offset];
                    }
                  }
                }
              } else {
                if (this.channels === 1) {
                  outputLeft.fill(0);
                } else if (this.channels === 2) {
                  outputLeft.fill(0);

                  if (outputRight) {
                    outputRight.fill(0);
                  }
                }
              }

              this.offset += 128;

              if (this.offset === this.audioBufferSize) {
                this.offset = 0;

                if (this.state === 2) {
                  this.samplesArray.shift();
                }

                if (this.samplesArray.length === 0) {
                  this.state = 0;
                }
              }

              return this.start;
            }

          }

          registerProcessor('worklet-processor', WorkletProcessor);
        }

        this.audioContext.audioWorklet.addModule(createWorkletModuleUrl(audiWorkletProcessor)).then(() => {
          let outputChannelCount = [1];

          if (this.audioInfo.channels === 2) {
            outputChannelCount = [1, 1];
          }

          this.workletProcessorNode = new AudioWorkletNode(this.audioContext, "worklet-processor", {
            numberOfOutputs: this.audioInfo.channels,
            outputChannelCount
          });
          this.workletProcessorNode.connect(this.gainNode);
          this.gainNode.connect(this.audioContext.destination);
          this.gainNode.connect(this.mediaStreamAudioDestinationNode);
          this.hasInitScriptNode = true;
          this.workletProcessorNode.port.postMessage({
            message: "init",
            audioBufferSize: this.audioBufferSize,
            start: true,
            channels: this.audioInfo.channels
          });

          this.workletProcessorNode.port.onmessage = e => {
            // console.log('workletProcessorNode onmessage', e.data);
            if (this.workletProcessorNode) {
              if (this.audioContext) {
                this.handleScriptNodeCallback(this.workletProcessorNode, null, true);
              } else {
                this.workletProcessorNode.port.postMessage({
                  message: "zero"
                });
              }
            } else {
              this.player.debug.error('workletProcessorNode is null');
            }
          };
        });
      }

      handleScriptNodeCallback(outputBuffer, cb) {
        let isWorklet = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;
        cb = cb || noop$2;
        let workletProcessorNode;
        let outputBufferLength = outputBuffer.length;

        if (isWorklet) {
          workletProcessorNode = outputBuffer;
          outputBufferLength = this.audioBufferSize;
        }

        const channels = this.audioInfo.channels;

        if (this.bufferList.length && this.playing) {
          const opt = this.player._opt;

          if (opt.syncAudioAndVideo && opt.hasVideo) {
            this.calcPlaybackRateBySync(); // audio > video
            // wait

            if (this.audioSyncVideoOption.diff > AUDIO_SYNC_VIDEO_DIFF) {
              this.player.debug.warn('AudioContext', `audioSyncVideoOption more than diff :${this.audioSyncVideoOption.diff}, waiting`); // empty audio

              if (isWorklet) {
                workletProcessorNode.port.postMessage({
                  message: "zero"
                });
              } else {
                this.fillScriptNodeOutputBuffer(outputBuffer, channels);
              }

              cb();
              return;
            }
          }

          let bufferItem = this._provide(outputBufferLength);

          if (bufferItem.size === 0) {
            // this.player.debug.warn('AudioContext', `bufferList size  is ${this.bufferList.length} outputBufferLength is ${outputBufferLength},and bufferItem.size is 0`)
            // empty audio
            if (isWorklet) {
              workletProcessorNode.port.postMessage({
                message: "zero"
              });
            } else {
              this.fillScriptNodeOutputBuffer(outputBuffer, channels);
            }

            cb();
            return;
          } // update audio time stamp


          if (bufferItem && bufferItem.ts) {
            this.player.audioTimestamp = bufferItem.ts;
          }

          if (isWorklet) {
            workletProcessorNode.port.postMessage({
              message: "data",
              buffer: bufferItem
            });
          } else {
            this.fillScriptNodeOutputBuffer(outputBuffer, channels, bufferItem);
          }

          cb();
        } else {
          if (isWorklet) {
            workletProcessorNode.port.postMessage({
              message: "zero"
            });
          } else {
            this.fillScriptNodeOutputBuffer(outputBuffer, channels);
          }

          cb();
        }
      }

      fillScriptNodeOutputBuffer(outputBuffer, channels, bufferItem) {
        if (channels === 1) {
          const leftBuffer = outputBuffer.getChannelData(0);

          if (bufferItem) {
            if (bufferItem.size === 0) {
              leftBuffer.fill(0);
            } else {
              leftBuffer.set(bufferItem.left);
            }
          } else {
            leftBuffer.fill(0);
          }
        } else if (channels === 2) {
          const leftBuffer = outputBuffer.getChannelData(0);
          const rightBuffer = outputBuffer.getChannelData(1);

          if (bufferItem) {
            if (bufferItem.size === 0) {
              leftBuffer.fill(0);
              rightBuffer.fill(0);
            } else {
              leftBuffer.set(bufferItem.left);
              rightBuffer.set(bufferItem.right);
            }
          } else {
            leftBuffer.fill(0);
            rightBuffer.fill(0);
          }
        }
      } //


      play(buffer, ts) {
        // if is mute
        if (this.isMute) {
          return;
        }

        this.hasAudio = true;
        this.bufferList.push({
          buffer,
          ts
        }); //

        if (!this.player._opt.syncAudioAndVideo) {
          this.calcPlaybackRateByBuffer();
        }
      }

      calcPlaybackRateBySync() {
        // audio 的速率小于 video
        // 持续丢掉音频数据，让音频数据赶上视频。
        let playbackRate = this.playbackRate;

        if (this.audioSyncVideoOption.diff < -AUDIO_SYNC_VIDEO_DIFF) {
          this.player.debug.warn('AudioContext', `audioSyncVideoOption ${-AUDIO_SYNC_VIDEO_DIFF} less than diff :${this.audioSyncVideoOption.diff}, speed up`);
          playbackRate = this.defaultPlaybackRate + 0.1;
        } else if (this.audioSyncVideoOption.diff < -AUDIO_SYNC_VIDEO_DIFF / 2) {
          playbackRate = this.defaultPlaybackRate;
        }

        this.updatePlaybackRate(playbackRate);
      }

      calcPlaybackRateByBuffer() {
        let playbackRate = this.playbackRate;
        const maxSize = Math.floor(AUDIO_SYNC_VIDEO_DIFF / this.oneBufferDuration); // out of memory

        if (this.bufferList.length > maxSize) {
          this.player.debug.warn('AudioContext', `bufferList length ${this.bufferList.length} more than ${maxSize}, speed up`);
          playbackRate = this.defaultPlaybackRate + 0.1;
        } else if (this.bufferList.length < maxSize / 2) {
          playbackRate = this.defaultPlaybackRate;
        }

        this.updatePlaybackRate(playbackRate);
      }

      updatePlaybackRate(playbackRate) {
        this.playbackRate = playbackRate;
        this.rateProcessor.setRate(this.playbackRate);
      }

      _provide(size) {
        let provider = this.playbackRate === 1 ? this.processor : this.rateProcessor;
        let audioData = provider.provide(size);
        return audioData;
      }

    }

    class AudioLoader extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.$video = player.video.$videoElement;
        this.init = false;

        if (this.player._opt.hlsUseCanvasRender) {
          this.$video = this.player.hlsDecoder.$videoElement;
        }

        this.audioInfo = {
          encType: '',
          channels: '',
          sampleRate: ''
        };
        this.player.debug.log('Audio', 'init');
      }

      destroy() {
        this.init = false;
        this.audioInfo = {
          encType: '',
          channels: '',
          sampleRate: ''
        };
        this.off();
        this.player.debug.log('Audio', 'destroy');
      }

      resetInit() {}

      updateAudioInfo(data) {
        if (isNotEmpty(data.encTypeCode)) {
          this.audioInfo.encType = AUDIO_ENC_TYPE[data.encTypeCode];
        }

        if (isNotEmpty(data.encType)) {
          this.audioInfo.encType = data.encType;
        }

        if (isNotEmpty(data.channels)) {
          this.audioInfo.channels = data.channels;
        }

        if (isNotEmpty(data.sampleRate)) {
          this.audioInfo.sampleRate = data.sampleRate;
        } // audio 基本信息


        if (isNotEmpty(this.audioInfo.sampleRate) && isNotEmpty(this.audioInfo.channels) && isNotEmpty(this.audioInfo.encType) && !this.init) {
          this.player.emit(EVENTS.audioInfo, this.audioInfo);
          this.init = true;
        }
      }

      get isPlaying() {
        return true;
      }

      get volume() {
        return this.$video.muted === true ? 0 : this.$video.volume;
      }

      get isMute() {
        return this.$video.volume === 0 || this.$video.muted === true;
      }

      mute(muted) {
        this.setVolume(muted ? 0 : this.player.lastVolume || 0.5);
      }

      setVolume(volume) {
        volume = parseFloat(volume);

        if (isNaN(volume)) {
          return;
        }

        volume = clamp(volume, 0, 1); // 值从0.0（静音）到1.0（最大音量）。

        if (this.$video.muted) {
          this.$video.muted = false;
        }

        this.$video.volume = volume;
        this.player.emit(EVENTS.volumechange, this.player.volume);
      }

      clear() {}

      play() {}

      pause() {}

      resume() {}

      getEngineType() {
        return 'inline';
      }

    }

    class AudioPlaybackLoader extends AudioContextLoader {
      constructor(player) {
        super(player);
        this.player.on(EVENTS.playbackPause, this.listenPlaybackPause);
        this.player.debug.log('AudioPlaybackContext', 'init');
      }

      destroy() {
        super.destroy();
        this.player.off(EVENTS.playbackPause, this.listenPlaybackPause);
        this.player.debug.log(`AudioPlaybackLoader`, 'destroy');
      }

      listenPlaybackPause(flag) {
        if (flag) {
          this.pause();
        } else {
          this.resume();
        }
      } //


      initScriptNodeDelay() {
        const delayTime = this.player._opt.playbackDelayTime;

        if (delayTime > 0) {
          setTimeout(() => {
            this.initScriptNode(); // console.error('initScriptNodeDelay , bufferList length', this.bufferList.length);
          }, delayTime);
        } else {
          this.initScriptNode();
        }
      }

      setRate(value) {
        if (value !== this.defaultPlaybackRate && this.rateProcessor) {
          this.player.debug.log('AudioPlaybackContext', 'setRate', value);
          this.defaultPlaybackRate = value;
          this.updatePlaybackRate(value);
        }
      }

      play(buffer, ts) {
        // if is mute
        if (this.isMute) {
          return;
        }

        if (this.firstTimestamp === null) {
          this.firstTimestamp = ts;
        }

        this.hasAudio = true;
        this.bufferList.push({
          buffer,
          ts: ts - this.firstTimestamp
        });
      }

    }

    class Audio {
      constructor(player) {
        const Loader = Audio.getLoaderFactory(player._opt);
        return new Loader(player);
      }

      static getLoaderFactory(opt) {
        if (opt.playType === PLAY_TYPE.playbackTF) {
          return AudioPlaybackLoader;
        } else {
          if (opt.isHls || opt.isWebrtc) {
            return AudioLoader;
          }

          return AudioContextLoader;
        }
      }

    }

    class FetchLoader extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.playing = false;
        this.abortController = new AbortController(); //

        this.streamRate = calculationRate(rate => {
          player.emit(EVENTS.kBps, (rate / 1024).toFixed(2));
        });
        this.streamRateInterval = null;
        player.debug.log('FetchStream', 'init');
      }

      destroy() {
        this.abort();
        this.off();
        this.streamRate = null;
        this.stopStreamRateInterval();
        this.player.debug.log('FetchStream', 'destroy');
      }

      startStreamRateInterval() {
        this.stopStreamRateInterval();
        this.streamRateInterval = setInterval(() => {
          this.streamRate && this.streamRate(0);
        }, 1000);
      }

      stopStreamRateInterval() {
        if (this.streamRateInterval) {
          clearInterval(this.streamRateInterval);
          this.streamRateInterval = null;
        }
      }
      /**
       *
       * @param url
       * @param options
       */


      fetchStream(url) {
        let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
        const {
          demux
        } = this.player;
        this.player._times.streamStart = now$1();
        const fetchOptions = Object.assign({
          signal: this.abortController.signal
        }, {
          headers: options.headers || {}
        });
        fetch(url, fetchOptions).then(res => {
          this.emit(EVENTS.streamSuccess);
          this.startStreamRateInterval();
          res.body.pipeTo(new WritableStream({
            write: value => {
              this.streamRate && this.streamRate(value.byteLength);
              return demux.dispatch(value);
            },
            close: () => {
              demux.close();
            },
            abort: e => {
              demux.close();
              const errorString = e.toString(); // aborted a request 。

              if (errorString.indexOf(FETCH_ERROR.abortError) !== -1) {
                return;
              }

              if (errorString.indexOf(FETCH_ERROR.abortError2) !== -1) {
                return;
              }

              if (e.name === FETCH_ERROR.abort) {
                return;
              }

              this.abort(); // / 这边会报用户 aborted a request 错误。

              this.emit(EVENTS_ERROR.fetchError, e);
              this.player.emit(EVENTS.error, EVENTS_ERROR.fetchError);
            }
          }));
        }).catch(e => {
          if (e.name === 'AbortError') {
            return;
          }

          demux.close();
          this.abort();
          this.emit(EVENTS_ERROR.fetchError, e);
          this.player.emit(EVENTS.error, EVENTS_ERROR.fetchError);
        });
      }

      abort() {
        if (this.abortController) {
          this.abortController.abort();
          this.abortController = null;
        }
      }

    }

    class WebsocketLoader extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.socket = null;
        this.socketStatus = WEBSOCKET_STATUS.notConnect;
        this.wsUrl = null;
        this.socketDestroyFnList = []; //

        this.streamRate = calculationRate(rate => {
          player.emit(EVENTS.kBps, (rate / 1024).toFixed(2));
        });
        this.streamRateInterval = null;
        player.debug.log('WebsocketStream', 'init');
      }

      destroy() {
        this._closeWebSocket();

        this.stopStreamRateInterval();
        this.wsUrl = null;
        this.off();
        this.player.debug.log('WebsocketStream', 'destroy');
      }

      startStreamRateInterval() {
        this.stopStreamRateInterval();
        this.streamRateInterval = setInterval(() => {
          this.streamRate && this.streamRate(0);
        }, 1000);
      }

      stopStreamRateInterval() {
        if (this.streamRateInterval) {
          clearInterval(this.streamRateInterval);
          this.streamRateInterval = null;
        }
      }

      _createWebSocket() {
        const player = this.player;
        const {
          debug,
          events: {
            proxy
          },
          demux
        } = player;
        this.socket = new WebSocket(this.wsUrl);
        this.socket.binaryType = 'arraybuffer';
        const socketOpenDestroy = proxy(this.socket, 'open', () => {
          this.emit(EVENTS.streamSuccess);
          this.startStreamRateInterval();
          debug.log('WebsocketStream', 'socket open');
          this.socketStatus = WEBSOCKET_STATUS.open;
        });
        const socketMessageDestroy = proxy(this.socket, 'message', event => {
          this.streamRate && this.streamRate(event.data.byteLength);

          this._handleMessage(event.data);
        });
        const socketCloseDestroy = proxy(this.socket, 'close', () => {
          debug.log('WebsocketStream', 'socket close');
          this.emit(EVENTS.streamEnd);
          this.socketStatus = WEBSOCKET_STATUS.close;
        });
        const socketErrorDestroy = proxy(this.socket, 'error', error => {
          debug.log('WebsocketStream', 'socket error');
          this.emit(EVENTS_ERROR.websocketError, error);
          this.player.emit(EVENTS.error, EVENTS_ERROR.websocketError);
          this.socketStatus = WEBSOCKET_STATUS.error;
          demux.close();
          debug.log('WebsocketStream', `socket error:`, error);
        });
        this.socketDestroyFnList.push(socketOpenDestroy, socketMessageDestroy, socketCloseDestroy, socketErrorDestroy);
      }

      _closeWebSocket() {
        this.socketDestroyFnList.forEach(event => event());

        if (this.socket) {
          this.socket.close();
          this.socket = null;
        }

        this.socketStatus = WEBSOCKET_STATUS.notConnect;
        this.streamRate = null;
      } //


      _handleMessage(message) {
        const {
          demux
        } = this.player;

        if (!demux) {
          this.player.debug.warn('WebsocketStream', 'websocket handle message demux is null');
          return;
        }

        demux.dispatch(message);
      }
      /**
       *
       * @param url
       * @param options
       */


      fetchStream(url, options) {
        this.player._times.streamStart = now$1();
        this.wsUrl = url;

        this._createWebSocket();
      }
      /**
       *
       */


      resetFetchStream() {
        this._closeWebSocket();

        this._createWebSocket();
      }

    }

    class HlsLoader extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        player.debug.log('HlsStream', 'init');
      }

      destroy() {
        this.off();
        this.player.debug.log('HlsStream', 'destroy');
      }

      fetchStream(url) {
        const {
          hlsDecoder,
          debug
        } = this.player;
        this.player._times.streamStart = now$1();
        hlsDecoder.loadSource(url).then(() => {
          this.player.debug.log('HlsStream', 'loadSource success');
          this.emit(EVENTS.streamSuccess);
        }).catch(error => {
          this.emit(EVENTS_ERROR.hlsError, error);
          this.emit(EVENTS.error, EVENTS_ERROR.hlsError);
        });
      }

    }

    class WebrtcLoader extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.webrctUrl = null;
        player.debug.log('WebrtcStream', 'init');
      }

      destroy() {
        this.webrctUrl = null;
        this.off();
        this.player.debug.log('WebrtcStream', 'destroy');
      }
      /**
       * webrtc://host:port/webrtc/play/[streamPath]
       * @param url
       */


      fetchStream(url) {
        const {
          webrtc,
          debug
        } = this.player;
        this.player._times.streamStart = now$1();
        this.webrctUrl = url.replace('webrtc:', window.location.protocol);
        webrtc.loadSource(this.webrctUrl).then(() => {
          this.player.debug.log('WebrtcStream', 'loadSource success');
          this.emit(EVENTS.streamSuccess);
        }).catch(error => {
          this.emit(EVENTS_ERROR.webrtcError, error);
          this.emit(EVENTS.error, EVENTS_ERROR.webrtcError);
        });
      }

    }

    class WebTransportLoader$1 extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.transport = null;
        this.wtUrl = null; //

        this.streamRate = calculationRate(rate => {
          player.emit(EVENTS.kBps, (rate / 1024).toFixed(2));
        });
        this.streamRateInterval = null;
        player.debug.log('WebTransportLoader', 'init');
      }

      destroy() {
        this.abort();
        this.off();
        this.player.debug.log('WebTransportLoader', 'destroy');
      }

      startStreamRateInterval() {
        this.stopStreamRateInterval();
        this.streamRateInterval = setInterval(() => {
          this.streamRate && this.streamRate(0);
        }, 1000);
      }

      stopStreamRateInterval() {
        if (this.streamRateInterval) {
          clearInterval(this.streamRateInterval);
          this.streamRateInterval = null;
        }
      }

      _createWebTransport() {
        const player = this.player;
        const {
          debug,
          events: {
            proxy
          },
          demux
        } = player;

        try {
          this.transport = new WebTransport(this.wtUrl);
          this.transport.ready.then(() => {
            this.emit(EVENTS.streamSuccess);
            this.startStreamRateInterval();
            this.transport.createBidirectionalStream().then(stream => {
              stream.readable.pipeTo(new WritableStream(demux.input));
            });
          }).catch(e => {
            this.player.debug.warn('WebTransportLoader', '_createWebTransport-ready', e);
          });
        } catch (e) {
          this.player.debug.warn('WebTransportLoader', '_createWebTransport', e);
        }
      }

      fetchStream(url) {
        this.player._times.streamStart = now$1();
        this.wtUrl = url.replace(/^wt/, 'https');

        this._createWebTransport();
      }

      abort() {
        if (this.transport) {
          try {
            this.transport.close();
            this.transport = null;
          } catch (e) {
            this.transport = null;
          }
        }
      }

    }

    class WorkerLoader extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.workUrl = null;
        player.debug.log('WorkerStream', 'init');
      }

      destroy() {
        this.workUrl = null;
        this.player.debug.log('WorkerStream', 'destroy');
      }

      fetchStream(url) {
        this.workUrl = url;
        this.player._times.streamStart = now$1();
        this.player.decoderWorker.workerFetchStream(url);
      }

    }

    class Stream {
      constructor(player) {
        const Loader = Stream.getLoaderFactory(player._opt);
        return new Loader(player);
      }

      static getLoaderFactory(opt) {
        const {
          protocol,
          useWasm,
          playType
        } = opt;

        if (protocol === PLAYER_PLAY_PROTOCOL.fetch) {
          if (playType === PLAY_TYPE.player) {
            if (useWasm && !onlyMseOrWcsVideo(opt)) {
              return WorkerLoader; // return FetchLoader;
            } else {
              return FetchLoader;
            }
          } else {
            return WorkerLoader; // return FetchLoader;
          }
        } else if (protocol === PLAYER_PLAY_PROTOCOL.websocket) {
          if (playType === PLAY_TYPE.player) {
            if (useWasm && !onlyMseOrWcsVideo(opt)) {
              return WorkerLoader; // return WebsocketLoader;
            } else {
              return WebsocketLoader;
            }
          } else {
            return WorkerLoader; // return WebsocketLoader;
          }
        } else if (protocol === PLAYER_PLAY_PROTOCOL.hls) {
          return HlsLoader;
        } else if (protocol === PLAYER_PLAY_PROTOCOL.webrtc) {
          return WebrtcLoader;
        } else if (protocol === PLAYER_PLAY_PROTOCOL.webTransport) {
          return WebTransportLoader$1;
        }
      }

    }

    var RecordRTC_1 = createCommonjsModule(function (module) {

    // Last time updated: 2021-03-09 3:20:22 AM UTC

    // ________________
    // RecordRTC v5.6.2

    // Open-Sourced: https://github.com/muaz-khan/RecordRTC

    // --------------------------------------------------
    // Muaz Khan     - www.MuazKhan.com
    // MIT License   - www.WebRTC-Experiment.com/licence
    // --------------------------------------------------

    // ____________
    // RecordRTC.js

    /**
     * {@link https://github.com/muaz-khan/RecordRTC|RecordRTC} is a WebRTC JavaScript library for audio/video as well as screen activity recording. It supports Chrome, Firefox, Opera, Android, and Microsoft Edge. Platforms: Linux, Mac and Windows. 
     * @summary Record audio, video or screen inside the browser.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef RecordRTC
     * @class
     * @example
     * var recorder = RecordRTC(mediaStream or [arrayOfMediaStream], {
     *     type: 'video', // audio or video or gif or canvas
     *     recorderType: MediaStreamRecorder || CanvasRecorder || StereoAudioRecorder || Etc
     * });
     * recorder.startRecording();
     * @see For further information:
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     * @param {MediaStream} mediaStream - Single media-stream object, array of media-streams, html-canvas-element, etc.
     * @param {object} config - {type:"video", recorderType: MediaStreamRecorder, disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, desiredSampRate: 16000, video: HTMLVideoElement, etc.}
     */

    function RecordRTC(mediaStream, config) {
        if (!mediaStream) {
            throw 'First parameter is required.';
        }

        config = config || {
            type: 'video'
        };

        config = new RecordRTCConfiguration(mediaStream, config);

        // a reference to user's recordRTC object
        var self = this;

        function startRecording(config2) {
            if (!config.disableLogs) {
                console.log('RecordRTC version: ', self.version);
            }

            if (!!config2) {
                // allow users to set options using startRecording method
                // config2 is similar to main "config" object (second parameter over RecordRTC constructor)
                config = new RecordRTCConfiguration(mediaStream, config2);
            }

            if (!config.disableLogs) {
                console.log('started recording ' + config.type + ' stream.');
            }

            if (mediaRecorder) {
                mediaRecorder.clearRecordedData();
                mediaRecorder.record();

                setState('recording');

                if (self.recordingDuration) {
                    handleRecordingDuration();
                }
                return self;
            }

            initRecorder(function() {
                if (self.recordingDuration) {
                    handleRecordingDuration();
                }
            });

            return self;
        }

        function initRecorder(initCallback) {
            if (initCallback) {
                config.initCallback = function() {
                    initCallback();
                    initCallback = config.initCallback = null; // recorder.initRecorder should be call-backed once.
                };
            }

            var Recorder = new GetRecorderType(mediaStream, config);

            mediaRecorder = new Recorder(mediaStream, config);
            mediaRecorder.record();

            setState('recording');

            if (!config.disableLogs) {
                console.log('Initialized recorderType:', mediaRecorder.constructor.name, 'for output-type:', config.type);
            }
        }

        function stopRecording(callback) {
            callback = callback || function() {};

            if (!mediaRecorder) {
                warningLog();
                return;
            }

            if (self.state === 'paused') {
                self.resumeRecording();

                setTimeout(function() {
                    stopRecording(callback);
                }, 1);
                return;
            }

            if (self.state !== 'recording' && !config.disableLogs) {
                console.warn('Recording state should be: "recording", however current state is: ', self.state);
            }

            if (!config.disableLogs) {
                console.log('Stopped recording ' + config.type + ' stream.');
            }

            if (config.type !== 'gif') {
                mediaRecorder.stop(_callback);
            } else {
                mediaRecorder.stop();
                _callback();
            }

            setState('stopped');

            function _callback(__blob) {
                if (!mediaRecorder) {
                    if (typeof callback.call === 'function') {
                        callback.call(self, '');
                    } else {
                        callback('');
                    }
                    return;
                }

                Object.keys(mediaRecorder).forEach(function(key) {
                    if (typeof mediaRecorder[key] === 'function') {
                        return;
                    }

                    self[key] = mediaRecorder[key];
                });

                var blob = mediaRecorder.blob;

                if (!blob) {
                    if (__blob) {
                        mediaRecorder.blob = blob = __blob;
                    } else {
                        throw 'Recording failed.';
                    }
                }

                if (blob && !config.disableLogs) {
                    console.log(blob.type, '->', bytesToSize(blob.size));
                }

                if (callback) {
                    var url;

                    try {
                        url = URL.createObjectURL(blob);
                    } catch (e) {}

                    if (typeof callback.call === 'function') {
                        callback.call(self, url);
                    } else {
                        callback(url);
                    }
                }

                if (!config.autoWriteToDisk) {
                    return;
                }

                getDataURL(function(dataURL) {
                    var parameter = {};
                    parameter[config.type + 'Blob'] = dataURL;
                    DiskStorage.Store(parameter);
                });
            }
        }

        function pauseRecording() {
            if (!mediaRecorder) {
                warningLog();
                return;
            }

            if (self.state !== 'recording') {
                if (!config.disableLogs) {
                    console.warn('Unable to pause the recording. Recording state: ', self.state);
                }
                return;
            }

            setState('paused');

            mediaRecorder.pause();

            if (!config.disableLogs) {
                console.log('Paused recording.');
            }
        }

        function resumeRecording() {
            if (!mediaRecorder) {
                warningLog();
                return;
            }

            if (self.state !== 'paused') {
                if (!config.disableLogs) {
                    console.warn('Unable to resume the recording. Recording state: ', self.state);
                }
                return;
            }

            setState('recording');

            // not all libs have this method yet
            mediaRecorder.resume();

            if (!config.disableLogs) {
                console.log('Resumed recording.');
            }
        }

        function readFile(_blob) {
            postMessage(new FileReaderSync().readAsDataURL(_blob));
        }

        function getDataURL(callback, _mediaRecorder) {
            if (!callback) {
                throw 'Pass a callback function over getDataURL.';
            }

            var blob = _mediaRecorder ? _mediaRecorder.blob : (mediaRecorder || {}).blob;

            if (!blob) {
                if (!config.disableLogs) {
                    console.warn('Blob encoder did not finish its job yet.');
                }

                setTimeout(function() {
                    getDataURL(callback, _mediaRecorder);
                }, 1000);
                return;
            }

            if (typeof Worker !== 'undefined' && !navigator.mozGetUserMedia) {
                var webWorker = processInWebWorker(readFile);

                webWorker.onmessage = function(event) {
                    callback(event.data);
                };

                webWorker.postMessage(blob);
            } else {
                var reader = new FileReader();
                reader.readAsDataURL(blob);
                reader.onload = function(event) {
                    callback(event.target.result);
                };
            }

            function processInWebWorker(_function) {
                try {
                    var blob = URL.createObjectURL(new Blob([_function.toString(),
                        'this.onmessage =  function (eee) {' + _function.name + '(eee.data);}'
                    ], {
                        type: 'application/javascript'
                    }));

                    var worker = new Worker(blob);
                    URL.revokeObjectURL(blob);
                    return worker;
                } catch (e) {}
            }
        }

        function handleRecordingDuration(counter) {
            counter = counter || 0;

            if (self.state === 'paused') {
                setTimeout(function() {
                    handleRecordingDuration(counter);
                }, 1000);
                return;
            }

            if (self.state === 'stopped') {
                return;
            }

            if (counter >= self.recordingDuration) {
                stopRecording(self.onRecordingStopped);
                return;
            }

            counter += 1000; // 1-second

            setTimeout(function() {
                handleRecordingDuration(counter);
            }, 1000);
        }

        function setState(state) {
            if (!self) {
                return;
            }

            self.state = state;

            if (typeof self.onStateChanged.call === 'function') {
                self.onStateChanged.call(self, state);
            } else {
                self.onStateChanged(state);
            }
        }

        var WARNING = 'It seems that recorder is destroyed or "startRecording" is not invoked for ' + config.type + ' recorder.';

        function warningLog() {
            if (config.disableLogs === true) {
                return;
            }

            console.warn(WARNING);
        }

        var mediaRecorder;

        var returnObject = {
            /**
             * This method starts the recording.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * var recorder = RecordRTC(mediaStream, {
             *     type: 'video'
             * });
             * recorder.startRecording();
             */
            startRecording: startRecording,

            /**
             * This method stops the recording. It is strongly recommended to get "blob" or "URI" inside the callback to make sure all recorders finished their job.
             * @param {function} callback - Callback to get the recorded blob.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * recorder.stopRecording(function() {
             *     // use either "this" or "recorder" object; both are identical
             *     video.src = this.toURL();
             *     var blob = this.getBlob();
             * });
             */
            stopRecording: stopRecording,

            /**
             * This method pauses the recording. You can resume recording using "resumeRecording" method.
             * @method
             * @memberof RecordRTC
             * @instance
             * @todo Firefox is unable to pause the recording. Fix it.
             * @example
             * recorder.pauseRecording();  // pause the recording
             * recorder.resumeRecording(); // resume again
             */
            pauseRecording: pauseRecording,

            /**
             * This method resumes the recording.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * recorder.pauseRecording();  // first of all, pause the recording
             * recorder.resumeRecording(); // now resume it
             */
            resumeRecording: resumeRecording,

            /**
             * This method initializes the recording.
             * @method
             * @memberof RecordRTC
             * @instance
             * @todo This method should be deprecated.
             * @example
             * recorder.initRecorder();
             */
            initRecorder: initRecorder,

            /**
             * Ask RecordRTC to auto-stop the recording after 5 minutes.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * var fiveMinutes = 5 * 1000 * 60;
             * recorder.setRecordingDuration(fiveMinutes, function() {
             *    var blob = this.getBlob();
             *    video.src = this.toURL();
             * });
             * 
             * // or otherwise
             * recorder.setRecordingDuration(fiveMinutes).onRecordingStopped(function() {
             *    var blob = this.getBlob();
             *    video.src = this.toURL();
             * });
             */
            setRecordingDuration: function(recordingDuration, callback) {
                if (typeof recordingDuration === 'undefined') {
                    throw 'recordingDuration is required.';
                }

                if (typeof recordingDuration !== 'number') {
                    throw 'recordingDuration must be a number.';
                }

                self.recordingDuration = recordingDuration;
                self.onRecordingStopped = callback || function() {};

                return {
                    onRecordingStopped: function(callback) {
                        self.onRecordingStopped = callback;
                    }
                };
            },

            /**
             * This method can be used to clear/reset all the recorded data.
             * @method
             * @memberof RecordRTC
             * @instance
             * @todo Figure out the difference between "reset" and "clearRecordedData" methods.
             * @example
             * recorder.clearRecordedData();
             */
            clearRecordedData: function() {
                if (!mediaRecorder) {
                    warningLog();
                    return;
                }

                mediaRecorder.clearRecordedData();

                if (!config.disableLogs) {
                    console.log('Cleared old recorded data.');
                }
            },

            /**
             * Get the recorded blob. Use this method inside the "stopRecording" callback.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * recorder.stopRecording(function() {
             *     var blob = this.getBlob();
             *
             *     var file = new File([blob], 'filename.webm', {
             *         type: 'video/webm'
             *     });
             *
             *     var formData = new FormData();
             *     formData.append('file', file); // upload "File" object rather than a "Blob"
             *     uploadToServer(formData);
             * });
             * @returns {Blob} Returns recorded data as "Blob" object.
             */
            getBlob: function() {
                if (!mediaRecorder) {
                    warningLog();
                    return;
                }

                return mediaRecorder.blob;
            },

            /**
             * Get data-URI instead of Blob.
             * @param {function} callback - Callback to get the Data-URI.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * recorder.stopRecording(function() {
             *     recorder.getDataURL(function(dataURI) {
             *         video.src = dataURI;
             *     });
             * });
             */
            getDataURL: getDataURL,

            /**
             * Get virtual/temporary URL. Usage of this URL is limited to current tab.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * recorder.stopRecording(function() {
             *     video.src = this.toURL();
             * });
             * @returns {String} Returns a virtual/temporary URL for the recorded "Blob".
             */
            toURL: function() {
                if (!mediaRecorder) {
                    warningLog();
                    return;
                }

                return URL.createObjectURL(mediaRecorder.blob);
            },

            /**
             * Get internal recording object (i.e. internal module) e.g. MutliStreamRecorder, MediaStreamRecorder, StereoAudioRecorder or WhammyRecorder etc.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * var internalRecorder = recorder.getInternalRecorder();
             * if(internalRecorder instanceof MultiStreamRecorder) {
             *     internalRecorder.addStreams([newAudioStream]);
             *     internalRecorder.resetVideoStreams([screenStream]);
             * }
             * @returns {Object} Returns internal recording object.
             */
            getInternalRecorder: function() {
                return mediaRecorder;
            },

            /**
             * Invoke save-as dialog to save the recorded blob into your disk.
             * @param {string} fileName - Set your own file name.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * recorder.stopRecording(function() {
             *     this.save('file-name');
             *
             *     // or manually:
             *     invokeSaveAsDialog(this.getBlob(), 'filename.webm');
             * });
             */
            save: function(fileName) {
                if (!mediaRecorder) {
                    warningLog();
                    return;
                }

                invokeSaveAsDialog(mediaRecorder.blob, fileName);
            },

            /**
             * This method gets a blob from indexed-DB storage.
             * @param {function} callback - Callback to get the recorded blob.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * recorder.getFromDisk(function(dataURL) {
             *     video.src = dataURL;
             * });
             */
            getFromDisk: function(callback) {
                if (!mediaRecorder) {
                    warningLog();
                    return;
                }

                RecordRTC.getFromDisk(config.type, callback);
            },

            /**
             * This method appends an array of webp images to the recorded video-blob. It takes an "array" object.
             * @type {Array.<Array>}
             * @param {Array} arrayOfWebPImages - Array of webp images.
             * @method
             * @memberof RecordRTC
             * @instance
             * @todo This method should be deprecated.
             * @example
             * var arrayOfWebPImages = [];
             * arrayOfWebPImages.push({
             *     duration: index,
             *     image: 'data:image/webp;base64,...'
             * });
             * recorder.setAdvertisementArray(arrayOfWebPImages);
             */
            setAdvertisementArray: function(arrayOfWebPImages) {
                config.advertisement = [];

                var length = arrayOfWebPImages.length;
                for (var i = 0; i < length; i++) {
                    config.advertisement.push({
                        duration: i,
                        image: arrayOfWebPImages[i]
                    });
                }
            },

            /**
             * It is equivalent to <code class="str">"recorder.getBlob()"</code> method. Usage of "getBlob" is recommended, though.
             * @property {Blob} blob - Recorded Blob can be accessed using this property.
             * @memberof RecordRTC
             * @instance
             * @readonly
             * @example
             * recorder.stopRecording(function() {
             *     var blob = this.blob;
             *
             *     // below one is recommended
             *     var blob = this.getBlob();
             * });
             */
            blob: null,

            /**
             * This works only with {recorderType:StereoAudioRecorder}. Use this property on "stopRecording" to verify the encoder's sample-rates.
             * @property {number} bufferSize - Buffer-size used to encode the WAV container
             * @memberof RecordRTC
             * @instance
             * @readonly
             * @example
             * recorder.stopRecording(function() {
             *     alert('Recorder used this buffer-size: ' + this.bufferSize);
             * });
             */
            bufferSize: 0,

            /**
             * This works only with {recorderType:StereoAudioRecorder}. Use this property on "stopRecording" to verify the encoder's sample-rates.
             * @property {number} sampleRate - Sample-rates used to encode the WAV container
             * @memberof RecordRTC
             * @instance
             * @readonly
             * @example
             * recorder.stopRecording(function() {
             *     alert('Recorder used these sample-rates: ' + this.sampleRate);
             * });
             */
            sampleRate: 0,

            /**
             * {recorderType:StereoAudioRecorder} returns ArrayBuffer object.
             * @property {ArrayBuffer} buffer - Audio ArrayBuffer, supported only in Chrome.
             * @memberof RecordRTC
             * @instance
             * @readonly
             * @example
             * recorder.stopRecording(function() {
             *     var arrayBuffer = this.buffer;
             *     alert(arrayBuffer.byteLength);
             * });
             */
            buffer: null,

            /**
             * This method resets the recorder. So that you can reuse single recorder instance many times.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * recorder.reset();
             * recorder.startRecording();
             */
            reset: function() {
                if (self.state === 'recording' && !config.disableLogs) {
                    console.warn('Stop an active recorder.');
                }

                if (mediaRecorder && typeof mediaRecorder.clearRecordedData === 'function') {
                    mediaRecorder.clearRecordedData();
                }
                mediaRecorder = null;
                setState('inactive');
                self.blob = null;
            },

            /**
             * This method is called whenever recorder's state changes. Use this as an "event".
             * @property {String} state - A recorder's state can be: recording, paused, stopped or inactive.
             * @method
             * @memberof RecordRTC
             * @instance
             * @example
             * recorder.onStateChanged = function(state) {
             *     console.log('Recorder state: ', state);
             * };
             */
            onStateChanged: function(state) {
                if (!config.disableLogs) {
                    console.log('Recorder state changed:', state);
                }
            },

            /**
             * A recorder can have inactive, recording, paused or stopped states.
             * @property {String} state - A recorder's state can be: recording, paused, stopped or inactive.
             * @memberof RecordRTC
             * @static
             * @readonly
             * @example
             * // this looper function will keep you updated about the recorder's states.
             * (function looper() {
             *     document.querySelector('h1').innerHTML = 'Recorder\'s state is: ' + recorder.state;
             *     if(recorder.state === 'stopped') return; // ignore+stop
             *     setTimeout(looper, 1000); // update after every 3-seconds
             * })();
             * recorder.startRecording();
             */
            state: 'inactive',

            /**
             * Get recorder's readonly state.
             * @method
             * @memberof RecordRTC
             * @example
             * var state = recorder.getState();
             * @returns {String} Returns recording state.
             */
            getState: function() {
                return self.state;
            },

            /**
             * Destroy RecordRTC instance. Clear all recorders and objects.
             * @method
             * @memberof RecordRTC
             * @example
             * recorder.destroy();
             */
            destroy: function() {
                var disableLogsCache = config.disableLogs;

                config = {
                    disableLogs: true
                };
                self.reset();
                setState('destroyed');
                returnObject = self = null;

                if (Storage.AudioContextConstructor) {
                    Storage.AudioContextConstructor.close();
                    Storage.AudioContextConstructor = null;
                }

                config.disableLogs = disableLogsCache;

                if (!config.disableLogs) {
                    console.log('RecordRTC is destroyed.');
                }
            },

            /**
             * RecordRTC version number
             * @property {String} version - Release version number.
             * @memberof RecordRTC
             * @static
             * @readonly
             * @example
             * alert(recorder.version);
             */
            version: '5.6.2'
        };

        if (!this) {
            self = returnObject;
            return returnObject;
        }

        // if someone wants to use RecordRTC with the "new" keyword.
        for (var prop in returnObject) {
            this[prop] = returnObject[prop];
        }

        self = this;

        return returnObject;
    }

    RecordRTC.version = '5.6.2';

    {
        module.exports = RecordRTC;
    }

    RecordRTC.getFromDisk = function(type, callback) {
        if (!callback) {
            throw 'callback is mandatory.';
        }

        console.log('Getting recorded ' + (type === 'all' ? 'blobs' : type + ' blob ') + ' from disk!');
        DiskStorage.Fetch(function(dataURL, _type) {
            if (type !== 'all' && _type === type + 'Blob' && callback) {
                callback(dataURL);
            }

            if (type === 'all' && callback) {
                callback(dataURL, _type.replace('Blob', ''));
            }
        });
    };

    /**
     * This method can be used to store recorded blobs into IndexedDB storage.
     * @param {object} options - {audio: Blob, video: Blob, gif: Blob}
     * @method
     * @memberof RecordRTC
     * @example
     * RecordRTC.writeToDisk({
     *     audio: audioBlob,
     *     video: videoBlob,
     *     gif  : gifBlob
     * });
     */
    RecordRTC.writeToDisk = function(options) {
        console.log('Writing recorded blob(s) to disk!');
        options = options || {};
        if (options.audio && options.video && options.gif) {
            options.audio.getDataURL(function(audioDataURL) {
                options.video.getDataURL(function(videoDataURL) {
                    options.gif.getDataURL(function(gifDataURL) {
                        DiskStorage.Store({
                            audioBlob: audioDataURL,
                            videoBlob: videoDataURL,
                            gifBlob: gifDataURL
                        });
                    });
                });
            });
        } else if (options.audio && options.video) {
            options.audio.getDataURL(function(audioDataURL) {
                options.video.getDataURL(function(videoDataURL) {
                    DiskStorage.Store({
                        audioBlob: audioDataURL,
                        videoBlob: videoDataURL
                    });
                });
            });
        } else if (options.audio && options.gif) {
            options.audio.getDataURL(function(audioDataURL) {
                options.gif.getDataURL(function(gifDataURL) {
                    DiskStorage.Store({
                        audioBlob: audioDataURL,
                        gifBlob: gifDataURL
                    });
                });
            });
        } else if (options.video && options.gif) {
            options.video.getDataURL(function(videoDataURL) {
                options.gif.getDataURL(function(gifDataURL) {
                    DiskStorage.Store({
                        videoBlob: videoDataURL,
                        gifBlob: gifDataURL
                    });
                });
            });
        } else if (options.audio) {
            options.audio.getDataURL(function(audioDataURL) {
                DiskStorage.Store({
                    audioBlob: audioDataURL
                });
            });
        } else if (options.video) {
            options.video.getDataURL(function(videoDataURL) {
                DiskStorage.Store({
                    videoBlob: videoDataURL
                });
            });
        } else if (options.gif) {
            options.gif.getDataURL(function(gifDataURL) {
                DiskStorage.Store({
                    gifBlob: gifDataURL
                });
            });
        }
    };

    // __________________________
    // RecordRTC-Configuration.js

    /**
     * {@link RecordRTCConfiguration} is an inner/private helper for {@link RecordRTC}.
     * @summary It configures the 2nd parameter passed over {@link RecordRTC} and returns a valid "config" object.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef RecordRTCConfiguration
     * @class
     * @example
     * var options = RecordRTCConfiguration(mediaStream, options);
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
     * @param {object} config - {type:"video", disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, video: HTMLVideoElement, getNativeBlob:true, etc.}
     */

    function RecordRTCConfiguration(mediaStream, config) {
        if (!config.recorderType && !config.type) {
            if (!!config.audio && !!config.video) {
                config.type = 'video';
            } else if (!!config.audio && !config.video) {
                config.type = 'audio';
            }
        }

        if (config.recorderType && !config.type) {
            if (config.recorderType === WhammyRecorder || config.recorderType === CanvasRecorder || (typeof WebAssemblyRecorder !== 'undefined' && config.recorderType === WebAssemblyRecorder)) {
                config.type = 'video';
            } else if (config.recorderType === GifRecorder) {
                config.type = 'gif';
            } else if (config.recorderType === StereoAudioRecorder) {
                config.type = 'audio';
            } else if (config.recorderType === MediaStreamRecorder) {
                if (getTracks(mediaStream, 'audio').length && getTracks(mediaStream, 'video').length) {
                    config.type = 'video';
                } else if (!getTracks(mediaStream, 'audio').length && getTracks(mediaStream, 'video').length) {
                    config.type = 'video';
                } else if (getTracks(mediaStream, 'audio').length && !getTracks(mediaStream, 'video').length) {
                    config.type = 'audio';
                } else ;
            }
        }

        if (typeof MediaStreamRecorder !== 'undefined' && typeof MediaRecorder !== 'undefined' && 'requestData' in MediaRecorder.prototype) {
            if (!config.mimeType) {
                config.mimeType = 'video/webm';
            }

            if (!config.type) {
                config.type = config.mimeType.split('/')[0];
            }

            if (!config.bitsPerSecond) ;
        }

        // consider default type=audio
        if (!config.type) {
            if (config.mimeType) {
                config.type = config.mimeType.split('/')[0];
            }
            if (!config.type) {
                config.type = 'audio';
            }
        }

        return config;
    }

    // __________________
    // GetRecorderType.js

    /**
     * {@link GetRecorderType} is an inner/private helper for {@link RecordRTC}.
     * @summary It returns best recorder-type available for your browser.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef GetRecorderType
     * @class
     * @example
     * var RecorderType = GetRecorderType(options);
     * var recorder = new RecorderType(options);
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
     * @param {object} config - {type:"video", disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, video: HTMLVideoElement, etc.}
     */

    function GetRecorderType(mediaStream, config) {
        var recorder;

        // StereoAudioRecorder can work with all three: Edge, Firefox and Chrome
        // todo: detect if it is Edge, then auto use: StereoAudioRecorder
        if (isChrome || isEdge || isOpera) {
            // Media Stream Recording API has not been implemented in chrome yet;
            // That's why using WebAudio API to record stereo audio in WAV format
            recorder = StereoAudioRecorder;
        }

        if (typeof MediaRecorder !== 'undefined' && 'requestData' in MediaRecorder.prototype && !isChrome) {
            recorder = MediaStreamRecorder;
        }

        // video recorder (in WebM format)
        if (config.type === 'video' && (isChrome || isOpera)) {
            recorder = WhammyRecorder;

            if (typeof WebAssemblyRecorder !== 'undefined' && typeof ReadableStream !== 'undefined') {
                recorder = WebAssemblyRecorder;
            }
        }

        // video recorder (in Gif format)
        if (config.type === 'gif') {
            recorder = GifRecorder;
        }

        // html2canvas recording!
        if (config.type === 'canvas') {
            recorder = CanvasRecorder;
        }

        if (isMediaRecorderCompatible() && recorder !== CanvasRecorder && recorder !== GifRecorder && typeof MediaRecorder !== 'undefined' && 'requestData' in MediaRecorder.prototype) {
            if (getTracks(mediaStream, 'video').length || getTracks(mediaStream, 'audio').length) {
                // audio-only recording
                if (config.type === 'audio') {
                    if (typeof MediaRecorder.isTypeSupported === 'function' && MediaRecorder.isTypeSupported('audio/webm')) {
                        recorder = MediaStreamRecorder;
                    }
                    // else recorder = StereoAudioRecorder;
                } else {
                    // video or screen tracks
                    if (typeof MediaRecorder.isTypeSupported === 'function' && MediaRecorder.isTypeSupported('video/webm')) {
                        recorder = MediaStreamRecorder;
                    }
                }
            }
        }

        if (mediaStream instanceof Array && mediaStream.length) {
            recorder = MultiStreamRecorder;
        }

        if (config.recorderType) {
            recorder = config.recorderType;
        }

        if (!config.disableLogs && !!recorder && !!recorder.name) {
            console.log('Using recorderType:', recorder.name || recorder.constructor.name);
        }

        if (!recorder && isSafari) {
            recorder = MediaStreamRecorder;
        }

        return recorder;
    }

    // _____________
    // MRecordRTC.js

    /**
     * MRecordRTC runs on top of {@link RecordRTC} to bring multiple recordings in a single place, by providing simple API.
     * @summary MRecordRTC stands for "Multiple-RecordRTC".
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef MRecordRTC
     * @class
     * @example
     * var recorder = new MRecordRTC();
     * recorder.addStream(MediaStream);
     * recorder.mediaType = {
     *     audio: true, // or StereoAudioRecorder or MediaStreamRecorder
     *     video: true, // or WhammyRecorder or MediaStreamRecorder or WebAssemblyRecorder or CanvasRecorder
     *     gif: true    // or GifRecorder
     * };
     * // mimeType is optional and should be set only in advance cases.
     * recorder.mimeType = {
     *     audio: 'audio/wav',
     *     video: 'video/webm',
     *     gif:   'image/gif'
     * };
     * recorder.startRecording();
     * @see For further information:
     * @see {@link https://github.com/muaz-khan/RecordRTC/tree/master/MRecordRTC|MRecordRTC Source Code}
     * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
     * @requires {@link RecordRTC}
     */

    function MRecordRTC(mediaStream) {

        /**
         * This method attaches MediaStream object to {@link MRecordRTC}.
         * @param {MediaStream} mediaStream - A MediaStream object, either fetched using getUserMedia API, or generated using captureStreamUntilEnded or WebAudio API.
         * @method
         * @memberof MRecordRTC
         * @example
         * recorder.addStream(MediaStream);
         */
        this.addStream = function(_mediaStream) {
            if (_mediaStream) {
                mediaStream = _mediaStream;
            }
        };

        /**
         * This property can be used to set the recording type e.g. audio, or video, or gif, or canvas.
         * @property {object} mediaType - {audio: true, video: true, gif: true}
         * @memberof MRecordRTC
         * @example
         * var recorder = new MRecordRTC();
         * recorder.mediaType = {
         *     audio: true, // TRUE or StereoAudioRecorder or MediaStreamRecorder
         *     video: true, // TRUE or WhammyRecorder or MediaStreamRecorder or WebAssemblyRecorder or CanvasRecorder
         *     gif  : true  // TRUE or GifRecorder
         * };
         */
        this.mediaType = {
            audio: true,
            video: true
        };

        /**
         * This method starts recording.
         * @method
         * @memberof MRecordRTC
         * @example
         * recorder.startRecording();
         */
        this.startRecording = function() {
            var mediaType = this.mediaType;
            var recorderType;
            var mimeType = this.mimeType || {
                audio: null,
                video: null,
                gif: null
            };

            if (typeof mediaType.audio !== 'function' && isMediaRecorderCompatible() && !getTracks(mediaStream, 'audio').length) {
                mediaType.audio = false;
            }

            if (typeof mediaType.video !== 'function' && isMediaRecorderCompatible() && !getTracks(mediaStream, 'video').length) {
                mediaType.video = false;
            }

            if (typeof mediaType.gif !== 'function' && isMediaRecorderCompatible() && !getTracks(mediaStream, 'video').length) {
                mediaType.gif = false;
            }

            if (!mediaType.audio && !mediaType.video && !mediaType.gif) {
                throw 'MediaStream must have either audio or video tracks.';
            }

            if (!!mediaType.audio) {
                recorderType = null;
                if (typeof mediaType.audio === 'function') {
                    recorderType = mediaType.audio;
                }

                this.audioRecorder = new RecordRTC(mediaStream, {
                    type: 'audio',
                    bufferSize: this.bufferSize,
                    sampleRate: this.sampleRate,
                    numberOfAudioChannels: this.numberOfAudioChannels || 2,
                    disableLogs: this.disableLogs,
                    recorderType: recorderType,
                    mimeType: mimeType.audio,
                    timeSlice: this.timeSlice,
                    onTimeStamp: this.onTimeStamp
                });

                if (!mediaType.video) {
                    this.audioRecorder.startRecording();
                }
            }

            if (!!mediaType.video) {
                recorderType = null;
                if (typeof mediaType.video === 'function') {
                    recorderType = mediaType.video;
                }

                var newStream = mediaStream;

                if (isMediaRecorderCompatible() && !!mediaType.audio && typeof mediaType.audio === 'function') {
                    var videoTrack = getTracks(mediaStream, 'video')[0];

                    if (isFirefox) {
                        newStream = new MediaStream();
                        newStream.addTrack(videoTrack);

                        if (recorderType && recorderType === WhammyRecorder) {
                            // Firefox does NOT supports webp-encoding yet
                            // But Firefox do supports WebAssemblyRecorder
                            recorderType = MediaStreamRecorder;
                        }
                    } else {
                        newStream = new MediaStream();
                        newStream.addTrack(videoTrack);
                    }
                }

                this.videoRecorder = new RecordRTC(newStream, {
                    type: 'video',
                    video: this.video,
                    canvas: this.canvas,
                    frameInterval: this.frameInterval || 10,
                    disableLogs: this.disableLogs,
                    recorderType: recorderType,
                    mimeType: mimeType.video,
                    timeSlice: this.timeSlice,
                    onTimeStamp: this.onTimeStamp,
                    workerPath: this.workerPath,
                    webAssemblyPath: this.webAssemblyPath,
                    frameRate: this.frameRate, // used by WebAssemblyRecorder; values: usually 30; accepts any.
                    bitrate: this.bitrate // used by WebAssemblyRecorder; values: 0 to 1000+
                });

                if (!mediaType.audio) {
                    this.videoRecorder.startRecording();
                }
            }

            if (!!mediaType.audio && !!mediaType.video) {
                var self = this;

                var isSingleRecorder = isMediaRecorderCompatible() === true;

                if (mediaType.audio instanceof StereoAudioRecorder && !!mediaType.video) {
                    isSingleRecorder = false;
                } else if (mediaType.audio !== true && mediaType.video !== true && mediaType.audio !== mediaType.video) {
                    isSingleRecorder = false;
                }

                if (isSingleRecorder === true) {
                    self.audioRecorder = null;
                    self.videoRecorder.startRecording();
                } else {
                    self.videoRecorder.initRecorder(function() {
                        self.audioRecorder.initRecorder(function() {
                            // Both recorders are ready to record things accurately
                            self.videoRecorder.startRecording();
                            self.audioRecorder.startRecording();
                        });
                    });
                }
            }

            if (!!mediaType.gif) {
                recorderType = null;
                if (typeof mediaType.gif === 'function') {
                    recorderType = mediaType.gif;
                }
                this.gifRecorder = new RecordRTC(mediaStream, {
                    type: 'gif',
                    frameRate: this.frameRate || 200,
                    quality: this.quality || 10,
                    disableLogs: this.disableLogs,
                    recorderType: recorderType,
                    mimeType: mimeType.gif
                });
                this.gifRecorder.startRecording();
            }
        };

        /**
         * This method stops recording.
         * @param {function} callback - Callback function is invoked when all encoders finished their jobs.
         * @method
         * @memberof MRecordRTC
         * @example
         * recorder.stopRecording(function(recording){
         *     var audioBlob = recording.audio;
         *     var videoBlob = recording.video;
         *     var gifBlob   = recording.gif;
         * });
         */
        this.stopRecording = function(callback) {
            callback = callback || function() {};

            if (this.audioRecorder) {
                this.audioRecorder.stopRecording(function(blobURL) {
                    callback(blobURL, 'audio');
                });
            }

            if (this.videoRecorder) {
                this.videoRecorder.stopRecording(function(blobURL) {
                    callback(blobURL, 'video');
                });
            }

            if (this.gifRecorder) {
                this.gifRecorder.stopRecording(function(blobURL) {
                    callback(blobURL, 'gif');
                });
            }
        };

        /**
         * This method pauses recording.
         * @method
         * @memberof MRecordRTC
         * @example
         * recorder.pauseRecording();
         */
        this.pauseRecording = function() {
            if (this.audioRecorder) {
                this.audioRecorder.pauseRecording();
            }

            if (this.videoRecorder) {
                this.videoRecorder.pauseRecording();
            }

            if (this.gifRecorder) {
                this.gifRecorder.pauseRecording();
            }
        };

        /**
         * This method resumes recording.
         * @method
         * @memberof MRecordRTC
         * @example
         * recorder.resumeRecording();
         */
        this.resumeRecording = function() {
            if (this.audioRecorder) {
                this.audioRecorder.resumeRecording();
            }

            if (this.videoRecorder) {
                this.videoRecorder.resumeRecording();
            }

            if (this.gifRecorder) {
                this.gifRecorder.resumeRecording();
            }
        };

        /**
         * This method can be used to manually get all recorded blobs.
         * @param {function} callback - All recorded blobs are passed back to the "callback" function.
         * @method
         * @memberof MRecordRTC
         * @example
         * recorder.getBlob(function(recording){
         *     var audioBlob = recording.audio;
         *     var videoBlob = recording.video;
         *     var gifBlob   = recording.gif;
         * });
         * // or
         * var audioBlob = recorder.getBlob().audio;
         * var videoBlob = recorder.getBlob().video;
         */
        this.getBlob = function(callback) {
            var output = {};

            if (this.audioRecorder) {
                output.audio = this.audioRecorder.getBlob();
            }

            if (this.videoRecorder) {
                output.video = this.videoRecorder.getBlob();
            }

            if (this.gifRecorder) {
                output.gif = this.gifRecorder.getBlob();
            }

            if (callback) {
                callback(output);
            }

            return output;
        };

        /**
         * Destroy all recorder instances.
         * @method
         * @memberof MRecordRTC
         * @example
         * recorder.destroy();
         */
        this.destroy = function() {
            if (this.audioRecorder) {
                this.audioRecorder.destroy();
                this.audioRecorder = null;
            }

            if (this.videoRecorder) {
                this.videoRecorder.destroy();
                this.videoRecorder = null;
            }

            if (this.gifRecorder) {
                this.gifRecorder.destroy();
                this.gifRecorder = null;
            }
        };

        /**
         * This method can be used to manually get all recorded blobs' DataURLs.
         * @param {function} callback - All recorded blobs' DataURLs are passed back to the "callback" function.
         * @method
         * @memberof MRecordRTC
         * @example
         * recorder.getDataURL(function(recording){
         *     var audioDataURL = recording.audio;
         *     var videoDataURL = recording.video;
         *     var gifDataURL   = recording.gif;
         * });
         */
        this.getDataURL = function(callback) {
            this.getBlob(function(blob) {
                if (blob.audio && blob.video) {
                    getDataURL(blob.audio, function(_audioDataURL) {
                        getDataURL(blob.video, function(_videoDataURL) {
                            callback({
                                audio: _audioDataURL,
                                video: _videoDataURL
                            });
                        });
                    });
                } else if (blob.audio) {
                    getDataURL(blob.audio, function(_audioDataURL) {
                        callback({
                            audio: _audioDataURL
                        });
                    });
                } else if (blob.video) {
                    getDataURL(blob.video, function(_videoDataURL) {
                        callback({
                            video: _videoDataURL
                        });
                    });
                }
            });

            function getDataURL(blob, callback00) {
                if (typeof Worker !== 'undefined') {
                    var webWorker = processInWebWorker(function readFile(_blob) {
                        postMessage(new FileReaderSync().readAsDataURL(_blob));
                    });

                    webWorker.onmessage = function(event) {
                        callback00(event.data);
                    };

                    webWorker.postMessage(blob);
                } else {
                    var reader = new FileReader();
                    reader.readAsDataURL(blob);
                    reader.onload = function(event) {
                        callback00(event.target.result);
                    };
                }
            }

            function processInWebWorker(_function) {
                var blob = URL.createObjectURL(new Blob([_function.toString(),
                    'this.onmessage =  function (eee) {' + _function.name + '(eee.data);}'
                ], {
                    type: 'application/javascript'
                }));

                var worker = new Worker(blob);
                var url;
                if (typeof URL !== 'undefined') {
                    url = URL;
                } else if (typeof webkitURL !== 'undefined') {
                    url = webkitURL;
                } else {
                    throw 'Neither URL nor webkitURL detected.';
                }
                url.revokeObjectURL(blob);
                return worker;
            }
        };

        /**
         * This method can be used to ask {@link MRecordRTC} to write all recorded blobs into IndexedDB storage.
         * @method
         * @memberof MRecordRTC
         * @example
         * recorder.writeToDisk();
         */
        this.writeToDisk = function() {
            RecordRTC.writeToDisk({
                audio: this.audioRecorder,
                video: this.videoRecorder,
                gif: this.gifRecorder
            });
        };

        /**
         * This method can be used to invoke a save-as dialog for all recorded blobs.
         * @param {object} args - {audio: 'audio-name', video: 'video-name', gif: 'gif-name'}
         * @method
         * @memberof MRecordRTC
         * @example
         * recorder.save({
         *     audio: 'audio-file-name',
         *     video: 'video-file-name',
         *     gif  : 'gif-file-name'
         * });
         */
        this.save = function(args) {
            args = args || {
                audio: true,
                video: true,
                gif: true
            };

            if (!!args.audio && this.audioRecorder) {
                this.audioRecorder.save(typeof args.audio === 'string' ? args.audio : '');
            }

            if (!!args.video && this.videoRecorder) {
                this.videoRecorder.save(typeof args.video === 'string' ? args.video : '');
            }
            if (!!args.gif && this.gifRecorder) {
                this.gifRecorder.save(typeof args.gif === 'string' ? args.gif : '');
            }
        };
    }

    /**
     * This method can be used to get all recorded blobs from IndexedDB storage.
     * @param {string} type - 'all' or 'audio' or 'video' or 'gif'
     * @param {function} callback - Callback function to get all stored blobs.
     * @method
     * @memberof MRecordRTC
     * @example
     * MRecordRTC.getFromDisk('all', function(dataURL, type){
     *     if(type === 'audio') { }
     *     if(type === 'video') { }
     *     if(type === 'gif')   { }
     * });
     */
    MRecordRTC.getFromDisk = RecordRTC.getFromDisk;

    /**
     * This method can be used to store recorded blobs into IndexedDB storage.
     * @param {object} options - {audio: Blob, video: Blob, gif: Blob}
     * @method
     * @memberof MRecordRTC
     * @example
     * MRecordRTC.writeToDisk({
     *     audio: audioBlob,
     *     video: videoBlob,
     *     gif  : gifBlob
     * });
     */
    MRecordRTC.writeToDisk = RecordRTC.writeToDisk;

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.MRecordRTC = MRecordRTC;
    }

    var browserFakeUserAgent = 'Fake/5.0 (FakeOS) AppleWebKit/123 (KHTML, like Gecko) Fake/12.3.4567.89 Fake/123.45';

    (function(that) {
        if (!that) {
            return;
        }

        if (typeof window !== 'undefined') {
            return;
        }

        if (typeof commonjsGlobal === 'undefined') {
            return;
        }

        commonjsGlobal.navigator = {
            userAgent: browserFakeUserAgent,
            getUserMedia: function() {}
        };

        if (!commonjsGlobal.console) {
            commonjsGlobal.console = {};
        }

        if (typeof commonjsGlobal.console.log === 'undefined' || typeof commonjsGlobal.console.error === 'undefined') {
            commonjsGlobal.console.error = commonjsGlobal.console.log = commonjsGlobal.console.log || function() {
                console.log(arguments);
            };
        }

        if (typeof document === 'undefined') {
            /*global document:true */
            that.document = {
                documentElement: {
                    appendChild: function() {
                        return '';
                    }
                }
            };

            document.createElement = document.captureStream = document.mozCaptureStream = function() {
                var obj = {
                    getContext: function() {
                        return obj;
                    },
                    play: function() {},
                    pause: function() {},
                    drawImage: function() {},
                    toDataURL: function() {
                        return '';
                    },
                    style: {}
                };
                return obj;
            };

            that.HTMLVideoElement = function() {};
        }

        if (typeof location === 'undefined') {
            /*global location:true */
            that.location = {
                protocol: 'file:',
                href: '',
                hash: ''
            };
        }

        if (typeof screen === 'undefined') {
            /*global screen:true */
            that.screen = {
                width: 0,
                height: 0
            };
        }

        if (typeof URL === 'undefined') {
            /*global screen:true */
            that.URL = {
                createObjectURL: function() {
                    return '';
                },
                revokeObjectURL: function() {
                    return '';
                }
            };
        }

        /*global window:true */
        that.window = commonjsGlobal;
    })(typeof commonjsGlobal !== 'undefined' ? commonjsGlobal : null);

    // _____________________________
    // Cross-Browser-Declarations.js

    // animation-frame used in WebM recording

    /*jshint -W079 */
    var requestAnimationFrame = window.requestAnimationFrame;
    if (typeof requestAnimationFrame === 'undefined') {
        if (typeof webkitRequestAnimationFrame !== 'undefined') {
            /*global requestAnimationFrame:true */
            requestAnimationFrame = webkitRequestAnimationFrame;
        } else if (typeof mozRequestAnimationFrame !== 'undefined') {
            /*global requestAnimationFrame:true */
            requestAnimationFrame = mozRequestAnimationFrame;
        } else if (typeof msRequestAnimationFrame !== 'undefined') {
            /*global requestAnimationFrame:true */
            requestAnimationFrame = msRequestAnimationFrame;
        } else if (typeof requestAnimationFrame === 'undefined') {
            // via: https://gist.github.com/paulirish/1579671
            var lastTime = 0;

            /*global requestAnimationFrame:true */
            requestAnimationFrame = function(callback, element) {
                var currTime = new Date().getTime();
                var timeToCall = Math.max(0, 16 - (currTime - lastTime));
                var id = setTimeout(function() {
                    callback(currTime + timeToCall);
                }, timeToCall);
                lastTime = currTime + timeToCall;
                return id;
            };
        }
    }

    /*jshint -W079 */
    var cancelAnimationFrame = window.cancelAnimationFrame;
    if (typeof cancelAnimationFrame === 'undefined') {
        if (typeof webkitCancelAnimationFrame !== 'undefined') {
            /*global cancelAnimationFrame:true */
            cancelAnimationFrame = webkitCancelAnimationFrame;
        } else if (typeof mozCancelAnimationFrame !== 'undefined') {
            /*global cancelAnimationFrame:true */
            cancelAnimationFrame = mozCancelAnimationFrame;
        } else if (typeof msCancelAnimationFrame !== 'undefined') {
            /*global cancelAnimationFrame:true */
            cancelAnimationFrame = msCancelAnimationFrame;
        } else if (typeof cancelAnimationFrame === 'undefined') {
            /*global cancelAnimationFrame:true */
            cancelAnimationFrame = function(id) {
                clearTimeout(id);
            };
        }
    }

    // WebAudio API representer
    var AudioContext = window.AudioContext;

    if (typeof AudioContext === 'undefined') {
        if (typeof webkitAudioContext !== 'undefined') {
            /*global AudioContext:true */
            AudioContext = webkitAudioContext;
        }

        if (typeof mozAudioContext !== 'undefined') {
            /*global AudioContext:true */
            AudioContext = mozAudioContext;
        }
    }

    /*jshint -W079 */
    var URL = window.URL;

    if (typeof URL === 'undefined' && typeof webkitURL !== 'undefined') {
        /*global URL:true */
        URL = webkitURL;
    }

    if (typeof navigator !== 'undefined' && typeof navigator.getUserMedia === 'undefined') { // maybe window.navigator?
        if (typeof navigator.webkitGetUserMedia !== 'undefined') {
            navigator.getUserMedia = navigator.webkitGetUserMedia;
        }

        if (typeof navigator.mozGetUserMedia !== 'undefined') {
            navigator.getUserMedia = navigator.mozGetUserMedia;
        }
    }

    var isEdge = navigator.userAgent.indexOf('Edge') !== -1 && (!!navigator.msSaveBlob || !!navigator.msSaveOrOpenBlob);
    var isOpera = !!window.opera || navigator.userAgent.indexOf('OPR/') !== -1;
    var isFirefox = navigator.userAgent.toLowerCase().indexOf('firefox') > -1 && ('netscape' in window) && / rv:/.test(navigator.userAgent);
    var isChrome = (!isOpera && !isEdge && !!navigator.webkitGetUserMedia) || isElectron() || navigator.userAgent.toLowerCase().indexOf('chrome/') !== -1;

    var isSafari = /^((?!chrome|android).)*safari/i.test(navigator.userAgent);

    if (isSafari && !isChrome && navigator.userAgent.indexOf('CriOS') !== -1) {
        isSafari = false;
        isChrome = true;
    }

    var MediaStream = window.MediaStream;

    if (typeof MediaStream === 'undefined' && typeof webkitMediaStream !== 'undefined') {
        MediaStream = webkitMediaStream;
    }

    /*global MediaStream:true */
    if (typeof MediaStream !== 'undefined') {
        // override "stop" method for all browsers
        if (typeof MediaStream.prototype.stop === 'undefined') {
            MediaStream.prototype.stop = function() {
                this.getTracks().forEach(function(track) {
                    track.stop();
                });
            };
        }
    }

    // below function via: http://goo.gl/B3ae8c
    /**
     * Return human-readable file size.
     * @param {number} bytes - Pass bytes and get formatted string.
     * @returns {string} - formatted string
     * @example
     * bytesToSize(1024*1024*5) === '5 GB'
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     */
    function bytesToSize(bytes) {
        var k = 1000;
        var sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];
        if (bytes === 0) {
            return '0 Bytes';
        }
        var i = parseInt(Math.floor(Math.log(bytes) / Math.log(k)), 10);
        return (bytes / Math.pow(k, i)).toPrecision(3) + ' ' + sizes[i];
    }

    /**
     * @param {Blob} file - File or Blob object. This parameter is required.
     * @param {string} fileName - Optional file name e.g. "Recorded-Video.webm"
     * @example
     * invokeSaveAsDialog(blob or file, [optional] fileName);
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     */
    function invokeSaveAsDialog(file, fileName) {
        if (!file) {
            throw 'Blob object is required.';
        }

        if (!file.type) {
            try {
                file.type = 'video/webm';
            } catch (e) {}
        }

        var fileExtension = (file.type || 'video/webm').split('/')[1];
        if (fileExtension.indexOf(';') !== -1) {
            // extended mimetype, e.g. 'video/webm;codecs=vp8,opus'
            fileExtension = fileExtension.split(';')[0];
        }
        if (fileName && fileName.indexOf('.') !== -1) {
            var splitted = fileName.split('.');
            fileName = splitted[0];
            fileExtension = splitted[1];
        }

        var fileFullName = (fileName || (Math.round(Math.random() * 9999999999) + 888888888)) + '.' + fileExtension;

        if (typeof navigator.msSaveOrOpenBlob !== 'undefined') {
            return navigator.msSaveOrOpenBlob(file, fileFullName);
        } else if (typeof navigator.msSaveBlob !== 'undefined') {
            return navigator.msSaveBlob(file, fileFullName);
        }

        var hyperlink = document.createElement('a');
        hyperlink.href = URL.createObjectURL(file);
        hyperlink.download = fileFullName;

        hyperlink.style = 'display:none;opacity:0;color:transparent;';
        (document.body || document.documentElement).appendChild(hyperlink);

        if (typeof hyperlink.click === 'function') {
            hyperlink.click();
        } else {
            hyperlink.target = '_blank';
            hyperlink.dispatchEvent(new MouseEvent('click', {
                view: window,
                bubbles: true,
                cancelable: true
            }));
        }

        URL.revokeObjectURL(hyperlink.href);
    }

    /**
     * from: https://github.com/cheton/is-electron/blob/master/index.js
     **/
    function isElectron() {
        // Renderer process
        if (typeof window !== 'undefined' && typeof window.process === 'object' && window.process.type === 'renderer') {
            return true;
        }

        // Main process
        if (typeof process !== 'undefined' && typeof process.versions === 'object' && !!process.versions.electron) {
            return true;
        }

        // Detect the user agent when the `nodeIntegration` option is set to true
        if (typeof navigator === 'object' && typeof navigator.userAgent === 'string' && navigator.userAgent.indexOf('Electron') >= 0) {
            return true;
        }

        return false;
    }

    function getTracks(stream, kind) {
        if (!stream || !stream.getTracks) {
            return [];
        }

        return stream.getTracks().filter(function(t) {
            return t.kind === (kind || 'audio');
        });
    }

    function setSrcObject(stream, element) {
        if ('srcObject' in element) {
            element.srcObject = stream;
        } else if ('mozSrcObject' in element) {
            element.mozSrcObject = stream;
        } else {
            element.srcObject = stream;
        }
    }

    /**
     * @param {Blob} file - File or Blob object.
     * @param {function} callback - Callback function.
     * @example
     * getSeekableBlob(blob or file, callback);
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     */
    function getSeekableBlob(inputBlob, callback) {
        // EBML.js copyrights goes to: https://github.com/legokichi/ts-ebml
        if (typeof EBML === 'undefined') {
            throw new Error('Please link: https://www.webrtc-experiment.com/EBML.js');
        }

        var reader = new EBML.Reader();
        var decoder = new EBML.Decoder();
        var tools = EBML.tools;

        var fileReader = new FileReader();
        fileReader.onload = function(e) {
            var ebmlElms = decoder.decode(this.result);
            ebmlElms.forEach(function(element) {
                reader.read(element);
            });
            reader.stop();
            var refinedMetadataBuf = tools.makeMetadataSeekable(reader.metadatas, reader.duration, reader.cues);
            var body = this.result.slice(reader.metadataSize);
            var newBlob = new Blob([refinedMetadataBuf, body], {
                type: 'video/webm'
            });

            callback(newBlob);
        };
        fileReader.readAsArrayBuffer(inputBlob);
    }

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.invokeSaveAsDialog = invokeSaveAsDialog;
        RecordRTC.getTracks = getTracks;
        RecordRTC.getSeekableBlob = getSeekableBlob;
        RecordRTC.bytesToSize = bytesToSize;
        RecordRTC.isElectron = isElectron;
    }

    // __________ (used to handle stuff like http://goo.gl/xmE5eg) issue #129
    // Storage.js

    /**
     * Storage is a standalone object used by {@link RecordRTC} to store reusable objects e.g. "new AudioContext".
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @example
     * Storage.AudioContext === webkitAudioContext
     * @property {webkitAudioContext} AudioContext - Keeps a reference to AudioContext object.
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     */

    var Storage = {};

    if (typeof AudioContext !== 'undefined') {
        Storage.AudioContext = AudioContext;
    } else if (typeof webkitAudioContext !== 'undefined') {
        Storage.AudioContext = webkitAudioContext;
    }

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.Storage = Storage;
    }

    function isMediaRecorderCompatible() {
        if (isFirefox || isSafari || isEdge) {
            return true;
        }
        var nAgt = navigator.userAgent;
        var fullVersion = '' + parseFloat(navigator.appVersion);
        var majorVersion = parseInt(navigator.appVersion, 10);
        var verOffset, ix;

        if (isChrome || isOpera) {
            verOffset = nAgt.indexOf('Chrome');
            fullVersion = nAgt.substring(verOffset + 7);
        }

        // trim the fullVersion string at semicolon/space if present
        if ((ix = fullVersion.indexOf(';')) !== -1) {
            fullVersion = fullVersion.substring(0, ix);
        }

        if ((ix = fullVersion.indexOf(' ')) !== -1) {
            fullVersion = fullVersion.substring(0, ix);
        }

        majorVersion = parseInt('' + fullVersion, 10);

        if (isNaN(majorVersion)) {
            fullVersion = '' + parseFloat(navigator.appVersion);
            majorVersion = parseInt(navigator.appVersion, 10);
        }

        return majorVersion >= 49;
    }

    // ______________________
    // MediaStreamRecorder.js

    /**
     * MediaStreamRecorder is an abstraction layer for {@link https://w3c.github.io/mediacapture-record/MediaRecorder.html|MediaRecorder API}. It is used by {@link RecordRTC} to record MediaStream(s) in both Chrome and Firefox.
     * @summary Runs top over {@link https://w3c.github.io/mediacapture-record/MediaRecorder.html|MediaRecorder API}.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://github.com/muaz-khan|Muaz Khan}
     * @typedef MediaStreamRecorder
     * @class
     * @example
     * var config = {
     *     mimeType: 'video/webm', // vp8, vp9, h264, mkv, opus/vorbis
     *     audioBitsPerSecond : 256 * 8 * 1024,
     *     videoBitsPerSecond : 256 * 8 * 1024,
     *     bitsPerSecond: 256 * 8 * 1024,  // if this is provided, skip above two
     *     checkForInactiveTracks: true,
     *     timeSlice: 1000, // concatenate intervals based blobs
     *     ondataavailable: function() {} // get intervals based blobs
     * }
     * var recorder = new MediaStreamRecorder(mediaStream, config);
     * recorder.record();
     * recorder.stop(function(blob) {
     *     video.src = URL.createObjectURL(blob);
     *
     *     // or
     *     var blob = recorder.blob;
     * });
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
     * @param {object} config - {disableLogs:true, initCallback: function, mimeType: "video/webm", timeSlice: 1000}
     * @throws Will throw an error if first argument "MediaStream" is missing. Also throws error if "MediaRecorder API" are not supported by the browser.
     */

    function MediaStreamRecorder(mediaStream, config) {
        var self = this;

        if (typeof mediaStream === 'undefined') {
            throw 'First argument "MediaStream" is required.';
        }

        if (typeof MediaRecorder === 'undefined') {
            throw 'Your browser does not support the Media Recorder API. Please try other modules e.g. WhammyRecorder or StereoAudioRecorder.';
        }

        config = config || {
            // bitsPerSecond: 256 * 8 * 1024,
            mimeType: 'video/webm'
        };

        if (config.type === 'audio') {
            if (getTracks(mediaStream, 'video').length && getTracks(mediaStream, 'audio').length) {
                var stream;
                if (!!navigator.mozGetUserMedia) {
                    stream = new MediaStream();
                    stream.addTrack(getTracks(mediaStream, 'audio')[0]);
                } else {
                    // webkitMediaStream
                    stream = new MediaStream(getTracks(mediaStream, 'audio'));
                }
                mediaStream = stream;
            }

            if (!config.mimeType || config.mimeType.toString().toLowerCase().indexOf('audio') === -1) {
                config.mimeType = isChrome ? 'audio/webm' : 'audio/ogg';
            }

            if (config.mimeType && config.mimeType.toString().toLowerCase() !== 'audio/ogg' && !!navigator.mozGetUserMedia) {
                // forcing better codecs on Firefox (via #166)
                config.mimeType = 'audio/ogg';
            }
        }

        var arrayOfBlobs = [];

        /**
         * This method returns array of blobs. Use only with "timeSlice". Its useful to preview recording anytime, without using the "stop" method.
         * @method
         * @memberof MediaStreamRecorder
         * @example
         * var arrayOfBlobs = recorder.getArrayOfBlobs();
         * @returns {Array} Returns array of recorded blobs.
         */
        this.getArrayOfBlobs = function() {
            return arrayOfBlobs;
        };

        /**
         * This method records MediaStream.
         * @method
         * @memberof MediaStreamRecorder
         * @example
         * recorder.record();
         */
        this.record = function() {
            // set defaults
            self.blob = null;
            self.clearRecordedData();
            self.timestamps = [];
            allStates = [];
            arrayOfBlobs = [];

            var recorderHints = config;

            if (!config.disableLogs) {
                console.log('Passing following config over MediaRecorder API.', recorderHints);
            }

            if (mediaRecorder) {
                // mandatory to make sure Firefox doesn't fails to record streams 3-4 times without reloading the page.
                mediaRecorder = null;
            }

            if (isChrome && !isMediaRecorderCompatible()) {
                // to support video-only recording on stable
                recorderHints = 'video/vp8';
            }

            if (typeof MediaRecorder.isTypeSupported === 'function' && recorderHints.mimeType) {
                if (!MediaRecorder.isTypeSupported(recorderHints.mimeType)) {
                    if (!config.disableLogs) {
                        console.warn('MediaRecorder API seems unable to record mimeType:', recorderHints.mimeType);
                    }

                    recorderHints.mimeType = config.type === 'audio' ? 'audio/webm' : 'video/webm';
                }
            }

            // using MediaRecorder API here
            try {
                mediaRecorder = new MediaRecorder(mediaStream, recorderHints);

                // reset
                config.mimeType = recorderHints.mimeType;
            } catch (e) {
                // chrome-based fallback
                mediaRecorder = new MediaRecorder(mediaStream);
            }

            // old hack?
            if (recorderHints.mimeType && !MediaRecorder.isTypeSupported && 'canRecordMimeType' in mediaRecorder && mediaRecorder.canRecordMimeType(recorderHints.mimeType) === false) {
                if (!config.disableLogs) {
                    console.warn('MediaRecorder API seems unable to record mimeType:', recorderHints.mimeType);
                }
            }

            // Dispatching OnDataAvailable Handler
            mediaRecorder.ondataavailable = function(e) {
                if (e.data) {
                    allStates.push('ondataavailable: ' + bytesToSize(e.data.size));
                }

                if (typeof config.timeSlice === 'number') {
                    if (e.data && e.data.size) {
                        arrayOfBlobs.push(e.data);
                        updateTimeStamp();

                        if (typeof config.ondataavailable === 'function') {
                            // intervals based blobs
                            var blob = config.getNativeBlob ? e.data : new Blob([e.data], {
                                type: getMimeType(recorderHints)
                            });
                            config.ondataavailable(blob);
                        }
                    }
                    return;
                }

                if (!e.data || !e.data.size || e.data.size < 100 || self.blob) {
                    // make sure that stopRecording always getting fired
                    // even if there is invalid data
                    if (self.recordingCallback) {
                        self.recordingCallback(new Blob([], {
                            type: getMimeType(recorderHints)
                        }));
                        self.recordingCallback = null;
                    }
                    return;
                }

                self.blob = config.getNativeBlob ? e.data : new Blob([e.data], {
                    type: getMimeType(recorderHints)
                });

                if (self.recordingCallback) {
                    self.recordingCallback(self.blob);
                    self.recordingCallback = null;
                }
            };

            mediaRecorder.onstart = function() {
                allStates.push('started');
            };

            mediaRecorder.onpause = function() {
                allStates.push('paused');
            };

            mediaRecorder.onresume = function() {
                allStates.push('resumed');
            };

            mediaRecorder.onstop = function() {
                allStates.push('stopped');
            };

            mediaRecorder.onerror = function(error) {
                if (!error) {
                    return;
                }

                if (!error.name) {
                    error.name = 'UnknownError';
                }

                allStates.push('error: ' + error);

                if (!config.disableLogs) {
                    // via: https://w3c.github.io/mediacapture-record/MediaRecorder.html#exception-summary
                    if (error.name.toString().toLowerCase().indexOf('invalidstate') !== -1) {
                        console.error('The MediaRecorder is not in a state in which the proposed operation is allowed to be executed.', error);
                    } else if (error.name.toString().toLowerCase().indexOf('notsupported') !== -1) {
                        console.error('MIME type (', recorderHints.mimeType, ') is not supported.', error);
                    } else if (error.name.toString().toLowerCase().indexOf('security') !== -1) {
                        console.error('MediaRecorder security error', error);
                    }

                    // older code below
                    else if (error.name === 'OutOfMemory') {
                        console.error('The UA has exhaused the available memory. User agents SHOULD provide as much additional information as possible in the message attribute.', error);
                    } else if (error.name === 'IllegalStreamModification') {
                        console.error('A modification to the stream has occurred that makes it impossible to continue recording. An example would be the addition of a Track while recording is occurring. User agents SHOULD provide as much additional information as possible in the message attribute.', error);
                    } else if (error.name === 'OtherRecordingError') {
                        console.error('Used for an fatal error other than those listed above. User agents SHOULD provide as much additional information as possible in the message attribute.', error);
                    } else if (error.name === 'GenericError') {
                        console.error('The UA cannot provide the codec or recording option that has been requested.', error);
                    } else {
                        console.error('MediaRecorder Error', error);
                    }
                }

                (function(looper) {
                    if (!self.manuallyStopped && mediaRecorder && mediaRecorder.state === 'inactive') {
                        delete config.timeslice;

                        // 10 minutes, enough?
                        mediaRecorder.start(10 * 60 * 1000);
                        return;
                    }

                    setTimeout(looper, 1000);
                })();

                if (mediaRecorder.state !== 'inactive' && mediaRecorder.state !== 'stopped') {
                    mediaRecorder.stop();
                }
            };

            if (typeof config.timeSlice === 'number') {
                updateTimeStamp();
                mediaRecorder.start(config.timeSlice);
            } else {
                // default is 60 minutes; enough?
                // use config => {timeSlice: 1000} otherwise

                mediaRecorder.start(3.6e+6);
            }

            if (config.initCallback) {
                config.initCallback(); // old code
            }
        };

        /**
         * @property {Array} timestamps - Array of time stamps
         * @memberof MediaStreamRecorder
         * @example
         * console.log(recorder.timestamps);
         */
        this.timestamps = [];

        function updateTimeStamp() {
            self.timestamps.push(new Date().getTime());

            if (typeof config.onTimeStamp === 'function') {
                config.onTimeStamp(self.timestamps[self.timestamps.length - 1], self.timestamps);
            }
        }

        function getMimeType(secondObject) {
            if (mediaRecorder && mediaRecorder.mimeType) {
                return mediaRecorder.mimeType;
            }

            return secondObject.mimeType || 'video/webm';
        }

        /**
         * This method stops recording MediaStream.
         * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.
         * @method
         * @memberof MediaStreamRecorder
         * @example
         * recorder.stop(function(blob) {
         *     video.src = URL.createObjectURL(blob);
         * });
         */
        this.stop = function(callback) {
            callback = callback || function() {};

            self.manuallyStopped = true; // used inside the mediaRecorder.onerror

            if (!mediaRecorder) {
                return;
            }

            this.recordingCallback = callback;

            if (mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }

            if (typeof config.timeSlice === 'number') {
                setTimeout(function() {
                    self.blob = new Blob(arrayOfBlobs, {
                        type: getMimeType(config)
                    });

                    self.recordingCallback(self.blob);
                }, 100);
            }
        };

        /**
         * This method pauses the recording process.
         * @method
         * @memberof MediaStreamRecorder
         * @example
         * recorder.pause();
         */
        this.pause = function() {
            if (!mediaRecorder) {
                return;
            }

            if (mediaRecorder.state === 'recording') {
                mediaRecorder.pause();
            }
        };

        /**
         * This method resumes the recording process.
         * @method
         * @memberof MediaStreamRecorder
         * @example
         * recorder.resume();
         */
        this.resume = function() {
            if (!mediaRecorder) {
                return;
            }

            if (mediaRecorder.state === 'paused') {
                mediaRecorder.resume();
            }
        };

        /**
         * This method resets currently recorded data.
         * @method
         * @memberof MediaStreamRecorder
         * @example
         * recorder.clearRecordedData();
         */
        this.clearRecordedData = function() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                self.stop(clearRecordedDataCB);
            }

            clearRecordedDataCB();
        };

        function clearRecordedDataCB() {
            arrayOfBlobs = [];
            mediaRecorder = null;
            self.timestamps = [];
        }

        // Reference to "MediaRecorder" object
        var mediaRecorder;

        /**
         * Access to native MediaRecorder API
         * @method
         * @memberof MediaStreamRecorder
         * @instance
         * @example
         * var internal = recorder.getInternalRecorder();
         * internal.ondataavailable = function() {}; // override
         * internal.stream, internal.onpause, internal.onstop, etc.
         * @returns {Object} Returns internal recording object.
         */
        this.getInternalRecorder = function() {
            return mediaRecorder;
        };

        function isMediaStreamActive() {
            if ('active' in mediaStream) {
                if (!mediaStream.active) {
                    return false;
                }
            } else if ('ended' in mediaStream) { // old hack
                if (mediaStream.ended) {
                    return false;
                }
            }
            return true;
        }

        /**
         * @property {Blob} blob - Recorded data as "Blob" object.
         * @memberof MediaStreamRecorder
         * @example
         * recorder.stop(function() {
         *     var blob = recorder.blob;
         * });
         */
        this.blob = null;


        /**
         * Get MediaRecorder readonly state.
         * @method
         * @memberof MediaStreamRecorder
         * @example
         * var state = recorder.getState();
         * @returns {String} Returns recording state.
         */
        this.getState = function() {
            if (!mediaRecorder) {
                return 'inactive';
            }

            return mediaRecorder.state || 'inactive';
        };

        // list of all recording states
        var allStates = [];

        /**
         * Get MediaRecorder all recording states.
         * @method
         * @memberof MediaStreamRecorder
         * @example
         * var state = recorder.getAllStates();
         * @returns {Array} Returns all recording states
         */
        this.getAllStates = function() {
            return allStates;
        };

        // if any Track within the MediaStream is muted or not enabled at any time, 
        // the browser will only record black frames 
        // or silence since that is the content produced by the Track
        // so we need to stopRecording as soon as any single track ends.
        if (typeof config.checkForInactiveTracks === 'undefined') {
            config.checkForInactiveTracks = false; // disable to minimize CPU usage
        }

        var self = this;

        // this method checks if media stream is stopped
        // or if any track is ended.
        (function looper() {
            if (!mediaRecorder || config.checkForInactiveTracks === false) {
                return;
            }

            if (isMediaStreamActive() === false) {
                if (!config.disableLogs) {
                    console.log('MediaStream seems stopped.');
                }
                self.stop();
                return;
            }

            setTimeout(looper, 1000); // check every second
        })();

        // for debugging
        this.name = 'MediaStreamRecorder';
        this.toString = function() {
            return this.name;
        };
    }

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.MediaStreamRecorder = MediaStreamRecorder;
    }

    // source code from: http://typedarray.org/wp-content/projects/WebAudioRecorder/script.js
    // https://github.com/mattdiamond/Recorderjs#license-mit
    // ______________________
    // StereoAudioRecorder.js

    /**
     * StereoAudioRecorder is a standalone class used by {@link RecordRTC} to bring "stereo" audio-recording in chrome.
     * @summary JavaScript standalone object for stereo audio recording.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef StereoAudioRecorder
     * @class
     * @example
     * var recorder = new StereoAudioRecorder(MediaStream, {
     *     sampleRate: 44100,
     *     bufferSize: 4096
     * });
     * recorder.record();
     * recorder.stop(function(blob) {
     *     video.src = URL.createObjectURL(blob);
     * });
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
     * @param {object} config - {sampleRate: 44100, bufferSize: 4096, numberOfAudioChannels: 1, etc.}
     */

    function StereoAudioRecorder(mediaStream, config) {
        if (!getTracks(mediaStream, 'audio').length) {
            throw 'Your stream has no audio tracks.';
        }

        config = config || {};

        var self = this;

        // variables
        var leftchannel = [];
        var rightchannel = [];
        var recording = false;
        var recordingLength = 0;
        var jsAudioNode;

        var numberOfAudioChannels = 2;

        /**
         * Set sample rates such as 8K or 16K. Reference: http://stackoverflow.com/a/28977136/552182
         * @property {number} desiredSampRate - Desired Bits per sample * 1000
         * @memberof StereoAudioRecorder
         * @instance
         * @example
         * var recorder = StereoAudioRecorder(mediaStream, {
         *   desiredSampRate: 16 * 1000 // bits-per-sample * 1000
         * });
         */
        var desiredSampRate = config.desiredSampRate;

        // backward compatibility
        if (config.leftChannel === true) {
            numberOfAudioChannels = 1;
        }

        if (config.numberOfAudioChannels === 1) {
            numberOfAudioChannels = 1;
        }

        if (!numberOfAudioChannels || numberOfAudioChannels < 1) {
            numberOfAudioChannels = 2;
        }

        if (!config.disableLogs) {
            console.log('StereoAudioRecorder is set to record number of channels: ' + numberOfAudioChannels);
        }

        // if any Track within the MediaStream is muted or not enabled at any time, 
        // the browser will only record black frames 
        // or silence since that is the content produced by the Track
        // so we need to stopRecording as soon as any single track ends.
        if (typeof config.checkForInactiveTracks === 'undefined') {
            config.checkForInactiveTracks = true;
        }

        function isMediaStreamActive() {
            if (config.checkForInactiveTracks === false) {
                // always return "true"
                return true;
            }

            if ('active' in mediaStream) {
                if (!mediaStream.active) {
                    return false;
                }
            } else if ('ended' in mediaStream) { // old hack
                if (mediaStream.ended) {
                    return false;
                }
            }
            return true;
        }

        /**
         * This method records MediaStream.
         * @method
         * @memberof StereoAudioRecorder
         * @example
         * recorder.record();
         */
        this.record = function() {
            if (isMediaStreamActive() === false) {
                throw 'Please make sure MediaStream is active.';
            }

            resetVariables();

            isAudioProcessStarted = isPaused = false;
            recording = true;

            if (typeof config.timeSlice !== 'undefined') {
                looper();
            }
        };

        function mergeLeftRightBuffers(config, callback) {
            function mergeAudioBuffers(config, cb) {
                var numberOfAudioChannels = config.numberOfAudioChannels;

                // todo: "slice(0)" --- is it causes loop? Should be removed?
                var leftBuffers = config.leftBuffers.slice(0);
                var rightBuffers = config.rightBuffers.slice(0);
                var sampleRate = config.sampleRate;
                var internalInterleavedLength = config.internalInterleavedLength;
                var desiredSampRate = config.desiredSampRate;

                if (numberOfAudioChannels === 2) {
                    leftBuffers = mergeBuffers(leftBuffers, internalInterleavedLength);
                    rightBuffers = mergeBuffers(rightBuffers, internalInterleavedLength);

                    if (desiredSampRate) {
                        leftBuffers = interpolateArray(leftBuffers, desiredSampRate, sampleRate);
                        rightBuffers = interpolateArray(rightBuffers, desiredSampRate, sampleRate);
                    }
                }

                if (numberOfAudioChannels === 1) {
                    leftBuffers = mergeBuffers(leftBuffers, internalInterleavedLength);

                    if (desiredSampRate) {
                        leftBuffers = interpolateArray(leftBuffers, desiredSampRate, sampleRate);
                    }
                }

                // set sample rate as desired sample rate
                if (desiredSampRate) {
                    sampleRate = desiredSampRate;
                }

                // for changing the sampling rate, reference:
                // http://stackoverflow.com/a/28977136/552182
                function interpolateArray(data, newSampleRate, oldSampleRate) {
                    var fitCount = Math.round(data.length * (newSampleRate / oldSampleRate));
                    var newData = [];
                    var springFactor = Number((data.length - 1) / (fitCount - 1));
                    newData[0] = data[0];
                    for (var i = 1; i < fitCount - 1; i++) {
                        var tmp = i * springFactor;
                        var before = Number(Math.floor(tmp)).toFixed();
                        var after = Number(Math.ceil(tmp)).toFixed();
                        var atPoint = tmp - before;
                        newData[i] = linearInterpolate(data[before], data[after], atPoint);
                    }
                    newData[fitCount - 1] = data[data.length - 1];
                    return newData;
                }

                function linearInterpolate(before, after, atPoint) {
                    return before + (after - before) * atPoint;
                }

                function mergeBuffers(channelBuffer, rLength) {
                    var result = new Float64Array(rLength);
                    var offset = 0;
                    var lng = channelBuffer.length;

                    for (var i = 0; i < lng; i++) {
                        var buffer = channelBuffer[i];
                        result.set(buffer, offset);
                        offset += buffer.length;
                    }

                    return result;
                }

                function interleave(leftChannel, rightChannel) {
                    var length = leftChannel.length + rightChannel.length;

                    var result = new Float64Array(length);

                    var inputIndex = 0;

                    for (var index = 0; index < length;) {
                        result[index++] = leftChannel[inputIndex];
                        result[index++] = rightChannel[inputIndex];
                        inputIndex++;
                    }
                    return result;
                }

                function writeUTFBytes(view, offset, string) {
                    var lng = string.length;
                    for (var i = 0; i < lng; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                }

                // interleave both channels together
                var interleaved;

                if (numberOfAudioChannels === 2) {
                    interleaved = interleave(leftBuffers, rightBuffers);
                }

                if (numberOfAudioChannels === 1) {
                    interleaved = leftBuffers;
                }

                var interleavedLength = interleaved.length;

                // create wav file
                var resultingBufferLength = 44 + interleavedLength * 2;

                var buffer = new ArrayBuffer(resultingBufferLength);

                var view = new DataView(buffer);

                // RIFF chunk descriptor/identifier 
                writeUTFBytes(view, 0, 'RIFF');

                // RIFF chunk length
                // changed "44" to "36" via #401
                view.setUint32(4, 36 + interleavedLength * 2, true);

                // RIFF type 
                writeUTFBytes(view, 8, 'WAVE');

                // format chunk identifier 
                // FMT sub-chunk
                writeUTFBytes(view, 12, 'fmt ');

                // format chunk length 
                view.setUint32(16, 16, true);

                // sample format (raw)
                view.setUint16(20, 1, true);

                // stereo (2 channels)
                view.setUint16(22, numberOfAudioChannels, true);

                // sample rate 
                view.setUint32(24, sampleRate, true);

                // byte rate (sample rate * block align)
                view.setUint32(28, sampleRate * numberOfAudioChannels * 2, true);

                // block align (channel count * bytes per sample) 
                view.setUint16(32, numberOfAudioChannels * 2, true);

                // bits per sample 
                view.setUint16(34, 16, true);

                // data sub-chunk
                // data chunk identifier 
                writeUTFBytes(view, 36, 'data');

                // data chunk length 
                view.setUint32(40, interleavedLength * 2, true);

                // write the PCM samples
                var lng = interleavedLength;
                var index = 44;
                var volume = 1;
                for (var i = 0; i < lng; i++) {
                    view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
                    index += 2;
                }

                if (cb) {
                    return cb({
                        buffer: buffer,
                        view: view
                    });
                }

                postMessage({
                    buffer: buffer,
                    view: view
                });
            }

            if (config.noWorker) {
                mergeAudioBuffers(config, function(data) {
                    callback(data.buffer, data.view);
                });
                return;
            }


            var webWorker = processInWebWorker(mergeAudioBuffers);

            webWorker.onmessage = function(event) {
                callback(event.data.buffer, event.data.view);

                // release memory
                URL.revokeObjectURL(webWorker.workerURL);

                // kill webworker (or Chrome will kill your page after ~25 calls)
                webWorker.terminate();
            };

            webWorker.postMessage(config);
        }

        function processInWebWorker(_function) {
            var workerURL = URL.createObjectURL(new Blob([_function.toString(),
                ';this.onmessage =  function (eee) {' + _function.name + '(eee.data);}'
            ], {
                type: 'application/javascript'
            }));

            var worker = new Worker(workerURL);
            worker.workerURL = workerURL;
            return worker;
        }

        /**
         * This method stops recording MediaStream.
         * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.
         * @method
         * @memberof StereoAudioRecorder
         * @example
         * recorder.stop(function(blob) {
         *     video.src = URL.createObjectURL(blob);
         * });
         */
        this.stop = function(callback) {
            callback = callback || function() {};

            // stop recording
            recording = false;

            mergeLeftRightBuffers({
                desiredSampRate: desiredSampRate,
                sampleRate: sampleRate,
                numberOfAudioChannels: numberOfAudioChannels,
                internalInterleavedLength: recordingLength,
                leftBuffers: leftchannel,
                rightBuffers: numberOfAudioChannels === 1 ? [] : rightchannel,
                noWorker: config.noWorker
            }, function(buffer, view) {
                /**
                 * @property {Blob} blob - The recorded blob object.
                 * @memberof StereoAudioRecorder
                 * @example
                 * recorder.stop(function(){
                 *     var blob = recorder.blob;
                 * });
                 */
                self.blob = new Blob([view], {
                    type: 'audio/wav'
                });

                /**
                 * @property {ArrayBuffer} buffer - The recorded buffer object.
                 * @memberof StereoAudioRecorder
                 * @example
                 * recorder.stop(function(){
                 *     var buffer = recorder.buffer;
                 * });
                 */
                self.buffer = new ArrayBuffer(view.buffer.byteLength);

                /**
                 * @property {DataView} view - The recorded data-view object.
                 * @memberof StereoAudioRecorder
                 * @example
                 * recorder.stop(function(){
                 *     var view = recorder.view;
                 * });
                 */
                self.view = view;

                self.sampleRate = desiredSampRate || sampleRate;
                self.bufferSize = bufferSize;

                // recorded audio length
                self.length = recordingLength;

                isAudioProcessStarted = false;

                if (callback) {
                    callback(self.blob);
                }
            });
        };

        if (typeof RecordRTC.Storage === 'undefined') {
            RecordRTC.Storage = {
                AudioContextConstructor: null,
                AudioContext: window.AudioContext || window.webkitAudioContext
            };
        }

        if (!RecordRTC.Storage.AudioContextConstructor || RecordRTC.Storage.AudioContextConstructor.state === 'closed') {
            RecordRTC.Storage.AudioContextConstructor = new RecordRTC.Storage.AudioContext();
        }

        var context = RecordRTC.Storage.AudioContextConstructor;

        // creates an audio node from the microphone incoming stream
        var audioInput = context.createMediaStreamSource(mediaStream);

        var legalBufferValues = [0, 256, 512, 1024, 2048, 4096, 8192, 16384];

        /**
         * From the spec: This value controls how frequently the audioprocess event is
         * dispatched and how many sample-frames need to be processed each call.
         * Lower values for buffer size will result in a lower (better) latency.
         * Higher values will be necessary to avoid audio breakup and glitches
         * The size of the buffer (in sample-frames) which needs to
         * be processed each time onprocessaudio is called.
         * Legal values are (256, 512, 1024, 2048, 4096, 8192, 16384).
         * @property {number} bufferSize - Buffer-size for how frequently the audioprocess event is dispatched.
         * @memberof StereoAudioRecorder
         * @example
         * recorder = new StereoAudioRecorder(mediaStream, {
         *     bufferSize: 4096
         * });
         */

        // "0" means, let chrome decide the most accurate buffer-size for current platform.
        var bufferSize = typeof config.bufferSize === 'undefined' ? 4096 : config.bufferSize;

        if (legalBufferValues.indexOf(bufferSize) === -1) {
            if (!config.disableLogs) {
                console.log('Legal values for buffer-size are ' + JSON.stringify(legalBufferValues, null, '\t'));
            }
        }

        if (context.createJavaScriptNode) {
            jsAudioNode = context.createJavaScriptNode(bufferSize, numberOfAudioChannels, numberOfAudioChannels);
        } else if (context.createScriptProcessor) {
            jsAudioNode = context.createScriptProcessor(bufferSize, numberOfAudioChannels, numberOfAudioChannels);
        } else {
            throw 'WebAudio API has no support on this browser.';
        }

        // connect the stream to the script processor
        audioInput.connect(jsAudioNode);

        if (!config.bufferSize) {
            bufferSize = jsAudioNode.bufferSize; // device buffer-size
        }

        /**
         * The sample rate (in sample-frames per second) at which the
         * AudioContext handles audio. It is assumed that all AudioNodes
         * in the context run at this rate. In making this assumption,
         * sample-rate converters or "varispeed" processors are not supported
         * in real-time processing.
         * The sampleRate parameter describes the sample-rate of the
         * linear PCM audio data in the buffer in sample-frames per second.
         * An implementation must support sample-rates in at least
         * the range 22050 to 96000.
         * @property {number} sampleRate - Buffer-size for how frequently the audioprocess event is dispatched.
         * @memberof StereoAudioRecorder
         * @example
         * recorder = new StereoAudioRecorder(mediaStream, {
         *     sampleRate: 44100
         * });
         */
        var sampleRate = typeof config.sampleRate !== 'undefined' ? config.sampleRate : context.sampleRate || 44100;

        if (sampleRate < 22050 || sampleRate > 96000) {
            // Ref: http://stackoverflow.com/a/26303918/552182
            if (!config.disableLogs) {
                console.log('sample-rate must be under range 22050 and 96000.');
            }
        }

        if (!config.disableLogs) {
            if (config.desiredSampRate) {
                console.log('Desired sample-rate: ' + config.desiredSampRate);
            }
        }

        var isPaused = false;
        /**
         * This method pauses the recording process.
         * @method
         * @memberof StereoAudioRecorder
         * @example
         * recorder.pause();
         */
        this.pause = function() {
            isPaused = true;
        };

        /**
         * This method resumes the recording process.
         * @method
         * @memberof StereoAudioRecorder
         * @example
         * recorder.resume();
         */
        this.resume = function() {
            if (isMediaStreamActive() === false) {
                throw 'Please make sure MediaStream is active.';
            }

            if (!recording) {
                if (!config.disableLogs) {
                    console.log('Seems recording has been restarted.');
                }
                this.record();
                return;
            }

            isPaused = false;
        };

        /**
         * This method resets currently recorded data.
         * @method
         * @memberof StereoAudioRecorder
         * @example
         * recorder.clearRecordedData();
         */
        this.clearRecordedData = function() {
            config.checkForInactiveTracks = false;

            if (recording) {
                this.stop(clearRecordedDataCB);
            }

            clearRecordedDataCB();
        };

        function resetVariables() {
            leftchannel = [];
            rightchannel = [];
            recordingLength = 0;
            isAudioProcessStarted = false;
            recording = false;
            isPaused = false;
            context = null;

            self.leftchannel = leftchannel;
            self.rightchannel = rightchannel;
            self.numberOfAudioChannels = numberOfAudioChannels;
            self.desiredSampRate = desiredSampRate;
            self.sampleRate = sampleRate;
            self.recordingLength = recordingLength;

            intervalsBasedBuffers = {
                left: [],
                right: [],
                recordingLength: 0
            };
        }

        function clearRecordedDataCB() {
            if (jsAudioNode) {
                jsAudioNode.onaudioprocess = null;
                jsAudioNode.disconnect();
                jsAudioNode = null;
            }

            if (audioInput) {
                audioInput.disconnect();
                audioInput = null;
            }

            resetVariables();
        }

        // for debugging
        this.name = 'StereoAudioRecorder';
        this.toString = function() {
            return this.name;
        };

        var isAudioProcessStarted = false;

        function onAudioProcessDataAvailable(e) {
            if (isPaused) {
                return;
            }

            if (isMediaStreamActive() === false) {
                if (!config.disableLogs) {
                    console.log('MediaStream seems stopped.');
                }
                jsAudioNode.disconnect();
                recording = false;
            }

            if (!recording) {
                if (audioInput) {
                    audioInput.disconnect();
                    audioInput = null;
                }
                return;
            }

            /**
             * This method is called on "onaudioprocess" event's first invocation.
             * @method {function} onAudioProcessStarted
             * @memberof StereoAudioRecorder
             * @example
             * recorder.onAudioProcessStarted: function() { };
             */
            if (!isAudioProcessStarted) {
                isAudioProcessStarted = true;
                if (config.onAudioProcessStarted) {
                    config.onAudioProcessStarted();
                }

                if (config.initCallback) {
                    config.initCallback();
                }
            }

            var left = e.inputBuffer.getChannelData(0);

            // we clone the samples
            var chLeft = new Float32Array(left);
            leftchannel.push(chLeft);

            if (numberOfAudioChannels === 2) {
                var right = e.inputBuffer.getChannelData(1);
                var chRight = new Float32Array(right);
                rightchannel.push(chRight);
            }

            recordingLength += bufferSize;

            // export raw PCM
            self.recordingLength = recordingLength;

            if (typeof config.timeSlice !== 'undefined') {
                intervalsBasedBuffers.recordingLength += bufferSize;
                intervalsBasedBuffers.left.push(chLeft);

                if (numberOfAudioChannels === 2) {
                    intervalsBasedBuffers.right.push(chRight);
                }
            }
        }

        jsAudioNode.onaudioprocess = onAudioProcessDataAvailable;

        // to prevent self audio to be connected with speakers
        if (context.createMediaStreamDestination) {
            jsAudioNode.connect(context.createMediaStreamDestination());
        } else {
            jsAudioNode.connect(context.destination);
        }

        // export raw PCM
        this.leftchannel = leftchannel;
        this.rightchannel = rightchannel;
        this.numberOfAudioChannels = numberOfAudioChannels;
        this.desiredSampRate = desiredSampRate;
        this.sampleRate = sampleRate;
        self.recordingLength = recordingLength;

        // helper for intervals based blobs
        var intervalsBasedBuffers = {
            left: [],
            right: [],
            recordingLength: 0
        };

        // this looper is used to support intervals based blobs (via timeSlice+ondataavailable)
        function looper() {
            if (!recording || typeof config.ondataavailable !== 'function' || typeof config.timeSlice === 'undefined') {
                return;
            }

            if (intervalsBasedBuffers.left.length) {
                mergeLeftRightBuffers({
                    desiredSampRate: desiredSampRate,
                    sampleRate: sampleRate,
                    numberOfAudioChannels: numberOfAudioChannels,
                    internalInterleavedLength: intervalsBasedBuffers.recordingLength,
                    leftBuffers: intervalsBasedBuffers.left,
                    rightBuffers: numberOfAudioChannels === 1 ? [] : intervalsBasedBuffers.right
                }, function(buffer, view) {
                    var blob = new Blob([view], {
                        type: 'audio/wav'
                    });
                    config.ondataavailable(blob);

                    setTimeout(looper, config.timeSlice);
                });

                intervalsBasedBuffers = {
                    left: [],
                    right: [],
                    recordingLength: 0
                };
            } else {
                setTimeout(looper, config.timeSlice);
            }
        }
    }

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.StereoAudioRecorder = StereoAudioRecorder;
    }

    // _________________
    // CanvasRecorder.js

    /**
     * CanvasRecorder is a standalone class used by {@link RecordRTC} to bring HTML5-Canvas recording into video WebM. It uses HTML2Canvas library and runs top over {@link Whammy}.
     * @summary HTML2Canvas recording into video WebM.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef CanvasRecorder
     * @class
     * @example
     * var recorder = new CanvasRecorder(htmlElement, { disableLogs: true, useWhammyRecorder: true });
     * recorder.record();
     * recorder.stop(function(blob) {
     *     video.src = URL.createObjectURL(blob);
     * });
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     * @param {HTMLElement} htmlElement - querySelector/getElementById/getElementsByTagName[0]/etc.
     * @param {object} config - {disableLogs:true, initCallback: function}
     */

    function CanvasRecorder(htmlElement, config) {
        if (typeof html2canvas === 'undefined') {
            throw 'Please link: https://www.webrtc-experiment.com/screenshot.js';
        }

        config = config || {};
        if (!config.frameInterval) {
            config.frameInterval = 10;
        }

        // via DetectRTC.js
        var isCanvasSupportsStreamCapturing = false;
        ['captureStream', 'mozCaptureStream', 'webkitCaptureStream'].forEach(function(item) {
            if (item in document.createElement('canvas')) {
                isCanvasSupportsStreamCapturing = true;
            }
        });

        var _isChrome = (!!window.webkitRTCPeerConnection || !!window.webkitGetUserMedia) && !!window.chrome;

        var chromeVersion = 50;
        var matchArray = navigator.userAgent.match(/Chrom(e|ium)\/([0-9]+)\./);
        if (_isChrome && matchArray && matchArray[2]) {
            chromeVersion = parseInt(matchArray[2], 10);
        }

        if (_isChrome && chromeVersion < 52) {
            isCanvasSupportsStreamCapturing = false;
        }

        if (config.useWhammyRecorder) {
            isCanvasSupportsStreamCapturing = false;
        }

        var globalCanvas, mediaStreamRecorder;

        if (isCanvasSupportsStreamCapturing) {
            if (!config.disableLogs) {
                console.log('Your browser supports both MediRecorder API and canvas.captureStream!');
            }

            if (htmlElement instanceof HTMLCanvasElement) {
                globalCanvas = htmlElement;
            } else if (htmlElement instanceof CanvasRenderingContext2D) {
                globalCanvas = htmlElement.canvas;
            } else {
                throw 'Please pass either HTMLCanvasElement or CanvasRenderingContext2D.';
            }
        } else if (!!navigator.mozGetUserMedia) {
            if (!config.disableLogs) {
                console.error('Canvas recording is NOT supported in Firefox.');
            }
        }

        var isRecording;

        /**
         * This method records Canvas.
         * @method
         * @memberof CanvasRecorder
         * @example
         * recorder.record();
         */
        this.record = function() {
            isRecording = true;

            if (isCanvasSupportsStreamCapturing && !config.useWhammyRecorder) {
                // CanvasCaptureMediaStream
                var canvasMediaStream;
                if ('captureStream' in globalCanvas) {
                    canvasMediaStream = globalCanvas.captureStream(25); // 25 FPS
                } else if ('mozCaptureStream' in globalCanvas) {
                    canvasMediaStream = globalCanvas.mozCaptureStream(25);
                } else if ('webkitCaptureStream' in globalCanvas) {
                    canvasMediaStream = globalCanvas.webkitCaptureStream(25);
                }

                try {
                    var mdStream = new MediaStream();
                    mdStream.addTrack(getTracks(canvasMediaStream, 'video')[0]);
                    canvasMediaStream = mdStream;
                } catch (e) {}

                if (!canvasMediaStream) {
                    throw 'captureStream API are NOT available.';
                }

                // Note: Jan 18, 2016 status is that, 
                // Firefox MediaRecorder API can't record CanvasCaptureMediaStream object.
                mediaStreamRecorder = new MediaStreamRecorder(canvasMediaStream, {
                    mimeType: config.mimeType || 'video/webm'
                });
                mediaStreamRecorder.record();
            } else {
                whammy.frames = [];
                lastTime = new Date().getTime();
                drawCanvasFrame();
            }

            if (config.initCallback) {
                config.initCallback();
            }
        };

        this.getWebPImages = function(callback) {
            if (htmlElement.nodeName.toLowerCase() !== 'canvas') {
                callback();
                return;
            }

            var framesLength = whammy.frames.length;
            whammy.frames.forEach(function(frame, idx) {
                var framesRemaining = framesLength - idx;
                if (!config.disableLogs) {
                    console.log(framesRemaining + '/' + framesLength + ' frames remaining');
                }

                if (config.onEncodingCallback) {
                    config.onEncodingCallback(framesRemaining, framesLength);
                }

                var webp = frame.image.toDataURL('image/webp', 1);
                whammy.frames[idx].image = webp;
            });

            if (!config.disableLogs) {
                console.log('Generating WebM');
            }

            callback();
        };

        /**
         * This method stops recording Canvas.
         * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.
         * @method
         * @memberof CanvasRecorder
         * @example
         * recorder.stop(function(blob) {
         *     video.src = URL.createObjectURL(blob);
         * });
         */
        this.stop = function(callback) {
            isRecording = false;

            var that = this;

            if (isCanvasSupportsStreamCapturing && mediaStreamRecorder) {
                mediaStreamRecorder.stop(callback);
                return;
            }

            this.getWebPImages(function() {
                /**
                 * @property {Blob} blob - Recorded frames in video/webm blob.
                 * @memberof CanvasRecorder
                 * @example
                 * recorder.stop(function() {
                 *     var blob = recorder.blob;
                 * });
                 */
                whammy.compile(function(blob) {
                    if (!config.disableLogs) {
                        console.log('Recording finished!');
                    }

                    that.blob = blob;

                    if (that.blob.forEach) {
                        that.blob = new Blob([], {
                            type: 'video/webm'
                        });
                    }

                    if (callback) {
                        callback(that.blob);
                    }

                    whammy.frames = [];
                });
            });
        };

        var isPausedRecording = false;

        /**
         * This method pauses the recording process.
         * @method
         * @memberof CanvasRecorder
         * @example
         * recorder.pause();
         */
        this.pause = function() {
            isPausedRecording = true;

            if (mediaStreamRecorder instanceof MediaStreamRecorder) {
                mediaStreamRecorder.pause();
                return;
            }
        };

        /**
         * This method resumes the recording process.
         * @method
         * @memberof CanvasRecorder
         * @example
         * recorder.resume();
         */
        this.resume = function() {
            isPausedRecording = false;

            if (mediaStreamRecorder instanceof MediaStreamRecorder) {
                mediaStreamRecorder.resume();
                return;
            }

            if (!isRecording) {
                this.record();
            }
        };

        /**
         * This method resets currently recorded data.
         * @method
         * @memberof CanvasRecorder
         * @example
         * recorder.clearRecordedData();
         */
        this.clearRecordedData = function() {
            if (isRecording) {
                this.stop(clearRecordedDataCB);
            }
            clearRecordedDataCB();
        };

        function clearRecordedDataCB() {
            whammy.frames = [];
            isRecording = false;
            isPausedRecording = false;
        }

        // for debugging
        this.name = 'CanvasRecorder';
        this.toString = function() {
            return this.name;
        };

        function cloneCanvas() {
            //create a new canvas
            var newCanvas = document.createElement('canvas');
            var context = newCanvas.getContext('2d');

            //set dimensions
            newCanvas.width = htmlElement.width;
            newCanvas.height = htmlElement.height;

            //apply the old canvas to the new one
            context.drawImage(htmlElement, 0, 0);

            //return the new canvas
            return newCanvas;
        }

        function drawCanvasFrame() {
            if (isPausedRecording) {
                lastTime = new Date().getTime();
                return setTimeout(drawCanvasFrame, 500);
            }

            if (htmlElement.nodeName.toLowerCase() === 'canvas') {
                var duration = new Date().getTime() - lastTime;
                // via #206, by Jack i.e. @Seymourr
                lastTime = new Date().getTime();

                whammy.frames.push({
                    image: cloneCanvas(),
                    duration: duration
                });

                if (isRecording) {
                    setTimeout(drawCanvasFrame, config.frameInterval);
                }
                return;
            }

            html2canvas(htmlElement, {
                grabMouse: typeof config.showMousePointer === 'undefined' || config.showMousePointer,
                onrendered: function(canvas) {
                    var duration = new Date().getTime() - lastTime;
                    if (!duration) {
                        return setTimeout(drawCanvasFrame, config.frameInterval);
                    }

                    // via #206, by Jack i.e. @Seymourr
                    lastTime = new Date().getTime();

                    whammy.frames.push({
                        image: canvas.toDataURL('image/webp', 1),
                        duration: duration
                    });

                    if (isRecording) {
                        setTimeout(drawCanvasFrame, config.frameInterval);
                    }
                }
            });
        }

        var lastTime = new Date().getTime();

        var whammy = new Whammy.Video(100);
    }

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.CanvasRecorder = CanvasRecorder;
    }

    // _________________
    // WhammyRecorder.js

    /**
     * WhammyRecorder is a standalone class used by {@link RecordRTC} to bring video recording in Chrome. It runs top over {@link Whammy}.
     * @summary Video recording feature in Chrome.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef WhammyRecorder
     * @class
     * @example
     * var recorder = new WhammyRecorder(mediaStream);
     * recorder.record();
     * recorder.stop(function(blob) {
     *     video.src = URL.createObjectURL(blob);
     * });
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
     * @param {object} config - {disableLogs: true, initCallback: function, video: HTMLVideoElement, etc.}
     */

    function WhammyRecorder(mediaStream, config) {

        config = config || {};

        if (!config.frameInterval) {
            config.frameInterval = 10;
        }

        if (!config.disableLogs) {
            console.log('Using frames-interval:', config.frameInterval);
        }

        /**
         * This method records video.
         * @method
         * @memberof WhammyRecorder
         * @example
         * recorder.record();
         */
        this.record = function() {
            if (!config.width) {
                config.width = 320;
            }

            if (!config.height) {
                config.height = 240;
            }

            if (!config.video) {
                config.video = {
                    width: config.width,
                    height: config.height
                };
            }

            if (!config.canvas) {
                config.canvas = {
                    width: config.width,
                    height: config.height
                };
            }

            canvas.width = config.canvas.width || 320;
            canvas.height = config.canvas.height || 240;

            context = canvas.getContext('2d');

            // setting defaults
            if (config.video && config.video instanceof HTMLVideoElement) {
                video = config.video.cloneNode();

                if (config.initCallback) {
                    config.initCallback();
                }
            } else {
                video = document.createElement('video');

                setSrcObject(mediaStream, video);

                video.onloadedmetadata = function() { // "onloadedmetadata" may NOT work in FF?
                    if (config.initCallback) {
                        config.initCallback();
                    }
                };

                video.width = config.video.width;
                video.height = config.video.height;
            }

            video.muted = true;
            video.play();

            lastTime = new Date().getTime();
            whammy = new Whammy.Video();

            if (!config.disableLogs) {
                console.log('canvas resolutions', canvas.width, '*', canvas.height);
                console.log('video width/height', video.width || canvas.width, '*', video.height || canvas.height);
            }

            drawFrames(config.frameInterval);
        };

        /**
         * Draw and push frames to Whammy
         * @param {integer} frameInterval - set minimum interval (in milliseconds) between each time we push a frame to Whammy
         */
        function drawFrames(frameInterval) {
            frameInterval = typeof frameInterval !== 'undefined' ? frameInterval : 10;

            var duration = new Date().getTime() - lastTime;
            if (!duration) {
                return setTimeout(drawFrames, frameInterval, frameInterval);
            }

            if (isPausedRecording) {
                lastTime = new Date().getTime();
                return setTimeout(drawFrames, 100);
            }

            // via #206, by Jack i.e. @Seymourr
            lastTime = new Date().getTime();

            if (video.paused) {
                // via: https://github.com/muaz-khan/WebRTC-Experiment/pull/316
                // Tweak for Android Chrome
                video.play();
            }

            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            whammy.frames.push({
                duration: duration,
                image: canvas.toDataURL('image/webp')
            });

            if (!isStopDrawing) {
                setTimeout(drawFrames, frameInterval, frameInterval);
            }
        }

        function asyncLoop(o) {
            var i = -1,
                length = o.length;

            (function loop() {
                i++;
                if (i === length) {
                    o.callback();
                    return;
                }

                // "setTimeout" added by Jim McLeod
                setTimeout(function() {
                    o.functionToLoop(loop, i);
                }, 1);
            })();
        }


        /**
         * remove black frames from the beginning to the specified frame
         * @param {Array} _frames - array of frames to be checked
         * @param {number} _framesToCheck - number of frame until check will be executed (-1 - will drop all frames until frame not matched will be found)
         * @param {number} _pixTolerance - 0 - very strict (only black pixel color) ; 1 - all
         * @param {number} _frameTolerance - 0 - very strict (only black frame color) ; 1 - all
         * @returns {Array} - array of frames
         */
        // pull#293 by @volodalexey
        function dropBlackFrames(_frames, _framesToCheck, _pixTolerance, _frameTolerance, callback) {
            var localCanvas = document.createElement('canvas');
            localCanvas.width = canvas.width;
            localCanvas.height = canvas.height;
            var context2d = localCanvas.getContext('2d');
            var resultFrames = [];

            var checkUntilNotBlack = _framesToCheck === -1;
            var endCheckFrame = (_framesToCheck && _framesToCheck > 0 && _framesToCheck <= _frames.length) ?
                _framesToCheck : _frames.length;
            var sampleColor = {
                r: 0,
                g: 0,
                b: 0
            };
            var maxColorDifference = Math.sqrt(
                Math.pow(255, 2) +
                Math.pow(255, 2) +
                Math.pow(255, 2)
            );
            var pixTolerance = _pixTolerance && _pixTolerance >= 0 && _pixTolerance <= 1 ? _pixTolerance : 0;
            var frameTolerance = _frameTolerance && _frameTolerance >= 0 && _frameTolerance <= 1 ? _frameTolerance : 0;
            var doNotCheckNext = false;

            asyncLoop({
                length: endCheckFrame,
                functionToLoop: function(loop, f) {
                    var matchPixCount, endPixCheck, maxPixCount;

                    var finishImage = function() {
                        if (!doNotCheckNext && maxPixCount - matchPixCount <= maxPixCount * frameTolerance) ; else {
                            // console.log('frame is passed : ' + f);
                            if (checkUntilNotBlack) {
                                doNotCheckNext = true;
                            }
                            resultFrames.push(_frames[f]);
                        }
                        loop();
                    };

                    if (!doNotCheckNext) {
                        var image = new Image();
                        image.onload = function() {
                            context2d.drawImage(image, 0, 0, canvas.width, canvas.height);
                            var imageData = context2d.getImageData(0, 0, canvas.width, canvas.height);
                            matchPixCount = 0;
                            endPixCheck = imageData.data.length;
                            maxPixCount = imageData.data.length / 4;

                            for (var pix = 0; pix < endPixCheck; pix += 4) {
                                var currentColor = {
                                    r: imageData.data[pix],
                                    g: imageData.data[pix + 1],
                                    b: imageData.data[pix + 2]
                                };
                                var colorDifference = Math.sqrt(
                                    Math.pow(currentColor.r - sampleColor.r, 2) +
                                    Math.pow(currentColor.g - sampleColor.g, 2) +
                                    Math.pow(currentColor.b - sampleColor.b, 2)
                                );
                                // difference in color it is difference in color vectors (r1,g1,b1) <=> (r2,g2,b2)
                                if (colorDifference <= maxColorDifference * pixTolerance) {
                                    matchPixCount++;
                                }
                            }
                            finishImage();
                        };
                        image.src = _frames[f].image;
                    } else {
                        finishImage();
                    }
                },
                callback: function() {
                    resultFrames = resultFrames.concat(_frames.slice(endCheckFrame));

                    if (resultFrames.length <= 0) {
                        // at least one last frame should be available for next manipulation
                        // if total duration of all frames will be < 1000 than ffmpeg doesn't work well...
                        resultFrames.push(_frames[_frames.length - 1]);
                    }
                    callback(resultFrames);
                }
            });
        }

        var isStopDrawing = false;

        /**
         * This method stops recording video.
         * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.
         * @method
         * @memberof WhammyRecorder
         * @example
         * recorder.stop(function(blob) {
         *     video.src = URL.createObjectURL(blob);
         * });
         */
        this.stop = function(callback) {
            callback = callback || function() {};

            isStopDrawing = true;

            var _this = this;
            // analyse of all frames takes some time!
            setTimeout(function() {
                // e.g. dropBlackFrames(frames, 10, 1, 1) - will cut all 10 frames
                // e.g. dropBlackFrames(frames, 10, 0.5, 0.5) - will analyse 10 frames
                // e.g. dropBlackFrames(frames, 10) === dropBlackFrames(frames, 10, 0, 0) - will analyse 10 frames with strict black color
                dropBlackFrames(whammy.frames, -1, null, null, function(frames) {
                    whammy.frames = frames;

                    // to display advertisement images!
                    if (config.advertisement && config.advertisement.length) {
                        whammy.frames = config.advertisement.concat(whammy.frames);
                    }

                    /**
                     * @property {Blob} blob - Recorded frames in video/webm blob.
                     * @memberof WhammyRecorder
                     * @example
                     * recorder.stop(function() {
                     *     var blob = recorder.blob;
                     * });
                     */
                    whammy.compile(function(blob) {
                        _this.blob = blob;

                        if (_this.blob.forEach) {
                            _this.blob = new Blob([], {
                                type: 'video/webm'
                            });
                        }

                        if (callback) {
                            callback(_this.blob);
                        }
                    });
                });
            }, 10);
        };

        var isPausedRecording = false;

        /**
         * This method pauses the recording process.
         * @method
         * @memberof WhammyRecorder
         * @example
         * recorder.pause();
         */
        this.pause = function() {
            isPausedRecording = true;
        };

        /**
         * This method resumes the recording process.
         * @method
         * @memberof WhammyRecorder
         * @example
         * recorder.resume();
         */
        this.resume = function() {
            isPausedRecording = false;

            if (isStopDrawing) {
                this.record();
            }
        };

        /**
         * This method resets currently recorded data.
         * @method
         * @memberof WhammyRecorder
         * @example
         * recorder.clearRecordedData();
         */
        this.clearRecordedData = function() {
            if (!isStopDrawing) {
                this.stop(clearRecordedDataCB);
            }
            clearRecordedDataCB();
        };

        function clearRecordedDataCB() {
            whammy.frames = [];
            isStopDrawing = true;
            isPausedRecording = false;
        }

        // for debugging
        this.name = 'WhammyRecorder';
        this.toString = function() {
            return this.name;
        };

        var canvas = document.createElement('canvas');
        var context = canvas.getContext('2d');

        var video;
        var lastTime;
        var whammy;
    }

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.WhammyRecorder = WhammyRecorder;
    }

    // https://github.com/antimatter15/whammy/blob/master/LICENSE
    // _________
    // Whammy.js

    // todo: Firefox now supports webp for webm containers!
    // their MediaRecorder implementation works well!
    // should we provide an option to record via Whammy.js or MediaRecorder API is a better solution?

    /**
     * Whammy is a standalone class used by {@link RecordRTC} to bring video recording in Chrome. It is written by {@link https://github.com/antimatter15|antimatter15}
     * @summary A real time javascript webm encoder based on a canvas hack.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef Whammy
     * @class
     * @example
     * var recorder = new Whammy().Video(15);
     * recorder.add(context || canvas || dataURL);
     * var output = recorder.compile();
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     */

    var Whammy = (function() {
        // a more abstract-ish API

        function WhammyVideo(duration) {
            this.frames = [];
            this.duration = duration || 1;
            this.quality = 0.8;
        }

        /**
         * Pass Canvas or Context or image/webp(string) to {@link Whammy} encoder.
         * @method
         * @memberof Whammy
         * @example
         * recorder = new Whammy().Video(0.8, 100);
         * recorder.add(canvas || context || 'image/webp');
         * @param {string} frame - Canvas || Context || image/webp
         * @param {number} duration - Stick a duration (in milliseconds)
         */
        WhammyVideo.prototype.add = function(frame, duration) {
            if ('canvas' in frame) { //CanvasRenderingContext2D
                frame = frame.canvas;
            }

            if ('toDataURL' in frame) {
                frame = frame.toDataURL('image/webp', this.quality);
            }

            if (!(/^data:image\/webp;base64,/ig).test(frame)) {
                throw 'Input must be formatted properly as a base64 encoded DataURI of type image/webp';
            }
            this.frames.push({
                image: frame,
                duration: duration || this.duration
            });
        };

        function processInWebWorker(_function) {
            var blob = URL.createObjectURL(new Blob([_function.toString(),
                'this.onmessage =  function (eee) {' + _function.name + '(eee.data);}'
            ], {
                type: 'application/javascript'
            }));

            var worker = new Worker(blob);
            URL.revokeObjectURL(blob);
            return worker;
        }

        function whammyInWebWorker(frames) {
            function ArrayToWebM(frames) {
                var info = checkFrames(frames);
                if (!info) {
                    return [];
                }

                var clusterMaxDuration = 30000;

                var EBML = [{
                    'id': 0x1a45dfa3, // EBML
                    'data': [{
                        'data': 1,
                        'id': 0x4286 // EBMLVersion
                    }, {
                        'data': 1,
                        'id': 0x42f7 // EBMLReadVersion
                    }, {
                        'data': 4,
                        'id': 0x42f2 // EBMLMaxIDLength
                    }, {
                        'data': 8,
                        'id': 0x42f3 // EBMLMaxSizeLength
                    }, {
                        'data': 'webm',
                        'id': 0x4282 // DocType
                    }, {
                        'data': 2,
                        'id': 0x4287 // DocTypeVersion
                    }, {
                        'data': 2,
                        'id': 0x4285 // DocTypeReadVersion
                    }]
                }, {
                    'id': 0x18538067, // Segment
                    'data': [{
                        'id': 0x1549a966, // Info
                        'data': [{
                            'data': 1e6, //do things in millisecs (num of nanosecs for duration scale)
                            'id': 0x2ad7b1 // TimecodeScale
                        }, {
                            'data': 'whammy',
                            'id': 0x4d80 // MuxingApp
                        }, {
                            'data': 'whammy',
                            'id': 0x5741 // WritingApp
                        }, {
                            'data': doubleToString(info.duration),
                            'id': 0x4489 // Duration
                        }]
                    }, {
                        'id': 0x1654ae6b, // Tracks
                        'data': [{
                            'id': 0xae, // TrackEntry
                            'data': [{
                                'data': 1,
                                'id': 0xd7 // TrackNumber
                            }, {
                                'data': 1,
                                'id': 0x73c5 // TrackUID
                            }, {
                                'data': 0,
                                'id': 0x9c // FlagLacing
                            }, {
                                'data': 'und',
                                'id': 0x22b59c // Language
                            }, {
                                'data': 'V_VP8',
                                'id': 0x86 // CodecID
                            }, {
                                'data': 'VP8',
                                'id': 0x258688 // CodecName
                            }, {
                                'data': 1,
                                'id': 0x83 // TrackType
                            }, {
                                'id': 0xe0, // Video
                                'data': [{
                                    'data': info.width,
                                    'id': 0xb0 // PixelWidth
                                }, {
                                    'data': info.height,
                                    'id': 0xba // PixelHeight
                                }]
                            }]
                        }]
                    }]
                }];

                //Generate clusters (max duration)
                var frameNumber = 0;
                var clusterTimecode = 0;
                while (frameNumber < frames.length) {

                    var clusterFrames = [];
                    var clusterDuration = 0;
                    do {
                        clusterFrames.push(frames[frameNumber]);
                        clusterDuration += frames[frameNumber].duration;
                        frameNumber++;
                    } while (frameNumber < frames.length && clusterDuration < clusterMaxDuration);

                    var clusterCounter = 0;
                    var cluster = {
                        'id': 0x1f43b675, // Cluster
                        'data': getClusterData(clusterTimecode, clusterCounter, clusterFrames)
                    }; //Add cluster to segment
                    EBML[1].data.push(cluster);
                    clusterTimecode += clusterDuration;
                }

                return generateEBML(EBML);
            }

            function getClusterData(clusterTimecode, clusterCounter, clusterFrames) {
                return [{
                    'data': clusterTimecode,
                    'id': 0xe7 // Timecode
                }].concat(clusterFrames.map(function(webp) {
                    var block = makeSimpleBlock({
                        discardable: 0,
                        frame: webp.data.slice(4),
                        invisible: 0,
                        keyframe: 1,
                        lacing: 0,
                        trackNum: 1,
                        timecode: Math.round(clusterCounter)
                    });
                    clusterCounter += webp.duration;
                    return {
                        data: block,
                        id: 0xa3
                    };
                }));
            }

            // sums the lengths of all the frames and gets the duration

            function checkFrames(frames) {
                if (!frames[0]) {
                    postMessage({
                        error: 'Something went wrong. Maybe WebP format is not supported in the current browser.'
                    });
                    return;
                }

                var width = frames[0].width,
                    height = frames[0].height,
                    duration = frames[0].duration;

                for (var i = 1; i < frames.length; i++) {
                    duration += frames[i].duration;
                }
                return {
                    duration: duration,
                    width: width,
                    height: height
                };
            }

            function numToBuffer(num) {
                var parts = [];
                while (num > 0) {
                    parts.push(num & 0xff);
                    num = num >> 8;
                }
                return new Uint8Array(parts.reverse());
            }

            function strToBuffer(str) {
                return new Uint8Array(str.split('').map(function(e) {
                    return e.charCodeAt(0);
                }));
            }

            function bitsToBuffer(bits) {
                var data = [];
                var pad = (bits.length % 8) ? (new Array(1 + 8 - (bits.length % 8))).join('0') : '';
                bits = pad + bits;
                for (var i = 0; i < bits.length; i += 8) {
                    data.push(parseInt(bits.substr(i, 8), 2));
                }
                return new Uint8Array(data);
            }

            function generateEBML(json) {
                var ebml = [];
                for (var i = 0; i < json.length; i++) {
                    var data = json[i].data;

                    if (typeof data === 'object') {
                        data = generateEBML(data);
                    }

                    if (typeof data === 'number') {
                        data = bitsToBuffer(data.toString(2));
                    }

                    if (typeof data === 'string') {
                        data = strToBuffer(data);
                    }

                    var len = data.size || data.byteLength || data.length;
                    var zeroes = Math.ceil(Math.ceil(Math.log(len) / Math.log(2)) / 8);
                    var sizeToString = len.toString(2);
                    var padded = (new Array((zeroes * 7 + 7 + 1) - sizeToString.length)).join('0') + sizeToString;
                    var size = (new Array(zeroes)).join('0') + '1' + padded;

                    ebml.push(numToBuffer(json[i].id));
                    ebml.push(bitsToBuffer(size));
                    ebml.push(data);
                }

                return new Blob(ebml, {
                    type: 'video/webm'
                });
            }

            function makeSimpleBlock(data) {
                var flags = 0;

                if (data.keyframe) {
                    flags |= 128;
                }

                if (data.invisible) {
                    flags |= 8;
                }

                if (data.lacing) {
                    flags |= (data.lacing << 1);
                }

                if (data.discardable) {
                    flags |= 1;
                }

                if (data.trackNum > 127) {
                    throw 'TrackNumber > 127 not supported';
                }

                var out = [data.trackNum | 0x80, data.timecode >> 8, data.timecode & 0xff, flags].map(function(e) {
                    return String.fromCharCode(e);
                }).join('') + data.frame;

                return out;
            }

            function parseWebP(riff) {
                var VP8 = riff.RIFF[0].WEBP[0];

                var frameStart = VP8.indexOf('\x9d\x01\x2a'); // A VP8 keyframe starts with the 0x9d012a header
                for (var i = 0, c = []; i < 4; i++) {
                    c[i] = VP8.charCodeAt(frameStart + 3 + i);
                }

                var width, height, tmp;

                //the code below is literally copied verbatim from the bitstream spec
                tmp = (c[1] << 8) | c[0];
                width = tmp & 0x3FFF;
                tmp = (c[3] << 8) | c[2];
                height = tmp & 0x3FFF;
                return {
                    width: width,
                    height: height,
                    data: VP8,
                    riff: riff
                };
            }

            function getStrLength(string, offset) {
                return parseInt(string.substr(offset + 4, 4).split('').map(function(i) {
                    var unpadded = i.charCodeAt(0).toString(2);
                    return (new Array(8 - unpadded.length + 1)).join('0') + unpadded;
                }).join(''), 2);
            }

            function parseRIFF(string) {
                var offset = 0;
                var chunks = {};

                while (offset < string.length) {
                    var id = string.substr(offset, 4);
                    var len = getStrLength(string, offset);
                    var data = string.substr(offset + 4 + 4, len);
                    offset += 4 + 4 + len;
                    chunks[id] = chunks[id] || [];

                    if (id === 'RIFF' || id === 'LIST') {
                        chunks[id].push(parseRIFF(data));
                    } else {
                        chunks[id].push(data);
                    }
                }
                return chunks;
            }

            function doubleToString(num) {
                return [].slice.call(
                    new Uint8Array((new Float64Array([num])).buffer), 0).map(function(e) {
                    return String.fromCharCode(e);
                }).reverse().join('');
            }

            var webm = new ArrayToWebM(frames.map(function(frame) {
                var webp = parseWebP(parseRIFF(atob(frame.image.slice(23))));
                webp.duration = frame.duration;
                return webp;
            }));

            postMessage(webm);
        }

        /**
         * Encodes frames in WebM container. It uses WebWorkinvoke to invoke 'ArrayToWebM' method.
         * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.
         * @method
         * @memberof Whammy
         * @example
         * recorder = new Whammy().Video(0.8, 100);
         * recorder.compile(function(blob) {
         *    // blob.size - blob.type
         * });
         */
        WhammyVideo.prototype.compile = function(callback) {
            var webWorker = processInWebWorker(whammyInWebWorker);

            webWorker.onmessage = function(event) {
                if (event.data.error) {
                    console.error(event.data.error);
                    return;
                }
                callback(event.data);
            };

            webWorker.postMessage(this.frames);
        };

        return {
            /**
             * A more abstract-ish API.
             * @method
             * @memberof Whammy
             * @example
             * recorder = new Whammy().Video(0.8, 100);
             * @param {?number} speed - 0.8
             * @param {?number} quality - 100
             */
            Video: WhammyVideo
        };
    })();

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.Whammy = Whammy;
    }

    // ______________ (indexed-db)
    // DiskStorage.js

    /**
     * DiskStorage is a standalone object used by {@link RecordRTC} to store recorded blobs in IndexedDB storage.
     * @summary Writing blobs into IndexedDB.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @example
     * DiskStorage.Store({
     *     audioBlob: yourAudioBlob,
     *     videoBlob: yourVideoBlob,
     *     gifBlob  : yourGifBlob
     * });
     * DiskStorage.Fetch(function(dataURL, type) {
     *     if(type === 'audioBlob') { }
     *     if(type === 'videoBlob') { }
     *     if(type === 'gifBlob')   { }
     * });
     * // DiskStorage.dataStoreName = 'recordRTC';
     * // DiskStorage.onError = function(error) { };
     * @property {function} init - This method must be called once to initialize IndexedDB ObjectStore. Though, it is auto-used internally.
     * @property {function} Fetch - This method fetches stored blobs from IndexedDB.
     * @property {function} Store - This method stores blobs in IndexedDB.
     * @property {function} onError - This function is invoked for any known/unknown error.
     * @property {string} dataStoreName - Name of the ObjectStore created in IndexedDB storage.
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     */


    var DiskStorage = {
        /**
         * This method must be called once to initialize IndexedDB ObjectStore. Though, it is auto-used internally.
         * @method
         * @memberof DiskStorage
         * @internal
         * @example
         * DiskStorage.init();
         */
        init: function() {
            var self = this;

            if (typeof indexedDB === 'undefined' || typeof indexedDB.open === 'undefined') {
                console.error('IndexedDB API are not available in this browser.');
                return;
            }

            var dbVersion = 1;
            var dbName = this.dbName || location.href.replace(/\/|:|#|%|\.|\[|\]/g, ''),
                db;
            var request = indexedDB.open(dbName, dbVersion);

            function createObjectStore(dataBase) {
                dataBase.createObjectStore(self.dataStoreName);
            }

            function putInDB() {
                var transaction = db.transaction([self.dataStoreName], 'readwrite');

                if (self.videoBlob) {
                    transaction.objectStore(self.dataStoreName).put(self.videoBlob, 'videoBlob');
                }

                if (self.gifBlob) {
                    transaction.objectStore(self.dataStoreName).put(self.gifBlob, 'gifBlob');
                }

                if (self.audioBlob) {
                    transaction.objectStore(self.dataStoreName).put(self.audioBlob, 'audioBlob');
                }

                function getFromStore(portionName) {
                    transaction.objectStore(self.dataStoreName).get(portionName).onsuccess = function(event) {
                        if (self.callback) {
                            self.callback(event.target.result, portionName);
                        }
                    };
                }

                getFromStore('audioBlob');
                getFromStore('videoBlob');
                getFromStore('gifBlob');
            }

            request.onerror = self.onError;

            request.onsuccess = function() {
                db = request.result;
                db.onerror = self.onError;

                if (db.setVersion) {
                    if (db.version !== dbVersion) {
                        var setVersion = db.setVersion(dbVersion);
                        setVersion.onsuccess = function() {
                            createObjectStore(db);
                            putInDB();
                        };
                    } else {
                        putInDB();
                    }
                } else {
                    putInDB();
                }
            };
            request.onupgradeneeded = function(event) {
                createObjectStore(event.target.result);
            };
        },
        /**
         * This method fetches stored blobs from IndexedDB.
         * @method
         * @memberof DiskStorage
         * @internal
         * @example
         * DiskStorage.Fetch(function(dataURL, type) {
         *     if(type === 'audioBlob') { }
         *     if(type === 'videoBlob') { }
         *     if(type === 'gifBlob')   { }
         * });
         */
        Fetch: function(callback) {
            this.callback = callback;
            this.init();

            return this;
        },
        /**
         * This method stores blobs in IndexedDB.
         * @method
         * @memberof DiskStorage
         * @internal
         * @example
         * DiskStorage.Store({
         *     audioBlob: yourAudioBlob,
         *     videoBlob: yourVideoBlob,
         *     gifBlob  : yourGifBlob
         * });
         */
        Store: function(config) {
            this.audioBlob = config.audioBlob;
            this.videoBlob = config.videoBlob;
            this.gifBlob = config.gifBlob;

            this.init();

            return this;
        },
        /**
         * This function is invoked for any known/unknown error.
         * @method
         * @memberof DiskStorage
         * @internal
         * @example
         * DiskStorage.onError = function(error){
         *     alerot( JSON.stringify(error) );
         * };
         */
        onError: function(error) {
            console.error(JSON.stringify(error, null, '\t'));
        },

        /**
         * @property {string} dataStoreName - Name of the ObjectStore created in IndexedDB storage.
         * @memberof DiskStorage
         * @internal
         * @example
         * DiskStorage.dataStoreName = 'recordRTC';
         */
        dataStoreName: 'recordRTC',
        dbName: null
    };

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.DiskStorage = DiskStorage;
    }

    // ______________
    // GifRecorder.js

    /**
     * GifRecorder is standalone calss used by {@link RecordRTC} to record video or canvas into animated gif.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef GifRecorder
     * @class
     * @example
     * var recorder = new GifRecorder(mediaStream || canvas || context, { onGifPreview: function, onGifRecordingStarted: function, width: 1280, height: 720, frameRate: 200, quality: 10 });
     * recorder.record();
     * recorder.stop(function(blob) {
     *     img.src = URL.createObjectURL(blob);
     * });
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     * @param {MediaStream} mediaStream - MediaStream object or HTMLCanvasElement or CanvasRenderingContext2D.
     * @param {object} config - {disableLogs:true, initCallback: function, width: 320, height: 240, frameRate: 200, quality: 10}
     */

    function GifRecorder(mediaStream, config) {
        if (typeof GIFEncoder === 'undefined') {
            var script = document.createElement('script');
            script.src = 'https://www.webrtc-experiment.com/gif-recorder.js';
            (document.body || document.documentElement).appendChild(script);
        }

        config = config || {};

        var isHTMLObject = mediaStream instanceof CanvasRenderingContext2D || mediaStream instanceof HTMLCanvasElement;

        /**
         * This method records MediaStream.
         * @method
         * @memberof GifRecorder
         * @example
         * recorder.record();
         */
        this.record = function() {
            if (typeof GIFEncoder === 'undefined') {
                setTimeout(self.record, 1000);
                return;
            }

            if (!isLoadedMetaData) {
                setTimeout(self.record, 1000);
                return;
            }

            if (!isHTMLObject) {
                if (!config.width) {
                    config.width = video.offsetWidth || 320;
                }

                if (!config.height) {
                    config.height = video.offsetHeight || 240;
                }

                if (!config.video) {
                    config.video = {
                        width: config.width,
                        height: config.height
                    };
                }

                if (!config.canvas) {
                    config.canvas = {
                        width: config.width,
                        height: config.height
                    };
                }

                canvas.width = config.canvas.width || 320;
                canvas.height = config.canvas.height || 240;

                video.width = config.video.width || 320;
                video.height = config.video.height || 240;
            }

            // external library to record as GIF images
            gifEncoder = new GIFEncoder();

            // void setRepeat(int iter) 
            // Sets the number of times the set of GIF frames should be played. 
            // Default is 1; 0 means play indefinitely.
            gifEncoder.setRepeat(0);

            // void setFrameRate(Number fps) 
            // Sets frame rate in frames per second. 
            // Equivalent to setDelay(1000/fps).
            // Using "setDelay" instead of "setFrameRate"
            gifEncoder.setDelay(config.frameRate || 200);

            // void setQuality(int quality) 
            // Sets quality of color quantization (conversion of images to the 
            // maximum 256 colors allowed by the GIF specification). 
            // Lower values (minimum = 1) produce better colors, 
            // but slow processing significantly. 10 is the default, 
            // and produces good color mapping at reasonable speeds. 
            // Values greater than 20 do not yield significant improvements in speed.
            gifEncoder.setQuality(config.quality || 10);

            // Boolean start() 
            // This writes the GIF Header and returns false if it fails.
            gifEncoder.start();

            if (typeof config.onGifRecordingStarted === 'function') {
                config.onGifRecordingStarted();
            }

            function drawVideoFrame(time) {
                if (self.clearedRecordedData === true) {
                    return;
                }

                if (isPausedRecording) {
                    return setTimeout(function() {
                        drawVideoFrame(time);
                    }, 100);
                }

                lastAnimationFrame = requestAnimationFrame(drawVideoFrame);

                if (typeof lastFrameTime === undefined) {
                    lastFrameTime = time;
                }

                // ~10 fps
                if (time - lastFrameTime < 90) {
                    return;
                }

                if (!isHTMLObject && video.paused) {
                    // via: https://github.com/muaz-khan/WebRTC-Experiment/pull/316
                    // Tweak for Android Chrome
                    video.play();
                }

                if (!isHTMLObject) {
                    context.drawImage(video, 0, 0, canvas.width, canvas.height);
                }

                if (config.onGifPreview) {
                    config.onGifPreview(canvas.toDataURL('image/png'));
                }

                gifEncoder.addFrame(context);
                lastFrameTime = time;
            }

            lastAnimationFrame = requestAnimationFrame(drawVideoFrame);

            if (config.initCallback) {
                config.initCallback();
            }
        };

        /**
         * This method stops recording MediaStream.
         * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.
         * @method
         * @memberof GifRecorder
         * @example
         * recorder.stop(function(blob) {
         *     img.src = URL.createObjectURL(blob);
         * });
         */
        this.stop = function(callback) {
            callback = callback || function() {};

            if (lastAnimationFrame) {
                cancelAnimationFrame(lastAnimationFrame);
            }

            /**
             * @property {Blob} blob - The recorded blob object.
             * @memberof GifRecorder
             * @example
             * recorder.stop(function(){
             *     var blob = recorder.blob;
             * });
             */
            this.blob = new Blob([new Uint8Array(gifEncoder.stream().bin)], {
                type: 'image/gif'
            });

            callback(this.blob);

            // bug: find a way to clear old recorded blobs
            gifEncoder.stream().bin = [];
        };

        var isPausedRecording = false;

        /**
         * This method pauses the recording process.
         * @method
         * @memberof GifRecorder
         * @example
         * recorder.pause();
         */
        this.pause = function() {
            isPausedRecording = true;
        };

        /**
         * This method resumes the recording process.
         * @method
         * @memberof GifRecorder
         * @example
         * recorder.resume();
         */
        this.resume = function() {
            isPausedRecording = false;
        };

        /**
         * This method resets currently recorded data.
         * @method
         * @memberof GifRecorder
         * @example
         * recorder.clearRecordedData();
         */
        this.clearRecordedData = function() {
            self.clearedRecordedData = true;
            clearRecordedDataCB();
        };

        function clearRecordedDataCB() {
            if (gifEncoder) {
                gifEncoder.stream().bin = [];
            }
        }

        // for debugging
        this.name = 'GifRecorder';
        this.toString = function() {
            return this.name;
        };

        var canvas = document.createElement('canvas');
        var context = canvas.getContext('2d');

        if (isHTMLObject) {
            if (mediaStream instanceof CanvasRenderingContext2D) {
                context = mediaStream;
                canvas = context.canvas;
            } else if (mediaStream instanceof HTMLCanvasElement) {
                context = mediaStream.getContext('2d');
                canvas = mediaStream;
            }
        }

        var isLoadedMetaData = true;

        if (!isHTMLObject) {
            var video = document.createElement('video');
            video.muted = true;
            video.autoplay = true;
            video.playsInline = true;

            isLoadedMetaData = false;
            video.onloadedmetadata = function() {
                isLoadedMetaData = true;
            };

            setSrcObject(mediaStream, video);

            video.play();
        }

        var lastAnimationFrame = null;
        var lastFrameTime;

        var gifEncoder;

        var self = this;
    }

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.GifRecorder = GifRecorder;
    }

    // Last time updated: 2019-06-21 4:09:42 AM UTC

    // ________________________
    // MultiStreamsMixer v1.2.2

    // Open-Sourced: https://github.com/muaz-khan/MultiStreamsMixer

    // --------------------------------------------------
    // Muaz Khan     - www.MuazKhan.com
    // MIT License   - www.WebRTC-Experiment.com/licence
    // --------------------------------------------------

    function MultiStreamsMixer(arrayOfMediaStreams, elementClass) {

        var browserFakeUserAgent = 'Fake/5.0 (FakeOS) AppleWebKit/123 (KHTML, like Gecko) Fake/12.3.4567.89 Fake/123.45';

        (function(that) {
            if (typeof RecordRTC !== 'undefined') {
                return;
            }

            if (!that) {
                return;
            }

            if (typeof window !== 'undefined') {
                return;
            }

            if (typeof commonjsGlobal === 'undefined') {
                return;
            }

            commonjsGlobal.navigator = {
                userAgent: browserFakeUserAgent,
                getUserMedia: function() {}
            };

            if (!commonjsGlobal.console) {
                commonjsGlobal.console = {};
            }

            if (typeof commonjsGlobal.console.log === 'undefined' || typeof commonjsGlobal.console.error === 'undefined') {
                commonjsGlobal.console.error = commonjsGlobal.console.log = commonjsGlobal.console.log || function() {
                    console.log(arguments);
                };
            }

            if (typeof document === 'undefined') {
                /*global document:true */
                that.document = {
                    documentElement: {
                        appendChild: function() {
                            return '';
                        }
                    }
                };

                document.createElement = document.captureStream = document.mozCaptureStream = function() {
                    var obj = {
                        getContext: function() {
                            return obj;
                        },
                        play: function() {},
                        pause: function() {},
                        drawImage: function() {},
                        toDataURL: function() {
                            return '';
                        },
                        style: {}
                    };
                    return obj;
                };

                that.HTMLVideoElement = function() {};
            }

            if (typeof location === 'undefined') {
                /*global location:true */
                that.location = {
                    protocol: 'file:',
                    href: '',
                    hash: ''
                };
            }

            if (typeof screen === 'undefined') {
                /*global screen:true */
                that.screen = {
                    width: 0,
                    height: 0
                };
            }

            if (typeof URL === 'undefined') {
                /*global screen:true */
                that.URL = {
                    createObjectURL: function() {
                        return '';
                    },
                    revokeObjectURL: function() {
                        return '';
                    }
                };
            }

            /*global window:true */
            that.window = commonjsGlobal;
        })(typeof commonjsGlobal !== 'undefined' ? commonjsGlobal : null);

        // requires: chrome://flags/#enable-experimental-web-platform-features

        elementClass = elementClass || 'multi-streams-mixer';

        var videos = [];
        var isStopDrawingFrames = false;

        var canvas = document.createElement('canvas');
        var context = canvas.getContext('2d');
        canvas.style.opacity = 0;
        canvas.style.position = 'absolute';
        canvas.style.zIndex = -1;
        canvas.style.top = '-1000em';
        canvas.style.left = '-1000em';
        canvas.className = elementClass;
        (document.body || document.documentElement).appendChild(canvas);

        this.disableLogs = false;
        this.frameInterval = 10;

        this.width = 360;
        this.height = 240;

        // use gain node to prevent echo
        this.useGainNode = true;

        var self = this;

        // _____________________________
        // Cross-Browser-Declarations.js

        // WebAudio API representer
        var AudioContext = window.AudioContext;

        if (typeof AudioContext === 'undefined') {
            if (typeof webkitAudioContext !== 'undefined') {
                /*global AudioContext:true */
                AudioContext = webkitAudioContext;
            }

            if (typeof mozAudioContext !== 'undefined') {
                /*global AudioContext:true */
                AudioContext = mozAudioContext;
            }
        }

        /*jshint -W079 */
        var URL = window.URL;

        if (typeof URL === 'undefined' && typeof webkitURL !== 'undefined') {
            /*global URL:true */
            URL = webkitURL;
        }

        if (typeof navigator !== 'undefined' && typeof navigator.getUserMedia === 'undefined') { // maybe window.navigator?
            if (typeof navigator.webkitGetUserMedia !== 'undefined') {
                navigator.getUserMedia = navigator.webkitGetUserMedia;
            }

            if (typeof navigator.mozGetUserMedia !== 'undefined') {
                navigator.getUserMedia = navigator.mozGetUserMedia;
            }
        }

        var MediaStream = window.MediaStream;

        if (typeof MediaStream === 'undefined' && typeof webkitMediaStream !== 'undefined') {
            MediaStream = webkitMediaStream;
        }

        /*global MediaStream:true */
        if (typeof MediaStream !== 'undefined') {
            // override "stop" method for all browsers
            if (typeof MediaStream.prototype.stop === 'undefined') {
                MediaStream.prototype.stop = function() {
                    this.getTracks().forEach(function(track) {
                        track.stop();
                    });
                };
            }
        }

        var Storage = {};

        if (typeof AudioContext !== 'undefined') {
            Storage.AudioContext = AudioContext;
        } else if (typeof webkitAudioContext !== 'undefined') {
            Storage.AudioContext = webkitAudioContext;
        }

        function setSrcObject(stream, element) {
            if ('srcObject' in element) {
                element.srcObject = stream;
            } else if ('mozSrcObject' in element) {
                element.mozSrcObject = stream;
            } else {
                element.srcObject = stream;
            }
        }

        this.startDrawingFrames = function() {
            drawVideosToCanvas();
        };

        function drawVideosToCanvas() {
            if (isStopDrawingFrames) {
                return;
            }

            var videosLength = videos.length;

            var fullcanvas = false;
            var remaining = [];
            videos.forEach(function(video) {
                if (!video.stream) {
                    video.stream = {};
                }

                if (video.stream.fullcanvas) {
                    fullcanvas = video;
                } else {
                    // todo: video.stream.active or video.stream.live to fix blank frames issues?
                    remaining.push(video);
                }
            });

            if (fullcanvas) {
                canvas.width = fullcanvas.stream.width;
                canvas.height = fullcanvas.stream.height;
            } else if (remaining.length) {
                canvas.width = videosLength > 1 ? remaining[0].width * 2 : remaining[0].width;

                var height = 1;
                if (videosLength === 3 || videosLength === 4) {
                    height = 2;
                }
                if (videosLength === 5 || videosLength === 6) {
                    height = 3;
                }
                if (videosLength === 7 || videosLength === 8) {
                    height = 4;
                }
                if (videosLength === 9 || videosLength === 10) {
                    height = 5;
                }
                canvas.height = remaining[0].height * height;
            } else {
                canvas.width = self.width || 360;
                canvas.height = self.height || 240;
            }

            if (fullcanvas && fullcanvas instanceof HTMLVideoElement) {
                drawImage(fullcanvas);
            }

            remaining.forEach(function(video, idx) {
                drawImage(video, idx);
            });

            setTimeout(drawVideosToCanvas, self.frameInterval);
        }

        function drawImage(video, idx) {
            if (isStopDrawingFrames) {
                return;
            }

            var x = 0;
            var y = 0;
            var width = video.width;
            var height = video.height;

            if (idx === 1) {
                x = video.width;
            }

            if (idx === 2) {
                y = video.height;
            }

            if (idx === 3) {
                x = video.width;
                y = video.height;
            }

            if (idx === 4) {
                y = video.height * 2;
            }

            if (idx === 5) {
                x = video.width;
                y = video.height * 2;
            }

            if (idx === 6) {
                y = video.height * 3;
            }

            if (idx === 7) {
                x = video.width;
                y = video.height * 3;
            }

            if (typeof video.stream.left !== 'undefined') {
                x = video.stream.left;
            }

            if (typeof video.stream.top !== 'undefined') {
                y = video.stream.top;
            }

            if (typeof video.stream.width !== 'undefined') {
                width = video.stream.width;
            }

            if (typeof video.stream.height !== 'undefined') {
                height = video.stream.height;
            }

            context.drawImage(video, x, y, width, height);

            if (typeof video.stream.onRender === 'function') {
                video.stream.onRender(context, x, y, width, height, idx);
            }
        }

        function getMixedStream() {
            isStopDrawingFrames = false;
            var mixedVideoStream = getMixedVideoStream();

            var mixedAudioStream = getMixedAudioStream();
            if (mixedAudioStream) {
                mixedAudioStream.getTracks().filter(function(t) {
                    return t.kind === 'audio';
                }).forEach(function(track) {
                    mixedVideoStream.addTrack(track);
                });
            }
            arrayOfMediaStreams.forEach(function(stream) {
                if (stream.fullcanvas) ;
            });

            // mixedVideoStream.prototype.appendStreams = appendStreams;
            // mixedVideoStream.prototype.resetVideoStreams = resetVideoStreams;
            // mixedVideoStream.prototype.clearRecordedData = clearRecordedData;

            return mixedVideoStream;
        }

        function getMixedVideoStream() {
            resetVideoStreams();

            var capturedStream;

            if ('captureStream' in canvas) {
                capturedStream = canvas.captureStream();
            } else if ('mozCaptureStream' in canvas) {
                capturedStream = canvas.mozCaptureStream();
            } else if (!self.disableLogs) {
                console.error('Upgrade to latest Chrome or otherwise enable this flag: chrome://flags/#enable-experimental-web-platform-features');
            }

            var videoStream = new MediaStream();

            capturedStream.getTracks().filter(function(t) {
                return t.kind === 'video';
            }).forEach(function(track) {
                videoStream.addTrack(track);
            });

            canvas.stream = videoStream;

            return videoStream;
        }

        function getMixedAudioStream() {
            // via: @pehrsons
            if (!Storage.AudioContextConstructor) {
                Storage.AudioContextConstructor = new Storage.AudioContext();
            }

            self.audioContext = Storage.AudioContextConstructor;

            self.audioSources = [];

            if (self.useGainNode === true) {
                self.gainNode = self.audioContext.createGain();
                self.gainNode.connect(self.audioContext.destination);
                self.gainNode.gain.value = 0; // don't hear self
            }

            var audioTracksLength = 0;
            arrayOfMediaStreams.forEach(function(stream) {
                if (!stream.getTracks().filter(function(t) {
                        return t.kind === 'audio';
                    }).length) {
                    return;
                }

                audioTracksLength++;

                var audioSource = self.audioContext.createMediaStreamSource(stream);

                if (self.useGainNode === true) {
                    audioSource.connect(self.gainNode);
                }

                self.audioSources.push(audioSource);
            });

            if (!audioTracksLength) {
                // because "self.audioContext" is not initialized
                // that's why we've to ignore rest of the code
                return;
            }

            self.audioDestination = self.audioContext.createMediaStreamDestination();
            self.audioSources.forEach(function(audioSource) {
                audioSource.connect(self.audioDestination);
            });
            return self.audioDestination.stream;
        }

        function getVideo(stream) {
            var video = document.createElement('video');

            setSrcObject(stream, video);

            video.className = elementClass;

            video.muted = true;
            video.volume = 0;

            video.width = stream.width || self.width || 360;
            video.height = stream.height || self.height || 240;

            video.play();

            return video;
        }

        this.appendStreams = function(streams) {
            if (!streams) {
                throw 'First parameter is required.';
            }

            if (!(streams instanceof Array)) {
                streams = [streams];
            }

            streams.forEach(function(stream) {
                var newStream = new MediaStream();

                if (stream.getTracks().filter(function(t) {
                        return t.kind === 'video';
                    }).length) {
                    var video = getVideo(stream);
                    video.stream = stream;
                    videos.push(video);

                    newStream.addTrack(stream.getTracks().filter(function(t) {
                        return t.kind === 'video';
                    })[0]);
                }

                if (stream.getTracks().filter(function(t) {
                        return t.kind === 'audio';
                    }).length) {
                    var audioSource = self.audioContext.createMediaStreamSource(stream);
                    self.audioDestination = self.audioContext.createMediaStreamDestination();
                    audioSource.connect(self.audioDestination);

                    newStream.addTrack(self.audioDestination.stream.getTracks().filter(function(t) {
                        return t.kind === 'audio';
                    })[0]);
                }

                arrayOfMediaStreams.push(newStream);
            });
        };

        this.releaseStreams = function() {
            videos = [];
            isStopDrawingFrames = true;

            if (self.gainNode) {
                self.gainNode.disconnect();
                self.gainNode = null;
            }

            if (self.audioSources.length) {
                self.audioSources.forEach(function(source) {
                    source.disconnect();
                });
                self.audioSources = [];
            }

            if (self.audioDestination) {
                self.audioDestination.disconnect();
                self.audioDestination = null;
            }

            if (self.audioContext) {
                self.audioContext.close();
            }

            self.audioContext = null;

            context.clearRect(0, 0, canvas.width, canvas.height);

            if (canvas.stream) {
                canvas.stream.stop();
                canvas.stream = null;
            }
        };

        this.resetVideoStreams = function(streams) {
            if (streams && !(streams instanceof Array)) {
                streams = [streams];
            }

            resetVideoStreams(streams);
        };

        function resetVideoStreams(streams) {
            videos = [];
            streams = streams || arrayOfMediaStreams;

            // via: @adrian-ber
            streams.forEach(function(stream) {
                if (!stream.getTracks().filter(function(t) {
                        return t.kind === 'video';
                    }).length) {
                    return;
                }

                var video = getVideo(stream);
                video.stream = stream;
                videos.push(video);
            });
        }

        // for debugging
        this.name = 'MultiStreamsMixer';
        this.toString = function() {
            return this.name;
        };

        this.getMixedStream = getMixedStream;

    }

    if (typeof RecordRTC === 'undefined') {
        {
            module.exports = MultiStreamsMixer;
        }
    }

    // ______________________
    // MultiStreamRecorder.js

    /*
     * Video conference recording, using captureStream API along with WebAudio and Canvas2D API.
     */

    /**
     * MultiStreamRecorder can record multiple videos in single container.
     * @summary Multi-videos recorder.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef MultiStreamRecorder
     * @class
     * @example
     * var options = {
     *     mimeType: 'video/webm'
     * }
     * var recorder = new MultiStreamRecorder(ArrayOfMediaStreams, options);
     * recorder.record();
     * recorder.stop(function(blob) {
     *     video.src = URL.createObjectURL(blob);
     *
     *     // or
     *     var blob = recorder.blob;
     * });
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     * @param {MediaStreams} mediaStreams - Array of MediaStreams.
     * @param {object} config - {disableLogs:true, frameInterval: 1, mimeType: "video/webm"}
     */

    function MultiStreamRecorder(arrayOfMediaStreams, options) {
        arrayOfMediaStreams = arrayOfMediaStreams || [];
        var self = this;

        var mixer;
        var mediaRecorder;

        options = options || {
            elementClass: 'multi-streams-mixer',
            mimeType: 'video/webm',
            video: {
                width: 360,
                height: 240
            }
        };

        if (!options.frameInterval) {
            options.frameInterval = 10;
        }

        if (!options.video) {
            options.video = {};
        }

        if (!options.video.width) {
            options.video.width = 360;
        }

        if (!options.video.height) {
            options.video.height = 240;
        }

        /**
         * This method records all MediaStreams.
         * @method
         * @memberof MultiStreamRecorder
         * @example
         * recorder.record();
         */
        this.record = function() {
            // github/muaz-khan/MultiStreamsMixer
            mixer = new MultiStreamsMixer(arrayOfMediaStreams, options.elementClass || 'multi-streams-mixer');

            if (getAllVideoTracks().length) {
                mixer.frameInterval = options.frameInterval || 10;
                mixer.width = options.video.width || 360;
                mixer.height = options.video.height || 240;
                mixer.startDrawingFrames();
            }

            if (options.previewStream && typeof options.previewStream === 'function') {
                options.previewStream(mixer.getMixedStream());
            }

            // record using MediaRecorder API
            mediaRecorder = new MediaStreamRecorder(mixer.getMixedStream(), options);
            mediaRecorder.record();
        };

        function getAllVideoTracks() {
            var tracks = [];
            arrayOfMediaStreams.forEach(function(stream) {
                getTracks(stream, 'video').forEach(function(track) {
                    tracks.push(track);
                });
            });
            return tracks;
        }

        /**
         * This method stops recording MediaStream.
         * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.
         * @method
         * @memberof MultiStreamRecorder
         * @example
         * recorder.stop(function(blob) {
         *     video.src = URL.createObjectURL(blob);
         * });
         */
        this.stop = function(callback) {
            if (!mediaRecorder) {
                return;
            }

            mediaRecorder.stop(function(blob) {
                self.blob = blob;

                callback(blob);

                self.clearRecordedData();
            });
        };

        /**
         * This method pauses the recording process.
         * @method
         * @memberof MultiStreamRecorder
         * @example
         * recorder.pause();
         */
        this.pause = function() {
            if (mediaRecorder) {
                mediaRecorder.pause();
            }
        };

        /**
         * This method resumes the recording process.
         * @method
         * @memberof MultiStreamRecorder
         * @example
         * recorder.resume();
         */
        this.resume = function() {
            if (mediaRecorder) {
                mediaRecorder.resume();
            }
        };

        /**
         * This method resets currently recorded data.
         * @method
         * @memberof MultiStreamRecorder
         * @example
         * recorder.clearRecordedData();
         */
        this.clearRecordedData = function() {
            if (mediaRecorder) {
                mediaRecorder.clearRecordedData();
                mediaRecorder = null;
            }

            if (mixer) {
                mixer.releaseStreams();
                mixer = null;
            }
        };

        /**
         * Add extra media-streams to existing recordings.
         * @method
         * @memberof MultiStreamRecorder
         * @param {MediaStreams} mediaStreams - Array of MediaStreams
         * @example
         * recorder.addStreams([newAudioStream, newVideoStream]);
         */
        this.addStreams = function(streams) {
            if (!streams) {
                throw 'First parameter is required.';
            }

            if (!(streams instanceof Array)) {
                streams = [streams];
            }

            arrayOfMediaStreams.concat(streams);

            if (!mediaRecorder || !mixer) {
                return;
            }

            mixer.appendStreams(streams);

            if (options.previewStream && typeof options.previewStream === 'function') {
                options.previewStream(mixer.getMixedStream());
            }
        };

        /**
         * Reset videos during live recording. Replace old videos e.g. replace cameras with full-screen.
         * @method
         * @memberof MultiStreamRecorder
         * @param {MediaStreams} mediaStreams - Array of MediaStreams
         * @example
         * recorder.resetVideoStreams([newVideo1, newVideo2]);
         */
        this.resetVideoStreams = function(streams) {
            if (!mixer) {
                return;
            }

            if (streams && !(streams instanceof Array)) {
                streams = [streams];
            }

            mixer.resetVideoStreams(streams);
        };

        /**
         * Returns MultiStreamsMixer
         * @method
         * @memberof MultiStreamRecorder
         * @example
         * let mixer = recorder.getMixer();
         * mixer.appendStreams([newStream]);
         */
        this.getMixer = function() {
            return mixer;
        };

        // for debugging
        this.name = 'MultiStreamRecorder';
        this.toString = function() {
            return this.name;
        };
    }

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.MultiStreamRecorder = MultiStreamRecorder;
    }

    // _____________________
    // RecordRTC.promises.js

    /**
     * RecordRTCPromisesHandler adds promises support in {@link RecordRTC}. Try a {@link https://github.com/muaz-khan/RecordRTC/blob/master/simple-demos/RecordRTCPromisesHandler.html|demo here}
     * @summary Promises for {@link RecordRTC}
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef RecordRTCPromisesHandler
     * @class
     * @example
     * var recorder = new RecordRTCPromisesHandler(mediaStream, options);
     * recorder.startRecording()
     *         .then(successCB)
     *         .catch(errorCB);
     * // Note: You can access all RecordRTC API using "recorder.recordRTC" e.g. 
     * recorder.recordRTC.onStateChanged = function(state) {};
     * recorder.recordRTC.setRecordingDuration(5000);
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     * @param {MediaStream} mediaStream - Single media-stream object, array of media-streams, html-canvas-element, etc.
     * @param {object} config - {type:"video", recorderType: MediaStreamRecorder, disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, video: HTMLVideoElement, etc.}
     * @throws Will throw an error if "new" keyword is not used to initiate "RecordRTCPromisesHandler". Also throws error if first argument "MediaStream" is missing.
     * @requires {@link RecordRTC}
     */

    function RecordRTCPromisesHandler(mediaStream, options) {
        if (!this) {
            throw 'Use "new RecordRTCPromisesHandler()"';
        }

        if (typeof mediaStream === 'undefined') {
            throw 'First argument "MediaStream" is required.';
        }

        var self = this;

        /**
         * @property {Blob} blob - Access/reach the native {@link RecordRTC} object.
         * @memberof RecordRTCPromisesHandler
         * @example
         * let internal = recorder.recordRTC.getInternalRecorder();
         * alert(internal instanceof MediaStreamRecorder);
         * recorder.recordRTC.onStateChanged = function(state) {};
         */
        self.recordRTC = new RecordRTC(mediaStream, options);

        /**
         * This method records MediaStream.
         * @method
         * @memberof RecordRTCPromisesHandler
         * @example
         * recorder.startRecording()
         *         .then(successCB)
         *         .catch(errorCB);
         */
        this.startRecording = function() {
            return new Promise(function(resolve, reject) {
                try {
                    self.recordRTC.startRecording();
                    resolve();
                } catch (e) {
                    reject(e);
                }
            });
        };

        /**
         * This method stops the recording.
         * @method
         * @memberof RecordRTCPromisesHandler
         * @example
         * recorder.stopRecording().then(function() {
         *     var blob = recorder.getBlob();
         * }).catch(errorCB);
         */
        this.stopRecording = function() {
            return new Promise(function(resolve, reject) {
                try {
                    self.recordRTC.stopRecording(function(url) {
                        self.blob = self.recordRTC.getBlob();

                        if (!self.blob || !self.blob.size) {
                            reject('Empty blob.', self.blob);
                            return;
                        }

                        resolve(url);
                    });
                } catch (e) {
                    reject(e);
                }
            });
        };

        /**
         * This method pauses the recording. You can resume recording using "resumeRecording" method.
         * @method
         * @memberof RecordRTCPromisesHandler
         * @example
         * recorder.pauseRecording()
         *         .then(successCB)
         *         .catch(errorCB);
         */
        this.pauseRecording = function() {
            return new Promise(function(resolve, reject) {
                try {
                    self.recordRTC.pauseRecording();
                    resolve();
                } catch (e) {
                    reject(e);
                }
            });
        };

        /**
         * This method resumes the recording.
         * @method
         * @memberof RecordRTCPromisesHandler
         * @example
         * recorder.resumeRecording()
         *         .then(successCB)
         *         .catch(errorCB);
         */
        this.resumeRecording = function() {
            return new Promise(function(resolve, reject) {
                try {
                    self.recordRTC.resumeRecording();
                    resolve();
                } catch (e) {
                    reject(e);
                }
            });
        };

        /**
         * This method returns data-url for the recorded blob.
         * @method
         * @memberof RecordRTCPromisesHandler
         * @example
         * recorder.stopRecording().then(function() {
         *     recorder.getDataURL().then(function(dataURL) {
         *         window.open(dataURL);
         *     }).catch(errorCB);;
         * }).catch(errorCB);
         */
        this.getDataURL = function(callback) {
            return new Promise(function(resolve, reject) {
                try {
                    self.recordRTC.getDataURL(function(dataURL) {
                        resolve(dataURL);
                    });
                } catch (e) {
                    reject(e);
                }
            });
        };

        /**
         * This method returns the recorded blob.
         * @method
         * @memberof RecordRTCPromisesHandler
         * @example
         * recorder.stopRecording().then(function() {
         *     recorder.getBlob().then(function(blob) {})
         * }).catch(errorCB);
         */
        this.getBlob = function() {
            return new Promise(function(resolve, reject) {
                try {
                    resolve(self.recordRTC.getBlob());
                } catch (e) {
                    reject(e);
                }
            });
        };

        /**
         * This method returns the internal recording object.
         * @method
         * @memberof RecordRTCPromisesHandler
         * @example
         * let internalRecorder = await recorder.getInternalRecorder();
         * if(internalRecorder instanceof MultiStreamRecorder) {
         *     internalRecorder.addStreams([newAudioStream]);
         *     internalRecorder.resetVideoStreams([screenStream]);
         * }
         * @returns {Object} 
         */
        this.getInternalRecorder = function() {
            return new Promise(function(resolve, reject) {
                try {
                    resolve(self.recordRTC.getInternalRecorder());
                } catch (e) {
                    reject(e);
                }
            });
        };

        /**
         * This method resets the recorder. So that you can reuse single recorder instance many times.
         * @method
         * @memberof RecordRTCPromisesHandler
         * @example
         * await recorder.reset();
         * recorder.startRecording(); // record again
         */
        this.reset = function() {
            return new Promise(function(resolve, reject) {
                try {
                    resolve(self.recordRTC.reset());
                } catch (e) {
                    reject(e);
                }
            });
        };

        /**
         * Destroy RecordRTC instance. Clear all recorders and objects.
         * @method
         * @memberof RecordRTCPromisesHandler
         * @example
         * recorder.destroy().then(successCB).catch(errorCB);
         */
        this.destroy = function() {
            return new Promise(function(resolve, reject) {
                try {
                    resolve(self.recordRTC.destroy());
                } catch (e) {
                    reject(e);
                }
            });
        };

        /**
         * Get recorder's readonly state.
         * @method
         * @memberof RecordRTCPromisesHandler
         * @example
         * let state = await recorder.getState();
         * // or
         * recorder.getState().then(state => { console.log(state); })
         * @returns {String} Returns recording state.
         */
        this.getState = function() {
            return new Promise(function(resolve, reject) {
                try {
                    resolve(self.recordRTC.getState());
                } catch (e) {
                    reject(e);
                }
            });
        };

        /**
         * @property {Blob} blob - Recorded data as "Blob" object.
         * @memberof RecordRTCPromisesHandler
         * @example
         * await recorder.stopRecording();
         * let blob = recorder.getBlob(); // or "recorder.recordRTC.blob"
         * invokeSaveAsDialog(blob);
         */
        this.blob = null;

        /**
         * RecordRTC version number
         * @property {String} version - Release version number.
         * @memberof RecordRTCPromisesHandler
         * @static
         * @readonly
         * @example
         * alert(recorder.version);
         */
        this.version = '5.6.2';
    }

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.RecordRTCPromisesHandler = RecordRTCPromisesHandler;
    }

    // ______________________
    // WebAssemblyRecorder.js

    /**
     * WebAssemblyRecorder lets you create webm videos in JavaScript via WebAssembly. The library consumes raw RGBA32 buffers (4 bytes per pixel) and turns them into a webm video with the given framerate and quality. This makes it compatible out-of-the-box with ImageData from a CANVAS. With realtime mode you can also use webm-wasm for streaming webm videos.
     * @summary Video recording feature in Chrome, Firefox and maybe Edge.
     * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
     * @author {@link https://MuazKhan.com|Muaz Khan}
     * @typedef WebAssemblyRecorder
     * @class
     * @example
     * var recorder = new WebAssemblyRecorder(mediaStream);
     * recorder.record();
     * recorder.stop(function(blob) {
     *     video.src = URL.createObjectURL(blob);
     * });
     * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
     * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
     * @param {object} config - {webAssemblyPath:'webm-wasm.wasm',workerPath: 'webm-worker.js', frameRate: 30, width: 1920, height: 1080, bitrate: 1024, realtime: true}
     */
    function WebAssemblyRecorder(stream, config) {
        // based on: github.com/GoogleChromeLabs/webm-wasm

        if (typeof ReadableStream === 'undefined' || typeof WritableStream === 'undefined') {
            // because it fixes readable/writable streams issues
            console.error('Following polyfill is strongly recommended: https://unpkg.com/@mattiasbuelens/web-streams-polyfill/dist/polyfill.min.js');
        }

        config = config || {};

        config.width = config.width || 640;
        config.height = config.height || 480;
        config.frameRate = config.frameRate || 30;
        config.bitrate = config.bitrate || 1200;
        config.realtime = config.realtime || true;

        var finished;

        function cameraStream() {
            return new ReadableStream({
                start: function(controller) {
                    var cvs = document.createElement('canvas');
                    var video = document.createElement('video');
                    var first = true;
                    video.srcObject = stream;
                    video.muted = true;
                    video.height = config.height;
                    video.width = config.width;
                    video.volume = 0;
                    video.onplaying = function() {
                        cvs.width = config.width;
                        cvs.height = config.height;
                        var ctx = cvs.getContext('2d');
                        var frameTimeout = 1000 / config.frameRate;
                        var cameraTimer = setInterval(function f() {
                            if (finished) {
                                clearInterval(cameraTimer);
                                controller.close();
                            }

                            if (first) {
                                first = false;
                                if (config.onVideoProcessStarted) {
                                    config.onVideoProcessStarted();
                                }
                            }

                            ctx.drawImage(video, 0, 0);
                            if (controller._controlledReadableStream.state !== 'closed') {
                                try {
                                    controller.enqueue(
                                        ctx.getImageData(0, 0, config.width, config.height)
                                    );
                                } catch (e) {}
                            }
                        }, frameTimeout);
                    };
                    video.play();
                }
            });
        }

        var worker;

        function startRecording(stream, buffer) {
            if (!config.workerPath && !buffer) {
                finished = false;

                // is it safe to use @latest ?

                fetch(
                    'https://unpkg.com/webm-wasm@latest/dist/webm-worker.js'
                ).then(function(r) {
                    r.arrayBuffer().then(function(buffer) {
                        startRecording(stream, buffer);
                    });
                });
                return;
            }

            if (!config.workerPath && buffer instanceof ArrayBuffer) {
                var blob = new Blob([buffer], {
                    type: 'text/javascript'
                });
                config.workerPath = URL.createObjectURL(blob);
            }

            if (!config.workerPath) {
                console.error('workerPath parameter is missing.');
            }

            worker = new Worker(config.workerPath);

            worker.postMessage(config.webAssemblyPath || 'https://unpkg.com/webm-wasm@latest/dist/webm-wasm.wasm');
            worker.addEventListener('message', function(event) {
                if (event.data === 'READY') {
                    worker.postMessage({
                        width: config.width,
                        height: config.height,
                        bitrate: config.bitrate || 1200,
                        timebaseDen: config.frameRate || 30,
                        realtime: config.realtime
                    });

                    cameraStream().pipeTo(new WritableStream({
                        write: function(image) {
                            if (finished) {
                                console.error('Got image, but recorder is finished!');
                                return;
                            }

                            worker.postMessage(image.data.buffer, [image.data.buffer]);
                        }
                    }));
                } else if (!!event.data) {
                    if (!isPaused) {
                        arrayOfBuffers.push(event.data);
                    }
                }
            });
        }

        /**
         * This method records video.
         * @method
         * @memberof WebAssemblyRecorder
         * @example
         * recorder.record();
         */
        this.record = function() {
            arrayOfBuffers = [];
            isPaused = false;
            this.blob = null;
            startRecording(stream);

            if (typeof config.initCallback === 'function') {
                config.initCallback();
            }
        };

        var isPaused;

        /**
         * This method pauses the recording process.
         * @method
         * @memberof WebAssemblyRecorder
         * @example
         * recorder.pause();
         */
        this.pause = function() {
            isPaused = true;
        };

        /**
         * This method resumes the recording process.
         * @method
         * @memberof WebAssemblyRecorder
         * @example
         * recorder.resume();
         */
        this.resume = function() {
            isPaused = false;
        };

        function terminate(callback) {
            if (!worker) {
                if (callback) {
                    callback();
                }

                return;
            }

            // Wait for null event data to indicate that the encoding is complete
            worker.addEventListener('message', function(event) {
                if (event.data === null) {
                    worker.terminate();
                    worker = null;

                    if (callback) {
                        callback();
                    }
                }
            });

            worker.postMessage(null);
        }

        var arrayOfBuffers = [];

        /**
         * This method stops recording video.
         * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.
         * @method
         * @memberof WebAssemblyRecorder
         * @example
         * recorder.stop(function(blob) {
         *     video.src = URL.createObjectURL(blob);
         * });
         */
        this.stop = function(callback) {
            finished = true;

            var recorder = this;

            terminate(function() {
                recorder.blob = new Blob(arrayOfBuffers, {
                    type: 'video/webm'
                });

                callback(recorder.blob);
            });
        };

        // for debugging
        this.name = 'WebAssemblyRecorder';
        this.toString = function() {
            return this.name;
        };

        /**
         * This method resets currently recorded data.
         * @method
         * @memberof WebAssemblyRecorder
         * @example
         * recorder.clearRecordedData();
         */
        this.clearRecordedData = function() {
            arrayOfBuffers = [];
            isPaused = false;
            this.blob = null;

            // todo: if recording-ON then STOP it first
        };

        /**
         * @property {Blob} blob - The recorded blob object.
         * @memberof WebAssemblyRecorder
         * @example
         * recorder.stop(function(){
         *     var blob = recorder.blob;
         * });
         */
        this.blob = null;
    }

    if (typeof RecordRTC !== 'undefined') {
        RecordRTC.WebAssemblyRecorder = WebAssemblyRecorder;
    }
    });

    // Exponential-Golomb buffer decoder
    class ExpGolomb {
      constructor(uint8array) {
        this._buffer = uint8array;
        this._buffer_index = 0;
        this._total_bytes = uint8array.byteLength;
        this._total_bits = uint8array.byteLength * 8;
        this._current_word = 0;
        this._current_word_bits_left = 0;
      }

      destroy() {
        this._buffer = null;
      }

      _fillCurrentWord() {
        let buffer_bytes_left = this._total_bytes - this._buffer_index;

        if (buffer_bytes_left <= 0) {
          // throw new IllegalStateException('ExpGolomb: _fillCurrentWord() but no bytes available');
          console.error('ExpGolomb: _fillCurrentWord() but no bytes available', this._total_bytes, this._buffer_index);
          return;
        }

        let bytes_read = Math.min(4, buffer_bytes_left);
        let word = new Uint8Array(4);
        word.set(this._buffer.subarray(this._buffer_index, this._buffer_index + bytes_read));
        this._current_word = new DataView(word.buffer).getUint32(0, false);
        this._buffer_index += bytes_read;
        this._current_word_bits_left = bytes_read * 8;
      }

      readBits(bits) {
        if (bits > 32) {
          // throw new InvalidArgumentException('ExpGolomb: readBits() bits exceeded max 32bits!');
          console.error('ExpGolomb: readBits() bits exceeded max 32bits!');
        }

        if (bits <= this._current_word_bits_left) {
          let result = this._current_word >>> 32 - bits;
          this._current_word <<= bits;
          this._current_word_bits_left -= bits;
          return result;
        }

        let result = this._current_word_bits_left ? this._current_word : 0;
        result = result >>> 32 - this._current_word_bits_left;
        let bits_need_left = bits - this._current_word_bits_left;

        this._fillCurrentWord();

        let bits_read_next = Math.min(bits_need_left, this._current_word_bits_left);
        let result2 = this._current_word >>> 32 - bits_read_next;
        this._current_word <<= bits_read_next;
        this._current_word_bits_left -= bits_read_next;
        result = result << bits_read_next | result2;
        return result;
      }

      readBool() {
        return this.readBits(1) === 1;
      }

      readByte() {
        return this.readBits(8);
      }

      _skipLeadingZero() {
        let zero_count;

        for (zero_count = 0; zero_count < this._current_word_bits_left; zero_count++) {
          if (0 !== (this._current_word & 0x80000000 >>> zero_count)) {
            this._current_word <<= zero_count;
            this._current_word_bits_left -= zero_count;
            return zero_count;
          }
        }

        this._fillCurrentWord();

        return zero_count + this._skipLeadingZero();
      }

      readUEG() {
        // unsigned exponential golomb
        let leading_zeros = this._skipLeadingZero();

        return this.readBits(leading_zeros + 1) - 1;
      }

      readSEG() {
        // signed exponential golomb
        let value = this.readUEG();

        if (value & 0x01) {
          return value + 1 >>> 1;
        } else {
          return -1 * (value >>> 1);
        }
      }

    }

    /*
     * Copyright (C) 2016 Bilibili. All Rights Reserved.
     *
     * @author zheng qian <xqq@xqq.im>
     *
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     *     http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     */

    class SPSParser {
      static _ebsp2rbsp(uint8array) {
        let src = uint8array;
        let src_length = src.byteLength;
        let dst = new Uint8Array(src_length);
        let dst_idx = 0;

        for (let i = 0; i < src_length; i++) {
          if (i >= 2) {
            // Unescape: Skip 0x03 after 00 00
            if (src[i] === 0x03 && src[i - 1] === 0x00 && src[i - 2] === 0x00) {
              continue;
            }
          }

          dst[dst_idx] = src[i];
          dst_idx++;
        }

        return new Uint8Array(dst.buffer, 0, dst_idx);
      } // 解析 SPS
      // https://zhuanlan.zhihu.com/p/27896239


      static parseSPS(uint8array) {
        let rbsp = SPSParser._ebsp2rbsp(uint8array);

        let gb = new ExpGolomb(rbsp);
        gb.readByte(); // 标识当前H.264码流的profile。
        // 我们知道，H.264中定义了三种常用的档次profile： 基准档次：baseline profile;主要档次：main profile; 扩展档次：extended profile;

        let profile_idc = gb.readByte(); // profile_idc

        gb.readByte(); // constraint_set_flags[5] + reserved_zero[3]
        // 标识当前码流的Level。编码的Level定义了某种条件下的最大视频分辨率、最大视频帧率等参数，码流所遵从的level由level_idc指定。

        let level_idc = gb.readByte(); // level_idc
        // 表示当前的序列参数集的id。通过该id值，图像参数集pps可以引用其代表的sps中的参数。

        gb.readUEG(); // seq_parameter_set_id

        let profile_string = SPSParser.getProfileString(profile_idc);
        let level_string = SPSParser.getLevelString(level_idc);
        let chroma_format_idc = 1;
        let chroma_format = 420;
        let chroma_format_table = [0, 420, 422, 444];
        let bit_depth = 8; //

        if (profile_idc === 100 || profile_idc === 110 || profile_idc === 122 || profile_idc === 244 || profile_idc === 44 || profile_idc === 83 || profile_idc === 86 || profile_idc === 118 || profile_idc === 128 || profile_idc === 138 || profile_idc === 144) {
          //
          chroma_format_idc = gb.readUEG();

          if (chroma_format_idc === 3) {
            gb.readBits(1); // separate_colour_plane_flag
          }

          if (chroma_format_idc <= 3) {
            chroma_format = chroma_format_table[chroma_format_idc];
          }

          bit_depth = gb.readUEG() + 8; // bit_depth_luma_minus8

          gb.readUEG(); // bit_depth_chroma_minus8

          gb.readBits(1); // qpprime_y_zero_transform_bypass_flag

          if (gb.readBool()) {
            // seq_scaling_matrix_present_flag
            let scaling_list_count = chroma_format_idc !== 3 ? 8 : 12;

            for (let i = 0; i < scaling_list_count; i++) {
              if (gb.readBool()) {
                // seq_scaling_list_present_flag
                if (i < 6) {
                  SPSParser._skipScalingList(gb, 16);
                } else {
                  SPSParser._skipScalingList(gb, 64);
                }
              }
            }
          }
        } // 用于计算MaxFrameNum的值。计算公式为MaxFrameNum = 2^(log2_max_frame_num_minus4 +


        gb.readUEG(); // log2_max_frame_num_minus4
        // 表示解码picture order count(POC)的方法。POC是另一种计量图像序号的方式，与frame_num有着不同的计算方法。该语法元素的取值为0、1或2。

        let pic_order_cnt_type = gb.readUEG();

        if (pic_order_cnt_type === 0) {
          gb.readUEG(); // log2_max_pic_order_cnt_lsb_minus_4
        } else if (pic_order_cnt_type === 1) {
          gb.readBits(1); // delta_pic_order_always_zero_flag

          gb.readSEG(); // offset_for_non_ref_pic

          gb.readSEG(); // offset_for_top_to_bottom_field

          let num_ref_frames_in_pic_order_cnt_cycle = gb.readUEG();

          for (let i = 0; i < num_ref_frames_in_pic_order_cnt_cycle; i++) {
            gb.readSEG(); // offset_for_ref_frame
          }
        } // 用于表示参考帧的最大数目。


        let ref_frames = gb.readUEG(); // max_num_ref_frames
        // 标识位，说明frame_num中是否允许不连续的值。

        gb.readBits(1); // gaps_in_frame_num_value_allowed_flag
        // 用于计算图像的宽度。单位为宏块个数，因此图像的实际宽度为:

        let pic_width_in_mbs_minus1 = gb.readUEG(); // 使用PicHeightInMapUnits来度量视频中一帧图像的高度。
        // PicHeightInMapUnits并非图像明确的以像素或宏块为单位的高度，而需要考虑该宏块是帧编码或场编码。PicHeightInMapUnits的计算方式为：

        let pic_height_in_map_units_minus1 = gb.readUEG(); // 标识位，说明宏块的编码方式。当该标识位为0时，宏块可能为帧编码或场编码；
        // 该标识位为1时，所有宏块都采用帧编码。根据该标识位取值不同，PicHeightInMapUnits的含义也不同，
        // 为0时表示一场数据按宏块计算的高度，为1时表示一帧数据按宏块计算的高度。

        let frame_mbs_only_flag = gb.readBits(1);

        if (frame_mbs_only_flag === 0) {
          // 标识位，说明是否采用了宏块级的帧场自适应编码。当该标识位为0时，不存在帧编码和场编码之间的切换；当标识位为1时，宏块可能在帧编码和场编码模式之间进行选择。
          gb.readBits(1); // mb_adaptive_frame_field_flag
        } // 标识位，用于B_Skip、B_Direct模式运动矢量的推导计算。


        gb.readBits(1); // direct_8x8_inference_flag

        let frame_crop_left_offset = 0;
        let frame_crop_right_offset = 0;
        let frame_crop_top_offset = 0;
        let frame_crop_bottom_offset = 0;
        let frame_cropping_flag = gb.readBool();

        if (frame_cropping_flag) {
          frame_crop_left_offset = gb.readUEG();
          frame_crop_right_offset = gb.readUEG();
          frame_crop_top_offset = gb.readUEG();
          frame_crop_bottom_offset = gb.readUEG();
        }

        let sar_width = 1,
            sar_height = 1;
        let fps = 0,
            fps_fixed = true,
            fps_num = 0,
            fps_den = 0; // 标识位，说明SPS中是否存在VUI信息。

        let vui_parameters_present_flag = gb.readBool();

        if (vui_parameters_present_flag) {
          if (gb.readBool()) {
            // aspect_ratio_info_present_flag
            let aspect_ratio_idc = gb.readByte();
            let sar_w_table = [1, 12, 10, 16, 40, 24, 20, 32, 80, 18, 15, 64, 160, 4, 3, 2];
            let sar_h_table = [1, 11, 11, 11, 33, 11, 11, 11, 33, 11, 11, 33, 99, 3, 2, 1];

            if (aspect_ratio_idc > 0 && aspect_ratio_idc < 16) {
              sar_width = sar_w_table[aspect_ratio_idc - 1];
              sar_height = sar_h_table[aspect_ratio_idc - 1];
            } else if (aspect_ratio_idc === 255) {
              sar_width = gb.readByte() << 8 | gb.readByte();
              sar_height = gb.readByte() << 8 | gb.readByte();
            }
          }

          if (gb.readBool()) {
            // overscan_info_present_flag
            gb.readBool(); // overscan_appropriate_flag
          }

          if (gb.readBool()) {
            // video_signal_type_present_flag
            gb.readBits(4); // video_format & video_full_range_flag

            if (gb.readBool()) {
              // colour_description_present_flag
              gb.readBits(24); // colour_primaries & transfer_characteristics & matrix_coefficients
            }
          }

          if (gb.readBool()) {
            // chroma_loc_info_present_flag
            gb.readUEG(); // chroma_sample_loc_type_top_field

            gb.readUEG(); // chroma_sample_loc_type_bottom_field
          }

          if (gb.readBool()) {
            // timing_info_present_flag
            let num_units_in_tick = gb.readBits(32);
            let time_scale = gb.readBits(32);
            fps_fixed = gb.readBool(); // fixed_frame_rate_flag

            fps_num = time_scale;
            fps_den = num_units_in_tick * 2;
            fps = fps_num / fps_den;
          }
        }

        let sarScale = 1;

        if (sar_width !== 1 || sar_height !== 1) {
          sarScale = sar_width / sar_height;
        }

        let crop_unit_x = 0,
            crop_unit_y = 0;

        if (chroma_format_idc === 0) {
          crop_unit_x = 1;
          crop_unit_y = 2 - frame_mbs_only_flag;
        } else {
          let sub_wc = chroma_format_idc === 3 ? 1 : 2;
          let sub_hc = chroma_format_idc === 1 ? 2 : 1;
          crop_unit_x = sub_wc;
          crop_unit_y = sub_hc * (2 - frame_mbs_only_flag);
        }

        let codec_width = (pic_width_in_mbs_minus1 + 1) * 16;
        let codec_height = (2 - frame_mbs_only_flag) * ((pic_height_in_map_units_minus1 + 1) * 16);
        codec_width -= (frame_crop_left_offset + frame_crop_right_offset) * crop_unit_x;
        codec_height -= (frame_crop_top_offset + frame_crop_bottom_offset) * crop_unit_y;
        let present_width = Math.ceil(codec_width * sarScale);
        gb.destroy();
        gb = null; // 解析出来的SPS 内容。

        return {
          profile_string: profile_string,
          // baseline, high, high10, ...
          level_string: level_string,
          // 3, 3.1, 4, 4.1, 5, 5.1, ...
          bit_depth: bit_depth,
          // 8bit, 10bit, ...
          ref_frames: ref_frames,
          chroma_format: chroma_format,
          // 4:2:0, 4:2:2, ...
          chroma_format_string: SPSParser.getChromaFormatString(chroma_format),
          frame_rate: {
            fixed: fps_fixed,
            fps: fps,
            fps_den: fps_den,
            fps_num: fps_num
          },
          sar_ratio: {
            width: sar_width,
            height: sar_height
          },
          codec_size: {
            width: codec_width,
            height: codec_height
          },
          present_size: {
            width: present_width,
            height: codec_height
          }
        };
      }

      static parseSPS$2(uint8array) {
        let codec_array = uint8array.subarray(1, 4);
        let codec_mimetype = 'avc1.';

        for (let j = 0; j < 3; j++) {
          let h = codec_array[j].toString(16);

          if (h.length < 2) {
            h = '0' + h;
          }

          codec_mimetype += h;
        }

        let rbsp = SPSParser._ebsp2rbsp(uint8array);

        let gb = new ExpGolomb(rbsp);
        gb.readByte();
        let profile_idc = gb.readByte(); // profile_idc

        gb.readByte(); // constraint_set_flags[5] + reserved_zero[3]

        let level_idc = gb.readByte(); // level_idc

        gb.readUEG(); // seq_parameter_set_id

        let profile_string = SPSParser.getProfileString(profile_idc);
        let level_string = SPSParser.getLevelString(level_idc);
        let chroma_format_idc = 1;
        let chroma_format = 420;
        let chroma_format_table = [0, 420, 422, 444];
        let bit_depth_luma = 8;
        let bit_depth_chroma = 8;

        if (profile_idc === 100 || profile_idc === 110 || profile_idc === 122 || profile_idc === 244 || profile_idc === 44 || profile_idc === 83 || profile_idc === 86 || profile_idc === 118 || profile_idc === 128 || profile_idc === 138 || profile_idc === 144) {
          chroma_format_idc = gb.readUEG();

          if (chroma_format_idc === 3) {
            gb.readBits(1); // separate_colour_plane_flag
          }

          if (chroma_format_idc <= 3) {
            chroma_format = chroma_format_table[chroma_format_idc];
          }

          bit_depth_luma = gb.readUEG() + 8; // bit_depth_luma_minus8

          bit_depth_chroma = gb.readUEG() + 8; // bit_depth_chroma_minus8

          gb.readBits(1); // qpprime_y_zero_transform_bypass_flag

          if (gb.readBool()) {
            // seq_scaling_matrix_present_flag
            let scaling_list_count = chroma_format_idc !== 3 ? 8 : 12;

            for (let i = 0; i < scaling_list_count; i++) {
              if (gb.readBool()) {
                // seq_scaling_list_present_flag
                if (i < 6) {
                  SPSParser._skipScalingList(gb, 16);
                } else {
                  SPSParser._skipScalingList(gb, 64);
                }
              }
            }
          }
        }

        gb.readUEG(); // log2_max_frame_num_minus4

        let pic_order_cnt_type = gb.readUEG();

        if (pic_order_cnt_type === 0) {
          gb.readUEG(); // log2_max_pic_order_cnt_lsb_minus_4
        } else if (pic_order_cnt_type === 1) {
          gb.readBits(1); // delta_pic_order_always_zero_flag

          gb.readSEG(); // offset_for_non_ref_pic

          gb.readSEG(); // offset_for_top_to_bottom_field

          let num_ref_frames_in_pic_order_cnt_cycle = gb.readUEG();

          for (let i = 0; i < num_ref_frames_in_pic_order_cnt_cycle; i++) {
            gb.readSEG(); // offset_for_ref_frame
          }
        }

        let ref_frames = gb.readUEG(); // max_num_ref_frames

        gb.readBits(1); // gaps_in_frame_num_value_allowed_flag

        let pic_width_in_mbs_minus1 = gb.readUEG();
        let pic_height_in_map_units_minus1 = gb.readUEG();
        let frame_mbs_only_flag = gb.readBits(1);

        if (frame_mbs_only_flag === 0) {
          gb.readBits(1); // mb_adaptive_frame_field_flag
        }

        gb.readBits(1); // direct_8x8_inference_flag

        let frame_crop_left_offset = 0;
        let frame_crop_right_offset = 0;
        let frame_crop_top_offset = 0;
        let frame_crop_bottom_offset = 0;
        let frame_cropping_flag = gb.readBool();

        if (frame_cropping_flag) {
          frame_crop_left_offset = gb.readUEG();
          frame_crop_right_offset = gb.readUEG();
          frame_crop_top_offset = gb.readUEG();
          frame_crop_bottom_offset = gb.readUEG();
        }

        let sar_width = 1,
            sar_height = 1;
        let fps = 0,
            fps_fixed = true,
            fps_num = 0,
            fps_den = 0;
        let vui_parameters_present_flag = gb.readBool();

        if (vui_parameters_present_flag) {
          if (gb.readBool()) {
            // aspect_ratio_info_present_flag
            let aspect_ratio_idc = gb.readByte();
            let sar_w_table = [1, 12, 10, 16, 40, 24, 20, 32, 80, 18, 15, 64, 160, 4, 3, 2];
            let sar_h_table = [1, 11, 11, 11, 33, 11, 11, 11, 33, 11, 11, 33, 99, 3, 2, 1];

            if (aspect_ratio_idc > 0 && aspect_ratio_idc < 16) {
              sar_width = sar_w_table[aspect_ratio_idc - 1];
              sar_height = sar_h_table[aspect_ratio_idc - 1];
            } else if (aspect_ratio_idc === 255) {
              sar_width = gb.readByte() << 8 | gb.readByte();
              sar_height = gb.readByte() << 8 | gb.readByte();
            }
          }

          if (gb.readBool()) {
            // overscan_info_present_flag
            gb.readBool(); // overscan_appropriate_flag
          }

          if (gb.readBool()) {
            // video_signal_type_present_flag
            gb.readBits(4); // video_format & video_full_range_flag

            if (gb.readBool()) {
              // colour_description_present_flag
              gb.readBits(24); // colour_primaries & transfer_characteristics & matrix_coefficients
            }
          }

          if (gb.readBool()) {
            // chroma_loc_info_present_flag
            gb.readUEG(); // chroma_sample_loc_type_top_field

            gb.readUEG(); // chroma_sample_loc_type_bottom_field
          }

          if (gb.readBool()) {
            // timing_info_present_flag
            let num_units_in_tick = gb.readBits(32);
            let time_scale = gb.readBits(32);
            fps_fixed = gb.readBool(); // fixed_frame_rate_flag

            fps_num = time_scale;
            fps_den = num_units_in_tick * 2;
            fps = fps_num / fps_den;
          }
        }

        let sarScale = 1;

        if (sar_width !== 1 || sar_height !== 1) {
          sarScale = sar_width / sar_height;
        }

        let crop_unit_x = 0,
            crop_unit_y = 0;

        if (chroma_format_idc === 0) {
          crop_unit_x = 1;
          crop_unit_y = 2 - frame_mbs_only_flag;
        } else {
          let sub_wc = chroma_format_idc === 3 ? 1 : 2;
          let sub_hc = chroma_format_idc === 1 ? 2 : 1;
          crop_unit_x = sub_wc;
          crop_unit_y = sub_hc * (2 - frame_mbs_only_flag);
        }

        let codec_width = (pic_width_in_mbs_minus1 + 1) * 16;
        let codec_height = (2 - frame_mbs_only_flag) * ((pic_height_in_map_units_minus1 + 1) * 16);
        codec_width -= (frame_crop_left_offset + frame_crop_right_offset) * crop_unit_x;
        codec_height -= (frame_crop_top_offset + frame_crop_bottom_offset) * crop_unit_y;
        let present_width = Math.ceil(codec_width * sarScale);
        gb.destroy();
        gb = null;
        return {
          codec_mimetype,
          profile_idc,
          level_idc,
          profile_string,
          // baseline, high, high10, ...
          level_string,
          // 3, 3.1, 4, 4.1, 5, 5.1, ...
          chroma_format_idc,
          bit_depth: bit_depth_luma,
          // 8bit, 10bit, ...
          bit_depth_luma,
          bit_depth_chroma,
          ref_frames,
          chroma_format,
          // 4:2:0, 4:2:2, ...
          chroma_format_string: SPSParser.getChromaFormatString(chroma_format),
          frame_rate: {
            fixed: fps_fixed,
            fps: fps,
            fps_den: fps_den,
            fps_num: fps_num
          },
          sar_ratio: {
            width: sar_width,
            height: sar_height
          },
          codec_size: {
            width: codec_width,
            height: codec_height
          },
          present_size: {
            width: present_width,
            height: codec_height
          }
        };
      }

      static _skipScalingList(gb, count) {
        let last_scale = 8,
            next_scale = 8;
        let delta_scale = 0;

        for (let i = 0; i < count; i++) {
          if (next_scale !== 0) {
            delta_scale = gb.readSEG();
            next_scale = (last_scale + delta_scale + 256) % 256;
          }

          last_scale = next_scale === 0 ? last_scale : next_scale;
        }
      } // profile_idc = 66 → baseline profile;
      // profile_idc = 77 → main profile;
      // profile_idc = 88 → extended profile;
      // 在新版的标准中，还包括了High、High 10、High 4:2:2、High 4:4:4、High 10 Intra、High
      // 4:2:2 Intra、High 4:4:4 Intra、CAVLC 4:4:4 Intra


      static getProfileString(profile_idc) {
        switch (profile_idc) {
          case 66:
            return 'Baseline';

          case 77:
            return 'Main';

          case 88:
            return 'Extended';

          case 100:
            return 'High';

          case 110:
            return 'High10';

          case 122:
            return 'High422';

          case 244:
            return 'High444';

          default:
            return 'Unknown';
        }
      }

      static getLevelString(level_idc) {
        return (level_idc / 10).toFixed(1);
      }

      static getChromaFormatString(chroma) {
        switch (chroma) {
          case 420:
            return '4:2:0';

          case 422:
            return '4:2:2';

          case 444:
            return '4:4:4';

          default:
            return 'Unknown';
        }
      }

    }

    class Bitop {
      constructor(buffer) {
        this.buffer = buffer;
        this.buflen = buffer.length;
        this.bufpos = 0;
        this.bufoff = 0;
        this.iserro = false;
      }

      read(n) {
        let v = 0;
        let d = 0;

        while (n) {
          if (n < 0 || this.bufpos >= this.buflen) {
            this.iserro = true;
            return 0;
          }

          this.iserro = false;
          d = this.bufoff + n > 8 ? 8 - this.bufoff : n;
          v <<= d;
          v += this.buffer[this.bufpos] >> 8 - this.bufoff - d & 0xff >> 8 - d;
          this.bufoff += d;
          n -= d;

          if (this.bufoff == 8) {
            this.bufpos++;
            this.bufoff = 0;
          }
        }

        return v;
      }

      look(n) {
        let p = this.bufpos;
        let o = this.bufoff;
        let v = this.read(n);
        this.bufpos = p;
        this.bufoff = o;
        return v;
      }

      read_golomb() {
        let n;

        for (n = 0; this.read(1) === 0 && !this.iserro; n++);

        return (1 << n) + this.read(n) - 1;
      }

    }

    function parseAVCDecoderConfigurationRecord(arrayBuffer) {
      const meta = {};
      const v = new DataView(arrayBuffer.buffer);
      let version = v.getUint8(0); // configurationVersion

      let avcProfile = v.getUint8(1); // avcProfileIndication

      v.getUint8(2); // profile_compatibil

      v.getUint8(3); // AVCLevelIndication

      if (version !== 1 || avcProfile === 0) {
        // this._onError(DemuxErrors.FORMAT_ERROR, 'Flv: Invalid AVCDecoderConfigurationRecord');
        return;
      }

      const _naluLengthSize = (v.getUint8(4) & 3) + 1; // lengthSizeMinusOne


      if (_naluLengthSize !== 3 && _naluLengthSize !== 4) {
        // holy shit!!!
        // this._onError(DemuxErrors.FORMAT_ERROR, `Flv: Strange NaluLengthSizeMinusOne: ${_naluLengthSize - 1}`);
        return;
      }

      let spsCount = v.getUint8(5) & 31; // numOfSequenceParameterSets

      if (spsCount === 0) {
        // this._onError(DemuxErrors.FORMAT_ERROR, 'Flv: Invalid AVCDecoderConfigurationRecord: No SPS');
        return;
      }

      let offset = 6;

      for (let i = 0; i < spsCount; i++) {
        let len = v.getUint16(offset, false); // sequenceParameterSetLength

        offset += 2;

        if (len === 0) {
          continue;
        } // Notice: Nalu without startcode header (00 00 00 01)


        let sps = new Uint8Array(arrayBuffer.buffer, offset, len);
        offset += len; // flv.js作者选择了自己来解析这个数据结构，也是迫不得已，因为JS环境下没有ffmpeg，解析这个结构主要是为了提取 sps和pps。虽然理论上sps允许有多个，但其实一般就一个。
        // packetTtype 为 1 表示 NALU，NALU= network abstract layer unit，这是H.264的概念，网络抽象层数据单元，其实简单理解就是一帧视频数据。
        // pps的信息没什么用，所以作者只实现了sps的分析器，说明作者下了很大功夫去学习264的标准，其中的Golomb解码还是挺复杂的，能解对不容易，我在PC和手机平台都是用ffmpeg去解析的。
        // SPS里面包括了视频分辨率，帧率，profile level等视频重要信息。

        let config = SPSParser.parseSPS(sps); // console.log('h264 sps config',config)

        if (i !== 0) {
          // ignore other sps's config
          continue;
        }

        meta.sps = sps;
        meta.timescale = 1000;
        meta.codecWidth = config.codec_size.width;
        meta.codecHeight = config.codec_size.height;
        meta.presentWidth = config.present_size.width;
        meta.presentHeight = config.present_size.height;
        meta.profile = config.profile_string;
        meta.level = config.level_string;
        meta.bitDepth = config.bit_depth;
        meta.chromaFormat = config.chroma_format;
        meta.sarRatio = config.sar_ratio;
        meta.frameRate = config.frame_rate;

        if (config.frame_rate.fixed === false || config.frame_rate.fps_num === 0 || config.frame_rate.fps_den === 0) {
          meta.frameRate = {
            fixed: true,
            fps: 23.976,
            fps_num: 23976,
            fps_den: 1000
          };
        }

        let fps_den = meta.frameRate.fps_den;
        let fps_num = meta.frameRate.fps_num;
        meta.refSampleDuration = meta.timescale * (fps_den / fps_num);
        let codecArray = sps.subarray(1, 4);
        let codecString = 'avc1.';

        for (let j = 0; j < 3; j++) {
          let h = codecArray[j].toString(16);

          if (h.length < 2) {
            h = '0' + h;
          }

          codecString += h;
        } // codec


        meta.codec = codecString;
      }

      let ppsCount = v.getUint8(offset); // numOfPictureParameterSets

      if (ppsCount === 0) {
        // this._onError(DemuxErrors.FORMAT_ERROR, 'Flv: Invalid AVCDecoderConfigurationRecord: No PPS');
        return;
      }

      offset++;

      for (let i = 0; i < ppsCount; i++) {
        let len = v.getUint16(offset, false); // pictureParameterSetLength

        offset += 2;

        if (len === 0) {
          continue;
        }

        let pps = new Uint8Array(arrayBuffer.buffer, offset, len); // pps is useless for extracting video information

        offset += len;
        meta.pps = pps;
      }

      meta.videoType = 'avc';

      if (meta.sps) {
        const spsLength = meta.sps.byteLength;
        const spsFlag = new Uint8Array([spsLength >>> 24 & 0xFF, spsLength >>> 16 & 0xFF, spsLength >>> 8 & 0xFF, spsLength & 0xFF]);
        const sps = new Uint8Array(spsLength + 4);
        sps.set(spsFlag, 0);
        sps.set(meta.sps, 4);
        meta.sps = sps;
      }

      if (meta.pps) {
        const ppsLength = meta.pps.byteLength;
        const ppsFlag = new Uint8Array([ppsLength >>> 24 & 0xFF, ppsLength >>> 16 & 0xFF, ppsLength >>> 8 & 0xFF, ppsLength & 0xFF]);
        const pps = new Uint8Array(ppsLength + 4);
        pps.set(ppsFlag, 0);
        pps.set(meta.pps, 4);
        meta.pps = pps;
      } // meta.avcc = arrayBuffer;


      return meta;
    }
    function avcEncoderConfigurationRecord$2(_ref2) {
      let {
        sps,
        pps
      } = _ref2;
      let length = 6 + 2 + sps.byteLength + 1 + 2 + pps.byteLength;
      let need_extra_fields = false;
      const sps_details = SPSParser.parseSPS$2(sps);

      if (sps[3] !== 66 && sps[3] !== 77 && sps[3] !== 88) {
        need_extra_fields = true;
        length += 4;
      }

      let data = new Uint8Array(length);
      data[0] = 0x01; // configurationVersion

      data[1] = sps[1]; // AVCProfileIndication

      data[2] = sps[2]; // profile_compatibility

      data[3] = sps[3]; // AVCLevelIndication

      data[4] = 0xFF; // 111111 + lengthSizeMinusOne(3)

      data[5] = 0xE0 | 0x01; // 111 + numOfSequenceParameterSets

      let sps_length = sps.byteLength;
      data[6] = sps_length >>> 8; // sequenceParameterSetLength

      data[7] = sps_length & 0xFF;
      let offset = 8;
      data.set(sps, 8);
      offset += sps_length;
      data[offset] = 1; // numOfPictureParameterSets

      let pps_length = pps.byteLength;
      data[offset + 1] = pps_length >>> 8; // pictureParameterSetLength

      data[offset + 2] = pps_length & 0xFF;
      data.set(pps, offset + 3);
      offset += 3 + pps_length;

      if (need_extra_fields) {
        data[offset] = 0xFC | sps_details.chroma_format_idc;
        data[offset + 1] = 0xF8 | sps_details.bit_depth_luma - 8;
        data[offset + 2] = 0xF8 | sps_details.bit_depth_chroma - 8;
        data[offset + 3] = 0x00; // number of sps ext

        offset += 4;
      }

      const prevData = [0x17, 0x00, 0x00, 0x00, 0x00];
      const newData = new Uint8Array(prevData.length + data.byteLength);
      newData.set(prevData, 0);
      newData.set(data, prevData.length);
      return newData;
    }
    /**
     *
     * @param oneNALBuffer
     * @param isIframe
     * @returns {Uint8Array}
     */

    function avcEncoderNalePacket(oneNALBuffer, isIframe) {
      //     正常发送nal
      const idrBit = 0x10 | 7;
      const nIdrBit = 0x20 | 7;
      let tmp = [];

      if (isIframe) {
        tmp[0] = idrBit;
      } else {
        tmp[0] = nIdrBit;
      } // compositionTime


      tmp[1] = 1;
      tmp[2] = 0;
      tmp[3] = 0;
      tmp[4] = 0; //

      tmp[5] = oneNALBuffer.byteLength >> 24 & 0xff;
      tmp[6] = oneNALBuffer.byteLength >> 16 & 0xff;
      tmp[7] = oneNALBuffer.byteLength >> 8 & 0xff;
      tmp[8] = oneNALBuffer.byteLength & 0xff;
      const arrayBuffer = new Uint8Array(tmp.length + oneNALBuffer.byteLength);
      arrayBuffer.set(tmp, 0);
      arrayBuffer.set(oneNALBuffer, tmp.length);
      return arrayBuffer;
    }
    /**
     * (NALU类型  & 0001  1111)
     * @param nalu
     * @returns {number}
     */

    function getAvcSeqHeadType(nalu) {
      return nalu[0] & 0b0001_1111;
    }
    function isAvcSeqHead(type) {
      return type === H264_NAL_TYPE.sps || type === H264_NAL_TYPE.pps;
    }
    function isHvcSEIType(type) {
      return type === H264_NAL_TYPE.kSliceSEI;
    }
    function isNotAvcSeqHead(type) {
      return !isAvcSeqHead(type);
    }
    function isAvcNaluIFrame(type) {
      return type === H264_NAL_TYPE.iFrame;
    }

    const _ebsp2rbsp = uint8array => {
      let src = uint8array;
      let src_length = src.byteLength;
      let dst = new Uint8Array(src_length);
      let dst_idx = 0;

      for (let i = 0; i < src_length; i++) {
        if (i >= 2) {
          // Unescape: Skip 0x03 after 00 00
          if (src[i] === 0x03 && src[i - 1] === 0x00 && src[i - 2] === 0x00) {
            continue;
          }
        }

        dst[dst_idx] = src[i];
        dst_idx++;
      }

      return new Uint8Array(dst.buffer, 0, dst_idx);
    };

    const getLevelString = level_idc => {
      return (level_idc / 30).toFixed(1);
    };

    const getChromaFormatString = chroma_format_idc => {
      switch (chroma_format_idc) {
        case 0:
          return '4:0:0';

        case 1:
          return '4:2:0';

        case 2:
          return '4:2:2';

        case 3:
          return '4:4:4';

        default:
          return 'Unknown';
      }
    };

    const parseHevcSPS = uint8array => {
      let rbsp = _ebsp2rbsp(uint8array);

      let gb = new ExpGolomb(rbsp);
      /* remove NALu Header */

      gb.readByte();
      gb.readByte();
      let left_offset = 0,
          right_offset = 0,
          top_offset = 0,
          bottom_offset = 0; // SPS

      gb.readBits(4);
      let max_sub_layers_minus1 = gb.readBits(3);
      gb.readBool(); // profile_tier_level begin

      let general_profile_space = gb.readBits(2);
      let general_tier_flag = gb.readBool();
      let general_profile_idc = gb.readBits(5);
      let general_profile_compatibility_flags_1 = gb.readByte();
      let general_profile_compatibility_flags_2 = gb.readByte();
      let general_profile_compatibility_flags_3 = gb.readByte();
      let general_profile_compatibility_flags_4 = gb.readByte();
      let general_constraint_indicator_flags_1 = gb.readByte();
      let general_constraint_indicator_flags_2 = gb.readByte();
      let general_constraint_indicator_flags_3 = gb.readByte();
      let general_constraint_indicator_flags_4 = gb.readByte();
      let general_constraint_indicator_flags_5 = gb.readByte();
      let general_constraint_indicator_flags_6 = gb.readByte();
      let general_level_idc = gb.readByte();
      let sub_layer_profile_present_flag = [];
      let sub_layer_level_present_flag = [];

      for (let i = 0; i < max_sub_layers_minus1; i++) {
        sub_layer_profile_present_flag.push(gb.readBool());
        sub_layer_level_present_flag.push(gb.readBool());
      }

      if (max_sub_layers_minus1 > 0) {
        for (let i = max_sub_layers_minus1; i < 8; i++) {
          gb.readBits(2);
        }
      }

      for (let i = 0; i < max_sub_layers_minus1; i++) {
        if (sub_layer_profile_present_flag[i]) {
          gb.readByte(); // sub_layer_profile_space, sub_layer_tier_flag, sub_layer_profile_idc

          gb.readByte();
          gb.readByte();
          gb.readByte();
          gb.readByte(); // sub_layer_profile_compatibility_flag

          gb.readByte();
          gb.readByte();
          gb.readByte();
          gb.readByte();
          gb.readByte();
          gb.readByte();
        }

        if (sub_layer_profile_present_flag[i]) {
          gb.readByte();
        }
      } // profile_tier_level end


      gb.readUEG();
      let chroma_format_idc = gb.readUEG();

      if (chroma_format_idc == 3) {
        gb.readBits(1); // separate_colour_plane_flag
      }

      let pic_width_in_luma_samples = gb.readUEG();
      let pic_height_in_luma_samples = gb.readUEG();
      let conformance_window_flag = gb.readBool();

      if (conformance_window_flag) {
        left_offset += gb.readUEG();
        right_offset += gb.readUEG();
        top_offset += gb.readUEG();
        bottom_offset += gb.readUEG();
      }

      let bit_depth_luma_minus8 = gb.readUEG();
      let bit_depth_chroma_minus8 = gb.readUEG();
      let log2_max_pic_order_cnt_lsb_minus4 = gb.readUEG();
      let sub_layer_ordering_info_present_flag = gb.readBool();

      for (let i = sub_layer_ordering_info_present_flag ? 0 : max_sub_layers_minus1; i <= max_sub_layers_minus1; i++) {
        gb.readUEG(); // max_dec_pic_buffering_minus1[i]

        gb.readUEG(); // max_num_reorder_pics[i]

        gb.readUEG(); // max_latency_increase_plus1[i]
      }

      gb.readUEG();
      gb.readUEG();
      gb.readUEG();
      gb.readUEG();
      gb.readUEG();
      gb.readUEG();
      let scaling_list_enabled_flag = gb.readBool();

      if (scaling_list_enabled_flag) {
        let sps_scaling_list_data_present_flag = gb.readBool();

        if (sps_scaling_list_data_present_flag) {
          for (let sizeId = 0; sizeId < 4; sizeId++) {
            for (let matrixId = 0; matrixId < (sizeId === 3 ? 2 : 6); matrixId++) {
              let scaling_list_pred_mode_flag = gb.readBool();

              if (!scaling_list_pred_mode_flag) {
                gb.readUEG(); // scaling_list_pred_matrix_id_delta
              } else {
                let coefNum = Math.min(64, 1 << 4 + (sizeId << 1));

                if (sizeId > 1) {
                  gb.readSEG();
                }

                for (let i = 0; i < coefNum; i++) {
                  gb.readSEG();
                }
              }
            }
          }
        }
      }

      gb.readBool();
      gb.readBool();
      let pcm_enabled_flag = gb.readBool();

      if (pcm_enabled_flag) {
        gb.readByte();
        gb.readUEG();
        gb.readUEG();
        gb.readBool();
      }

      let num_short_term_ref_pic_sets = gb.readUEG();
      let num_delta_pocs = 0;

      for (let i = 0; i < num_short_term_ref_pic_sets; i++) {
        let inter_ref_pic_set_prediction_flag = false;

        if (i !== 0) {
          inter_ref_pic_set_prediction_flag = gb.readBool();
        }

        if (inter_ref_pic_set_prediction_flag) {
          if (i === num_short_term_ref_pic_sets) {
            gb.readUEG();
          }

          gb.readBool();
          gb.readUEG();
          let next_num_delta_pocs = 0;

          for (let j = 0; j <= num_delta_pocs; j++) {
            let used_by_curr_pic_flag = gb.readBool();
            let use_delta_flag = false;

            if (!used_by_curr_pic_flag) {
              use_delta_flag = gb.readBool();
            }

            if (used_by_curr_pic_flag || use_delta_flag) {
              next_num_delta_pocs++;
            }
          }

          num_delta_pocs = next_num_delta_pocs;
        } else {
          let num_negative_pics = gb.readUEG();
          let num_positive_pics = gb.readUEG();
          num_delta_pocs = num_negative_pics + num_positive_pics;

          for (let j = 0; j < num_negative_pics; j++) {
            gb.readUEG();
            gb.readBool();
          }

          for (let j = 0; j < num_positive_pics; j++) {
            gb.readUEG();
            gb.readBool();
          }
        }
      }

      let long_term_ref_pics_present_flag = gb.readBool();

      if (long_term_ref_pics_present_flag) {
        let num_long_term_ref_pics_sps = gb.readUEG();

        for (let i = 0; i < num_long_term_ref_pics_sps; i++) {
          for (let j = 0; j < log2_max_pic_order_cnt_lsb_minus4 + 4; j++) {
            gb.readBits(1);
          }

          gb.readBits(1);
        }
      } //*


      let default_display_window_flag = false; // for calc offset

      let min_spatial_segmentation_idc = 0; // for hvcC

      let sar_width = 1,
          sar_height = 1;
      let fps_fixed = false,
          fps_den = 1,
          fps_num = 1; //*/

      gb.readBool();
      gb.readBool();
      let vui_parameters_present_flag = gb.readBool();

      if (vui_parameters_present_flag) {
        let aspect_ratio_info_present_flag = gb.readBool();

        if (aspect_ratio_info_present_flag) {
          let aspect_ratio_idc = gb.readByte();
          let sar_w_table = [1, 12, 10, 16, 40, 24, 20, 32, 80, 18, 15, 64, 160, 4, 3, 2];
          let sar_h_table = [1, 11, 11, 11, 33, 11, 11, 11, 33, 11, 11, 33, 99, 3, 2, 1];

          if (aspect_ratio_idc > 0 && aspect_ratio_idc < 16) {
            sar_width = sar_w_table[aspect_ratio_idc - 1];
            sar_height = sar_h_table[aspect_ratio_idc - 1];
          } else if (aspect_ratio_idc === 255) {
            sar_width = gb.readBits(16);
            sar_height = gb.readBits(16);
          }
        }

        let overscan_info_present_flag = gb.readBool();

        if (overscan_info_present_flag) {
          gb.readBool();
        }

        let video_signal_type_present_flag = gb.readBool();

        if (video_signal_type_present_flag) {
          gb.readBits(3);
          gb.readBool();
          let colour_description_present_flag = gb.readBool();

          if (colour_description_present_flag) {
            gb.readByte();
            gb.readByte();
            gb.readByte();
          }
        }

        let chroma_loc_info_present_flag = gb.readBool();

        if (chroma_loc_info_present_flag) {
          gb.readUEG();
          gb.readUEG();
        }

        gb.readBool();
        gb.readBool();
        gb.readBool();
        default_display_window_flag = gb.readBool();

        if (default_display_window_flag) {
          left_offset += gb.readUEG();
          right_offset += gb.readUEG();
          top_offset += gb.readUEG();
          bottom_offset += gb.readUEG();
        }

        let vui_timing_info_present_flag = gb.readBool();

        if (vui_timing_info_present_flag) {
          fps_den = gb.readBits(32);
          fps_num = gb.readBits(32);
          let vui_poc_proportional_to_timing_flag = gb.readBool();

          if (vui_poc_proportional_to_timing_flag) {
            gb.readUEG();
            let vui_hrd_parameters_present_flag = gb.readBool();

            if (vui_hrd_parameters_present_flag) {
              let nal_hrd_parameters_present_flag = false;
              let vcl_hrd_parameters_present_flag = false;
              let sub_pic_hrd_params_present_flag = false;

              {
                nal_hrd_parameters_present_flag = gb.readBool();
                vcl_hrd_parameters_present_flag = gb.readBool();

                if (nal_hrd_parameters_present_flag || vcl_hrd_parameters_present_flag) {
                  sub_pic_hrd_params_present_flag = gb.readBool();

                  if (sub_pic_hrd_params_present_flag) {
                    gb.readByte();
                    gb.readBits(5);
                    gb.readBool();
                    gb.readBits(5);
                  }

                  gb.readBits(4);
                  gb.readBits(4);

                  if (sub_pic_hrd_params_present_flag) {
                    gb.readBits(4);
                  }

                  gb.readBits(5);
                  gb.readBits(5);
                  gb.readBits(5);
                }
              }

              for (let i = 0; i <= max_sub_layers_minus1; i++) {
                let fixed_pic_rate_general_flag = gb.readBool();
                fps_fixed = fixed_pic_rate_general_flag;
                let fixed_pic_rate_within_cvs_flag = false;
                let cpbCnt = 1;

                if (!fixed_pic_rate_general_flag) {
                  fixed_pic_rate_within_cvs_flag = gb.readBool();
                }

                let low_delay_hrd_flag = false;

                if (fixed_pic_rate_within_cvs_flag) {
                  gb.readSEG();
                } else {
                  low_delay_hrd_flag = gb.readBool();
                }

                if (!low_delay_hrd_flag) {
                  cpbcnt = gb.readUEG() + 1;
                }

                if (nal_hrd_parameters_present_flag) {
                  for (let j = 0; j < cpbCnt; j++) {
                    gb.readUEG();
                    gb.readUEG();

                    if (sub_pic_hrd_params_present_flag) {
                      gb.readUEG();
                      gb.readUEG();
                    }
                  }
                }

                if (vcl_hrd_parameters_present_flag) {
                  for (let j = 0; j < cpbCnt; j++) {
                    gb.readUEG();
                    gb.readUEG();

                    if (sub_pic_hrd_params_present_flag) {
                      gb.readUEG();
                      gb.readUEG();
                    }
                  }
                }
              }
            }
          }
        }

        let bitstream_restriction_flag = gb.readBool();

        if (bitstream_restriction_flag) {
          gb.readBool();
          gb.readBool();
          gb.readBool();
          min_spatial_segmentation_idc = gb.readUEG();
          gb.readUEG();
          gb.readUEG();
          gb.readUEG();
          gb.readUEG();
        }
      }

      gb.readBool(); // ignore...
      // for meta data

      let codec_mimetype = `hvc1.${general_profile_idc}.1.L${general_level_idc}.B0`;
      let codec_width = pic_width_in_luma_samples;
      let codec_height = pic_height_in_luma_samples;
      let sar_scale = 1;

      if (sar_width !== 1 && sar_height !== 1) {
        sar_scale = sar_width / sar_height;
      }

      gb.destroy();
      gb = null;
      return {
        codec_mimetype,
        level_string: getLevelString(general_level_idc),
        profile_idc: general_profile_idc,
        bit_depth: bit_depth_luma_minus8 + 8,
        ref_frames: 1,
        // FIXME!!!
        chroma_format: chroma_format_idc,
        chroma_format_string: getChromaFormatString(chroma_format_idc),
        general_level_idc,
        general_profile_space,
        general_tier_flag,
        general_profile_idc,
        general_profile_compatibility_flags_1,
        general_profile_compatibility_flags_2,
        general_profile_compatibility_flags_3,
        general_profile_compatibility_flags_4,
        general_constraint_indicator_flags_1,
        general_constraint_indicator_flags_2,
        general_constraint_indicator_flags_3,
        general_constraint_indicator_flags_4,
        general_constraint_indicator_flags_5,
        general_constraint_indicator_flags_6,
        min_spatial_segmentation_idc,
        constant_frame_rate: 0
        /* FIXME!! fps_fixed ? 1 : 0? */
        ,
        chroma_format_idc,
        bit_depth_luma_minus8,
        bit_depth_chroma_minus8,
        frame_rate: {
          fixed: fps_fixed,
          fps: fps_num / fps_den,
          fps_den: fps_den,
          fps_num: fps_num
        },
        sar_ratio: {
          width: sar_width,
          height: sar_height
        },
        codec_size: {
          width: codec_width,
          height: codec_height
        },
        present_size: {
          width: codec_width * sar_scale,
          height: codec_height
        }
      };
    };
    const parseHevcVPS = uint8array => {
      let rbsp = _ebsp2rbsp(uint8array);

      let gb = new ExpGolomb(rbsp);
      /* remove NALu Header */

      gb.readByte();
      gb.readByte(); // VPS

      gb.readBits(4);
      gb.readBits(2);
      gb.readBits(6);
      let max_sub_layers_minus1 = gb.readBits(3);
      let temporal_id_nesting_flag = gb.readBool(); // and more ...

      return {
        num_temporal_layers: max_sub_layers_minus1 + 1,
        temporal_id_nested: temporal_id_nesting_flag
      };
    };
    const parseHevcPPS = uint8array => {
      let rbsp = _ebsp2rbsp(uint8array);

      let gb = new ExpGolomb(rbsp);
      /* remove NALu Header */

      gb.readByte();
      gb.readByte();
      gb.readUEG();
      gb.readUEG();
      gb.readBool();
      gb.readBool();
      gb.readBits(3);
      gb.readBool();
      gb.readBool();
      gb.readUEG();
      gb.readUEG();
      gb.readSEG();
      gb.readBool();
      gb.readBool();
      let cu_qp_delta_enabled_flag = gb.readBool();

      if (cu_qp_delta_enabled_flag) {
        gb.readUEG();
      }

      gb.readSEG();
      gb.readSEG();
      gb.readBool();
      gb.readBool();
      gb.readBool();
      gb.readBool();
      let tiles_enabled_flag = gb.readBool();
      let entropy_coding_sync_enabled_flag = gb.readBool(); // and more ...
      // needs hvcC

      let parallelismType = 1; // slice-based parallel decoding

      if (entropy_coding_sync_enabled_flag && tiles_enabled_flag) {
        parallelismType = 0; // mixed-type parallel decoding
      } else if (entropy_coding_sync_enabled_flag) {
        parallelismType = 3; // wavefront-based parallel decoding
      } else if (tiles_enabled_flag) {
        parallelismType = 2; // tile-based parallel decoding
      }

      return {
        parallelismType
      };
    };

    /**
     *
     * @param arrayBuffer
     */

    function parseHEVCDecoderConfigurationRecord$2(arrayBuffer) {
      let info = {};
      info.width = 0;
      info.height = 0;
      info.profile = 0;
      info.level = 0;
      arrayBuffer = arrayBuffer.slice(5);

      do {
        let hevc = {};

        if (arrayBuffer.length < 23) {
          break;
        }

        hevc.configurationVersion = arrayBuffer[0];

        if (hevc.configurationVersion != 1) {
          break;
        }

        hevc.general_profile_space = arrayBuffer[1] >> 6 & 0x03;
        hevc.general_tier_flag = arrayBuffer[1] >> 5 & 0x01;
        hevc.general_profile_idc = arrayBuffer[1] & 0x1F;
        hevc.general_profile_compatibility_flags = arrayBuffer[2] << 24 | arrayBuffer[3] << 16 | arrayBuffer[4] << 8 | arrayBuffer[5];
        hevc.general_constraint_indicator_flags = arrayBuffer[6] << 24 | arrayBuffer[7] << 16 | arrayBuffer[8] << 8 | arrayBuffer[9];
        hevc.general_constraint_indicator_flags = hevc.general_constraint_indicator_flags << 16 | arrayBuffer[10] << 8 | arrayBuffer[11];
        hevc.general_level_idc = arrayBuffer[12];
        hevc.min_spatial_segmentation_idc = (arrayBuffer[13] & 0x0F) << 8 | arrayBuffer[14];
        hevc.parallelismType = arrayBuffer[15] & 0x03;
        hevc.chromaFormat = arrayBuffer[16] & 0x03;
        hevc.bitDepthLumaMinus8 = arrayBuffer[17] & 0x07;
        hevc.bitDepthChromaMinus8 = arrayBuffer[18] & 0x07;
        hevc.avgFrameRate = arrayBuffer[19] << 8 | arrayBuffer[20];
        hevc.constantFrameRate = arrayBuffer[21] >> 6 & 0x03;
        hevc.numTemporalLayers = arrayBuffer[21] >> 3 & 0x07;
        hevc.temporalIdNested = arrayBuffer[21] >> 2 & 0x01;
        hevc.lengthSizeMinusOne = arrayBuffer[21] & 0x03;
        let numOfArrays = arrayBuffer[22];
        let p = arrayBuffer.slice(23);

        for (let i = 0; i < numOfArrays; i++) {
          if (p.length < 3) {
            break;
          }

          let nalutype = p[0] & 0x3F;
          let n = p[1] << 8 | p[2]; // console.log('nalutype', nalutype,n)

          p = p.slice(3);

          for (let j = 0; j < n; j++) {
            if (p.length < 2) {
              break;
            }

            let k = p[0] << 8 | p[1]; // console.log('k', k)

            if (p.length < 2 + k) {
              break;
            }

            p = p.slice(2);

            if (nalutype == 33) {
              //SPS
              let sps = new Uint8Array(k);
              sps.set(p.slice(0, k), 0);
              hevc.psps = HEVCParseSPS(sps, hevc);
              info.profile = hevc.general_profile_idc;
              info.level = hevc.general_level_idc / 30.0;
              info.width = hevc.psps.pic_width_in_luma_samples - (hevc.psps.conf_win_left_offset + hevc.psps.conf_win_right_offset);
              info.height = hevc.psps.pic_height_in_luma_samples - (hevc.psps.conf_win_top_offset + hevc.psps.conf_win_bottom_offset);
            }

            p = p.slice(k);
          }
        }
      } while (0);

      info.codecWidth = info.width || 1920;
      info.codecHeight = info.height || 1080;
      info.presentHeight = info.codecHeight;
      info.presentWidth = info.codecWidth;
      info.timescale = 1000;
      info.refSampleDuration = 1000 * (1000 / 23976);
      info.videoType = VIDEO_ENCODE_TYPE.h265;
      return info;
    }
    function parseHEVCDecoderVPSAndSPSAndPPS(arrayBuffer) {
      //
      let offset = 28 - 5; // 23
      //

      const vpsTag = arrayBuffer[offset];

      if ((vpsTag & 0x3F) !== H265_NAL_TYPE.vps) {
        console.warn(`parseHEVCDecoderVPSAndSPSAndPPS and vpsTag is ${vpsTag}`);
        return {};
      }

      offset += 2;
      offset += 1;
      const vpsLength = arrayBuffer[offset + 1] | arrayBuffer[offset] << 8;
      offset += 2;
      const vpsData = arrayBuffer.slice(offset, offset + vpsLength); // console.log('vpsData:', Uint8Array.from(vpsData));

      offset += vpsLength;
      const spsTag = arrayBuffer[offset];

      if ((spsTag & 0x3F) !== H265_NAL_TYPE.sps) {
        console.warn(`parseHEVCDecoderVPSAndSPSAndPPS and sps tag is ${spsTag}`);
        return {};
      }

      offset += 2;
      offset += 1;
      const spsLength = arrayBuffer[offset + 1] | arrayBuffer[offset] << 8;
      offset += 2;
      const spsData = arrayBuffer.slice(offset, offset + spsLength); // console.log('spsData:', Uint8Array.from(spsData));

      offset += spsLength;
      const ppsTag = arrayBuffer[offset];

      if ((ppsTag & 0x3F) !== H265_NAL_TYPE.pps) {
        console.warn(`parseHEVCDecoderVPSAndSPSAndPPS and pps tag is ${ppsTag}`);
        return {};
      }

      offset += 2;
      offset += 1;
      const ppsLength = arrayBuffer[offset + 1] | arrayBuffer[offset] << 8;
      offset += 2;
      const ppsData = arrayBuffer.slice(offset, offset + ppsLength); // console.log('ppsData:', Uint8Array.from(ppsData));

      const spsFlag = new Uint8Array([spsLength >>> 24 & 0xFF, spsLength >>> 16 & 0xFF, spsLength >>> 8 & 0xFF, spsLength & 0xFF]);
      const ppsFlag = new Uint8Array([ppsLength >>> 24 & 0xFF, ppsLength >>> 16 & 0xFF, ppsLength >>> 8 & 0xFF, ppsLength & 0xFF]);
      const vpsFlag = new Uint8Array([vpsLength >>> 24 & 0xFF, vpsLength >>> 16 & 0xFF, vpsLength >>> 8 & 0xFF, vpsLength & 0xFF]);
      const sps = new Uint8Array(spsLength + 4);
      sps.set(spsFlag, 0);
      sps.set(spsData, 4);
      const pps = new Uint8Array(ppsLength + 4);
      pps.set(ppsFlag, 0);
      pps.set(ppsData, 4);
      const vps = new Uint8Array(vpsLength + 4);
      vps.set(vpsFlag, 0);
      vps.set(vpsData, 4);
      return {
        sps,
        pps,
        vps
      };
    }
    function HEVCParsePtl(bitop, hevc, max_sub_layers_minus1) {
      let general_ptl = {};
      general_ptl.profile_space = bitop.read(2);
      general_ptl.tier_flag = bitop.read(1);
      general_ptl.profile_idc = bitop.read(5);
      general_ptl.profile_compatibility_flags = bitop.read(32);
      general_ptl.general_progressive_source_flag = bitop.read(1);
      general_ptl.general_interlaced_source_flag = bitop.read(1);
      general_ptl.general_non_packed_constraint_flag = bitop.read(1);
      general_ptl.general_frame_only_constraint_flag = bitop.read(1);
      bitop.read(32);
      bitop.read(12);
      general_ptl.level_idc = bitop.read(8);
      general_ptl.sub_layer_profile_present_flag = [];
      general_ptl.sub_layer_level_present_flag = [];

      for (let i = 0; i < max_sub_layers_minus1; i++) {
        general_ptl.sub_layer_profile_present_flag[i] = bitop.read(1);
        general_ptl.sub_layer_level_present_flag[i] = bitop.read(1);
      }

      if (max_sub_layers_minus1 > 0) {
        for (let i = max_sub_layers_minus1; i < 8; i++) {
          bitop.read(2);
        }
      }

      general_ptl.sub_layer_profile_space = [];
      general_ptl.sub_layer_tier_flag = [];
      general_ptl.sub_layer_profile_idc = [];
      general_ptl.sub_layer_profile_compatibility_flag = [];
      general_ptl.sub_layer_progressive_source_flag = [];
      general_ptl.sub_layer_interlaced_source_flag = [];
      general_ptl.sub_layer_non_packed_constraint_flag = [];
      general_ptl.sub_layer_frame_only_constraint_flag = [];
      general_ptl.sub_layer_level_idc = [];

      for (let i = 0; i < max_sub_layers_minus1; i++) {
        if (general_ptl.sub_layer_profile_present_flag[i]) {
          general_ptl.sub_layer_profile_space[i] = bitop.read(2);
          general_ptl.sub_layer_tier_flag[i] = bitop.read(1);
          general_ptl.sub_layer_profile_idc[i] = bitop.read(5);
          general_ptl.sub_layer_profile_compatibility_flag[i] = bitop.read(32);
          general_ptl.sub_layer_progressive_source_flag[i] = bitop.read(1);
          general_ptl.sub_layer_interlaced_source_flag[i] = bitop.read(1);
          general_ptl.sub_layer_non_packed_constraint_flag[i] = bitop.read(1);
          general_ptl.sub_layer_frame_only_constraint_flag[i] = bitop.read(1);
          bitop.read(32);
          bitop.read(12);
        }

        if (general_ptl.sub_layer_level_present_flag[i]) {
          general_ptl.sub_layer_level_idc[i] = bitop.read(8);
        } else {
          general_ptl.sub_layer_level_idc[i] = 1;
        }
      }

      return general_ptl;
    }
    function HEVCParseSPS(SPS, hevc) {
      let psps = {};
      let NumBytesInNALunit = SPS.length;
      let rbsp_array = [];
      let bitop = new Bitop(SPS);
      bitop.read(1); //forbidden_zero_bit

      bitop.read(6); //nal_unit_type

      bitop.read(6); //nuh_reserved_zero_6bits

      bitop.read(3); //nuh_temporal_id_plus1

      for (let i = 2; i < NumBytesInNALunit; i++) {
        if (i + 2 < NumBytesInNALunit && bitop.look(24) == 0x000003) {
          rbsp_array.push(bitop.read(8));
          rbsp_array.push(bitop.read(8));
          i += 2;
          bitop.read(8);
          /* equal to 0x03 */
        } else {
          rbsp_array.push(bitop.read(8));
        }
      }

      let rbsp = new Uint8Array(rbsp_array);
      let rbspBitop = new Bitop(rbsp);
      psps.sps_video_parameter_set_id = rbspBitop.read(4);
      psps.sps_max_sub_layers_minus1 = rbspBitop.read(3);
      psps.sps_temporal_id_nesting_flag = rbspBitop.read(1);
      psps.profile_tier_level = HEVCParsePtl(rbspBitop, hevc, psps.sps_max_sub_layers_minus1);
      psps.sps_seq_parameter_set_id = rbspBitop.read_golomb();
      psps.chroma_format_idc = rbspBitop.read_golomb();

      if (psps.chroma_format_idc == 3) {
        psps.separate_colour_plane_flag = rbspBitop.read(1);
      } else {
        psps.separate_colour_plane_flag = 0;
      }

      psps.pic_width_in_luma_samples = rbspBitop.read_golomb();
      psps.pic_height_in_luma_samples = rbspBitop.read_golomb();
      psps.conformance_window_flag = rbspBitop.read(1);

      if (psps.conformance_window_flag) {
        let vert_mult = 1 + (psps.chroma_format_idc < 2);
        let horiz_mult = 1 + (psps.chroma_format_idc < 3);
        psps.conf_win_left_offset = rbspBitop.read_golomb() * horiz_mult;
        psps.conf_win_right_offset = rbspBitop.read_golomb() * horiz_mult;
        psps.conf_win_top_offset = rbspBitop.read_golomb() * vert_mult;
        psps.conf_win_bottom_offset = rbspBitop.read_golomb() * vert_mult;
      } else {
        psps.conf_win_left_offset = 0;
        psps.conf_win_right_offset = 0;
        psps.conf_win_top_offset = 0;
        psps.conf_win_bottom_offset = 0;
      } // Logger.debug(psps);


      return psps;
    }
    function hevcEncoderConfigurationRecord$2(_ref2) {
      let {
        vps,
        pps,
        sps
      } = _ref2;
      let detail = {
        configurationVersion: 1
      };
      const vpsDetail = parseHevcVPS(vps);
      const spsDetail = parseHevcSPS(sps);
      const ppsDetail = parseHevcPPS(pps);
      detail = Object.assign(detail, vpsDetail, spsDetail, ppsDetail);
      let length = 23 + (3 + 2 + vps.byteLength) + (3 + 2 + sps.byteLength) + (3 + 2 + pps.byteLength);
      let data = new Uint8Array(length);
      data[0] = 0x01; // configurationVersion

      data[1] = (detail.general_profile_space & 0x03) << 6 | (detail.general_tier_flag ? 1 : 0) << 5 | detail.general_profile_idc & 0x1F;
      data[2] = detail.general_profile_compatibility_flags_1 || 0;
      data[3] = detail.general_profile_compatibility_flags_2 || 0;
      data[4] = detail.general_profile_compatibility_flags_3 || 0;
      data[5] = detail.general_profile_compatibility_flags_4 || 0;
      data[6] = detail.general_constraint_indicator_flags_1 || 0;
      data[7] = detail.general_constraint_indicator_flags_2 || 0;
      data[8] = detail.general_constraint_indicator_flags_3 || 0;
      data[9] = detail.general_constraint_indicator_flags_4 || 0;
      data[10] = detail.general_constraint_indicator_flags_5 || 0;
      data[11] = detail.general_constraint_indicator_flags_6 || 0;
      data[12] = 0x3C;
      data[13] = 0xF0 | (detail.min_spatial_segmentation_idc & 0x0F00) >> 8;
      data[14] = detail.min_spatial_segmentation_idc & 0xFF;
      data[15] = 0xFC | detail.parallelismType & 0x03;
      data[16] = 0xFC | detail.chroma_format_idc & 0x03;
      data[17] = 0xF8 | detail.bit_depth_luma_minus8 & 0x07;
      data[18] = 0xF8 | detail.bit_depth_chroma_minus8 & 0x07;
      data[19] = 0;
      data[20] = 0;
      data[21] = (detail.constant_frame_rate & 0x03) << 6 | (detail.num_temporal_layers & 0x07) << 3 | (detail.temporal_id_nested ? 1 : 0) << 2 | 3;
      data[22] = 3;
      data[23 + 0 + 0] = 0x80 | H265_NAL_TYPE.vps;
      data[23 + 0 + 1] = 0;
      data[23 + 0 + 2] = 1;
      data[23 + 0 + 3] = (vps.byteLength & 0xFF00) >> 8;
      data[23 + 0 + 4] = (vps.byteLength & 0x00FF) >> 0;
      data.set(vps, 23 + 0 + 5);
      data[23 + (5 + vps.byteLength) + 0] = 0x80 | H265_NAL_TYPE.sps;
      data[23 + (5 + vps.byteLength) + 1] = 0;
      data[23 + (5 + vps.byteLength) + 2] = 1;
      data[23 + (5 + vps.byteLength) + 3] = (sps.byteLength & 0xFF00) >> 8;
      data[23 + (5 + vps.byteLength) + 4] = (sps.byteLength & 0x00FF) >> 0;
      data.set(sps, 23 + (5 + vps.byteLength) + 5);
      data[23 + (5 + vps.byteLength + 5 + sps.byteLength) + 0] = 0x80 | H265_NAL_TYPE.pps;
      data[23 + (5 + vps.byteLength + 5 + sps.byteLength) + 1] = 0;
      data[23 + (5 + vps.byteLength + 5 + sps.byteLength) + 2] = 1;
      data[23 + (5 + vps.byteLength + 5 + sps.byteLength) + 3] = (pps.byteLength & 0xFF00) >> 8;
      data[23 + (5 + vps.byteLength + 5 + sps.byteLength) + 4] = (pps.byteLength & 0x00FF) >> 0;
      data.set(pps, 23 + (5 + vps.byteLength + 5 + sps.byteLength) + 5);
      const prevData = [0x1c, 0, 0, 0, 0];
      const newData = new Uint8Array(prevData.length + data.byteLength);
      newData.set(prevData, 0);
      newData.set(data, prevData.length);
      return newData;
    }
    /**
     *
     * @param oneNALBuffer
     * @param isIframe
     * @returns {Uint8Array}
     */

    function hevcEncoderNalePacket(oneNALBuffer, isIframe) {
      //     正常发送nal
      // 这边增加 是否i帧， 然后前面封装了1 + 8 个字节的数据。
      const idrBit = 0x10 | 12;
      const nIdrBit = 0x20 | 12;
      let tmp = [];

      if (isIframe) {
        tmp[0] = idrBit;
      } else {
        tmp[0] = nIdrBit;
      }

      tmp[1] = 1; //

      tmp[2] = 0;
      tmp[3] = 0;
      tmp[4] = 0; // 真正开始的地方。。。

      tmp[5] = oneNALBuffer.byteLength >> 24 & 0xff;
      tmp[6] = oneNALBuffer.byteLength >> 16 & 0xff;
      tmp[7] = oneNALBuffer.byteLength >> 8 & 0xff;
      tmp[8] = oneNALBuffer.byteLength & 0xff;
      const arrayBuffer = new Uint8Array(tmp.length + oneNALBuffer.byteLength);
      arrayBuffer.set(tmp, 0);
      arrayBuffer.set(oneNALBuffer, tmp.length);
      return arrayBuffer;
    }
    function getHevcSeqHeadType(nalu) {
      return (nalu[0] & 0x7E) >> 1;
    }
    function isHevcSEIType(type) {
      return type === H265_NAL_TYPE.sei;
    } // 32-40是VPS SPS PPS SUFFIX_SEI_NUT等

    function isHevcSeqHead(type) {
      return type >= 32 && type <= 40;
    }
    function isNotHevcSeqHead(type) {
      return !isHevcSeqHead(type);
    } // 16-21是关键(I)帧

    function isHevcNalIFrame(type) {
      return type >= 16 && type <= 21;
    } // 0-9是P帧

    class CommonLoader$1 extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.fileName = '';
        this._isRecording = false;
        this._recordingTimestamp = 0;
        this.recordingInterval = null; //

        this.sps = null;
        this.pps = null;
        this.vps = null;
        this.codecId = null;
        this.mdatBytesLength = 0;
        this.metaInfo = {
          codecWidth: 0,
          codecHeight: 0,
          presentWidth: 0,
          presentHeight: 0,
          refSampleDuration: 0,
          timescale: 1000,
          avcc: null,
          videoType: ''
        };
      }

      destroy() {
        this._reset();
      }

      get isH264() {
        return this.codecId === VIDEO_ENC_CODE.h264;
      }

      get isH265() {
        return this.codecId === VIDEO_ENC_CODE.h265;
      }

      setFileName(fileName) {
        this.fileName = fileName;
      }

      get isRecording() {
        return this._isRecording;
      }

      get recording() {
        return this._isRecording;
      }

      get recordTime() {
        return this._recordingTimestamp;
      }

      startRecord() {} // just for mp4


      handleAddNaluTrack(payload, isIframe, dts, cts) {}

      handleAddTrack(arrayBuffer) {}

      stopRecordAndSave() {}

      startRecordingInterval() {
        this.stopRecordingInterval();
        this.recordingInterval = window.setInterval(() => {
          this._recordingTimestamp += 1;
          this.player.emit(EVENTS.recordingTimestamp, this._recordingTimestamp);
        }, 1000);
      }

      stopRecordingInterval() {
        if (this.recordingInterval) {
          clearInterval(this.recordingInterval);
        }

        this.recordingInterval = null;
      }

      getToTalByteLength() {}

      _reset() {
        this.fileName = '';
        this._isRecording = false;
        this._recordingTimestamp = 0;
        this.stopRecordingInterval();
        this.sps = null;
        this.pps = null;
        this.vps = null;
        this.codecId = null;
        this.mdatBytesLength = 0;
      }

      initMetaData(arrayBuffer, codecId) {
        let metaData;
        const extraData = arrayBuffer.slice(5);
        this.codecId = codecId;
        this.metaInfo.avcc = extraData; //

        if (codecId === VIDEO_ENC_CODE.h264) {
          metaData = parseAVCDecoderConfigurationRecord(extraData);
        } else if (codecId === VIDEO_ENC_CODE.h265) {
          metaData = parseHEVCDecoderVPSAndSPSAndPPS(extraData);
          const metaData2 = parseHEVCDecoderConfigurationRecord$2(arrayBuffer);
          metaData = Object.assign(metaData, metaData2);
        } //console.log('initMetaData-metaData', metaData);


        if (metaData) {
          if (metaData.vps) {
            this.vps = metaData.vps;
          }

          if (metaData.pps) {
            this.pps = metaData.pps;
          }

          if (metaData.sps) {
            this.sps = metaData.sps;
          }

          if (metaData.presentWidth) {
            this.metaInfo.presentWidth = metaData.presentWidth;
          }

          if (metaData.presentHeight) {
            this.metaInfo.presentHeight = metaData.presentHeight;
          }

          if (metaData.codecWidth) {
            this.metaInfo.codecWidth = metaData.codecWidth;
          }

          if (metaData.codecHeight) {
            this.metaInfo.codecHeight = metaData.codecHeight;
          }

          if (metaData.timescale) {
            this.metaInfo.timescale = metaData.timescale;
          }

          if (metaData.refSampleDuration) {
            this.metaInfo.refSampleDuration = metaData.refSampleDuration;
          }

          if (metaData.videoType) {
            this.metaInfo.videoType = metaData.videoType;
          }
        } // console.log('initMetaData-metaInfo', this.metaInfo);

      }

    }

    class RecordRTCLoader extends CommonLoader$1 {
      constructor(player) {
        super(player);
        this.totalByteLength = 0;
        player.debug.log('RecorderRTC', 'init');
      }

      _reset() {
        super._reset();

        this.totalByteLength = 0;

        if (this.recorder) {
          this.recorder.destroy();
          this.recorder = null;
        }
      }

      destroy() {
        super.destroy();

        this._reset();

        this.player.debug.log('RecorderRTC', 'destroy');
      }

      startRecord() {
        const debug = this.player.debug;
        const options = {
          type: 'video',
          mimeType: 'video/webm;codecs=h264',
          timeSlice: 1000,
          onTimeStamp: timestamp => {
            debug.log('RecorderRTC', 'record timestamp :' + timestamp);
          },
          ondataavailable: blob => {
            this.totalByteLength += blob.size;
            debug.log('RecorderRTC', 'ondataavailable', blob.size);
          },
          disableLogs: !this.player._opt.debug
        };

        try {
          // video
          let stream = null; // canvas

          if (this.player.getRenderType() === RENDER_TYPE.canvas) {
            stream = this.player.video.$videoElement.captureStream(25);
          } else {
            // video
            // wcs or wasm decode
            if (this.player.video.mediaStream) {
              stream = this.player.video.mediaStream;
            } else {
              if (this.player._opt.isHls) {// hls
              } else if (this.player._opt.useMSE) {// mse decode
              } else if (this.player._opt.useWCS) {//    wcs
              } else if (this.player._opt.isWebrtc) {
                // webrtc
                stream = this.player.webrtc.videoStream;
              }
            }
          }

          if (stream) {
            // audio
            if (this.player.audio && this.player.audio.mediaStreamAudioDestinationNode && this.player.audio.mediaStreamAudioDestinationNode.stream && !this.player.audio.isStateSuspended() && this.player.audio.hasAudio && this.player._opt.hasAudio) {
              const audioStream = this.player.audio.mediaStreamAudioDestinationNode.stream;

              if (audioStream.getAudioTracks().length > 0) {
                const audioTrack = audioStream.getAudioTracks()[0];

                if (audioTrack && audioTrack.enabled) {
                  stream.addTrack(audioTrack);
                }
              }
            }

            this.recorder = RecordRTC_1(stream, options);
          } else {
            debug.error('RecorderRTC', 'startRecord error and can not create stream');
            this.emit(EVENTS.recordCreateError);
          }
        } catch (e) {
          debug.error('RecorderRTC', 'startRecord error', e);
          this.emit(EVENTS.recordCreateError);
        }

        if (this.recorder) {
          this._isRecording = true;
          this.player.emit(EVENTS.recording, true);
          this.recorder.startRecording();
          debug.log('RecorderRTC', 'start recording');
          this.player.emit(EVENTS.recordStart);
          this.startRecordingInterval();
        }
      }

      stopRecordAndSave() {
        let type = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : RECORDING_TYPE.download;
        let fileName = arguments.length > 1 ? arguments[1] : undefined;
        return new Promise((resolve, reject) => {
          if (!this.recorder || !this._isRecording) {
            reject('recorder is not ready');
          }

          if (fileName) {
            this.setFileName(fileName);
          }

          this.recorder.stopRecording(() => {
            this.player.debug.log('RecorderRTC', 'stop recording');
            const fileName = (this.fileName || now$1()) + '.' + FILE_SUFFIX.webm;

            if (type === RECORDING_TYPE.blob) {
              const blob = this.recorder.getBlob();
              resolve(blob);
              this.player.emit(EVENTS.recordBlob, blob);
            } else {
              resolve(); // saveAs(blob, fileName)

              this.recorder.save(fileName);
            }

            this.player.emit(EVENTS.recordEnd);

            this._reset();

            this.player.emit(EVENTS.recording, false);
          });
        });
      }

      getToTalByteLength() {
        return this.totalByteLength;
      }

      getTotalDuration() {
        return this.recordTime;
      }

      getType() {
        return FILE_SUFFIX.webm;
      } // 占个坑位


      initMetaData() {}

    }

    class MP4$2 {
      static init() {
        MP4$2.types = {
          avc1: [],
          avcC: [],
          hvc1: [],
          hvcC: [],
          btrt: [],
          dinf: [],
          dref: [],
          esds: [],
          ftyp: [],
          // 视频类型
          hdlr: [],
          mdat: [],
          // 视频数据
          mdhd: [],
          mdia: [],
          mfhd: [],
          minf: [],
          moof: [],
          //
          moov: [],
          // 视频信息(视频参数)
          mp4a: [],
          mvex: [],
          mvhd: [],
          sdtp: [],
          stbl: [],
          stco: [],
          stsc: [],
          stsd: [],
          stsz: [],
          stts: [],
          tfdt: [],
          tfhd: [],
          traf: [],
          // 视频参数（moov）中主要的子box 为track,每个track都是一个随时间变化的媒体序列，
          // 时间单位为一个sample，可以是一帧数据，或者音频（注意，一帧音频可以分解成多个音频sample，所以音频一般用sample作为单位，而不用帧）
          trak: [],
          trun: [],
          trex: [],
          tkhd: [],
          vmhd: [],
          smhd: [],
          '.mp3': [],
          free: [],
          edts: [],
          elst: [],
          stss: []
        };

        for (let name in MP4$2.types) {
          if (MP4$2.types.hasOwnProperty(name)) {
            MP4$2.types[name] = [name.charCodeAt(0), name.charCodeAt(1), name.charCodeAt(2), name.charCodeAt(3)];
          }
        }

        let constants = MP4$2.constants = {}; // File Type Box，描述文件遵从的MP4规范与版本

        constants.FTYP = new Uint8Array([0x69, 0x73, 0x6F, 0x6D, // major_brand: isom
        0x0, 0x0, 0x02, 0x0, // minor_version: 0x20
        0x69, 0x73, 0x6F, 0x6D, // isom
        0x69, 0x73, 0x6F, 0x32, // iso
        0x61, 0x76, 0x63, 0x31, // avc1
        0x6D, 0x70, 0x34, 0x31, // MP4
        0x00, 0x00, 0x00, 0x00]);
        constants.STSD_PREFIX = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x01 // entry_count
        ]);
        constants.STTS = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00 // entry_count
        ]);
        constants.STSC = constants.STCO = constants.STTS;
        constants.STSZ = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00, // sample_size
        0x00, 0x00, 0x00, 0x00 // sample_count
        ]);
        constants.HDLR_VIDEO = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00, // pre_defined
        0x76, 0x69, 0x64, 0x65, // handler_type: 'vide'
        0x00, 0x00, 0x00, 0x00, // reserved: 3 * 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x56, 0x69, 0x64, 0x65, 0x6F, 0x48, 0x61, 0x6E, 0x64, 0x6C, 0x65, 0x72, 0x00 // name: VideoHandler
        ]);
        constants.HDLR_AUDIO = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00, // pre_defined
        0x73, 0x6F, 0x75, 0x6E, // handler_type: 'soun'
        0x00, 0x00, 0x00, 0x00, // reserved: 3 * 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x53, 0x6F, 0x75, 0x6E, 0x64, 0x48, 0x61, 0x6E, 0x64, 0x6C, 0x65, 0x72, 0x00 // name: SoundHandler
        ]);
        constants.DREF = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x01, // entry_count
        0x00, 0x00, 0x00, 0x0C, // entry_size
        0x75, 0x72, 0x6C, 0x20, // type 'url '
        0x00, 0x00, 0x00, 0x01 // version(0) + flags
        ]); // Sound media header

        constants.SMHD = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00 // balance(2) + reserved(2)
        ]); // video media header

        constants.VMHD = new Uint8Array([0x00, 0x00, 0x00, 0x01, // version(0) + flags
        0x00, 0x00, // graphicsmode: 2 bytes
        0x00, 0x00, 0x00, 0x00, // opcolor: 3 * 2 bytes
        0x00, 0x00]);
      } // Generate a box
      // Type是box的类型
      // box的参数除了第一个为类型，其他参数都需要是二进制的arraybuffer类型。


      static box(type) {
        // box前8位为预留位，这8位中前4位为数据size，
        // 当size值为0时，表示该box为文件的最后一个box（仅存在于mdat box中），
        // 当size值为1时，表示该box的size为large size（8位）
        // 真正的box size要在largesize中得到（同样仅存在于mdat box中）。
        // 后4位为前面box type的Unicode编码。当type是uuid时，代表Box中的数据是用户自定义扩展类型。
        let size = 8;
        let result = null; // 方法中的第三行表示获取参数中除去第一个参数的其他参数

        let datas = Array.prototype.slice.call(arguments, 1);
        let arrayCount = datas.length;

        for (let i = 0; i < arrayCount; i++) {
          size += datas[i].byteLength;
        } // Box由header和body组成


        result = new Uint8Array(size); // 以32位的4字节整数存储方式存储到内存，
        // 开头4个字节（32位）为box size。

        result[0] = size >>> 24 & 0xFF; // size

        result[1] = size >>> 16 & 0xFF;
        result[2] = size >>> 8 & 0xFF;
        result[3] = size & 0xFF; // 后面紧跟的4位为box的类型

        result.set(type, 4); // type

        let offset = 8; // Box body可以由数据组成，也可以由子box组成。

        for (let i = 0; i < arrayCount; i++) {
          // data body
          result.set(datas[i], offset);
          offset += datas[i].byteLength;
        }

        return result;
      } // emit ftyp & moov


      static generateInitSegment(meta, trakList, mdatBytes) {
        // Ftypbox 是一个由四个字符组成的码字，用来表示编码类型、兼容协议或者媒体文件的用途。
        // 在普通MP4文件中，ftyp box有且仅有一个，在文件的开始位置。
        let ftyp = MP4$2.box(MP4$2.types.ftyp, MP4$2.constants.FTYP); //

        let free = MP4$2.box(MP4$2.types.free); // allocate mdatbox init fps = 25

        let offset = 8;
        let mdatbox = new Uint8Array(); // 所有的长度。。。。。
        // Mdat box中，可能会使用到box的large size，当数据足够大，无法用4个字节来描述时，便会使用到large size。
        // 在读取MP4文件时，当mdat box的size位为1时，真正的box size在large size中，
        // 同样在写mp4文件时，若需要large size，需要将box size位配置为1。

        if (mdatBytes + offset >= Math.pow(2, 32) - 1) {
          //large size
          offset = 16;
          mdatbox = new Uint8Array(mdatBytes + offset);
          mdatbox.set(new Uint8Array([0x00, 0x00, 0x00, 0x01]), 0); // 视频数据（mdat）

          mdatbox.set(MP4$2.types.mdat, 4);
          mdatbox.set(new Uint8Array([mdatBytes + 8 >>> 56 & 0xFF, mdatBytes + 8 >>> 48 & 0xFF, mdatBytes + 8 >>> 40 & 0xFF, mdatBytes + 8 >>> 32 & 0xFF, mdatBytes + 8 >>> 24 & 0xFF, mdatBytes + 8 >>> 16 & 0xFF, mdatBytes + 8 >>> 8 & 0xFF, mdatBytes + 8 & 0xFF]), 8);
        } else {
          mdatbox = new Uint8Array(mdatBytes + offset);
          mdatbox[0] = mdatBytes + 8 >>> 24 & 0xFF;
          mdatbox[1] = mdatBytes + 8 >>> 16 & 0xFF;
          mdatbox[2] = mdatBytes + 8 >>> 8 & 0xFF;
          mdatbox[3] = mdatBytes + 8 & 0xFF; //视频数据（mdat）

          mdatbox.set(MP4$2.types.mdat, 4);
        } // Write samples into mdatbox


        for (let i = 0; i < trakList.length; i++) {
          let trak = trakList[i]; // duration

          trak.duration = trak.refSampleDuration * trak.sequenceNumber;

          for (let j = 0; j < trak.sequenceNumber; j++) {
            // 遍历 samples
            let sample = trak.samples[j]; // sample

            sample.chunkOffset = ftyp.byteLength + free.byteLength + offset; // 合并 data 数据。。。。。。

            let data = sample.data;
            mdatbox.set(data, offset);
            offset += data.byteLength;
          }
        } // Moov box中存放着媒体信息，上面提到的stbl里存放帧信息，属于媒体信息，也在moov box里。
        // Moov box 用来描述媒体数据。
        // Moov box 主要包含 mvhd、trak、mvex三种子box。


        let moov = MP4$2.moov(meta, trakList); // 视频类型（ftyp）、视频数据（mdat）、视频信息（moov）

        let result = new Uint8Array(ftyp.byteLength + moov.byteLength + mdatbox.byteLength + free.byteLength); // ftyp 视频类型

        result.set(ftyp, 0); // free

        result.set(free, ftyp.byteLength); // mdat 视频数据

        result.set(mdatbox, ftyp.byteLength + free.byteLength); // moov 视频信息

        result.set(moov, ftyp.byteLength + mdatbox.byteLength + free.byteLength);
        return result;
      } // Movie metadata box
      // 媒体的metadata信息，有且仅有一个，位于moov box中。
      // Moov box 主要包含 mvhd、trak、mvex三种子box。
      // 视频参数（moov）中主要的子box 为track，
      // 每个track都是一个随时间变化的媒体序列，时间单位为一个sample，可以是一帧数据，
      // 或者音频（注意，一帧音频可以分解成多个音频sample，所以音频一般用sample作为单位，而不用帧）。
      // Sample按照事件顺序排列。track里面的每个sample通过引用关联到一个sample description。
      // 这个sample descriptios定义了怎样解码这个sample，例如使用的压缩算法。（注：在目前的使用中，该值为1）


      static moov(meta, trakList) {
        let timescale = meta.timescale;
        let duration = meta.duration;
        let trakLen = trakList.length; // Mvhd box定义了整个文件的特性

        let mvhd = MP4$2.mvhd(timescale, duration);
        let trakArrayBuffer = new Uint8Array();

        for (let i = 0; i < trakLen; i++) {
          let trak = MP4$2.trak(trakList[i]);
          let arrayBuffer = new Uint8Array(trak.byteLength + trakArrayBuffer.byteLength);
          arrayBuffer.set(trakArrayBuffer, 0);
          arrayBuffer.set(trak, trakArrayBuffer.byteLength);
          trakArrayBuffer = new Uint8Array(arrayBuffer.byteLength);
          trakArrayBuffer.set(arrayBuffer, 0);
        }

        return MP4$2.box(MP4$2.types.moov, mvhd, trakArrayBuffer);
      } // Movie header box
      // 这里写mp4时需要传入的参数为Time scale 和 Duration，其他的使用默认值即可。
      // MP4文件的整体信息，跟具体的视频流、音频流无关，比如创建时间、文件时长等。
      // mvhd针对整个影片
      // 这里写mp4时需要传入的参数为Time scale 和 Duration，其他的使用默认值即可。


      static mvhd(timescale, duration) {
        //
        return MP4$2.box(MP4$2.types.mvhd, new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0xCE, 0xBA, 0xFD, 0xA8, // creation_time 文件创建时间；
        0xCE, 0xBA, 0xFD, 0xA8, // modification_time 文件修改时间；
        timescale >>> 24 & 0xFF, // timescale: 4 bytes 一秒包含的时间单位（整数）。举个例子，如果timescale等于1000，那么，一秒包含1000个时间单位（后面track等的时间，都要用这个来换算，比如track的duration为10,000，那么，track的实际时长为10,000/1000=10s）；
        timescale >>> 16 & 0xFF, timescale >>> 8 & 0xFF, timescale & 0xFF, duration >>> 24 & 0xFF, // duration: 4 bytes 影片时长（整数），根据文件中的track的信息推导出来，等于时间最长的track的duration
        duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, 0x00, 0x01, 0x00, 0x00, // Preferred rate: 1.0 推荐的播放速率，32位整数，高16位、低16位分别代表整数部分、小数部分（[16.16]），举例 0x0001 0000 代表1.0，正常播放速度；
        0x01, 0x00, 0x00, 0x00, // Preferred Volume(1.0, 2bytes) + reserved(2bytes) 播放音量，16位整数，高8位、低8位分别代表整数部分、小数部分（[8.8]），举例 0x01 00 表示 1.0，即最大音量；
        0x00, 0x00, 0x00, 0x00, // reserved: 4 + 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, // ----begin composition matrix----
        0x00, 0x00, 0x00, 0x00, // 视频的转换矩阵，一般可以忽略不计；
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // ----end composition matrix----
        0x00, 0x00, 0x00, 0x00, // ----begin pre_defined 6 * 4 bytes----
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // ----end pre_defined 6 * 4 bytes----
        0x00, 0x00, 0x00, 0x03 // next_track_ID: 4 bytes  3 32位整数，非0，一般可以忽略不计。当要添加一个新的track到这个影片时，可以使用的track id，必须比当前已经使用的track id要大。也就是说，添加新的track时，需要遍历所有track，确认可用的track id；
        ]));
      } // Track box
      // 一个Track box定义了movie中的一个track。一部movie可以包含一个或多个tracks，它们之间相互独立，各自有各自的时间和空间信息。每个track box 都有与之关联的mdat box。
      // 包含媒体数据引用和描述
      // 包含modifier track
      // 流媒体协议的打包信息（hint trak），引用或者复用对应的媒体sample data。
      // Hint tracks和modifier tracks必须保证完整性，同时和至少一个media track一起存在。
      // 换句话说，即使hint tracks复制了对应的媒体sample data，media tracks 也不能从一部hinted movie中删除。
      // 写mp4时仅用到第一个目的，所以这里只介绍媒体数据的引用和描述。
      // 一个trak box一般主要包含了tkhd box、 edts box 、mdia box


      static trak(meta) {
        return MP4$2.box(MP4$2.types.trak, MP4$2.tkhd(meta), MP4$2.mdia(meta));
      } // Track header box
      // 用来描述trak box的header 信息，定义了一个trak的时间、空间、音量信息。


      static tkhd(meta) {
        let trackId = meta.id,
            duration = meta.duration;
        let width = meta.presentWidth,
            height = meta.presentHeight;
        return MP4$2.box(MP4$2.types.tkhd, new Uint8Array([0x00, 0x00, 0x00, 0x0F, // version(0) + flags tkhd box的版本；
        0xCE, 0xBA, 0xFD, 0xA8, // creation_time 当前track的创建时间；
        0xCE, 0xBA, 0xFD, 0xA8, // modification_time 当前track的最近修改时间；
        trackId >>> 24 & 0xFF, // track_ID: 4 bytes 当前track的唯一标识，不能为0，不能重复；
        trackId >>> 16 & 0xFF, trackId >>> 8 & 0xFF, trackId & 0xFF, 0x00, 0x00, 0x00, 0x00, // reserved: 4 bytes
        duration >>> 24 & 0xFF, // duration: 4 bytes 当前track的完整时长（需要除以timescale得到具体秒数）；
        duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, 0x00, 0x00, 0x00, 0x00, // reserved: 2 * 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // layer(2bytes) + alternate_group(2bytes)   layer 视频轨道的叠加顺序，数字越小越靠近观看者，比如1比2靠上，0比1靠上； alternate_group 当前track的分组ID，alternate_group值相同的track在同一个分组里面。同个分组里的track，同一时间只能有一个track处于播放状态。当alternate_group为0时，表示当前track没有跟其他track处于同个分组。一个分组里面，也可以只有一个track；
        0x00, 0x00, 0x00, 0x00, // volume(2bytes) + reserved(2bytes) audio track的音量，介于0.0~1.0之间；
        0x00, 0x01, 0x00, 0x00, // ----begin composition matrix----
        0x00, 0x00, 0x00, 0x00, // 视频的变换矩阵； 36
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // ----end composition matrix----
        width >>> 8 & 0xFF, // width and height 视频的宽高； 4
        width & 0xFF, 0x00, 0x00, height >>> 8 & 0xFF, // width and height 视频的宽高； 4
        height & 0xFF, 0x00, 0x00]));
      }

      static edts(meta, i) {
        return MP4$2.box(MP4$2.types.edts, MP4$2.elst(meta, i));
      } // 该box为edst box的唯一子box，不是所有的MP4文件都有edst box，这个box是使其对应的trak box的时间戳产生偏移。
      // 暂时未发现需要该偏移量的地方，编码时也未对该box进行编码。


      static elst(meta, i) {
        let videoDelayDuration = 0;

        for (let j = 0; j < i; j++) {
          if (meta[j].type === 'video') {
            videoDelayDuration += meta[j].duration;
          }
        }

        let duration = meta[i].duration;

        if (videoDelayDuration === 0) {
          videoDelayDuration = meta[i].refSampleDuration;
        }

        return MP4$2.box(MP4$2.types.elst, new Uint8Array([0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, videoDelayDuration >>> 24 & 0xFF, // SampleDuration: 4 bytes
        videoDelayDuration >>> 16 & 0xFF, videoDelayDuration >>> 8 & 0xFF, videoDelayDuration & 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, //media_time
        0x00, 0x01, 0x00, 0x00, //  media_rate(2byte) + Media rate fraction(3byte)
        duration >>> 24 & 0xFF, // Duration: 4 bytes
        duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00]));
      } // Media Box
      // 该box定义了trak box的类型和sample的信息。


      static mdia(meta) {
        return MP4$2.box(MP4$2.types.mdia, MP4$2.mdhd(meta), MP4$2.hdlr(meta), MP4$2.minf(meta));
      } // Media header box
      // mdhd box 定义了该box的timescale
      // 和duration（注：这里的这两个参数与前面说的mvhd有区别，这里的这两个参数都是以一个sample为时间单位的，
      // 例：在只有一个视频trak的情况下，mvhd的timescale为1000，一个sample的duration为40
      // ，那么这里的timescale为1000/40，同理这里的duration算法与之一样理解。）


      static mdhd(meta) {
        let timescale = meta.timescale / meta.refSampleDuration;
        let duration = timescale * meta.duration / meta.timescale;
        return MP4$2.box(MP4$2.types.mdhd, new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0xCE, 0xBA, 0xFD, 0xA8, // creation_time
        0xCE, 0xBA, 0xFD, 0xA8, // modification_time
        timescale >>> 24 & 0xFF, // timescale: 4 bytes
        timescale >>> 16 & 0xFF, timescale >>> 8 & 0xFF, timescale & 0xFF, duration >>> 24 & 0xFF, // duration: 4 bytes
        duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, 0x55, 0xC4, // language: und (undetermined)
        0x00, 0x00 // pre_defined = 0
        ]));
      } // Media handler reference box
      // 声明当前track的类型，以及对应的处理器（handler）。

      /**
       *  vide（0x76 69 64 65），video track；
       soun（0x73 6f 75 6e），audio track；
       hint（0x68 69 6e 74），hint track；
       //Hdlr box 定义了这段trak的媒体处理组件，以下图会更清晰的解释这个box
       * @param meta
       * @returns {null}
       */


      static hdlr(meta) {
        let data = null;
        data = MP4$2.constants.HDLR_VIDEO;
        return MP4$2.box(MP4$2.types.hdlr, data);
      } // Media infomation box
      // 该box也是上面的mdia box的子box，其主要用来描述该trak的具体的媒体处理组件内容的。


      static minf(meta) {
        let xmhd = null;
        xmhd = MP4$2.box(MP4$2.types.vmhd, MP4$2.constants.VMHD);
        return MP4$2.box(MP4$2.types.minf, xmhd, MP4$2.dinf(), MP4$2.stbl(meta));
      } // Data infomation box
      // dinf box 定义了该trak的数据信息，包括了数据的引用方式，数据的存储方式等。
      // dinf box 用来定义媒体处理组件如何获取媒体数据的


      static dinf() {
        return MP4$2.box(MP4$2.types.dinf, MP4$2.box(MP4$2.types.dref, MP4$2.constants.DREF));
      } // Sample table box
      // Sample Table Box（stbl）是上面minf的子box之一，用来定义存放时间/偏移的映射关系，数据信息都在以下子box中
      // 在普通mp4中，在获取数据之前，需要解析每个帧数据所在位置，每个帧数据都存放在mdat中，而这些帧的信息全部存放在stbl box 中，
      // 所以，若要mp4文件能够正常播放，需要在写mp4文件时，将所有的帧数据信息写入 stbl box中。
      // MP4文件的媒体数据部分在mdat box里，而stbl则包含了这些媒体数据的索引以及时间信息，了解stbl对解码、渲染MP4文件很关键。
      // 在MP4文件中，媒体数据被分成多个chunk，每个chunk可包含多个sample，而sample则由帧组成（通常1个sample对应1个帧），关系如下：


      static stbl(meta) {
        let sampleList = meta.samples;
        let sampleToChunk = [{
          No: 1,
          num: 0,
          sampleDelte: 1,
          chunkNo: 1,
          duration: sampleList[0].duration
        }];
        let durationList = [sampleList[0].duration];
        let len = sampleList.length;

        for (let i = 0; i < len; i++) {
          for (let j = 0; j < sampleToChunk.length; j++) {
            if (sampleList[i].duration === sampleToChunk[j].duration) {
              sampleToChunk[j].num++;
            } else {
              if (durationList.indexOf(sampleList[i].duration) < 0) {
                durationList.push(sampleList[i].duration);
                sampleToChunk.push({
                  No: 2,
                  num: 0,
                  sampleDelte: 1,
                  chunkNo: i + 1,
                  duration: sampleList[i].duration
                });
              }
            }
          }
        }

        return MP4$2.box(MP4$2.types.stbl, // type: stbl
        MP4$2.stsd(meta), // Sample Description Table Sample Description Box用来描述数据的格式，比如视频格式为avc，比如音频格式为aac
        MP4$2.stts(sampleToChunk), // Time-To-Sample 时间戳和Sample序号映射表
        MP4$2.stss(sampleList), // 关键帧序号，该box存在于video trak，因为audio trak 中以sample为单位，但多个sample才组成一帧音频，所以在audio trak中无需该box。
        MP4$2.stsc(sampleToChunk), //Sample-To-Chunk Sample to chunk 的映射表。这个算法比较巧妙，在多个chunk时，该算法较为复杂。在本次使用中未考虑多个chunk的状态，仅考虑整个文件单个chunk的情况。
        MP4$2.stsz(sampleList), // Sample size Sample Size Boxes 每个Sample大小的表。Stz2是另一种sample size的存储算法，更节省空间，使用时使用其中一种即可，这里使用stsz。原因简单，因为算法容易。
        MP4$2.stco(sampleToChunk, sampleList) // Chunk offset co64: 每个Chunk位置偏移表，sample的偏移可根据其他box推算出来，co64是指64位的chunk偏移，暂时只使用到32位的，因此这里使用stco即可。
        );
      } // 每个sample的时长；
      // stts包含了DTS到sample number的映射表，主要用来推导每个帧的时长。


      static stts(sampleToChunk) {
        let sampleToChunkLen = sampleToChunk.length;
        let stts = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        sampleToChunkLen >>> 24 & 0xFF, // entry_count: 4 bytes tts 中包含的entry条目数；
        sampleToChunkLen >>> 16 & 0xFF, sampleToChunkLen >>> 8 & 0xFF, sampleToChunkLen & 0xFF]);
        let offset = stts.byteLength,
            sttsInfo = new Uint8Array(offset + sampleToChunkLen * 8);
        sttsInfo.set(stts, 0);

        for (let index = 0; index < sampleToChunkLen; index++) {
          sttsInfo.set(new Uint8Array([sampleToChunk[index].num >>> 24 & 0xFF, // samplesPerChunk: 4 bytes
          sampleToChunk[index].num >>> 16 & 0xFF, sampleToChunk[index].num >>> 8 & 0xFF, sampleToChunk[index].num & 0xFF, sampleToChunk[index].sampleDelte >>> 24 & 0xFF, // samplesDescription index: 4 bytes
          sampleToChunk[index].sampleDelte >>> 16 & 0xFF, sampleToChunk[index].sampleDelte >>> 8 & 0xFF, sampleToChunk[index].sampleDelte & 0xFF]), offset);
          offset += 8;
        }

        return MP4$2.box(MP4$2.types.stts, sttsInfo);
      } // 哪些sample是关键帧；
      // mp4文件中，关键帧所在的sample序号。如果没有stss的话，所有的sample中都是关键帧。


      static stss(mdatDataList) {
        let keyFrameMap = [],
            len = mdatDataList.length;

        for (let i = 0; i < len; i++) {
          if (mdatDataList[i].isKeyframe === true) {
            keyFrameMap.push(i + 1);
          }
        }

        let keyFrameLen = keyFrameMap.length;
        let stss = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        keyFrameLen >>> 24 & 0xFF, // entry_count: 4 bytes entry的条目数，可以认为是关键帧的数目；
        keyFrameLen >>> 16 & 0xFF, keyFrameLen >>> 8 & 0xFF, keyFrameLen & 0xFF]);
        let offset = stss.byteLength,
            stssInfo = new Uint8Array(offset + keyFrameLen * 4);
        stssInfo.set(stss, 0);

        for (let index = 0; index < keyFrameLen; index++) {
          stssInfo.set(new Uint8Array([keyFrameMap[index] >>> 24 & 0xFF, // entry_count: 4 bytes
          keyFrameMap[index] >>> 16 & 0xFF, keyFrameMap[index] >>> 8 & 0xFF, keyFrameMap[index] & 0xFF]), offset);
          offset += 4;
        }

        return MP4$2.box(MP4$2.types.stss, stssInfo);
      } // 每个thunk中包含几个sample；
      // sample 以 chunk 为单位分成多个组。chunk的size可以是不同的，chunk里面的sample的size也可以是不同的。


      static stsc(sampleToChunk) {
        let sampleToChunkLen = sampleToChunk.length;
        let stsc = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        sampleToChunkLen >>> 24 & 0xFF, // entry_count: 4 bytes 有多少个表项（每个表项，包含first_chunk、samples_per_chunk、sample_description_index信息）；
        sampleToChunkLen >>> 16 & 0xFF, sampleToChunkLen >>> 8 & 0xFF, sampleToChunkLen & 0xFF]);
        let offset = stsc.byteLength,
            stscInfo = new Uint8Array(offset + sampleToChunkLen * 12);
        stscInfo.set(stsc, 0);

        for (let index = 0; index < sampleToChunkLen; index++) {
          let firstChunk = sampleToChunk[index].chunkNo,
              samplesPerChunk = sampleToChunk[index].num,
              sampleDelte = sampleToChunk[index].sampleDelte;
          stscInfo.set(new Uint8Array([firstChunk >>> 24 & 0xFF, // firstChunk: 4 bytes 当前表项中，对应的第一个chunk的序号；
          firstChunk >>> 16 & 0xFF, firstChunk >>> 8 & 0xFF, firstChunk & 0xFF, samplesPerChunk >>> 24 & 0xFF, // samplesPerChunk: 4 bytes 每个chunk包含的sample数；
          samplesPerChunk >>> 16 & 0xFF, samplesPerChunk >>> 8 & 0xFF, samplesPerChunk & 0xFF, sampleDelte >>> 24 & 0xFF, // samplesDescription index: 4 bytes 指向 stsd 中 sample description 的索引值（参考stsd小节）；
          sampleDelte >>> 16 & 0xFF, sampleDelte >>> 8 & 0xFF, sampleDelte & 0xFF]), offset);
          offset += 12;
        }

        return MP4$2.box(MP4$2.types.stsc, stscInfo);
      } // 每个sample的size（单位是字节）；
      // 每个sample的大小（字节），根据 sample_size 字段，可以知道当前track包含了多少个sample（或帧）。


      static stsz(mdatDataList) {
        let len = mdatDataList.length;
        let stsz = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00, // sample size    当所有sample的size都一样时，该值为sample的size ，否则为0
        len >>> 24 & 0xFF, // sample count: 4 bytes  当前track里面的sample数目。如果 sample_size==0，那么，sample_count 等于下面entry的条目；
        len >>> 16 & 0xFF, len >>> 8 & 0xFF, len & 0xFF]);
        let offset = stsz.byteLength,
            stszInfo = new Uint8Array(offset + len * 4);
        stszInfo.set(stsz, 0);

        for (let i = 0; i < len; i++) {
          let data = mdatDataList[i].data;
          let dataLen = data.byteLength;
          stszInfo.set(new Uint8Array([dataLen >>> 24 & 0xFF, //per  sample size: 4 bytes
          dataLen >>> 16 & 0xFF, dataLen >>> 8 & 0xFF, dataLen & 0xFF]), offset);
          offset += 4;
        }

        return MP4$2.box(MP4$2.types.stsz, stszInfo);
      } // thunk在文件中的偏移；


      static stco(sampleToChunk, mdatDataList) {
        let offset = mdatDataList[0].chunkOffset;
        return MP4$2.box(MP4$2.types.stco, new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x01, // entry_count: 4 bytes //默认只有视频时，只有一段chunk
        offset >>> 24 & 0xFF, // samplesPerChunk: 4 bytes
        offset >>> 16 & 0xFF, offset >>> 8 & 0xFF, offset & 0xFF]));
      } // Sample description box
      // 给出视频、音频的编码、宽高、音量等信息，以及每个sample中包含多少个frame；


      static stsd(meta) {
        if (meta.type === 'audio') {
          //
          if (meta.codec === 'mp3') {
            return MP4$2.box(MP4$2.types.stsd, MP4$2.constants.STSD_PREFIX, MP4$2.mp3(meta));
          } // else: aac -> mp4a


          return MP4$2.box(MP4$2.types.stsd, MP4$2.constants.STSD_PREFIX, MP4$2.mp4a(meta));
        } else {
          if (meta.videoType === 'avc') {
            return MP4$2.box(MP4$2.types.stsd, MP4$2.constants.STSD_PREFIX, MP4$2.avc1(meta));
          } else {
            return MP4$2.box(MP4$2.types.stsd, MP4$2.constants.STSD_PREFIX, MP4$2.hvc1(meta));
          } //

        }
      }

      static mp3(meta) {
        let channelCount = meta.channelCount;
        let sampleRate = meta.audioSampleRate;
        let data = new Uint8Array([0x00, 0x00, 0x00, 0x00, // reserved(4)
        0x00, 0x00, 0x00, 0x01, // reserved(2) + data_reference_index(2)
        0x00, 0x00, 0x00, 0x00, // reserved: 2 * 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, channelCount, // channelCount(2)
        0x00, 0x10, // sampleSize(2)
        0x00, 0x00, 0x00, 0x00, // reserved(4)
        sampleRate >>> 8 & 0xFF, // Audio sample rate
        sampleRate & 0xFF, 0x00, 0x00]);
        return MP4$2.box(MP4$2.types['.mp3'], data);
      }

      static mp4a(meta) {
        let channelCount = meta.channelCount;
        let sampleRate = meta.audioSampleRate;
        let data = new Uint8Array([0x00, 0x00, 0x00, 0x00, // reserved(4)
        0x00, 0x00, 0x00, 0x01, // reserved(2) + data_reference_index(2)
        0x00, 0x00, 0x00, 0x00, // reserved: 2 * 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, channelCount, // channelCount(2)
        0x00, 0x10, // sampleSize(2)
        0x00, 0x00, 0x00, 0x00, // reserved(4)
        sampleRate >>> 8 & 0xFF, // Audio sample rate
        sampleRate & 0xFF, 0x00, 0x00]);
        return MP4$2.box(MP4$2.types.mp4a, data, MP4$2.esds(meta));
      }

      static esds(meta) {
        let config = meta.config || [];
        let configSize = config.length;
        let data = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version 0 + flags
        0x03, // descriptor_type
        0x17 + configSize, // length3
        0x00, 0x01, // es_id
        0x00, // stream_priority
        0x04, // descriptor_type
        0x0F + configSize, // length
        0x40, // codec: mpeg4_audio
        0x15, // stream_type: Audio
        0x00, 0x00, 0x00, // buffer_size
        0x00, 0x00, 0x00, 0x00, // maxBitrate
        0x00, 0x00, 0x00, 0x00, // avgBitrate
        0x05 // descriptor_type
        ].concat([configSize]).concat(config).concat([0x06, 0x01, 0x02 // GASpecificConfig
        ]));
        return MP4$2.box(MP4$2.types.esds, data);
      }

      static avc1(meta) {
        let avcc = meta.avcc;
        let width = meta.codecWidth,
            height = meta.codecHeight;
        let data = new Uint8Array([0x00, 0x00, 0x00, 0x00, // reserved(4)
        0x00, 0x00, 0x00, 0x01, // reserved(2) + data_reference_index(2)
        0x00, 0x00, 0x00, 0x00, // pre_defined(2) + reserved(2)
        0x00, 0x00, 0x00, 0x00, // pre_defined: 3 * 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, width >>> 8 & 0xFF, // width: 2 bytes
        width & 0xFF, height >>> 8 & 0xFF, // height: 2 bytes
        height & 0xFF, 0x00, 0x48, 0x00, 0x00, // horizresolution: 4 bytes
        0x00, 0x48, 0x00, 0x00, // vertresolution: 4 bytes
        0x00, 0x00, 0x00, 0x00, // reserved: 4 bytes
        0x00, 0x01, // frame_count
        0x0D, // strlen  10bytes
        0x6a, 0x65, 0x73, 0x73, // compressorname: 32 bytes
        0x69, 0x62, 0x75, 0x63, 0x61, 0x2d, 0x70, 0x72, 0x6f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x18, // depth
        0xFF, 0xFF // pre_defined = -1
        ]);
        return MP4$2.box(MP4$2.types.avc1, data, MP4$2.box(MP4$2.types.avcC, avcc));
      } // hvc


      static hvc1(meta) {
        let avcc = meta.avcc;
        const width = meta.codecWidth;
        const height = meta.codecHeight;
        let data = new Uint8Array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, width >>> 8 & 255, width & 255, height >>> 8 & 255, height & 255, 0, 72, 0, 0, 0, 72, 0, 0, 0, 0, 0, 0, 0, 1, 13, 106, 101, 115, 115, 105, 98, 117, 99, 97, 45, 112, 114, 111, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 255, 255]);
        return MP4$2.box(MP4$2.types.hvc1, data, MP4$2.box(MP4$2.types.hvcC, avcc));
      } // Movie Extends box


      static mvex(meta) {
        return MP4$2.box(MP4$2.types.mvex, MP4$2.trex(meta));
      } // Track Extends box
      // 用来给 fMP4 的 sample 设置各种默认值，比如时长、大小等。


      static trex(meta) {
        let trackId = meta.id;
        let data = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        trackId >>> 24 & 0xFF, // track_ID 对应的 track 的 ID，比如video track、audio track 的ID；
        trackId >>> 16 & 0xFF, trackId >>> 8 & 0xFF, trackId & 0xFF, 0x00, 0x00, 0x00, 0x01, // default_sample_description_index sample description 的默认 index（指向stsd）；
        0x00, 0x00, 0x00, 0x00, // default_sample_duration sample 默认时长，一般为0；
        0x00, 0x00, 0x00, 0x00, // default_sample_size  sample 默认大小，一般为0；
        0x00, 0x01, 0x00, 0x01 // default_sample_flags sample 的默认flag，一般为0；
        ]);
        return MP4$2.box(MP4$2.types.trex, data);
      } // Movie fragment box
      // moof是个container box，相关 metadata 在内嵌box里，比如 mfhd、 tfhd、trun 等。


      static moof(meta, baseMediaDecodeTime) {
        return MP4$2.box(MP4$2.types.moof, MP4$2.mfhd(meta.sequenceNumber), MP4$2.traf(meta, baseMediaDecodeTime));
      } // 结构比较简单，sequence_number 为 movie fragment 的序列号。根据 movie fragment 产生的顺序，从1开始递增。


      static mfhd(sequenceNumber) {
        let data = new Uint8Array([0x00, 0x00, 0x00, 0x00, sequenceNumber >>> 24 & 0xFF, // sequence_number: int32
        sequenceNumber >>> 16 & 0xFF, sequenceNumber >>> 8 & 0xFF, sequenceNumber & 0xFF]);
        return MP4$2.box(MP4$2.types.mfhd, data);
      } // Track fragment box
      // 对 fmp4 来说，数据被氛围多个 movie fragment。一个 movie fragment 可包含多个track fragment（每个 track 包含0或多个 track fragment）。每个 track fragment 中，可以包含多个该 track 的 sample。
      // 每个 track fragment 中，包含多个 track run，每个 track run 代表一组连续的 sample。


      static traf(meta, baseMediaDecodeTime) {
        let trackId = meta.id; // Track fragment header box
        // tfhd 用来设置 track fragment 中 的 sample 的 metadata 的默认值。

        let tfhd = MP4$2.box(MP4$2.types.tfhd, new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) & flags
        trackId >>> 24 & 0xFF, // track_ID
        trackId >>> 16 & 0xFF, trackId >>> 8 & 0xFF, trackId & 0xFF])); // Track Fragment Decode Time

        let tfdt = MP4$2.box(MP4$2.types.tfdt, new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) & flags
        baseMediaDecodeTime >>> 24 & 0xFF, // baseMediaDecodeTime: int32
        baseMediaDecodeTime >>> 16 & 0xFF, baseMediaDecodeTime >>> 8 & 0xFF, baseMediaDecodeTime & 0xFF]));
        let sdtp = MP4$2.sdtp(meta);
        let trun = MP4$2.trun(meta, sdtp.byteLength + 16 + 16 + 8 + 16 + 8 + 8);
        return MP4$2.box(MP4$2.types.traf, tfhd, tfdt, trun, sdtp);
      } // Sample Dependency Type box


      static sdtp(meta) {
        let samples = meta.samples || [];
        let sampleCount = samples.length;
        let data = new Uint8Array(4 + sampleCount); // 0~4 bytes: version(0) & flags

        for (let i = 0; i < sampleCount; i++) {
          let flags = samples[i].flags;
          data[i + 4] = flags.isLeading << 6 // is_leading: 2 (bit)
          | flags.dependsOn << 4 // sample_depends_on
          | flags.isDependedOn << 2 // sample_is_depended_on
          | flags.hasRedundancy; // sample_has_redundancy
        }

        return MP4$2.box(MP4$2.types.sdtp, data);
      } // Track fragment run box


      static trun(meta, offset) {
        let samples = meta.samples || [];
        let sampleCount = samples.length;
        let dataSize = 12 + 16 * sampleCount;
        let data = new Uint8Array(dataSize);
        offset += 8 + dataSize;
        data.set([0x00, 0x00, 0x0F, 0x01, // version(0) & flags
        sampleCount >>> 24 & 0xFF, // sample_count
        sampleCount >>> 16 & 0xFF, sampleCount >>> 8 & 0xFF, sampleCount & 0xFF, offset >>> 24 & 0xFF, // data_offset
        offset >>> 16 & 0xFF, offset >>> 8 & 0xFF, offset & 0xFF], 0);

        for (let i = 0; i < sampleCount; i++) {
          let duration = samples[i].duration;
          let size = samples[i].size;
          let flags = samples[i].flags;
          let cts = samples[i].cts;
          data.set([duration >>> 24 & 0xFF, // sample_duration
          duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, size >>> 24 & 0xFF, // sample_size
          size >>> 16 & 0xFF, size >>> 8 & 0xFF, size & 0xFF, flags.isLeading << 2 | flags.dependsOn, // sample_flags
          flags.isDependedOn << 6 | flags.hasRedundancy << 4 | flags.isNonSync, 0x00, 0x00, // sample_degradation_priority
          cts >>> 24 & 0xFF, // sample_composition_time_offset
          cts >>> 16 & 0xFF, cts >>> 8 & 0xFF, cts & 0xFF], 12 + 16 * i);
        }

        return MP4$2.box(MP4$2.types.trun, data);
      } // Media Data Box，存放实际的媒体数据，一般有多个
      // Mdat box 中包含了MP4文件的媒体数据，在文件中的位置可以在moov的前面，也可以在moov的后面，
      // 因我们这里用到MP4文件格式用来写mp4文件，需要计算每一帧媒体数据在文件中的偏移量，为了方便计算，mdat放置moov前面。
      // Mdat box数据格式单一，无子box。主要分为box header 和box body，box header中存放box size 和box type（mdat），box body中存放所有媒体数据，媒体数据以sample为数据单元。
      // 这里使用时，视频数据中，每一个sample是一个视频帧，存放sample时，需要根据帧数据类型进行拼帧处理后存放。


      static mdat(data) {
        return MP4$2.box(MP4$2.types.mdat, data);
      }

    }

    MP4$2.init();

    class MP4RecorderLoader extends CommonLoader$1 {
      constructor(player) {
        super(player);
        this.tagName = 'recorderMP4';
        this.totalDuration = 0;
        this.totalByteLength = 0;
        this.bufferList = [];
        this.cacheTrack = {};
        this.sequenceNumber = 0;
        player.debug.log(this.tagName, 'init');
      }

      destroy() {
        super.destroy();

        this._reset();

        this.player.debug.log(this.tagName, 'destroy');
      }

      _reset() {
        super._reset();

        this.totalDuration = 0;
        this.totalByteLength = 0;
        this.sequenceNumber = 0;
        this.cacheTrack = {};
        this.bufferList = [];
      }

      startRecord() {
        const debug = this.player.debug;
        this._isRecording = true;
        this.player.emit(EVENTS.recording, true);
        debug.log(this.tagName, 'start recording');
        this.player.emit(EVENTS.recordStart);
        this.startRecordingInterval();
      }

      formatFmp4Track(payload, isIframe, dts, cts) {
        const track = {
          id: 1,
          sequenceNumber: ++this.sequenceNumber,
          size: payload.byteLength,
          dts: dts,
          cts: cts,
          isKeyframe: isIframe,
          data: payload,
          duration: 0,
          flags: {
            isLeading: 0,
            dependsOn: isIframe ? 2 : 1,
            isDependedOn: isIframe ? 1 : 0,
            hasRedundancy: 0,
            isNonSync: isIframe ? 0 : 1
          }
        };
        return track;
      }

      handleAddNaluTrack(payload, isIframe, dts, cts) {
        if (this.cacheTrack.id && dts >= this.cacheTrack.dts) {
          this.cacheTrack.duration = dts - this.cacheTrack.dts;
          this.handleAddFmp4Track(this.cacheTrack);
        } else {
          this.cacheTrack = {};
        }

        this.cacheTrack = this.formatFmp4Track(payload, isIframe, dts, cts);
      } //


      handleAddFmp4Track(track) {
        if (!this.isRecording) {
          this.player.debug.error(this.tagName, 'handleAddFmp4Track, isRecording is false ');
          return;
        }

        if (!(this.sps !== null && this.pps !== null) && this.isH264) {
          this.player.debug.error(this.tagName, 'handleAddFmp4Track, is h264 and this.sps or this.pps is null ');
          return;
        }

        if (!(this.sps !== null && this.pps !== null && this.vps !== null) && this.isH265) {
          this.player.debug.error(this.tagName, 'handleAddFmp4Track, is h265 and this.sps or this.pps or this.vps is null ');
          return;
        }

        const trackItem = Object.assign({}, track);
        trackItem.pts = trackItem.dts + trackItem.cts;
        const oldData = trackItem.data;

        if (trackItem.isKeyframe) {
          if (this.isH264) {
            const drFlag = new Uint8Array(this.sps.byteLength + this.pps.byteLength);
            drFlag.set(this.sps, 0);
            drFlag.set(this.pps, this.sps.byteLength);
            const newData = new Uint8Array(drFlag.byteLength + oldData.byteLength);
            newData.set(drFlag, 0);
            newData.set(oldData, drFlag.byteLength);
            trackItem.data = newData;
          } else if (this.isH265) {
            const drFlag = new Uint8Array(this.sps.byteLength + this.pps.byteLength + this.vps.byteLength);
            drFlag.set(this.vps, 0);
            drFlag.set(this.sps, this.vps.byteLength);
            drFlag.set(this.pps, this.vps.byteLength + this.sps.byteLength);
            const newData = new Uint8Array(drFlag.byteLength + oldData.byteLength);
            newData.set(drFlag, 0);
            newData.set(oldData, drFlag.byteLength);
            trackItem.data = newData;
          }
        }

        trackItem.size = trackItem.data.byteLength;
        this.totalDuration += trackItem.duration;
        this.totalByteLength += trackItem.data.byteLength; // console.log('handleAddTrack', trackItem);
        //console.log('handleAddTrack totalDuration', this.totalDuration);

        trackItem.duration = 0;
        trackItem.originalDts = trackItem.dts;
        delete trackItem.id;
        delete trackItem.sequenceNumber;
        this.bufferList.push(trackItem);
      }

      getTotalDuration() {
        return this.totalDuration / 1000;
      }

      getType() {
        return FILE_SUFFIX.mp4;
      } //


      getToTalByteLength() {
        return this.totalByteLength;
      }

      stopRecordAndSave() {
        let type = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : RECORDING_TYPE.download;
        let fileName = arguments.length > 1 ? arguments[1] : undefined;
        return new Promise((resolve, reject) => {
          if (!this.isRecording) {
            this.player.debug.error(this.tagName, 'stop recording fail, isRecording is false ');
            return reject('stop recording fail, isRecording is false ');
          }

          if (this.bufferList.length === 0) {
            this.player.debug.error(this.tagName, 'stop recording fail, this.bufferList.length is 0 ');
            return reject('stop recording fail, this.bufferList.length is 0 ');
          }

          if (fileName) {
            this.setFileName(fileName);
          }

          const trakItem = {
            id: 1,
            type: 'video',
            sps: this.sps,
            pps: this.pps,
            samples: this.bufferList,
            sequenceNumber: this.bufferList.length,
            length: 0,
            addSampleNum: 1,
            duration: 0,
            ...this.metaInfo
          }; // console.log('trakItem', trakItem);

          const metaBox = MP4$2.generateInitSegment({
            timescale: 1000,
            //flv 默认为1000
            duration: this.totalDuration
          }, [trakItem], this.totalByteLength);
          this.player.debug.log(this.tagName, 'stop recording');
          const blob = new Blob([metaBox], {
            'type': 'application/octet-stream'
          });

          if (type === RECORDING_TYPE.blob) {
            resolve(blob);
            this.player.emit(EVENTS.recordBlob, blob);
          } else {
            resolve();
            const fileName = (this.fileName || now$1()) + '.' + FILE_SUFFIX.mp4;
            saveBlobToFile(fileName, blob);
          }

          this._reset();

          this.player.emit(EVENTS.recording, false);
        });
      }

    }

    class Recorder {
      constructor(player) {
        const Loader = Recorder.getLoaderFactory(player._opt);
        return new Loader(player);
      }

      static getLoaderFactory(opt) {
        if (opt.recordType === FILE_SUFFIX.mp4) {
          return MP4RecorderLoader;
        } else {
          if (opt.useVideoRender && (opt.useWCS || opt.useMSE || opt.isHls)) {
            return MP4RecorderLoader;
          }
        }

        return RecordRTCLoader;
      }

    }

    class DecoderWorker {
      constructor(player) {
        this.player = player;
        this.decoderWorker = new Worker(player._opt.decoder); // const blob = new Blob([`importScripts("${player._opt.decoder}")`], {"type": 'application/javascript'});
        // const blobUrl = window.URL.createObjectURL(blob);
        // this.decoderWorker = new Worker(blobUrl);

        this._initDecoderWorker();

        player.debug.log('decoderWorker', 'init');
        player.on(EVENTS.visibilityChange, () => {
          this.updateWorkConfig({
            key: 'visibility',
            value: player.visibility
          });
        });
      }

      destroy() {
        this.decoderWorker.postMessage({
          cmd: WORKER_SEND_TYPE.close
        });
        this.decoderWorker.terminate();
        this.decoderWorker = null;
        this.player.debug.log(`decoderWorker`, 'destroy');
      }

      _initDecoderWorker() {
        const {
          debug,
          events: {
            proxy
          }
        } = this.player;

        this.decoderWorker.onmessage = event => {
          const msg = event.data;

          switch (msg.cmd) {
            case WORKER_CMD_TYPE.init:
              debug.log(`decoderWorker`, 'onmessage:', WORKER_CMD_TYPE.init); //

              if (this.decoderWorker) {
                this._initWork();
              }

              if (!this.player.loaded) {
                this.player.emit(EVENTS.load);
              }

              this.player.emit(EVENTS.decoderWorkerInit);
              break;

            case WORKER_CMD_TYPE.videoCode:
              debug.log(`decoderWorker`, 'onmessage:', WORKER_CMD_TYPE.videoCode, msg.code);

              if (!this.player._times.decodeStart) {
                this.player._times.decodeStart = now$1();
              }

              this.player.video.updateVideoInfo({
                encTypeCode: msg.code
              });
              break;

            case WORKER_CMD_TYPE.videoCodec:
              debug.log(`decoderWorker`, 'onmessage:', WORKER_CMD_TYPE.videoCodec, msg.codecId);

              if (this.player.recorder) {
                this.player.recorder.initMetaData(msg.buffer, msg.codecId);
              }

              break;

            case WORKER_CMD_TYPE.audioCode:
              debug.log(`decoderWorker`, 'onmessage:', WORKER_CMD_TYPE.audioCode, msg.code);
              this.player.audio && this.player.audio.updateAudioInfo({
                encTypeCode: msg.code
              });
              break;

            case WORKER_CMD_TYPE.initVideo:
              debug.log(`decoderWorker`, 'onmessage:', WORKER_CMD_TYPE.initVideo, `width:${msg.w},height:${msg.h}`);
              this.player.video.updateVideoInfo({
                width: msg.w,
                height: msg.h
              }); // just for canvas render

              if (!this.player._opt.openWebglAlignment && !isWebglRenderSupport(msg.w) && this.player.getRenderType() === RENDER_TYPE.canvas) {
                this.player.emit(EVENTS_ERROR.webglAlignmentError);
                return;
              }

              this.player.video.initCanvasViewSize();

              if (this.player._opt.playType === PLAY_TYPE.playbackTF) {
                this.player.video.initFps();
                this.player.video.initVideoDelay();
              }

              break;

            case WORKER_CMD_TYPE.initAudio:
              debug.log(`decoderWorker`, 'onmessage:', WORKER_CMD_TYPE.initAudio, `channels:${msg.channels},sampleRate:${msg.sampleRate}`);

              if (this.player.audio) {
                this.player.audio.updateAudioInfo(msg);

                if (this.player._opt.playType === PLAY_TYPE.player) {
                  this.player.audio.initScriptNode();
                } else if (this.player._opt.playType === PLAY_TYPE.playbackTF) {
                  this.player.audio.initScriptNodeDelay();
                }
              }

              break;

            case WORKER_CMD_TYPE.render:
              // debug.log(`decoderWorker`, 'onmessage:', WORKER_CMD_TYPE.render, `msg ts:${msg.ts}`);
              if (this.player._opt.playType === PLAY_TYPE.player) {
                this.player.video.render(msg);
                this.player.handleRender();
                this.player.emit(EVENTS.timeUpdate, msg.ts);
                this.player.updateStats({
                  dfps: true,
                  buf: msg.delay
                });

                if (!this.player._times.videoStart) {
                  this.player._times.videoStart = now$1();
                  this.player.handlePlayToRenderTimes();
                }
              } else if (this.player._opt.playType === PLAY_TYPE.playbackTF) {
                if (this.player.playbackPause === false) {
                  if (this.player.playback.isUseLocalCalculateTime) {
                    this.player.playback.increaseLocalTimestamp();
                  }

                  if (this.player.playback.isUseFpsRender) {
                    this.player.video.pushData(msg);
                  } else {
                    this.player.video.render$2(msg);
                  }
                }
              }

              break;

            case WORKER_CMD_TYPE.videoNalu:
              if (this.player.recorder && this.player.recorder.isRecording && this.player._opt.recordType === FILE_SUFFIX.mp4) {
                this.player.recorder.handleAddNaluTrack(msg.buffer, msg.isIFrame, msg.ts, msg.cts);
              }

              break;

            case WORKER_CMD_TYPE.playAudio:
              // debug.log(`decoderWorker`, 'onmessage:', WORKER_CMD_TYPE.playAudio, `msg ts:${msg.ts}`);
              // 只有在 playing 的时候。
              // 或者 设置hasVideo 为false的情况
              if (this.player.playing && this.player.audio || !this.player.video) {
                // 如果不解码video
                if (!this.player._opt.hasVideo) {
                  this.player.handleRender();
                }

                if (this.player._opt.playType === PLAY_TYPE.player) {
                  this.player.audio.play(msg.buffer, msg.ts);
                } else if (this.player._opt.playType === PLAY_TYPE.playbackTF) {
                  if (this.player.playbackPause === false) {
                    this.player.audio.play(msg.buffer, msg.ts);
                  }
                }
              }

              break;

            case WORKER_CMD_TYPE.workerFetch:
              // debug.log(`decoderWorker`, `workerFetch: ${msg.type},${msg.value}`);
              if (msg.type === EVENTS.streamSuccess) {
                this.player.stream.emit(EVENTS.streamSuccess);
              } else if (msg.type === EVENTS.streamRate) {
                this.player.emit(EVENTS.kBps, (msg.value / 1024).toFixed(2));
              } else if (msg.type === EVENTS.streamEnd) {
                this.player.stream.emit(EVENTS.streamEnd);
              } else if (msg.type === EVENTS_ERROR.websocketError) {
                this.player.stream.emit(EVENTS_ERROR.websocketError, msg.value);
                this.player.emit(EVENTS.error, EVENTS_ERROR.websocketError);
              } else if (msg.type === EVENTS_ERROR.fetchError) {
                this.player.stream.emit(EVENTS_ERROR.fetchError, msg.value);
                this.player.emit(EVENTS.error, EVENTS_ERROR.fetchError);
              } else if (msg.type === EVENTS.streamAbps) {
                this.player.updateStats({
                  abps: msg.value
                });
              } else if (msg.type === EVENTS.streamVbps) {
                if (!this.player._times.demuxStart) {
                  this.player._times.demuxStart = now$1();
                }

                this.player.updateStats({
                  vbps: msg.value
                });
              } else if (msg.type === EVENTS.streamDts) {
                this.player.updateStats({
                  dts: msg.value
                });
              } else if (msg.type === EVENTS.netBuf) {
                this.player.updateStats({
                  netBuf: msg.value
                });
              } else if (msg.type === EVENTS.networkDelayTimeout) {
                this.player.emit(EVENTS.networkDelayTimeout, msg.value);
              } else if (msg.type === EVENTS.streamStats) {
                const obj = JSON.parse(msg.value);
                this.player.updateStats({
                  workerStats: obj
                });
              }

              break;

            case WORKER_CMD_TYPE.iframeIntervalTs:
              if (this.player) {
                this.player.videoIframeIntervalTs = msg.value;
              }

              break;

            case WORKER_CMD_TYPE.playbackStreamVideoFps:
              if (this.player && this.player.video) {
                this.player.video.setStreamFps(msg.value);
              }

              break;

            case WORKER_CMD_TYPE.wasmError:
              if (msg.message) {
                if (msg.message.indexOf(WASM_ERROR.invalidNalUnitSize) !== -1) {
                  this.player.emit(EVENTS.error, EVENTS_ERROR.wasmDecodeError);
                  this.player.emit(EVENTS_ERROR.wasmDecodeError);
                }
              }

              break;

            case WORKER_CMD_TYPE.workerEnd:
              debug.log(`decoderWorker`, 'onmessage:', WORKER_CMD_TYPE.workerEnd);

              {
                this.player.destroy();
                console.error('jessibuca pro 体验结束,请刷新页面再次体验');
                alert('jessibuca pro 体验结束,请刷新页面再次体验，如需要购买商业授权，可以联系微信：bosswancheng');
                window.location.reload();
              }

              break;

            default:
              this.player[msg.cmd] && this.player[msg.cmd](msg);
          }
        };
      }

      _initWork() {
        const opt = {
          debug: this.player._opt.debug,
          useOffscreen: this.player._opt.useOffscreen,
          useWCS: this.player._opt.useWCS,
          videoBuffer: this.player._opt.videoBuffer,
          videoBufferDelay: this.player._opt.videoBufferDelay,
          openWebglAlignment: this.player._opt.openWebglAlignment,
          playType: this.player._opt.playType,
          hasAudio: this.player._opt.hasAudio,
          hasVideo: this.player._opt.hasVideo,
          playbackRate: 1,
          playbackForwardMaxRateDecodeIFrame: this.player._opt.playbackForwardMaxRateDecodeIFrame,
          playbackIsCacheBeforeDecodeForFpsRender: this.player._opt.playbackConfig.isCacheBeforeDecodeForFpsRender,
          sampleRate: this.player.audio && this.player.audio.audioContext.sampleRate || 0,
          audioBufferSize: this.player.audio && this.player.audio.getAudioBufferSize() || 1024,
          networkDelay: this.player._opt.networkDelay,
          visibility: this.player.visibility,
          useSIMD: this.player._opt.useSIMD,
          recordType: this.player._opt.recordType,
          isNakedFlow: this.player._opt.isNakedFlow,
          checkFirstIFrame: this.player._opt.checkFirstIFrame
        };
        this.decoderWorker.postMessage({
          cmd: WORKER_SEND_TYPE.init,
          opt: JSON.stringify(opt)
        });
      }

      decodeVideo(arrayBuffer, ts, isIFrame) {
        if (this.player._opt.playType === PLAY_TYPE.player) {
          this._decodeVideo(arrayBuffer, ts, isIFrame);
        } else if (this.player._opt.playType === PLAY_TYPE.playbackTF) {
          // if rate
          if (this.player.video.rate >= this.player._opt.playbackForwardMaxRateDecodeIFrame) {
            if (isIFrame) {
              this.player.debug.log(`decoderWorker`, `current rate is ${this.player.video.rate},only decode i frame`);

              this._decodeVideoNoDelay(arrayBuffer, ts, isIFrame);
            }
          } else {
            if (this.player.video.rate === 1) {
              this._decodeVideo(arrayBuffer, ts, isIFrame);
            } else {
              this._decodeVideoNoDelay(arrayBuffer, ts, isIFrame);
            }
          }
        }
      }

      _decodeVideo(arrayBuffer, ts, isIFrame) {
        const options = {
          type: MEDIA_TYPE.video,
          ts: Math.max(ts, 0),
          isIFrame
        }; // this.player.debug.log('decoderWorker', 'decodeVideo', options);

        this.decoderWorker.postMessage({
          cmd: WORKER_SEND_TYPE.decode,
          buffer: arrayBuffer,
          options
        }, [arrayBuffer.buffer]);
      }
      /**
       *
       * @param arrayBuffer
       * @param ts
       * @private
       */


      _decodeVideoNoDelay(arrayBuffer, ts, isIFrame) {
        this.decoderWorker.postMessage({
          cmd: WORKER_SEND_TYPE.videoDecode,
          buffer: arrayBuffer,
          ts: Math.max(ts, 0),
          isIFrame
        }, [arrayBuffer.buffer]);
      }

      decodeAudio(arrayBuffer, ts) {
        if (this.player._opt.playType === PLAY_TYPE.player) {
          if (this.player._opt.useWCS) {
            this._decodeAudioNoDelay(arrayBuffer, ts);
          } else if (this.player._opt.useMSE) {
            this._decodeAudioNoDelay(arrayBuffer, ts);
          } else {
            this._decodeAudio(arrayBuffer, ts);
          }
        } else if (this.player._opt.playType === PLAY_TYPE.playbackTF) {
          // this._decodeAudioNoDelay(arrayBuffer, ts);
          if (this.player.video.rate === 1) {
            this._decodeAudio(arrayBuffer, ts);
          } else {
            this._decodeAudioNoDelay(arrayBuffer, ts);
          }
        }
      } //


      _decodeAudio(arrayBuffer, ts) {
        const options = {
          type: MEDIA_TYPE.audio,
          ts: Math.max(ts, 0)
        }; // this.player.debug.log('decoderWorker', 'decodeAudio',options);

        this.decoderWorker.postMessage({
          cmd: WORKER_SEND_TYPE.decode,
          buffer: arrayBuffer,
          options
        }, [arrayBuffer.buffer]);
      }

      _decodeAudioNoDelay(arrayBuffer, ts) {
        // console.log('_decodeAudioNoDelay', ts);
        this.decoderWorker.postMessage({
          cmd: WORKER_SEND_TYPE.audioDecode,
          buffer: arrayBuffer,
          ts: Math.max(ts, 0)
        }, [arrayBuffer.buffer]);
      }

      updateWorkConfig(config) {
        this.decoderWorker && this.decoderWorker.postMessage({
          cmd: WORKER_SEND_TYPE.updateConfig,
          key: config.key,
          value: config.value
        });
      }

      workerFetchStream(url) {
        const {
          _opt
        } = this.player;
        const opt = {
          protocol: _opt.protocol,
          isFlv: _opt.isFlv
        };
        this.decoderWorker.postMessage({
          cmd: WORKER_SEND_TYPE.fetchStream,
          url,
          opt: JSON.stringify(opt)
        });
      }

      clearWorkBuffer() {
        let needClear = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;
        this.decoderWorker.postMessage({
          cmd: WORKER_SEND_TYPE.clearBuffer,
          needClear
        });
      }

    }

    class CommonLoader extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.stopId = null;
        this.firstTimestamp = null;
        this.startTimestamp = null;
        this.bufferStartDts = null;
        this.bufferStartLocalTs = null;
        this.preIframeTs = null;
        this.delay = -1;
        this.bufferList = [];
        this.dropping = false;
        this.initInterval();
        this.player.debug.log('CommonDemux', 'init');
      }

      destroy() {
        this.bufferList = [];

        if (this.stopId) {
          clearInterval(this.stopId);
          this.stopId = null;
        }

        this.firstTimestamp = null;
        this.startTimestamp = null;
        this.bufferStartDts = null;
        this.bufferStartLocalTs = null;
        this.preIframeTs = null;
        this.delay = -1;
        this.dropping = false;
        this.off();
        this.player.debug.log('CommonDemux', 'destroy');
      }

      isDropping() {
        return this.dropping;
      }

      getDelay(timestamp) {
        if (!timestamp || !this.player.isDemuxDecodeFirstIIframeInit()) {
          return -1;
        }

        if (!this.firstTimestamp) {
          this.firstTimestamp = timestamp;
          this.startTimestamp = Date.now();
          this.delay = -1;
        } else {
          if (timestamp) {
            const localTimestamp = Date.now() - this.startTimestamp;
            const timeTimestamp = timestamp - this.firstTimestamp; // console.error(`localTimestamp is ${localTimestamp}, timeTimestamp is ${timeTimestamp}`)

            if (localTimestamp >= timeTimestamp) {
              this.delay = localTimestamp - timeTimestamp;
            } else {
              // maybe some stream ts more large than local ts
              this.delay = timeTimestamp - localTimestamp;
            }
          }
        }

        return this.delay;
      }

      resetDelay() {
        this.firstTimestamp = null;
        this.startTimestamp = null;
        this.delay = -1;
        this.dropping = false;
      } //


      initInterval() {
        this.player.debug.log('CommonDemux', `init Interval`);

        this._loop();

        this.stopId = setInterval(() => {
          this._loop();
        }, 10);
      }

      _loop() {
        let data;
        const videoBuffer = this.player._opt.videoBuffer;
        const videoBufferDelay = this.player._opt.videoBufferDelay;
        const isPlayer = this.player._opt.playType === PLAY_TYPE.player;

        if (this.bufferList.length) {
          if (this.dropping) {
            this.player.debug.warn('CommonDemux', `is dropping and delay is ${this.delay}`);
            data = this.bufferList.shift();

            while (!data.isIFrame && this.bufferList.length) {
              data = this.bufferList.shift();
            } // i frame
            // min delay


            if (data.isIFrame && this.bufferList.length < DOCUMENT_ONE_SECOND_BUFFER_LENGTH * (videoBuffer / 1000)) {
              this.player.debug.warn('CommonDemux', `_loop data isIFrame is true and delay is ${this.delay}`);
              this.dropping = false;

              this._doDecoderDecode(data);
            }
          } else {
            data = this.bufferList[0];

            if (this.getDelay(data.ts) === -1) {
              // this.player.debug.log('CommonDemux', `delay is -1 and data.ts is ${data.ts} data.type is ${data.type}`);
              this.bufferList.shift();

              this._doDecoderDecode(data);
            } else if (this.delay > videoBufferDelay + videoBuffer && isPlayer) {
              this.player.debug.warn('CommonDemux', `delay is ${this.delay}, set dropping is true`);
              this.resetDelay();
              this.dropping = true;
            } else {
              if (this.delay > videoBuffer) {
                // drop frame
                this.bufferList.shift();

                this._doDecoderDecode(data); // this.player.debug.log('CommonDemux', `do decode`);

              } else {
                if (this.delay < 0) {
                  this.player.debug.error('CommonDemux', `delay is ${this.delay} bufferList is ${this.bufferList}`);
                }
              }
            }
          }
        }
      }

      _doDecode(payload, type, ts, isIFrame) {
        let cts = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;
        const player = this.player;
        let options = {
          ts: ts,
          cts: cts,
          type: type,
          isIFrame: false
        };

        if (type === MEDIA_TYPE.video) {
          // console.log('_doDecode', payload);
          // console.error('_doDecode', type, ts, isIFrame, cts);
          if (player._opt.playType === PLAY_TYPE.player) {
            this.calcNetworkDelay(ts);
          }
        } // use offscreen


        if (player._opt.useWCS && !player._opt.useOffscreen) {
          if (type === MEDIA_TYPE.video) {
            options.isIFrame = isIFrame;
          }

          this.pushBuffer(payload, options);
        } else if (player._opt.useMSE) {
          // use mse
          if (type === MEDIA_TYPE.video) {
            options.isIFrame = isIFrame;
          }

          this.pushBuffer(payload, options);
        } else {
          //
          if (type === MEDIA_TYPE.video) {
            player.decoderWorker && player.decoderWorker.decodeVideo(payload, ts, isIFrame);
          } else if (type === MEDIA_TYPE.audio) {
            if (player._opt.hasAudio) {
              player.decoderWorker && player.decoderWorker.decodeAudio(payload, ts);
            }
          }
        }
      }

      _doDecoderDecode(data) {
        const player = this.player;
        const {
          webcodecsDecoder,
          mseDecoder
        } = player; // player.debug.log('CommonDemux', `_doDecoderDecode data.type is ${data.type} data.ts is ${data.ts}`);

        if (data.type === MEDIA_TYPE.audio) {
          if (player._opt.hasAudio) {
            player.decoderWorker && player.decoderWorker.decodeAudio(data.payload, data.ts);
          }
        } else if (data.type === MEDIA_TYPE.video) {
          if (player._opt.useWCS && !player._opt.useOffscreen) {
            webcodecsDecoder.decodeVideo(data.payload, data.ts, data.isIFrame, data.cts);
          } else if (player._opt.useMSE) {
            mseDecoder.decodeVideo(data.payload, data.ts, data.isIFrame, data.cts);
          }
        }
      }

      pushBuffer(payload, options) {
        const videoBuffer = this.player._opt.videoBuffer;
        const videoBufferDelay = this.player._opt.videoBufferDelay;
        const isPlayer = this.player._opt.playType === PLAY_TYPE.player; // decode aac header

        if (options.type === MEDIA_TYPE.audio && isAacCodecPacket(payload)) {
          this.player.debug.log('CommonDemux', `pushBuffer audio ts is ${options.ts}, isAacCodecPacket is ${isAacCodecPacket(payload)}`);

          this._doDecoderDecode({
            ts: options.ts,
            payload: payload,
            type: MEDIA_TYPE.audio
          });

          return;
        } //


        if (isPlayer && this.player.isDemuxDecodeFirstIIframeInit()) {
          if (this.player._opt.useMSE) {
            // const sourceBufferDelay = this.player.mseDecoder.checkSourceBufferDelay();
            // if (sourceBufferDelay * 1000 > (videoBufferDelay + videoBuffer)) {
            //     this.player.debug.warn('CommonDemux', `pushBuffer mse source sourceBufferDelay is ${sourceBufferDelay} useMSE and next this.player.mseDecoder.dropSourceBuffer(true)`);
            //     this.player.mseDecoder.dropSourceBuffer(true);
            // }
            if (this.getDelay(options.ts) > videoBufferDelay + videoBuffer) {
              this.player.debug.warn('CommonDemux', `useMSE pushBuffer mse source delay is ${this.getDelay(options.ts)} `);
            }
          } else {
            if (this.getDelay(options.ts) > videoBufferDelay + videoBuffer) {
              this.player.debug.warn('CommonDemux', `useWCS pushBuffer mse source delay is ${this.getDelay(options.ts)} `); // this.player.debug.warn('CommonDemux', `pushBuffer ts is ${options.ts}, delay is ${this.getDelay(options.ts)},max delay is ${videoBufferDelay + videoBuffer} and next this.dropBuffer()`)
              // this.dropBuffer(true);
            }
          }
        } // 音频


        if (options.type === MEDIA_TYPE.audio) {
          // this.player.debug.warn('CommonDemux', `pushBuffer audio ts is ${options.ts}`);
          this.bufferList.push({
            ts: options.ts,
            payload: payload,
            type: MEDIA_TYPE.audio
          });
        } else if (options.type === MEDIA_TYPE.video) {
          // this.player.debug.warn('CommonDemux', `pushBuffer video ts is ${options.ts}`);
          this.bufferList.push({
            ts: options.ts,
            cts: options.cts,
            payload: payload,
            type: MEDIA_TYPE.video,
            isIFrame: options.isIFrame
          });
        } // just for hidden的时候check


        if (isPlayer && this.player.isDemuxDecodeFirstIIframeInit() && !this.player.visibility) {
          const maxBufferLength = DOCUMENT_ONE_SECOND_BUFFER_LENGTH + DOCUMENT_ONE_SECOND_BUFFER_LENGTH * (videoBuffer + videoBufferDelay) / 1000;

          if (this.bufferList.length > maxBufferLength) {
            this.player.debug.warn('CommonDemux', `pushBuffer bufferList.length is ${this.bufferList.length} and more than ${maxBufferLength}`);

            if (this.player._opt.useMSE) ; else {
              // this.player.debug.warn('CommonDemux', `bufferList is ${this.bufferList.length} and next is this.dropBuffer()`);
              this.dropBuffer();
            }
          }
        }
      }

      dropBuffer(notDropDelay) {
        const videoBuffer = this.player._opt.videoBuffer;
        const videoBufferDelay = this.player._opt.videoBufferDelay;
        let maxBufferLength = DOCUMENT_ONE_SECOND_BUFFER_LENGTH * ((videoBuffer + videoBufferDelay) / 1000);

        if (notDropDelay) {
          maxBufferLength = DOCUMENT_ONE_SECOND_BUFFER_LENGTH * (videoBuffer / 1000);
        }

        while (this.bufferList.length) {
          let data = this.bufferList[0]; // i frame
          // min delay

          if (data.type === MEDIA_TYPE.video && data.isIFrame && this.bufferList.length < maxBufferLength) {
            // this.player.debug.warn('CommonDemux', `dropBuffer end isIFrame ${data.isIFrame} and delay is ${this.delay} and bufferlist is ${this.bufferList.length}`);
            break;
          } // all drop and not decode
          // if (data.type === MEDIA_TYPE.video) {
          //     this._doDecoderDecode(data);
          // }
          // this.player.debug.log('CommonDemux', `is dropping and isIFrame ${data.isIFrame} and delay is ${this.delay} and bufferlist is ${this.bufferList.length}`);
          // just for drop


          this.bufferList.shift();
        } // if (this.player._opt.useMSE) {
        //     this.player.debug.warn('CommonDemux', `dropBuffer  useMSE and next this.player.mseDecoder.dropSourceBuffer(true)`);
        //     this.player.mseDecoder.dropSourceBuffer(true)
        // }

      }

      clearBuffer() {
        let needClear = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;
        this.player.debug.log('CommonDemux', `clearBuffer,buffer length is ${this.bufferList.length}, need clear is ${needClear}`);

        if (needClear) {
          this.bufferList = [];
        }

        this.resetDelay();
        this.dropping = true;
      }

      calcNetworkDelay(dts) {
        //
        if (!(this.player.isDemuxDecodeFirstIIframeInit() && dts > 0)) {
          return;
        }

        if (this.bufferStartDts === null) {
          this.bufferStartDts = dts;
          this.bufferStartLocalTs = now$1();
        } else {
          //
          if (dts < this.bufferStartDts) {
            this.player.debug.warn('CommonDemux', `calcNetworkDelay dts is ${dts} and bufferStartDts is ${this.bufferStartDts}`);
            this.bufferStartDts = dts;
            this.bufferStartLocalTs = now$1();
          }
        }

        let diff1 = dts - this.bufferStartDts;
        let localDiff = now$1() - this.bufferStartLocalTs;
        let delay = localDiff > diff1 ? localDiff - diff1 : 0; // just for

        if (delay > this.player._opt.networkDelay && this.player._opt.playType === PLAY_TYPE.player) {
          this.player.debug.warn('CommonDemux', `now dts:${dts},start dts is ${this.bufferStartDts}, vs start is ${diff1},local diff is ${localDiff} ,delay is ${delay}`);
          this.player.emit(EVENTS.networkDelayTimeout, delay);
        }

        this.player.updateStats({
          netBuf: delay
        });
      }

      calcIframeIntervalTimestamp(ts) {
        if (this.preIframeTs === null) {
          this.preIframeTs = ts;
        } else {
          if (this.preIframeTs < ts) {
            const intervalTimestamp = ts - this.preIframeTs;

            if (this.player) {
              this.player.videoIframeIntervalTs = intervalTimestamp;
            } // post 到主线程里面去。


            this.preIframeTs = ts;
          }
        }
      }

      getInputByteLength() {
        return 0;
      }

      close() {}

      reset() {}

    }

    var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
        function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
        return new (P || (P = Promise))(function (resolve, reject) {
            function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
            function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
            function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
            step((generator = generator.apply(thisArg, _arguments || [])).next());
        });
    };
    const Types = [[Uint8Array, Int8Array], [Uint16Array, Int16Array], [Uint32Array, Int32Array, Float32Array], [Float64Array]];
    const U32 = Symbol(32);
    const U16 = Symbol(16);
    const U8 = Symbol(8);
    const OPutMap = new Map();
    Types.forEach((t, i) => t.forEach((t) => OPutMap.set(t, i)));
    class OPut {
        constructor(g) {
            this.g = g;
            this.consumed = 0;
            if (g)
                this.need = g.next().value;
        }
        fillFromReader(source) {
            return __awaiter(this, void 0, void 0, function* () {
                const { done, value } = yield source.read();
                if (done) {
                    this.close();
                    return;
                }
                else {
                    this.write(value);
                    return this.fillFromReader(source);
                }
            });
        }
        ;
        consume() {
            if (this.buffer && this.consumed) {
                this.buffer.copyWithin(0, this.consumed);
                this.buffer = this.buffer.subarray(0, this.buffer.length - this.consumed);
                this.consumed = 0;
            }
        }
        demand(n, consume) {
            if (consume)
                this.consume();
            this.need = n;
            return this.flush();
        }
        read(need) {
            return new Promise((resolve, reject) => {
                if (this.resolve)
                    return reject("last read not complete yet");
                this.resolve = (data) => {
                    delete this.resolve;
                    delete this.need;
                    resolve(data);
                };
                this.demand(need, true);
            });
        }
        readU32() {
            return this.read(U32);
        }
        readU16() {
            return this.read(U16);
        }
        readU8() {
            return this.read(U8);
        }
        close() {
            if (this.g)
                this.g.return();
        }
        flush() {
            if (!this.buffer || !this.need)
                return;
            let returnValue = null;
            const unread = this.buffer.subarray(this.consumed);
            let n = 0;
            const notEnough = (x) => unread.length < (n = x);
            if (typeof this.need === 'number') {
                if (notEnough(this.need))
                    return;
                returnValue = unread.subarray(0, n);
            }
            else if (this.need instanceof ArrayBuffer) {
                if (notEnough(this.need.byteLength))
                    return;
                new Uint8Array(this.need).set(unread.subarray(0, n));
                returnValue = this.need;
            }
            else if (this.need === U32) {
                if (notEnough(4))
                    return;
                returnValue = (unread[0] << 24) | (unread[1] << 16) | (unread[2] << 8) | unread[3];
            }
            else if (this.need === U16) {
                if (notEnough(2))
                    return;
                returnValue = (unread[0] << 8) | unread[1];
            }
            else if (this.need === U8) {
                if (notEnough(1))
                    return;
                returnValue = unread[0];
            }
            else if (OPutMap.has(this.need.constructor)) {
                if (notEnough(this.need.length << OPutMap.get(this.need.constructor)))
                    return;
                new Uint8Array(this.need.buffer, this.need.byteOffset).set(unread.subarray(0, n));
                returnValue = this.need;
            }
            else if (this.g) {
                this.g.throw(new Error('Unsupported type'));
                return;
            }
            this.consumed += n;
            if (this.g)
                this.demand(this.g.next(returnValue).value, true);
            else if (this.resolve)
                this.resolve(returnValue);
            return returnValue;
        }
        write(value) {
            if (value instanceof ArrayBuffer) {
                this.malloc(value.byteLength).set(new Uint8Array(value));
            }
            else {
                this.malloc(value.byteLength).set(new Uint8Array(value.buffer, value.byteOffset, value.byteLength));
            }
            if (this.g || this.resolve)
                this.flush();
        }
        writeU32(value) {
            this.malloc(4).set([(value >> 24) & 0xff, (value >> 16) & 0xff, (value >> 8) & 0xff, value & 0xff]);
            this.flush();
        }
        writeU16(value) {
            this.malloc(2).set([(value >> 8) & 0xff, value & 0xff]);
            this.flush();
        }
        writeU8(value) {
            this.malloc(1)[0] = value;
            this.flush();
        }
        malloc(size) {
            if (this.buffer) {
                const l = this.buffer.length;
                const nl = l + size;
                if (nl <= this.buffer.buffer.byteLength - this.buffer.byteOffset) {
                    this.buffer = new Uint8Array(this.buffer.buffer, this.buffer.byteOffset, nl);
                }
                else {
                    const n = new Uint8Array(nl);
                    n.set(this.buffer);
                    this.buffer = n;
                }
                return this.buffer.subarray(l, nl);
            }
            else {
                this.buffer = new Uint8Array(size);
                return this.buffer;
            }
        }
    }
    OPut.U32 = U32;
    OPut.U16 = U16;
    OPut.U8 = U8;

    class FlvLoader extends CommonLoader {
      constructor(player) {
        super(player);
        this.input = new OPut(this.demux());
        player.debug.log('FlvDemux', 'init');
      }

      destroy() {
        super.destroy();
        this.input = null;
        this.player.debug.log('FlvDemux', 'destroy');
      }

      dispatch(data) {
        this.input.write(data); // this.player.debug.log('FlvDemux', `this.input.buffer.length is ${this.input.buffer.length},byteLength is ${this.input.buffer.byteLength}`);
      }

      *demux() {
        yield 9;
        const tmp = new ArrayBuffer(4);
        const tmp8 = new Uint8Array(tmp);
        const tmp32 = new Uint32Array(tmp);
        const player = this.player;

        while (true) {
          if (!this.input) {
            return;
          }

          tmp8[3] = 0;
          const t = yield 15;
          const type = t[4];
          tmp8[0] = t[7];
          tmp8[1] = t[6];
          tmp8[2] = t[5];
          const length = tmp32[0];
          tmp8[0] = t[10];
          tmp8[1] = t[9];
          tmp8[2] = t[8]; // dts

          let ts = tmp32[0];

          if (ts === 0xFFFFFF) {
            tmp8[3] = t[11];
            ts = tmp32[0];
          }

          const payload = (yield length).slice();

          if (!player) {
            return;
          }

          switch (type) {
            case FLV_MEDIA_TYPE.audio:
              if (player._opt.hasAudio) {
                player.updateStats({
                  abps: payload.byteLength
                });

                if (payload.byteLength > 0) {
                  this._doDecode(payload, MEDIA_TYPE.audio, ts);
                }
              }

              break;

            case FLV_MEDIA_TYPE.video:
              // console.log('flv loader demux', payload);
              if (player._opt.hasVideo) {
                let dts = ts;

                if (this.player._opt.useMSE && isNotEmpty(this.player.mseDecoder.firstRenderTime)) {
                  dts = ts - this.player.mseDecoder.firstRenderTime;
                }

                player.updateStats({
                  vbps: payload.byteLength,
                  dts: dts
                });
                const isIFrame = payload[0] >> 4 === 1;

                if (isIFrame) {
                  this.calcIframeIntervalTimestamp(ts);
                }

                if (payload.byteLength > 0) {
                  tmp32[0] = payload[4];
                  tmp32[1] = payload[3];
                  tmp32[2] = payload[2];
                  tmp32[3] = 0;
                  let cts = tmp32[0];

                  if (!player._times.demuxStart) {
                    player._times.demuxStart = now$1();
                  } // console.log(payload);


                  this._doDecode(payload, MEDIA_TYPE.video, ts, isIFrame, cts);
                }
              }

              break;
          }
        }
      }

      close() {
        this.input = null;
      }

      getInputByteLength() {
        let result = 0;

        if (this.input && this.input.buffer) {
          result = this.input.buffer.byteLength;
        }

        return result;
      }

    }

    class M7sLoader extends CommonLoader {
      constructor(player) {
        super(player);
        player.debug.log('M7sDemux', 'init');
      }

      destroy() {
        super.destroy();
        this.player.debug.log('M7sDemux', 'destroy');
      }

      dispatch(data) {
        const player = this.player;
        const dv = new DataView(data);
        const type = dv.getUint8(0);
        const ts = dv.getUint32(1, false);

        switch (type) {
          case MEDIA_TYPE.audio:
            if (player._opt.hasAudio) {
              const payload = new Uint8Array(data, 5);
              player.updateStats({
                abps: payload.byteLength
              });

              if (payload.byteLength > 0) {
                this._doDecode(payload, type, ts);
              }
            }

            break;

          case MEDIA_TYPE.video:
            if (player._opt.hasVideo) {
              if (!player._times.demuxStart) {
                player._times.demuxStart = now$1();
              }

              if (dv.byteLength > 5) {
                const payload = new Uint8Array(data, 5);
                const isIframe = dv.getUint8(5) >> 4 === 1;
                let dts = ts;

                if (this.player._opt.useMSE && isNotEmpty(this.player.mseDecoder.firstRenderTime)) {
                  dts = ts - this.player.mseDecoder.firstRenderTime;
                }

                player.updateStats({
                  vbps: payload.byteLength,
                  dts: dts
                });

                if (payload.byteLength > 0) {
                  if (isIframe) {
                    this.calcIframeIntervalTimestamp(ts);
                  }

                  this._doDecode(payload, type, ts, isIframe);
                }
              } else {
                this.player.debug.warn('M7sDemux', 'dispatch', 'dv byteLength is', dv.byteLength);
              }
            }

            break;
        }
      }

    }

    class WebTransportLoader extends FlvLoader {
      constructor(player) {
        super(player);
        player.debug.log('WebTransportDemux', 'init');
      }

      destroy() {
        this.player.debug.log('WebTransportDemux', 'destroy');
        super.destroy();
      }

    }

    class NakedFlowLoader extends CommonLoader {
      constructor(player) {
        super(player);
        this.name = 'NakedFlowDemux';
        this.lastBuf = null;
        this.vps = null;
        this.sps = null;
        this.pps = null;
        this.streamVideoType = null;
        this.streamAudioType = null;
        this.tempNaluBufferList = new Uint8Array(0);
        this.localDts = 0;
        this.localAudioDts = 0;
        this.isSendSeqHeader = false;
        this.isSendAACSeqHeader = false;
        player.debug.log(this.name, 'init');
      }

      destroy() {
        super.destroy();
        this.lastBuf = null;
        this.vps = null;
        this.sps = null;
        this.pps = null;
        this.streamVideoType = null;
        this.streamAudioType = null;
        this.tempNaluBufferList = new Uint8Array(0);
        this.localDts = 0;
        this.localAudioDts = 0;
        this.isSendSeqHeader = false;
        this.isSendAACSeqHeader = false;
        this.player.debug.log(this.name, 'destroy');
      } //


      dispatch(data) {
        this.player;
        const uint8Array = new Uint8Array(data); // player.debug.log(this.name, 'dispatch', uint8Array.byteLength);
        // const naluArray = this.extractNALu(uint8Array);
        // console.log('naluArray', naluArray);

        this.extractNALu$2(uint8Array); // this.addNaluToBuffer(uint8Array);
        // this.handleNALu(uint8Array);
      }

      addNaluToBuffer(nalu) {
        const len = nalu.byteLength + this.tempNaluBufferList.byteLength;
        const newBuffer = new Uint8Array(len);
        newBuffer.set(this.tempNaluBufferList, 0);
        newBuffer.set(nalu, this.tempNaluBufferList.byteLength);
        this.tempNaluBufferList = newBuffer; //console.log('addNaluToBuffer byteLength is', this.tempNaluBufferList.byteLength);
      }

      downloadNakedFlowFile() {
        const blob = new Blob([this.tempNaluBufferList]);

        try {
          const oa = document.createElement('a');
          oa.href = window.URL.createObjectURL(blob);
          oa.download = Date.now() + '.h265';
          oa.click();
        } catch (e) {
          console.error('downloadTempNalu', e);
        }
      } //


      getNaluDts() {
        const nakedFlowFps = this.player._opt.nakedFlowFps; // console.log(`nakedFlowFps is ${nakedFlowFps} and dts is ${(1000 / nakedFlowFps)}`);

        this.localDts = this.localDts + parseInt(1000 / nakedFlowFps);
        return this.localDts;
      }

      getNaluAudioDts() {
        const audioContextSampleRate = this.player.audio.audioContext.sampleRate; //  dts

        this.localAudioDts = this.localAudioDts + 1024 / audioContextSampleRate * 1000;
        return this.localAudioDts;
      } //


      extractNALu(buffer) {
        let i = 0,
            length = buffer.byteLength,
            value,
            state = 0,
            result = [],
            lastIndex;

        while (i < length) {
          value = buffer[i++]; // Annex-B格式使用start code进行分割，start code为0x000001或0x00000001，SPS/PPS作为一般NALU单元以start code作为分隔符的方式放在文件或者直播流的头部。
          // finding 3 or 4-byte start codes (00 00 01 OR 00 00 00 01)

          switch (state) {
            case 0:
              if (value === 0) {
                state = 1;
              }

              break;

            case 1:
              if (value === 0) {
                state = 2;
              } else {
                state = 0;
              }

              break;

            case 2:
            case 3:
              if (value === 0) {
                state = 3;
              } else if (value === 1 && i < length) {
                if (lastIndex) {
                  result.push(buffer.subarray(lastIndex, i - state - 1));
                }

                lastIndex = i;
                state = 0;
              } else {
                state = 0;
              }

              break;
          }
        }

        if (lastIndex) {
          result.push(buffer.subarray(lastIndex, length));
        }

        return result;
      }

      extractNALu$2(buffer) {
        let typedArray = null;
        if (!buffer || buffer.byteLength < 1) return;

        if (this.lastBuf) {
          typedArray = new Uint8Array(buffer.byteLength + this.lastBuf.length);
          typedArray.set(this.lastBuf);
          typedArray.set(new Uint8Array(buffer), this.lastBuf.length);
        } else {
          typedArray = new Uint8Array(buffer);
        }

        let lastNalEndPos = 0;
        let b1 = -1; // byte before one

        let b2 = -2; // byte before two

        const nalStartPos = new Array();

        for (let i = 0; i < typedArray.length; i += 2) {
          const b_0 = typedArray[i];
          const b_1 = typedArray[i + 1];

          if (b1 == 0 && b_0 == 0 && b_1 == 0) {
            nalStartPos.push(i - 1);
          } else if (b_1 == 1 && b_0 == 0 && b1 == 0 && b2 == 0) {
            nalStartPos.push(i - 2);
          }

          b2 = b_0;
          b1 = b_1;
        }

        if (nalStartPos.length > 1) {
          for (let i = 0; i < nalStartPos.length - 1; ++i) {
            const naluItem = typedArray.subarray(nalStartPos[i], nalStartPos[i + 1] + 1);
            this.handleNALu(naluItem); //console.log('nakedFlowDemuxer.lastBuf nalType', this.lastBuf.byteLength);

            lastNalEndPos = nalStartPos[i + 1];
          }
        } else {
          lastNalEndPos = nalStartPos[0];
        }

        if (lastNalEndPos != 0 && lastNalEndPos < typedArray.length) {
          this.lastBuf = typedArray.subarray(lastNalEndPos);
        } else {
          if (!!!this.lastBuf) {
            this.lastBuf = typedArray;
          }

          const _newBuf = new Uint8Array(this.lastBuf.length + buffer.byteLength);

          _newBuf.set(this.lastBuf);

          _newBuf.set(new Uint8Array(buffer), this.lastBuf.length);

          this.lastBuf = _newBuf;
        }
      }

      handleNALu(nalu) {
        if (nalu.byteLength < 4) {
          this.player.debug.error(this.name, 'handleNALu', 'nalu.byteLength <= 4');
          return;
        } // 0001 去掉前4个字节（start code）


        nalu = nalu.slice(4);
        this.handleVideoNalu(nalu);
      }

      handleVideoNalu(nalu) {
        const uint8Array = new Uint8Array(nalu);

        if (!this.streamVideoType) {
          this.streamVideoType = checkNaluType(uint8Array);
        }

        if (this.streamVideoType === VIDEO_ENC_TYPE_SHOW.h264) {
          const nalType = getAvcSeqHeadType(uint8Array);

          if (nalType === H264_NAL_TYPE.pps) {
            this.extractH264PPS(uint8Array);
          } else {
            this.handleVideoH264Nalu(uint8Array);
          }
        } else if (this.streamVideoType === VIDEO_ENC_TYPE_SHOW.h265) {
          const naluType = getHevcSeqHeadType(uint8Array);

          if (naluType === H265_NAL_TYPE.pps) {
            this.extractH265PPS(uint8Array);
          } else {
            this.handleVideoH265Nalu(uint8Array);
          }
        } else {
          this.player.debug.error(this.name, ` this.streamVideoType is null`);
        }
      }

      extractH264PPS(nalu) {
        const tempNalu = this.handleAddNaluStartCode(nalu);
        const naluList = this.extractNALu(tempNalu);
        naluList.forEach(naluItem => {
          const nalType = getAvcSeqHeadType(naluItem);

          if (isHvcSEIType(nalType)) {
            this.extractH264SEI(naluItem);
          } else {
            this.handleVideoH264Nalu(naluItem);
          }
        });
      }

      extractH265PPS(nalu) {
        const tempNalu = this.handleAddNaluStartCode(nalu);
        const naluList = this.extractNALu(tempNalu);
        naluList.forEach(naluItem => {
          const nalType = getHevcSeqHeadType(naluItem);

          if (isHevcSEIType(nalType)) {
            this.extractH265SEI(naluItem);
          } else {
            this.handleVideoH265Nalu(naluItem);
          }
        });
      }

      extractH264SEI(nalu) {
        const tempNalu = this.handleAddNaluStartCode(nalu);
        const naluList = this.extractNALu(tempNalu);
        naluList.forEach(naluItem => {
          this.handleVideoH264Nalu(naluItem);
        });
      }

      extractH265SEI(nalu) {
        const tempNalu = this.handleAddNaluStartCode(nalu);
        const naluList = this.extractNALu(tempNalu); //console.log('extractH265SEI', naluList);

        naluList.forEach(naluItem => {
          this.handleVideoH265Nalu(naluItem);
        });
      }

      handleAddNaluStartCode(nalu) {
        const prefix = [0, 0, 0, 1];
        const newNalu = new Uint8Array(nalu.length + prefix.length);
        newNalu.set(prefix);
        newNalu.set(nalu, prefix.length);
        return newNalu;
      }

      handleAudioAACNalu(nalu) {
        if (!nalu || nalu.byteLength < 1) return;

        if (!this.streamAudioType) {
          this.streamAudioType = AUDIO_ENC_CODE_SHOW.AAC;
        }

        let uint8Array = new Uint8Array(nalu); // 需要取出7个字节的ADTS头。

        const accADTSHeader = uint8Array.slice(0, 7); // 移除掉 ADTS头

        uint8Array = uint8Array.slice(7);

        if (!this.isSendAACSeqHeader) {
          // 七个字节的adts头；
          //     aac 格式
          // 需要先发序列帧。然后再发后续的
          // 序列帧：asc 序列
          // 后续的帧，0 变成 1 就行了。
          // 0: Main profile
          // 1: Low Complexity profile(LC)
          // 2: Scalable Sampling Rate profile(SSR)
          const profile = (accADTSHeader[2] & 0xc0) >> 6; // const profile = 0;
          // const sampleRate = (+audioInfo.sampleRate);

          const sampleRate = (accADTSHeader[2] & 0x3C) >> 2; // const channel = (+audioInfo.channel);

          const channel = (accADTSHeader[2] & 0x1) << 2 | (accADTSHeader[3] & 0xc0) >> 6;
          const config1 = profile << 3 | (sampleRate & 0xe) >> 1;
          const config2 = (sampleRate & 0x1) << 7 | channel << 3; // 0xAF >> 4 === 10

          const temp = [0xAF, 0x00, config1, config2];
          const arrayBuffer = new Uint8Array(temp);
          this.isSendAACSeqHeader = true;

          this._doDecode(arrayBuffer, MEDIA_TYPE.audio, 0, false, 0);
        }

        const dts = this.getNaluAudioDts();
        const arrayBuffer = new Uint8Array(uint8Array.length + 2);
        arrayBuffer.set([0xAF, 0x01], 0);
        arrayBuffer.set(uint8Array, 2);

        this._doDecode(arrayBuffer, MEDIA_TYPE.audio, dts, false, 0);
      }

      handleAudioG711ANalu(nalu) {
        if (!nalu || nalu.byteLength < 1) return;

        if (!this.streamAudioType) {
          this.streamAudioType = AUDIO_ENC_CODE_SHOW.ALAW;
        }

        let uint8Array = new Uint8Array(nalu);
        const dts = this.getNaluAudioDts();
        const arrayBuffer = new Uint8Array(uint8Array.length + 1);
        arrayBuffer.set([7 << 4 | 1 << 1], 0);
        arrayBuffer.set(uint8Array, 1);

        this._doDecode(arrayBuffer, MEDIA_TYPE.audio, dts, false, 0);
      }

      handleAudioG711UNalu(nalu) {
        if (!nalu || nalu.byteLength < 1) return;

        if (!this.streamAudioType) {
          this.streamAudioType = AUDIO_ENC_CODE_SHOW.MULAW;
        }

        let uint8Array = new Uint8Array(nalu);
        const dts = this.getNaluAudioDts();
        const arrayBuffer = new Uint8Array(uint8Array.length + 1);
        arrayBuffer.set([8 << 4 | 1 << 1], 0);
        arrayBuffer.set(uint8Array, 1);

        this._doDecode(arrayBuffer, MEDIA_TYPE.audio, dts, false, 0);
      }

      handleVideoH264Nalu(nalu) {
        const nalType = getAvcSeqHeadType(nalu);
        this.player.debug.log(this.name, `handleVideoH265Nalu nalType is ${nalType}, nalu[0] is ${nalu[0]}`);

        switch (nalType) {
          case H264_NAL_TYPE.sps:
            this.sps = nalu;
            break;

          case H264_NAL_TYPE.pps:
            this.pps = nalu;
            break;
        }

        if (!this.isSendSeqHeader) {
          if (this.sps && this.pps) {
            this.isSendSeqHeader = true;
            const seqHeader = avcEncoderConfigurationRecord$2({
              sps: this.sps,
              pps: this.pps
            }); //console.log('handleVideoH264Nalu seqHeader', seqHeader);

            this._doDecode(seqHeader, MEDIA_TYPE.video, 0, true, 0);
          }
        } else {
          if (isNotAvcSeqHead(nalType)) {
            if (!this.player._times.demuxStart) {
              this.player._times.demuxStart = now$1();
            }

            const isIFrame = isAvcNaluIFrame(nalType);
            const dts = this.getNaluDts();
            const packet = avcEncoderNalePacket(nalu, isIFrame);
            this.player.updateStats({
              vbps: packet.byteLength,
              dts: dts
            });
            this.player.debug.log(this.name, `handleVideoH264Nalu packet decode ts is ${dts}, and package byteLength is ${packet.byteLength} and isIFrame is ${isIFrame}`);

            if (isIFrame) {
              this.calcIframeIntervalTimestamp(dts);
            }

            this._doDecode(packet, MEDIA_TYPE.video, dts, isIFrame, 0);
          }
        }
      }

      handleVideoH265Nalu(nalu) {
        const nalType = getHevcSeqHeadType(nalu); // this.player.debug.log(this.name, `handleVideoH265Nalu nalType is ${nalType}, nalu[0] is ${nalu[0]}`);

        switch (nalType) {
          case H265_NAL_TYPE.vps:
            this.vps = nalu;
            break;

          case H265_NAL_TYPE.sps:
            this.sps = nalu;
            break;

          case H265_NAL_TYPE.pps:
            this.pps = nalu;
            break;
        }

        if (!this.isSendSeqHeader) {
          if (this.vps && this.sps && this.pps) {
            this.isSendSeqHeader = true;
            const seqHeader = hevcEncoderConfigurationRecord$2({
              vps: this.vps,
              sps: this.sps,
              pps: this.pps
            }); // console.log('handleVideoH265Nalu seqHeader', seqHeader);

            this._doDecode(seqHeader, MEDIA_TYPE.video, 0, true, 0);
          }
        } else {
          if (isNotHevcSeqHead(nalType)) {
            if (!this.player._times.demuxStart) {
              this.player._times.demuxStart = now$1();
            }

            const isIFrame = isHevcNalIFrame(nalType);
            const dts = this.getNaluDts();
            const packet = hevcEncoderNalePacket(nalu, isIFrame);
            this.player.updateStats({
              vbps: packet.byteLength,
              dts: dts
            });
            this.player.debug.log(this.name, `handleVideoH265Nalu packet decode ts is ${dts}, and package byteLength is ${packet.byteLength} and isIFrame is ${isIFrame}`);

            if (isIFrame) {
              this.calcIframeIntervalTimestamp(dts);
            }

            this._doDecode(packet, MEDIA_TYPE.video, dts, isIFrame, 0);
          }
        }
      }

      getInputByteLength() {
        let result = 0;

        if (this.lastBuf) {
          result = this.lastBuf.byteLength;
        }

        return result;
      }

    }

    class Demux {
      constructor(player) {
        const Loader = Demux.getLoaderFactory(player._opt.demuxType);
        return new Loader(player);
      }

      static getLoaderFactory(type) {
        if (type === DEMUX_TYPE.m7s) {
          return M7sLoader;
        } else if (type === DEMUX_TYPE.flv) {
          return FlvLoader;
        } else if (type === DEMUX_TYPE.webTransport) {
          return WebTransportLoader;
        } else if (type === DEMUX_TYPE.nakedFlow) {
          return NakedFlowLoader;
        }
      }

    }

    class WebcodecsDecoder extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.hasInit = false;
        this.isDecodeFirstIIframe = false;
        this.isInitInfo = false;
        this.prevTimestamp = null;
        this.decodeDiffTimestamp = null;
        this.prevDts = null;
        this.decoder = null;
        this.initDecoder();
        player.debug.log('Webcodecs', 'init');
      }

      destroy() {
        if (this.decoder) {
          if (this.decoder.state !== 'closed') {
            this.decoder.close();
          }

          this.decoder = null;
        }

        this.prevTimestamp = null;
        this.decodeDiffTimestamp = null;
        this.prevDts = null;
        this.hasInit = false;
        this.isInitInfo = false;
        this.isDecodeFirstIIframe = false;
        this.off();
        this.player.debug.log('Webcodecs', 'destroy');
      }

      initDecoder() {
        const _this = this;

        this.decoder = new VideoDecoder({
          output(videoFrame) {
            _this.handleDecode(videoFrame);
          },

          error(error) {
            _this.handleError(error);
          }

        });
      }

      handleDecode(videoFrame) {
        if (!this.isInitInfo) {
          this.player.video.updateVideoInfo({
            width: videoFrame.codedWidth,
            height: videoFrame.codedHeight
          });
          this.player.video.initCanvasViewSize();
          this.isInitInfo = true;
        } // console.log('Webcodecs', 'handleDecode duration and timestamp', videoFrame.duration, videoFrame.timestamp)


        if (!this.player._times.videoStart) {
          this.player._times.videoStart = now$1();
          this.player.handlePlayToRenderTimes();
        }

        this.player.video.render({
          videoFrame,
          ts: videoFrame.timestamp
        });
        this.player.handleRender();
        this.player.updateStats({
          dfps: true,
          buf: this.player.demux && this.player.demux.delay || 0
        }); // release resource
        // setTimeout(function () {
        //     if (videoFrame.close) {
        //         videoFrame.close()
        //     } else {
        //         videoFrame.destroy()
        //     }
        // }, 100)
      }

      handleError(error) {
        this.player.debug.error('Webcodecs', 'VideoDecoder handleError', error);
      }

      decodeVideo(payload, ts, isIframe, cts) {
        // this.player.debug.log('Webcodecs decoder', 'decodeVideo', ts, isIframe);
        if (!this.hasInit) {
          if (isIframe && payload[1] === 0) {
            const videoCodec = payload[0] & 0x0F;
            this.player.video.updateVideoInfo({
              encTypeCode: videoCodec
            }); // 如果解码出来的是

            if (videoCodec === VIDEO_ENC_CODE.h265 && !supportWCSDecodeHevc()) {
              const browserInfo = getBrowser();
              this.player.debug.warn('Webcodecs', 'WebcodecsDecoder not support hevc decode', browserInfo.type, browserInfo.version);
              this.emit(EVENTS_ERROR.webcodecsH265NotSupport);
              return;
            }

            if (!this.player._times.decodeStart) {
              this.player._times.decodeStart = now$1();
            }

            let config = null;
            const extraData = payload.slice(5);

            if (videoCodec === VIDEO_ENC_CODE.h264) {
              config = formatVideoDecoderConfigure(extraData);
            } else if (videoCodec === VIDEO_ENC_CODE.h265) {
              config = formatHevcVideoDecoderConfigure(extraData);
            }

            if (this.player.recorder && this.player._opt.recordType === FILE_SUFFIX.mp4) {
              this.player.recorder.initMetaData(payload, videoCodec);
            } // console.log('webcodecs decodeVideo config is ', config);


            this.player.debug.warn('Webcodecs', 'decodeVideo and webcodecs configure');
            this.decoder.configure(config);
            this.hasInit = true;
          }
        } else {
          // check width or height change
          // if (isIframe && payload[1] === 0) {
          //     let data = payload.slice(5);
          //     const config = parseAVCDecoderConfigurationRecord(data)
          //     this.player.debug.log('Webcodecs', `decoder config again`);
          //     // const videoInfo = this.player.video.videoInfo;
          //     // if (config.codecWidth !== videoInfo.width || config.codecHeight !== videoInfo.height) {
          //     //     this.player.debug.log('Webcodecs', `width or height is update, width ${videoInfo.width}-> ${config.codecWidth}, height ${videoInfo.height}-> ${config.codecHeight}`)
          //     //     this.player.emit(EVENTS_ERROR.webcodecsWidthOrHeightChange)
          //     //     return;
          //     // }
          //     this.decoder.configure(config);
          //     return;
          // }
          if (!this.isDecodeFirstIIframe && !isIframe) {
            this.player.debug.warn('Webcodecs', 'VideoDecoder isDecodeFirstIIframe false and isIframe is false');
          } // fix : Uncaught DOMException: Failed to execute 'decode' on 'VideoDecoder': A key frame is required after configure() or flush().


          if (!this.isDecodeFirstIIframe && isIframe) {
            this.isDecodeFirstIIframe = true;
          }

          if (this.isDecodeFirstIIframe) {
            let nowTime = new Date().getTime();

            if (!this.prevTimestamp) {
              this.prevTimestamp = nowTime;
            }

            const diffTime = nowTime - this.prevTimestamp;
            this.decodeDiffTimestamp = diffTime;

            if (diffTime < 5 || diffTime > 500) {
              this.player.debug.warn('Webcodecs', 'decodeVideo diff time is ', diffTime);
            } // this.player.debug.log('Webcodecs', 'VideoDecoder EncodedVideoChunk ,ts', ts)


            const buffer = payload.slice(5);
            const chunk = new EncodedVideoChunk({
              data: buffer,
              timestamp: ts,
              type: isIframe ? ENCODED_VIDEO_TYPE.key : ENCODED_VIDEO_TYPE.delta
            });
            this.player.emit(EVENTS.timeUpdate, ts);

            if (this.player.recorder && this.player.recorder.isRecording && this.player._opt.recordType === FILE_SUFFIX.mp4) {
              this.player.recorder.handleAddNaluTrack(buffer, isIframe, ts, cts);
            }

            try {
              this.decoder.decode(chunk);
            } catch (e) {
              this.player.debug.error('Webcodecs', 'VideoDecoder', e);
              const errorString = e.toString();

              if (errorString.indexOf(WCS_ERROR.keyframeIsRequiredError) !== -1) {
                this.player.emit(EVENTS_ERROR.webcodecsDecodeError);
              } else if (errorString.indexOf(WCS_ERROR.canNotDecodeClosedCodec) !== -1) {
                this.player.emit(EVENTS_ERROR.webcodecsDecodeError);
              }
            }

            this.prevTimestamp = new Date().getTime();
          } else {
            this.player.debug.warn('Webcodecs', 'VideoDecoder isDecodeFirstIIframe false');
          }
        }
      }

      getDecodeDiffTimes() {
        return this.decodeDiffTimestamp;
      }

    }

    const iconsMap = {
      play: '播放',
      pause: '暂停',
      audio: '',
      mute: '',
      screenshot: '截图',
      loading: '加载',
      fullscreen: '全屏',
      fullscreenExit: '退出全屏',
      record: '录制',
      recordStop: '停止录制',
      narrow: '缩小',
      expand: '放大',
      ptz: '操作盘',
      ptzActive: '操作盘激活',
      zoom: '电子放大',
      zoomStop: '关闭电子放大',
      close: '关闭',
      performance: '性能面板',
      performanceActive: '性能面板激活',
      face: '人脸识别',
      faceActive: '人脸识别激活'
    };
    var icons = Object.keys(iconsMap).reduce((icons, key) => {
      icons[key] = `
    <i class="jessibuca-icon jessibuca-icon-${key}"></i>
    ${iconsMap[key] ? `<span class="icon-title-tips"><span class="icon-title">${iconsMap[key]}</span></span>` : ''}
`;
      return icons;
    }, {});

    var template = ((player, control) => {
      if (player._opt.hasControl && player._opt.controlAutoHide) {
        player.$container.classList.add('jessibuca-controls-show-auto-hide');
      } else {
        player.$container.classList.add('jessibuca-controls-show');
      }

      const options = player._opt;
      const operateBtns = options.operateBtns;
      const playbackOperateDom = `
        <div class="jessibuca-controls-center">
            <div class="jessibuca-controls-playback-time">
                <div class="jessibuca-controls-playback-time-inner">
                    <div class="jessibuca-controls-playback-time-scroll">
                        <div class="jessibuca-controls-playback-time-list">
                            <div class="jessibuca-playback-time-day">
                                <div class="jessibuca-playback-time-one-wrap"></div>
                                <div class="jessibuca-playback-time-second-wrap"></div>
                            </div>
                        </div>
                        <div class="jessibuca-controls-playback-current-time">
                            <div class="jessibuca-controls-playback-current-time-text">00:00:00</div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="jessibuca-controls-playback-btns">
                <div class="jessibuca-controls-item jessibuca-playback-narrow">${icons.narrow}</div>
                <div class="jessibuca-controls-item jessibuca-playback-expand">${icons.expand}</div>
            </div>
        </div>
    `;
      player.$container.insertAdjacentHTML('beforeend', `
            ${options.background ? `<div class="jessibuca-poster" style="background-image: url(${options.background})"></div>` : ''}

            ${options.loadingIcon ? `
            <div class="jessibuca-loading">
                ${icons.loading}
                ${options.loadingText ? `<div class="jessibuca-loading-text">${options.loadingText}</div>` : ''}
            </div>
            ` : ''}
            ${options.hasControl && operateBtns.play ? `<div class="jessibuca-play-big"></div>` : ''}
            ${options.hasControl && operateBtns.ptz ? `
            <div class="jessibuca-ptz-controls">
                <div class="jessibuca-ptz-bg-active"></div>
                <div class="jessibuca-ptz-arrow jessibuca-ptz-arrow-up" data-arrow="up"></div>
                <div class="jessibuca-ptz-arrow jessibuca-ptz-arrow-right" data-arrow="right"></div>
                <div class="jessibuca-ptz-arrow jessibuca-ptz-arrow-down" data-arrow="down"></div>
                <div class="jessibuca-ptz-arrow jessibuca-ptz-arrow-left" data-arrow="left"></div>
                <div class="jessibuca-ptz-control"></div>
            </div>
            ` : ''}
           <div class="jessibuca-zoom-controls">
                <div class="jessibuca-zoom-narrow">${icons.narrow}</div>
                <div class="jessibuca-zoom-tips">电子放大</div>
                <div class="jessibuca-zoom-expand">${icons.expand}</div>
                <div class="jessibuca-zoom-stop2">${icons.zoomStop}</div>
            </div>
            <div class="jessibuca-recording">
                <div class="jessibuca-recording-red-point"></div>
                <div class="jessibuca-recording-time">00:00:01</div>
                <div class="jessibuca-icon-recordStop jessibuca-recording-stop">${icons.recordStop}</div>
            </div>
            ${options.hasControl ? `
                <div class="jessibuca-controls">
                    <div class="jessibuca-controls-bottom">
                        <div class="jessibuca-controls-left">
                            ${options.showBandwidth ? `<div class="jessibuca-controls-item jessibuca-speed"></div>` : ''}
                        </div>
                        ${options.playType === PLAY_TYPE.playbackTF && options.playbackConfig.showControl ? playbackOperateDom : ''}

                        <div class="jessibuca-controls-right">
                             ${operateBtns.close ? `<div class="jessibuca-controls-item jessibuca-close">${icons.close}</div>` : ''}
                             ${operateBtns.performance ? `<div class="jessibuca-controls-item jessibuca-performance">${icons.performance}</div><div class="jessibuca-controls-item jessibuca-performance-active">${icons.performanceActive}</div>` : ''}
                             ${operateBtns.face ? `<div class="jessibuca-controls-item jessibuca-face">${icons.face}</div><div class="jessibuca-controls-item jessibuca-face-active">${icons.faceActive}</div>` : ''}

                             ${operateBtns.quality ? `
                                 <div class="jessibuca-controls-item jessibuca-quality-menu">
                                    <div class="jessibuca-quality-icon-text"></div>
                                    <div class="jessibuca-quality-menu-list"></div>
                                 </div>
                             ` : ''}
                             ${operateBtns.scale ? `
                                 <div class="jessibuca-controls-item jessibuca-scale-menu">
                                    <div class="jessibuca-scale-icon-text"></div>
                                    <div class="jessibuca-scale-menu-list"></div>
                                 </div>
                             ` : ''}
                             ${operateBtns.audio ? `
                                 <div class="jessibuca-controls-item jessibuca-volume">
                                     ${icons.audio}
                                     ${icons.mute}
                                     <div class="jessibuca-volume-panel-wrap">
                                          <div class="jessibuca-volume-panel">
                                                 <div class="jessibuca-volume-panel-handle"></div>
                                          </div>
                                          <div class="jessibuca-volume-panel-text"></div>
                                     </div>
                                 </div>
                             ` : ''}
                             ${operateBtns.play ? `<div class="jessibuca-controls-item jessibuca-play">${icons.play}</div><div class="jessibuca-controls-item jessibuca-pause">${icons.pause}</div>` : ''}
                             ${operateBtns.screenshot ? `<div class="jessibuca-controls-item jessibuca-screenshot">${icons.screenshot}</div>` : ''}
                             ${operateBtns.record ? ` <div class="jessibuca-controls-item jessibuca-record">${icons.record}</div><div class="jessibuca-controls-item jessibuca-record-stop">${icons.recordStop}</div>` : ''}
                             ${operateBtns.ptz ? ` <div class="jessibuca-controls-item jessibuca-ptz">${icons.ptz}</div><div class="jessibuca-controls-item jessibuca-ptz-active">${icons.ptzActive}</div>` : ''}
                             ${operateBtns.zoom ? ` <div class="jessibuca-controls-item jessibuca-zoom">${icons.zoom}</div><div class="jessibuca-controls-item jessibuca-zoom-stop">${icons.zoomStop}</div>` : ''}
                             ${operateBtns.fullscreen ? `<div class="jessibuca-controls-item jessibuca-fullscreen">${icons.fullscreen}</div><div class="jessibuca-controls-item jessibuca-fullscreen-exit">${icons.fullscreenExit}</div>` : ''}
                        </div>
                    </div>
                </div>
            ` : ''}
             <div class="jessibuca-performance-panel"></div>
        `);
      Object.defineProperty(control, '$poster', {
        value: player.$container.querySelector('.jessibuca-poster')
      });
      Object.defineProperty(control, '$loading', {
        value: player.$container.querySelector('.jessibuca-loading')
      });
      Object.defineProperty(control, '$play', {
        value: player.$container.querySelector('.jessibuca-play')
      });
      Object.defineProperty(control, '$playBig', {
        value: player.$container.querySelector('.jessibuca-play-big')
      });
      Object.defineProperty(control, '$recording', {
        value: player.$container.querySelector('.jessibuca-recording')
      });
      Object.defineProperty(control, '$recordingTime', {
        value: player.$container.querySelector('.jessibuca-recording-time')
      });
      Object.defineProperty(control, '$recordingStop', {
        value: player.$container.querySelector('.jessibuca-recording-stop')
      });
      Object.defineProperty(control, '$pause', {
        value: player.$container.querySelector('.jessibuca-pause')
      });
      Object.defineProperty(control, '$controls', {
        value: player.$container.querySelector('.jessibuca-controls')
      });
      Object.defineProperty(control, '$controlsInner', {
        value: player.$container.querySelector('.jessibuca-controls-bottom')
      });
      Object.defineProperty(control, '$controlsLeft', {
        value: player.$container.querySelector('.jessibuca-controls-left')
      });
      Object.defineProperty(control, '$controlsRight', {
        value: player.$container.querySelector('.jessibuca-controls-right')
      });
      Object.defineProperty(control, '$fullscreen', {
        value: player.$container.querySelector('.jessibuca-fullscreen')
      });
      Object.defineProperty(control, '$volume', {
        value: player.$container.querySelector('.jessibuca-volume')
      });
      Object.defineProperty(control, '$volumePanelWrap', {
        value: player.$container.querySelector('.jessibuca-volume-panel-wrap')
      });
      Object.defineProperty(control, '$volumePanelText', {
        value: player.$container.querySelector('.jessibuca-volume-panel-text')
      });
      Object.defineProperty(control, '$volumePanel', {
        value: player.$container.querySelector('.jessibuca-volume-panel')
      });
      Object.defineProperty(control, '$volumeHandle', {
        value: player.$container.querySelector('.jessibuca-volume-panel-handle')
      });
      Object.defineProperty(control, '$volumeOn', {
        value: player.$container.querySelector('.jessibuca-icon-audio')
      });
      Object.defineProperty(control, '$volumeOff', {
        value: player.$container.querySelector('.jessibuca-icon-mute')
      });
      Object.defineProperty(control, '$fullscreen', {
        value: player.$container.querySelector('.jessibuca-fullscreen')
      });
      Object.defineProperty(control, '$fullscreenExit', {
        value: player.$container.querySelector('.jessibuca-fullscreen-exit')
      });
      Object.defineProperty(control, '$record', {
        value: player.$container.querySelector('.jessibuca-record')
      });
      Object.defineProperty(control, '$recordStop', {
        value: player.$container.querySelector('.jessibuca-record-stop')
      });
      Object.defineProperty(control, '$screenshot', {
        value: player.$container.querySelector('.jessibuca-screenshot')
      });
      Object.defineProperty(control, '$speed', {
        value: player.$container.querySelector('.jessibuca-speed')
      });
      Object.defineProperty(control, '$playbackTime', {
        value: player.$container.querySelector('.jessibuca-controls-playback-time')
      });
      Object.defineProperty(control, '$playbackTimeInner', {
        value: player.$container.querySelector('.jessibuca-controls-playback-time-inner')
      });
      Object.defineProperty(control, '$playbackTimeScroll', {
        value: player.$container.querySelector('.jessibuca-controls-playback-time-scroll')
      });
      Object.defineProperty(control, '$playbackTimeList', {
        value: player.$container.querySelector('.jessibuca-controls-playback-time-list')
      });
      Object.defineProperty(control, '$playbackTimeListOne', {
        value: player.$container.querySelector('.jessibuca-playback-time-one-wrap')
      });
      Object.defineProperty(control, '$playbackTimeListSecond', {
        value: player.$container.querySelector('.jessibuca-playback-time-second-wrap')
      });
      Object.defineProperty(control, '$playbackCurrentTime', {
        value: player.$container.querySelector('.jessibuca-controls-playback-current-time')
      });
      Object.defineProperty(control, '$playbackCurrentTimeText', {
        value: player.$container.querySelector('.jessibuca-controls-playback-current-time-text')
      });
      Object.defineProperty(control, '$controlsPlaybackBtns', {
        value: player.$container.querySelector('.jessibuca-controls-playback-btns')
      });
      Object.defineProperty(control, '$playbackNarrow', {
        value: player.$container.querySelector('.jessibuca-playback-narrow')
      }); //

      Object.defineProperty(control, '$playbackExpand', {
        value: player.$container.querySelector('.jessibuca-playback-expand')
      });
      Object.defineProperty(control, '$ptz', {
        value: player.$container.querySelector('.jessibuca-ptz')
      });
      Object.defineProperty(control, '$ptzActive', {
        value: player.$container.querySelector('.jessibuca-ptz-active')
      });
      Object.defineProperty(control, '$ptzControl', {
        value: player.$container.querySelector('.jessibuca-ptz-controls')
      });
      Object.defineProperty(control, '$ptzBgActive', {
        value: player.$container.querySelector('.jessibuca-ptz-bg-active')
      });
      Object.defineProperty(control, '$ptzControlCircular', {
        value: player.$container.querySelector('.jessibuca-ptz-control')
      });
      Object.defineProperty(control, '$ptzArrows', {
        value: player.$container.querySelectorAll('.jessibuca-ptz-arrow')
      });
      Object.defineProperty(control, '$qualityText', {
        value: player.$container.querySelector('.jessibuca-quality-icon-text')
      });
      Object.defineProperty(control, '$qualityMenu', {
        value: player.$container.querySelector('.jessibuca-quality-menu')
      });
      Object.defineProperty(control, '$qualityMenuList', {
        value: player.$container.querySelector('.jessibuca-quality-menu-list')
      });
      Object.defineProperty(control, '$scaleText', {
        value: player.$container.querySelector('.jessibuca-scale-icon-text')
      });
      Object.defineProperty(control, '$scaleMenu', {
        value: player.$container.querySelector('.jessibuca-scale-menu')
      });
      Object.defineProperty(control, '$scaleMenuList', {
        value: player.$container.querySelector('.jessibuca-scale-menu-list')
      });
      Object.defineProperty(control, '$zoom', {
        value: player.$container.querySelector('.jessibuca-zoom')
      });
      Object.defineProperty(control, '$zoomStop', {
        value: player.$container.querySelector('.jessibuca-zoom-stop')
      });
      Object.defineProperty(control, '$zoomNarrow', {
        value: player.$container.querySelector('.jessibuca-zoom-narrow')
      });
      Object.defineProperty(control, '$zoomExpand', {
        value: player.$container.querySelector('.jessibuca-zoom-expand')
      });
      Object.defineProperty(control, '$zoomStop2', {
        value: player.$container.querySelector('.jessibuca-zoom-stop2')
      });
      Object.defineProperty(control, '$close', {
        value: player.$container.querySelector('.jessibuca-close')
      });
      Object.defineProperty(control, '$zoomControls', {
        value: player.$container.querySelector('.jessibuca-zoom-controls')
      });
      Object.defineProperty(control, '$performancePanel', {
        value: player.$container.querySelector('.jessibuca-performance-panel')
      });
      Object.defineProperty(control, '$performance', {
        value: player.$container.querySelector('.jessibuca-performance')
      });
      Object.defineProperty(control, '$performanceActive', {
        value: player.$container.querySelector('.jessibuca-performance-active')
      });
      Object.defineProperty(control, '$faceDetect', {
        value: player.$container.querySelector('.jessibuca-face')
      });
      Object.defineProperty(control, '$faceDetectActive', {
        value: player.$container.querySelector('.jessibuca-face-active')
      });
    });

    // 24小时，以一个小时为单位的。

    function _isInPlayList(list, time) {
      let result = false;
      list.forEach(item => {
        if (!result) {
          if (item.startTimestamp <= time && item.endTimestamp > time) {
            result = true;
          }
        }
      });
      return result;
    } // 一个小时 60个格子


    function initHourMinList1() {
      let playbackList = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];
      let result = [];
      const playbackItem = playbackList[0] || {};
      const oneDay = playbackItem.startTimestamp;

      for (let i = 0; i < 24 * 60; i++) {
        const isStart = i % 60 === 0;
        let hasRecord = false;

        if (oneDay) {
          const tempMin = formatMinuteTimestamp(oneDay, i);
          hasRecord = _isInPlayList(playbackList, tempMin);
        }

        result.push({
          title: formatMinTimeTips(i),
          timestamp: i,
          dataType: 'min',
          hasRecord,
          isStart
        });
      }

      return result;
    } // 半个小时 60个格式

    function initHalfHourMinSecondList1() {
      let playbackList = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];
      let result = [];
      const playbackItem = playbackList[0] || {};
      const oneDay = playbackItem.startTimestamp;

      for (let i = 0; i < 24 * 60; i++) {
        let second = i * 60;
        let isStart = second % (30 * 60) === 0;
        let hasRecord = false;

        if (oneDay) {
          const tempSecond = formatSecondTimestamp(oneDay, second);
          hasRecord = _isInPlayList(playbackList, tempSecond);
        }

        result.push({
          title: formatSecondTimeTips(second),
          timestamp: second,
          dataType: 'second',
          hasRecord,
          isStart
        });
        let second2 = i * 60 + 30;
        isStart = second2 % (30 * 60) === 0;

        if (oneDay) {
          const tempSecond2 = formatSecondTimestamp(oneDay, second2);
          hasRecord = _isInPlayList(playbackList, tempSecond2);
        }

        result.push({
          title: formatSecondTimeTips(second2),
          timestamp: second2,
          dataType: 'second',
          hasRecord,
          isStart
        });
      }

      return result;
    } // 十分钟 60个格子

    function initTenMinSecondList1() {
      let playbackList = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];
      //
      let result = [];
      const playbackItem = playbackList[0] || {};
      const oneDay = playbackItem.startTimestamp; // 时

      for (let i = 0; i < 24 * 6; i++) {
        // 内层
        for (let j = 0; j < 60; j++) {
          let step = 10 * j + i * 600;
          let isStart = step % (10 * 60) === 0;
          let hasRecord = false;

          if (oneDay) {
            const tempSecond = formatSecondTimestamp(oneDay, step);
            hasRecord = _isInPlayList(playbackList, tempSecond);
          }

          result.push({
            title: formatSecondTimeTips(step),
            timestamp: step,
            dataType: 'second',
            isStart,
            hasRecord
          });
        }
      }

      return result;
    } // 五分钟 60个格子

    function initFiveMinSecondList1() {
      let playbackList = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];
      // 外层 23个 小时
      let result = [];
      const playbackItem = playbackList[0] || {};
      const oneDay = playbackItem.startTimestamp;

      for (let i = 0; i < 24 * 12; i++) {
        // 内层 60个格子
        for (let j = 0; j < 60; j++) {
          let step = 5 * j + i * 300;
          let isStart = step % (5 * 60) === 0;
          let hasRecord = false;

          if (oneDay) {
            const tempSecond = formatSecondTimestamp(oneDay, step);
            hasRecord = _isInPlayList(playbackList, tempSecond);
          }

          result.push({
            title: formatSecondTimeTips(step),
            timestamp: step,
            dataType: 'second',
            isStart,
            hasRecord
          });
        }
      }

      return result;
    } // 初始化以秒为单位

    function initHourList2() {
      let result = [];

      for (let i = 0; i < 24; i++) {
        let title = i + ":00";

        if (i < 10) {
          title = "0" + title;
        }

        result.push({
          title: title,
          hour: i,
          min: 0,
          second: 0
        });
      }

      return result;
    } // 24小时 以半个小时间隔

    function initHalfHourList2() {
      let result = [];

      for (let i = 0; i < 24; i++) {
        let title = i + ":00";
        let titleHalf = i + ':30';

        if (i < 10) {
          title = "0" + title;
          titleHalf = '0' + titleHalf;
        }

        result.push({
          title: title,
          hour: i,
          min: 0,
          second: 0
        });
        result.push({
          title: titleHalf,
          hour: i,
          min: 30,
          second: 0
        });
      }

      return result;
    } // 24小时，10分钟为间隔

    function initTenMinList2() {
      let result = [];

      for (let i = 0; i < 24; i++) {
        let title = i + ":00";

        if (i < 10) {
          title = "0" + title;
        }

        result.push({
          title: title,
          hour: i,
          min: 0,
          second: 0
        });

        for (let j = 1; j < 6; j++) {
          let tenMin = '' + j + '0';
          result.push({
            title: title.replace(':00', ':' + tenMin),
            hour: i,
            min: j * 10,
            second: 0
          });
        }
      }

      return result;
    } // 24小时，5分钟为间隔

    function initFileMinList2() {
      let result = [];

      for (let i = 0; i < 24; i++) {
        let title = i + ":00";

        if (i < 10) {
          title = "0" + title;
        }

        result.push({
          title: title,
          hour: i,
          min: 0,
          second: 0
        });
        result.push({
          title: title.replace(':00', ':05'),
          hour: i,
          min: 5,
          second: 0
        });

        for (let j = 1; j < 6; j++) {
          let tenMin = '' + j + '0';
          let fileMin = j + '5';
          result.push({
            title: title.replace(':00', ':' + tenMin),
            hour: i,
            min: j * 10,
            second: 0
          });
          result.push({
            title: title.replace(':00', ':' + fileMin),
            hour: i,
            min: j * 10 + 5,
            second: 0
          });
        }
      }

      return result;
    } // 24小时 1分钟为间隔

    function renderTimeDay() {
      let oneList = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];
      let secondList = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];
      let control = arguments.length > 2 ? arguments[2] : undefined;
      const oneListLength = oneList.length;
      const secondListLength = secondList.length;
      const total = Math.max(oneListLength, secondListLength);
      const once = PLAYBACK_RENDER_ONCE_LENGTH;
      const loopCount = Math.ceil(total / once);
      let countRender = 0;
      let currentIndex = 0;

      function render() {
        let fragment = '';
        let fragment2 = '';

        for (let i = 0; i < once; i++) {
          const time = oneList[currentIndex];

          if (time) {
            fragment += `
                     <div class="jessibuca-playback-time-minute-one${time.hasRecord ? ' active' : ''}${time.isStart ? ' start' : ''}" data-has-record="${time.hasRecord}"
                     data-time="${time.timestamp}" data-type="${time.dataType}">
                        <span class="jessibuca-playback-time-title-tips ${currentIndex > oneListLength - 60 ? 'jessibuca-playback-time-title-tips-left' : ''}"><span class="jessibuca-playback-time-title">${time.title}</span></span>
                    </div>
                `;
          }

          const hour = secondList[currentIndex];

          if (hour) {
            fragment2 += `
                  <div class="jessibuca-playback-time-hour" data-hour="${hour.hour}" data-min="${hour.min}" data-second="${hour.second}"><span class="jessibuca-playback-time-hour-text">${hour.title}</span></div>
                `;
          }

          currentIndex += 1;
        }

        if (fragment) {
          control.$playbackTimeListOne.insertAdjacentHTML('beforeend', fragment);
        }

        if (fragment2) {
          control.$playbackTimeListSecond.insertAdjacentHTML('beforeend', fragment2);
        }

        countRender += 1;

        if (countRender < loopCount) {
          control.rafId = window.requestAnimationFrame(render);
        }
      }

      render();
    } // 一个小时一个间隔


    function renderHourTimeDay(playbackList, control) {
      const minuteList = initHourMinList1(playbackList);
      const hourList = initHourList2();
      renderTimeDay(minuteList, hourList, control);
    } // 半个小时一个间隔

    function renderHalfHourTimeDay(playbackList, control) {
      const minuteList = initHalfHourMinSecondList1(playbackList);
      const hourList = initHalfHourList2();
      renderTimeDay(minuteList, hourList, control);
    } // 10分钟一个间隔

    function renderTenMinTimeDay(playbackList, control) {
      const minuteList = initTenMinSecondList1(playbackList);
      const hourList = initTenMinList2();
      renderTimeDay(minuteList, hourList, control);
    } // 5分钟一个间隔

    function renderFiveMinTimeDay(playbackList, control) {
      const minuteList = initFiveMinSecondList1(playbackList);
      const hourList = initFileMinList2();
      renderTimeDay(minuteList, hourList, control);
    } // 1分钟一个间隔

    var observer$1 = ((player, control) => {
      const {
        events: {
          proxy
        }
      } = player;
      const object = document.createElement('object');
      object.setAttribute('aria-hidden', 'true');
      object.setAttribute('tabindex', -1);
      object.type = 'text/html';
      object.data = 'about:blank';
      setStyle(object, {
        display: 'block',
        position: 'absolute',
        top: '0',
        left: '0',
        height: '100%',
        width: '100%',
        overflow: 'hidden',
        pointerEvents: 'none',
        zIndex: '-1'
      });
      let playerWidth = player.width;
      let playerHeight = player.height;
      proxy(object, 'load', () => {
        proxy(object.contentDocument.defaultView, 'resize', () => {
          if (player.width !== playerWidth || player.height !== playerHeight) {
            playerWidth = player.width;
            playerHeight = player.height;
            player.emit(EVENTS.resize);
            screenfullH5Control();
          }
        });
      });
      player.$container.appendChild(object);
      player.on(EVENTS.destroy, () => {
        player.$container.removeChild(object);
      });

      function setVolumeHandle(percentage) {
        if (percentage === 0) {
          setStyle(control.$volumeOn, 'display', 'none');
          setStyle(control.$volumeOff, 'display', 'flex');
          setStyle(control.$volumeHandle, 'top', `${48}px`);
        } else {
          if (control.$volumeHandle && control.$volumePanel) {
            const panelHeight = getStyle(control.$volumePanel, 'height') || 60;
            const handleHeight = getStyle(control.$volumeHandle, 'height');
            const top = panelHeight - (panelHeight - handleHeight) * percentage - handleHeight;
            setStyle(control.$volumeHandle, 'top', `${top}px`);
            setStyle(control.$volumeOn, 'display', 'flex');
            setStyle(control.$volumeOff, 'display', 'none');
          }
        }

        control.$volumePanelText && (control.$volumePanelText.innerHTML = parseInt(percentage * 100));
      }

      player.on(EVENTS.volumechange, () => {
        setVolumeHandle(player.volume);
      });
      player.on(EVENTS.loading, flag => {
        setStyle(control.$loading, 'display', flag ? 'flex' : 'none');
        setStyle(control.$poster, 'display', 'none');

        if (flag) {
          setStyle(control.$playBig, 'display', 'none');
        }
      });

      const screenfullChange = fullscreen => {
        let isFullScreen = isBoolean(fullscreen) ? fullscreen : player.fullscreen;
        setStyle(control.$fullscreenExit, 'display', isFullScreen ? 'flex' : 'none');
        setStyle(control.$fullscreen, 'display', isFullScreen ? 'none' : 'flex'); // control.autoSize();
      };

      const showPlaybackTFDom = () => {
        return player._opt.playType === PLAY_TYPE.playbackTF && player._opt.playbackConfig.showControl;
      };

      const screenfullH5Control = fn => {
        if (isMobile() && control.$controls) {
          setTimeout(() => {
            if (player.fullscreen) {
              // console.log(player.width, player.height);
              const controlHeight = showPlaybackTFDom() ? CONTROL_PLAYBACK_HEIGHT : CONTROL_HEIGHT;
              let translateX = player.height / 2 - player.width + controlHeight / 2;
              let translateY = player.height / 2 - controlHeight / 2;
              control.$controls.style.transform = `translateX(${-translateX}px) translateY(-${translateY}px) rotate(-90deg)`;
            } else {
              control.$controls.style.transform = `translateX(0) translateY(0) rotate(0)`;
            }

            fn && fn();
          }, 10);
        }
      };

      try {
        screenfull.on('change', screenfullChange);
        player.events.destroys.push(() => {
          screenfull.off('change', screenfullChange);
        });
      } catch (error) {//
      } //


      player.on(EVENTS.webFullscreen, value => {
        if (isMobile()) {
          screenfullChange(value);
          screenfullH5Control(() => {
            _resizePlaybackTime();
          });
        }
      });
      player.on(EVENTS.recording, () => {
        if (player.playing) {
          setStyle(control.$record, 'display', player.recording ? 'none' : 'flex');
          setStyle(control.$recordStop, 'display', player.recording ? 'flex' : 'none');

          if (player._opt.hasControl || player._opt.isShowRecordingUI) {
            setStyle(control.$recording, 'display', player.recording ? 'flex' : 'none');
          }
        }
      }); //

      player.on(EVENTS.recordingTimestamp, timestamp => {
        // console.log(timestamp);
        control.$recordingTime && (control.$recordingTime.innerHTML = formatTimeTips(timestamp));
      });
      player.on(EVENTS.zooming, () => {
        if (player.playing) {
          setStyle(control.$zoom, 'display', player.zooming ? 'none' : 'flex');
          setStyle(control.$zoomStop, 'display', player.zooming ? 'flex' : 'none');

          if (player._opt.hasControl || player._opt.isShowZoomingUI) {
            setStyle(control.$zoomControls, 'display', player.zooming ? 'flex' : 'none');
          }
        }
      });
      player.on(EVENTS.playing, flag => {
        handlePlaying(flag);
      });

      const handlePlaying = flag => {
        setStyle(control.$play, 'display', flag ? 'none' : 'flex');
        setStyle(control.$playBig, 'display', flag ? 'none' : 'block');
        setStyle(control.$pause, 'display', flag ? 'flex' : 'none');
        setStyle(control.$screenshot, 'display', flag ? 'flex' : 'none');
        setStyle(control.$record, 'display', flag ? 'flex' : 'none');
        setStyle(control.$qualityMenu, 'display', flag ? 'flex' : 'none');
        setStyle(control.$volume, 'display', flag ? 'flex' : 'none');
        setStyle(control.$ptz, 'display', flag ? 'flex' : 'none');
        setStyle(control.$zoom, 'display', flag ? 'flex' : 'none');
        setStyle(control.$scaleMenu, 'display', flag ? 'flex' : 'none');
        setStyle(control.$faceDetect, 'display', flag ? 'flex' : 'none');
        screenfullChange();

        if (player._opt.showPerformance) {
          setStyle(control.$performanceActive, 'display', flag ? 'flex' : 'none');
        } else {
          setStyle(control.$performance, 'display', flag ? 'flex' : 'none');
        }

        setStyle(control.$ptzActive, 'display', 'none');
        setStyle(control.$recordStop, 'display', 'none');
        setStyle(control.$zoomStop, 'display', 'none');
        setStyle(control.$faceDetectActive, 'display', 'none'); // 不在播放

        if (!flag) {
          control.$speed && (control.$speed.innerHTML = bpsSize('')); // zoom

          setStyle(control.$zoomControls, 'display', 'none'); // record

          setStyle(control.$recording, 'display', 'none'); // ptz

          if (control.$ptzControl) {
            control.$ptzControl.classList.remove('jessibuca-ptz-controls-show');
          }
        }

        _resizePlaybackTime();
      }; //


      player.on(EVENTS.playbackPause, flag => {
        handlePlaying(!flag);
      });
      player.on(EVENTS.kBps, rate => {
        if (player._opt.showBandwidth) {
          const bps = bpsSize$2(rate);
          control.$speed && (control.$speed.innerHTML = bps);

          _resizePlaybackTime();
        }
      });

      const _resizePlaybackTime = () => {
        if (showPlaybackTFDom()) {
          let width = control.controlsInnerRect.width - control.controlsLeftRect.width - control.controlsRightRect.width - control.controlsPlaybackBtnsRect.width;

          if (isMobile() && player.webFullscreen) {
            width = control.controlsInnerRect.height - control.controlsLeftRect.height - control.controlsRightRect.height - control.controlsPlaybackBtnsRect.height;
          }

          control.$playbackTimeInner.style.width = width + 'px';
        }
      }; // show playback operate


      if (showPlaybackTFDom()) {
        // 计算偏移量
        const _calcCurrentTimeTextOffset = () => {
          if (showPlaybackTFDom()) {
            let left = 0;
            const playingTimestamp = player.playback && player.playback.playingTimestamp;

            if (playingTimestamp) {
              const nowDate = new Date(playingTimestamp);
              const hour = nowDate.getHours();
              const min = nowDate.getMinutes();
              const second = nowDate.getSeconds();

              if (player.playback.is60Min) {
                left = hour * 60 + min;
              } else if (player.playback.is30Min) {
                left = (hour * 60 + min) * 2 + parseInt(second / 30, 10);
              } else if (player.playback.is10Min) {
                left = (hour * 60 + min) * 6 + parseInt(second / 10, 10);
              } else if (player.playback.is5Min) {
                left = (hour * 60 + min) * 12 + parseInt(second / 5, 10);
              } else if (player.playback.is1Min) {
                left = (hour * 60 + min) * 60 + parseInt(second, 10);
              }

              control.$playbackCurrentTime.style.left = left + 'px'; // console.log('playingTimestamp', playingTimestamp, 'hour is ', hour, 'min is', min, 'second is', second, 'left is ', left)
            }
          }
        }; // toggle playback button


        const _togglePlaybackButton = precision => {
          control.$playbackNarrow.classList.remove('disabled');
          control.$playbackExpand.classList.remove('disabled');

          if (precision === PLAYBACK_CONTROL_TIME_PRECISION.oneHour) {
            control.$playbackNarrow.classList.add('disabled');
          }

          if (precision === PLAYBACK_CONTROL_TIME_PRECISION.fiveMin) {
            control.$playbackExpand.classList.add('disabled');
          }
        }; // playback time offset


        const _playbackTimeOffset = () => {
          const leftPx = control.$playbackCurrentTime.style.left;
          let left = parseInt(leftPx, 10);
          const innerWidth = control.controlsPlaybackTimeInner.width;

          if (left - innerWidth / 2 > 0) {
            left = parseInt(left - innerWidth / 2, 10);
          } else {
            left = 0;
          } // console.log('_playbackTimeOffset', left);


          control.$playbackTimeInner.scrollLeft = left;
        }; //


        if (player._opt.showBandwidth) {
          control.$controlsLeft.style.width = '90px';
        } // 播放时间


        player.on(EVENTS.playbackTime, time => {
          // console.log('playbackTime', time);
          control.$playbackCurrentTimeText && (control.$playbackCurrentTimeText.innerText = parseTime(time, "{h}:{i}:{s}"));

          _calcCurrentTimeTextOffset();
        }); // 缩放类型

        player.on(EVENTS.playbackPrecision, (precision, playbackList) => {
          // update class
          control.$playbackTimeScroll.classList.remove(PLAYBACK_CONTROL_TIME_PRECISION_CLASS.oneHour, PLAYBACK_CONTROL_TIME_PRECISION_CLASS.halfHour, PLAYBACK_CONTROL_TIME_PRECISION_CLASS.fiveMin, PLAYBACK_CONTROL_TIME_PRECISION_CLASS.tenMin);
          control.$playbackTimeScroll.classList.add(PLAYBACK_CONTROL_TIME_PRECISION_CLASS[precision]);

          if (control.rafId) {
            window.cancelAnimationFrame(control.rafId);
            control.rafId = null;
          }

          if (control.changePercisitionInterval) {
            clearTimeout(control.changePercisitionInterval);
            control.changePercisitionInterval = null;
          } // clear inner html


          control.$playbackTimeListOne.innerHTML = '';
          control.$playbackTimeListSecond.innerHTML = '';
          control.changePercisitionInterval = setTimeout(() => {
            control.$playbackTimeListOne.innerHTML = '';
            control.$playbackTimeListSecond.innerHTML = '';

            switch (precision) {
              case PLAYBACK_CONTROL_TIME_PRECISION.oneHour:
                renderHourTimeDay(playbackList, control);
                break;

              case PLAYBACK_CONTROL_TIME_PRECISION.halfHour:
                renderHalfHourTimeDay(playbackList, control);
                break;

              case PLAYBACK_CONTROL_TIME_PRECISION.tenMin:
                renderTenMinTimeDay(playbackList, control);
                break;

              case PLAYBACK_CONTROL_TIME_PRECISION.fiveMin:
                renderFiveMinTimeDay(playbackList, control);
                break;
            }

            _calcCurrentTimeTextOffset();

            _togglePlaybackButton(precision);

            _playbackTimeOffset();
          }, 16); // if (renderDom) {
          //     control.$playbackTimeList.insertAdjacentHTML(
          //         'beforeend',
          //         renderDom
          //     )
          //
          // }
        }); //

        player.on(EVENTS.resize, () => {
          _resizePlaybackTime();
        }); //

        _resizePlaybackTime();
      } //


      if (player._opt.operateBtns.quality && player._opt.qualityConfig.length > 0) {
        player.on(EVENTS.streamQualityChange, value => {
          _changeStreamQuality(value);
        });

        const _changeStreamQuality = value => {
          control.$qualityText.innerText = value;
          control.$qualityMenuItems.forEach($qualityMenuItem => {
            const quality = $qualityMenuItem.dataset.quality;
            $qualityMenuItem.classList.remove('jessibuca-quality-menu-item-active');

            if (quality === value) {
              $qualityMenuItem.classList.add('jessibuca-quality-menu-item-active');
            }
          });
        };

        const _renderQuality = () => {
          const qualityList = player._opt.qualityConfig || [];
          let qualityDom = '';
          qualityList.forEach(item => {
            qualityDom += `
                    <div class="jessibuca-quality-menu-item" data-quality="${item}">${item}</div>
                `;
          });

          if (qualityDom) {
            control.$qualityMenuList.insertAdjacentHTML('beforeend', qualityDom); //

            Object.defineProperty(control, '$qualityMenuItems', {
              value: player.$container.querySelectorAll('.jessibuca-quality-menu-item')
            }); // init default quality

            setTimeout(() => {
              const defaultQuality = qualityList[0];
              player.streamQuality = defaultQuality;
            }, 0);
          }
        };

        _renderQuality();

        if (player.streamQuality) {
          _changeStreamQuality(player.streamQuality);
        }
      }

      if (player._opt.operateBtns.scale && player._opt.scaleConfig.length > 0) {
        player.on(EVENTS.viewResizeChange, value => {
          _changeViewResize(value);
        });

        const _changeViewResize = value => {
          const scaleTypeText = player._opt.scaleConfig[value];
          control.$scaleText.innerText = scaleTypeText;
          control.$scaleMenuItems.forEach($scaleMenuItem => {
            const scale = $scaleMenuItem.dataset.scale;
            $scaleMenuItem.classList.remove('jessibuca-scale-menu-item-active');

            if (toNumber(scale) === toNumber(value)) {
              $scaleMenuItem.classList.add('jessibuca-scale-menu-item-active');
            }
          });
        };

        const _renderScale = () => {
          const scaleList = player._opt.scaleConfig || [];
          let scaleDom = '';
          scaleList.forEach((item, index) => {
            scaleDom += `
                    <div class="jessibuca-scale-menu-item" data-scale="${index}">${item}</div>
                `;
          });

          if (scaleDom) {
            control.$scaleMenuList.insertAdjacentHTML('beforeend', scaleDom); //

            Object.defineProperty(control, '$scaleMenuItems', {
              value: player.$container.querySelectorAll('.jessibuca-scale-menu-item')
            }); // init default quality
          }
        };

        _renderScale();

        _changeViewResize(player.scaleType);
      }

      player.on(EVENTS.stats, function () {
        let stats = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};

        if (player._opt.showPerformance) {
          setStyle(control.$performancePanel, 'display', 'block');
          control.$performancePanel.innerHTML = '';
          const videoInfo = player.video && player.video.videoInfo || {};
          const audioInfo = player.audio && player.audio.audioInfo || {};
          const times = player._times || {};
          const renderType = player.getRenderType();
          const decoderType = player.getDecodeType();
          const demuxType = player.getDemuxType();
          const audioEngine = player.getAudioEngineType();
          let recordingDuration = player.getRecordingDuration();
          let recordingTotalSize = player.getRecordingByteLength();
          const isAudioPlaybackRateSpeed = player.isAudioPlaybackRateSpeed();
          const videoIframeIntervalTs = player.videoIframeIntervalTs;
          recordingDuration = formatTimeTips(recordingDuration);
          recordingTotalSize = formatFileSize(recordingTotalSize);
          const playType = player.isPlayback() ? '录播' : '直播';
          let isDropping = stats.buf > player._opt.videoBuffer + player._opt.videoBufferDelay;

          if (!isDropping) {
            isDropping = stats.isDropping;
          }

          const renderDom = `
                <div class="jessibuca-performance-item">
                    <span>播放模式 ${playType}</span>
                </div>
                ${player.isPlayback() ? `
                        <div class="jessibuca-performance-item">
                            <span>播放倍率 ${player.playback.rate}倍</span>
                        </div>
                        <div class="jessibuca-performance-item">
                            <span>播放模式 ${player.playback.isUseFpsRender ? '固定FPS' : '动态FPS'}</span>
                        </div>
                        ${player.playback.isUseFpsRender ? `
                             <div class="jessibuca-performance-item">
                                <span>固定FPS ${player.video.getStreamFps()}</span>
                            </div>
                            ` : ''}
                    ` : ""}
                <div class="jessibuca-performance-item">
                    <span>解封装模式 ${DEMUX_TYPE_SHOW[demuxType]}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>解码模式 ${decoderType}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>渲染组件 ${renderType}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>视频格式 ${videoInfo.encType || '-'}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>视频(宽x高) ${videoInfo.width || '-'}x${videoInfo.height || '-'}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>视频GOP(ms) ${videoIframeIntervalTs || '-'}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>音频格式 ${AUDIO_ENC_CODE_SHOW[audioInfo.encType] || '-'}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>音频引擎 ${audioEngine || '-'}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>音频通道 ${audioInfo.channels || '-'}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>音频采样率 ${audioInfo.sampleRate || '-'}</span>
                </div>
                ${player.isPlayer() ? `
                    <div class="jessibuca-performance-item">
                        <span>播放器初始化(ms) ${times.playTimestamp}</span>
                    </div>
                    <div class="jessibuca-performance-item">
                        <span>开始请求地址(ms) ${times.streamTimestamp}</span>
                    </div>
                    <div class="jessibuca-performance-item">
                        <span>请求响应(ms) ${times.streamResponseTimestamp}</span>
                    </div>
                    <div class="jessibuca-performance-item">
                        <span>解封装(ms) ${times.demuxTimestamp}</span>
                    </div>
                    <div class="jessibuca-performance-item">
                        <span>解码(ms) ${times.decodeTimestamp}</span>
                    </div>
                    <div class="jessibuca-performance-item">
                        <span>页面开始渲染(ms) ${times.videoTimestamp}</span>
                    </div>
                    <div class="jessibuca-performance-item">
                        <span>初始化到页面渲染(ms) ${times.allTimestamp}</span>
                    </div>
                    ${player.recording ? `
                        <div class="jessibuca-performance-item">
                            <span>视频录制时间 ${recordingTotalSize}</span>
                        </div>
                        <div class="jessibuca-performance-item">
                            <span>视频录制大小 ${recordingDuration}</span>
                        </div>
                    ` : ''}
                ` : ''}
                <div class="jessibuca-performance-item">
                    <span>网络延迟(ms) ${stats.netBuf}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>缓冲时长(ms) ${stats.buf}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>音频码率(bit) ${stats.abps}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>视频码率(bit) ${stats.vbps}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>视频帧率(fps) ${stats.fps}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>解码帧率(fps) ${stats.dfps}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>音频缓冲帧 ${stats.audioBuffer}</span>
                </div>
                ${player.isPlayer() ? `
                        <div class="jessibuca-performance-item">
                            <span>视频待解码帧 ${stats.demuxBuffer}</span>
                        </div>
                    ` : `
                         <div class="jessibuca-performance-item">
                            <span>视频待渲染 ${stats.playbackVideoBuffer}</span>
                        </div>
                        <div class="jessibuca-performance-item">
                            <span>视频待解码帧 ${stats.demuxBuffer}</span>
                        </div>
                        <div class="jessibuca-performance-item">
                            <span>音频待解码帧 ${stats.audioDemuxBuffer}</span>
                        </div>
                    `}
                <div class="jessibuca-performance-item">
                    <span>待解封装数据(byte) ${stats.flvBuffer}</span>
                </div>
                ${player._opt.useMSE ? `<div class="jessibuca-performance-item">
                        <span>MSE缓冲时长(ms) ${stats.mseDelay}</span>
                    </div>
                    <div class="jessibuca-performance-item">
                        <span>MSE解码间隔(ms) ${stats.mseDecodeDiffTimes}</span>
                    </div>
                    <div class="jessibuca-performance-item">
                        <span>MSE播放模式 ${stats.mseDecodePlaybackRate > 1 ? '加速' : '正常'}</span>
                    </div>
                    ` : ''}
                ${player._opt.useWCS ? `
                    <div class="jessibuca-performance-item">
                        <span>WCS解码间隔(ms) ${stats.wcsDecodeDiffTimes}</span>
                    </div>
                    ` : ''}
                ${player._opt.isHls ? `<div class="jessibuca-performance-item">
                            <span>HLS缓冲时长(ms) ${stats.hlsDelay}</span>
                         </div>
                         <div class="jessibuca-performance-item">
                            <span>HLS播放模式 ${stats.hlsDecodePlaybackRate > 1 ? '加速' : '正常'}</span>
                         </div>
                        ` : ''}
                <div class="jessibuca-performance-item">
                    <span>视频显示时间(ms) ${stats.ts}</span>
                </div>
                ${player._opt.hasAudio && player.isAudioNotMute() ? `
                        <div class="jessibuca-performance-item">
                            <span>音频显示时间(ms) ${stats.audioTs}</span>
                        </div>
                        ${player._opt.hasVideo ? `
                            <div class="jessibuca-performance-item">
                                <span>音视频同步时间戳(ms) ${stats.ts - stats.audioTs}</span>
                            </div>
                            ` : ''}
                        <div class="jessibuca-performance-item">
                            <span>音频播放模式 ${isAudioPlaybackRateSpeed ? '加速' : '正常'}</span>
                        </div>
                        ` : ''}
                <div class="jessibuca-performance-item">
                    <span>视频解码时间(ms) ${stats.dts}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>解码前-解码后延迟(ms) ${stats.delayTs}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>总延迟(网络+解码)(ms) ${stats.totalDelayTs}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>是否在丢帧 ${isDropping}</span>
                </div>
                <div class="jessibuca-performance-item">
                    <span>播放时长(s) ${formatTimeTips(stats.pTs)}</span>
                </div>
                <div class="jessibuca-performance-item-block"></div>
            `;
          control.$performancePanel.insertAdjacentHTML('beforeend', renderDom);
        } else {
          control.$performancePanel.innerHTML = '';
          setStyle(control.$performancePanel, 'display', 'none');
        }
      });
      player.on(EVENTS.togglePerformancePanel, flag => {
        setStyle(control.$performance, 'display', flag ? 'none' : 'flex');
        setStyle(control.$performanceActive, 'display', flag ? 'flex' : 'none');
      });
      player.on(EVENTS.faceDetectActive, flag => {
        setStyle(control.$faceDetect, 'display', flag ? 'none' : 'flex');
        setStyle(control.$faceDetectActive, 'display', flag ? 'flex' : 'none');
      });
    });

    var property = ((player, control) => {
      Object.defineProperty(control, 'controlsRect', {
        get: () => {
          return control.$controls.getBoundingClientRect();
        }
      });
      Object.defineProperty(control, 'controlsInnerRect', {
        get: () => {
          return control.$controlsInner.getBoundingClientRect();
        }
      });
      Object.defineProperty(control, 'controlsLeftRect', {
        get: () => {
          return control.$controlsLeft.getBoundingClientRect();
        }
      });
      Object.defineProperty(control, 'controlsRightRect', {
        get: () => {
          return control.$controlsRight.getBoundingClientRect();
        }
      });
      Object.defineProperty(control, 'controlsPlaybackTimeInner', {
        get: () => {
          return control.$playbackTimeInner && control.$playbackTimeInner.getBoundingClientRect() || {};
        }
      });
      Object.defineProperty(control, 'controlsPlaybackBtnsRect', {
        get: () => {
          return control.$controlsPlaybackBtns && control.$controlsPlaybackBtns.getBoundingClientRect() || {
            width: 0
          };
        }
      });
    });

    var events = ((player, control) => {
      const {
        events: {
          proxy
        },
        debug
      } = player; //

      const options = player._opt;
      const operateBtns = options.operateBtns;

      function volumeChangeFromEvent(event) {
        const {
          bottom: panelBottom,
          height: panelHeight
        } = control.$volumePanel.getBoundingClientRect();
        const {
          height: handleHeight
        } = control.$volumeHandle.getBoundingClientRect();
        let moveLen = event.y; // if (isMobile() && player.fullscreen) {
        //     moveLen = event.x;
        // }

        const percentage = clamp(panelBottom - moveLen - handleHeight / 2, 0, panelHeight - handleHeight / 2) / (panelHeight - handleHeight);
        return percentage;
      } //


      proxy(window, ['click', 'contextmenu'], event => {
        if (event.composedPath().indexOf(player.$container) > -1) {
          control.isFocus = true;
        } else {
          control.isFocus = false;
        }
      }); //

      proxy(window, 'orientationchange', () => {
        setTimeout(() => {
          player.resize();
        }, 300);
      });
      proxy(control.$controls, 'click', e => {
        e.stopPropagation();
      });

      if (operateBtns.play) {
        proxy(control.$pause, 'click', e => {
          if (options.playType === PLAY_TYPE.playbackTF && options.playbackConfig.uiUsePlaybackPause) {
            player.playbackPause = true;
            player.emit(EVENTS.playbackPauseOrResume, true);
          } else {
            if (isFunction$1(operateBtns.pauseFn)) {
              operateBtns.pauseFn();
            } else {
              player.pause();
            }
          }
        }); // 监听 play 方法

        proxy(control.$play, 'click', e => {
          if (options.playType === PLAY_TYPE.playbackTF && player.playbackPause) {
            player.playbackPause = false;
            player.emit(EVENTS.playbackPauseOrResume, false);
          } else {
            if (isFunction$1(operateBtns.playFn)) {
              operateBtns.playFn();
            } else {
              player.play();
              player.resumeAudioAfterPause();
            }
          }
        });
      } // 监听 play 方法


      proxy(control.$playBig, 'click', e => {
        if (options.playType === PLAY_TYPE.playbackTF && player.playbackPause) {
          player.playbackPause = false;
          player.emit(EVENTS.playbackPauseOrResume, false);
        } else {
          if (isFunction$1(operateBtns.playFn)) {
            operateBtns.playFn();
          } else {
            player.play();
            player.resumeAudioAfterPause();
          }
        }
      });

      if (operateBtns.screenshot) {
        proxy(control.$screenshot, 'click', e => {
          e.stopPropagation();

          if (isFunction$1(operateBtns.screenshotFn)) {
            operateBtns.screenshotFn();
          } else {
            player.video.screenshot();
          }
        });
      }

      if (operateBtns.audio) {
        proxy(control.$volume, 'mouseover', () => {
          control.$volumePanelWrap.classList.add('jessibuca-volume-panel-wrap-show');
        });
        proxy(control.$volume, 'mouseout', () => {
          control.$volumePanelWrap.classList.remove('jessibuca-volume-panel-wrap-show');
        });
        proxy(control.$volumeOn, 'click', e => {
          e.stopPropagation();
          setStyle(control.$volumeOn, 'display', 'none');
          setStyle(control.$volumeOff, 'display', 'block');
          const lastVolume = player.volume;
          player.volume = 0;
          player._lastVolume = lastVolume;
        });
        proxy(control.$volumeOff, 'click', e => {
          e.stopPropagation();
          setStyle(control.$volumeOn, 'display', 'block');
          setStyle(control.$volumeOff, 'display', 'none');
          player.volume = player.lastVolume || 0.5;
        });
        proxy(control.$volumePanel, 'click', event => {
          event.stopPropagation();
          player.volume = volumeChangeFromEvent(event);
        });
        proxy(control.$volumeHandle, 'mousedown', () => {
          control.isVolumeDroging = true;
        });
        proxy(control.$volumeHandle, 'mousemove', event => {
          if (control.isVolumeDroging) {
            player.volume = volumeChangeFromEvent(event);
          }
        });
      }

      proxy(document, 'mouseup', () => {
        if (control.isVolumeDroging) {
          control.isVolumeDroging = false;
        }
      });

      if (operateBtns.record) {
        proxy(control.$record, 'click', e => {
          e.stopPropagation();

          if (isFunction$1(operateBtns.recordFn)) {
            operateBtns.recordFn();
          } else {
            player.recording = true;
          }
        });
        proxy(control.$recordStop, 'click', e => {
          e.stopPropagation();

          if (isFunction$1(operateBtns.recordStopFn)) {
            operateBtns.recordStopFn();
          } else {
            player.recording = false;
          }
        });
        proxy(control.$recordingStop, 'click', e => {
          e.stopPropagation();

          if (isFunction$1(operateBtns.recordStopFn)) {
            operateBtns.recordStopFn();
          } else {
            player.recording = false;
          }
        });
      }

      if (operateBtns.fullscreen) {
        proxy(control.$fullscreen, 'click', e => {
          e.stopPropagation();

          if (isFunction$1(operateBtns.fullscreenFn)) {
            operateBtns.fullscreenFn();
          } else {
            player.fullscreen = true;
          }
        });
        proxy(control.$fullscreenExit, 'click', e => {
          e.stopPropagation();

          if (isFunction$1(operateBtns.fullscreenExitFn)) {
            operateBtns.fullscreenExitFn();
          } else {
            player.fullscreen = false;
          }
        });
      }

      if (operateBtns.ptz) {
        proxy(control.$ptz, 'click', e => {
          e.stopPropagation();
          setStyle(control.$ptzActive, 'display', 'flex');
          setStyle(control.$ptz, 'display', 'none');
          control.$ptzControl.classList.add('jessibuca-ptz-controls-show');
        });
        proxy(control.$ptzActive, 'click', e => {
          e.stopPropagation();
          setStyle(control.$ptz, 'display', 'flex');
          setStyle(control.$ptzActive, 'display', 'none');
          control.$ptzControl.classList.remove('jessibuca-ptz-controls-show');
        });
        control.$ptzArrows.forEach($ptzArrow => {
          proxy($ptzArrow, 'click', e => {
            e.stopPropagation();
            const target = e.currentTarget;
            const dataset = target.dataset;
            const arrow = dataset.arrow;
            control.$ptzBgActive.classList.add('jessibuca-ptz-bg-active-show');
            control.$ptzBgActive.classList.add(`jessibuca-ptz-bg-active-${arrow}`);
            control.$ptzControlCircular.classList.add(`jessibuca-ptz-control-${arrow}`);
            player.emit(EVENTS.ptz, arrow);
            setTimeout(() => {
              control.$ptzBgActive.classList.remove('jessibuca-ptz-bg-active-show');
              PTZ_ARROW.forEach(arrow => {
                control.$ptzBgActive.classList.remove(`jessibuca-ptz-bg-active-${arrow}`);
                control.$ptzControlCircular.classList.remove(`jessibuca-ptz-control-${arrow}`);
              });
              player.emit(EVENTS.ptz, PTZ_OBJ.stop);
            }, 300);
          });
        });
      }

      if (operateBtns.performance) {
        proxy(control.$performance, 'click', e => {
          e.stopPropagation();
          player.togglePerformancePanel(true);
        });
        proxy(control.$performanceActive, 'click', e => {
          e.stopPropagation();
          player.togglePerformancePanel(false);
        });
      }

      if (operateBtns.face) {
        proxy(control.$faceDetect, 'click', e => {
          e.stopPropagation();
          player.faceDetect(true);
        });
        proxy(control.$faceDetectActive, 'click', e => {
          e.stopPropagation();
          player.faceDetect(false);
        });
      }

      if (player._opt.hasControl && player._opt.controlAutoHide) {
        //
        proxy(player.$container, 'mouseover', () => {
          if (!player.fullscreen) {
            setStyle(control.$controls, 'display', 'block');
            startDelayControlHidden();
          }
        });
        proxy(player.$container, 'mousemove', () => {
          if (player.$container && control.$controls) {
            if (!player.fullscreen) {
              if (control.$controls.style.display === 'none') {
                setStyle(control.$controls, 'display', 'block');
                startDelayControlHidden();
              }
            } else {
              if (control.$controls.style.display === 'none') {
                setStyle(control.$controls, 'display', 'block');
                startDelayControlHidden();
              }
            }
          }
        });
        proxy(player.$container, 'mouseout', () => {
          stopDelayControlHidden();
          setStyle(control.$controls, 'display', 'none');
        });
        let delayHiddenTimeout = null;

        const startDelayControlHidden = () => {
          stopDelayControlHidden();
          delayHiddenTimeout = setTimeout(() => {
            setStyle(control.$controls, 'display', 'none');
          }, 5 * 1000);
        };

        const stopDelayControlHidden = () => {
          if (delayHiddenTimeout) {
            clearTimeout(delayHiddenTimeout);
            delayHiddenTimeout = null;
          }
        };
      } // show playback operate


      if (player._opt.playType === PLAY_TYPE.playbackTF) {
        //
        proxy(control.$playbackNarrow, 'click', e => {
          e.stopPropagation();

          if (player.playback) {
            player.playback.narrowPrecision();
          }
        });
        proxy(control.$playbackExpand, 'click', e => {
          e.stopPropagation();

          if (player.playback) {
            player.playback.expandPrecision();
          }
        }); //

        proxy(control.$playbackTimeList, 'click', e => {
          const target = getTarget(e);

          if (target.matches('div.jessibuca-playback-time-minute-one')) {
            if (player.playback) {
              player.playback.seek(target.dataset);
            }
          }
        });
      } //


      if (operateBtns.quality) {
        proxy(control.$qualityMenu, 'mouseover', () => {
          control.$qualityMenuList.classList.add('jessibuca-quality-menu-shown');
        });
        proxy(control.$qualityMenu, 'mouseout', () => {
          control.$qualityMenuList.classList.remove('jessibuca-quality-menu-shown');
        });
        proxy(control.$qualityMenuList, 'click', e => {
          const target = getTarget(e);

          if (target.matches('div.jessibuca-quality-menu-item')) {
            const dataset = target.dataset;
            player.streamQuality = dataset.quality;
          }
        });
      }

      if (operateBtns.scale) {
        proxy(control.$scaleMenu, 'mouseover', () => {
          control.$scaleMenuList.classList.add('jessibuca-scale-menu-shown');
        });
        proxy(control.$scaleMenu, 'mouseout', () => {
          control.$scaleMenuList.classList.remove('jessibuca-scale-menu-shown');
        });
        proxy(control.$scaleMenuList, 'click', e => {
          const target = getTarget(e);

          if (target.matches('div.jessibuca-scale-menu-item')) {
            const dataset = target.dataset;
            player.setScaleMode(dataset.scale);
          }
        });
      }

      if (operateBtns.zoom) {
        proxy(control.$zoom, 'click', e => {
          e.stopPropagation();
          player.zooming = true;
        });
        proxy(control.$zoomStop, 'click', e => {
          e.stopPropagation();
          player.zooming = false;
        });
      }

      proxy(control.$zoomExpand, 'click', e => {
        e.stopPropagation();

        if (player.zoom) {
          player.zoom.expandPrecision();
        }
      });
      proxy(control.$zoomNarrow, 'click', e => {
        e.stopPropagation();

        if (player.zoom) {
          player.zoom.narrowPrecision();
        }
      });
      proxy(control.$zoomStop2, 'click', e => {
        e.stopPropagation();
        player.zooming = false;
      });

      if (operateBtns.close) {
        proxy(control.$close, 'click', e => {
          e.stopPropagation();
          player.doDestroy();
        });
      }
    });

    function styleInject(css, ref) {
      if ( ref === void 0 ) ref = {};
      var insertAt = ref.insertAt;

      if (!css || typeof document === 'undefined') { return; }

      var head = document.head || document.getElementsByTagName('head')[0];
      var style = document.createElement('style');
      style.type = 'text/css';

      if (insertAt === 'top') {
        if (head.firstChild) {
          head.insertBefore(style, head.firstChild);
        } else {
          head.appendChild(style);
        }
      } else {
        head.appendChild(style);
      }

      if (style.styleSheet) {
        style.styleSheet.cssText = css;
      } else {
        style.appendChild(document.createTextNode(css));
      }
    }

    var css_248z$1 = "@keyframes rotation{0%{-webkit-transform:rotate(0deg)}to{-webkit-transform:rotate(1turn)}}@keyframes magentaPulse{0%{background-color:#630030;-webkit-box-shadow:0 0 9px #333}50%{background-color:#a9014b;-webkit-box-shadow:0 0 18px #a9014b}to{background-color:#630030;-webkit-box-shadow:0 0 9px #333}}.jessibuca-container .jessibuca-icon{cursor:pointer;width:16px;height:16px;display:inline-block}.jessibuca-container .jessibuca-ptz-controls{position:absolute;width:156px;height:156px;visibility:hidden;opacity:0;border-radius:78px;background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%;transition:visibility .3s,opacity .3s;right:43px;bottom:135px}.jessibuca-container .jessibuca-ptz-controls.jessibuca-ptz-controls-show{visibility:visible;opacity:1}.jessibuca-container .jessibuca-ptz-bg-active{visibility:hidden;opacity:0;width:156px;height:156px;background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-ptz-bg-active.jessibuca-ptz-bg-active-up{transform:rotate(-90deg)}.jessibuca-container .jessibuca-ptz-bg-active.jessibuca-ptz-bg-active-left{transform:rotate(180deg)}.jessibuca-container .jessibuca-ptz-bg-active.jessibuca-ptz-bg-active-down{transform:rotate(90deg)}.jessibuca-container .jessibuca-ptz-bg-active.jessibuca-ptz-bg-active-show{visibility:visible;opacity:1}.jessibuca-container .jessibuca-ptz-control{position:absolute;left:53px;top:53px;width:50px;height:50px;background:#fff;border-radius:50%;transition:left .3s,top .3s}.jessibuca-container .jessibuca-ptz-control.jessibuca-ptz-control-left{left:33px}.jessibuca-container .jessibuca-ptz-control.jessibuca-ptz-control-up{top:33px}.jessibuca-container .jessibuca-ptz-control.jessibuca-ptz-control-right{left:73px}.jessibuca-container .jessibuca-ptz-control.jessibuca-ptz-control-down{top:73px}.jessibuca-container .jessibuca-ptz-arrow{cursor:pointer;position:absolute;width:0;height:0}.jessibuca-container .jessibuca-ptz-arrow-up{left:71px;top:15px;border:7px solid transparent;border-bottom:10px solid #fff}.jessibuca-container .jessibuca-ptz-arrow-right{top:71px;right:15px;border:7px solid transparent;border-left:10px solid #fff}.jessibuca-container .jessibuca-ptz-arrow-down{left:71px;bottom:15px;border:7px solid transparent;border-top:10px solid #fff}.jessibuca-container .jessibuca-ptz-arrow-left{left:15px;top:71px;border:7px solid transparent;border-right:10px solid #fff}.jessibuca-container .jessibuca-poster{position:absolute;z-index:10;left:0;top:0;right:0;bottom:0;height:100%;width:100%;background-position:50%;background-repeat:no-repeat;background-size:contain;pointer-events:none}.jessibuca-container .jessibuca-play-big{position:absolute;display:none;height:100%;width:100%;background:rgba(0,0,0,.4)}.jessibuca-container .jessibuca-play-big:after{cursor:pointer;content:\"\";position:absolute;left:50%;top:50%;transform:translate(-50%,-50%);display:block;width:48px;height:48px;background-image:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAACgklEQVRoQ+3ZPYsTQRjA8eeZZCFlWttAwCIkZOaZJt8hlvkeHrlccuAFT6wEG0FQOeQQLCIWih6chQgKgkkKIyqKCVYip54IWmiQkTmyYhFvd3Zn3yDb7szu/7cv7GaDkPEFM94PK0DSZ9DzDAyHw7uI2HRDlVJX5/N5r9FoHCYdr/fvCRiNRmpJ6AEidoUQ15NG+AH8BgD2n9AHANAmohdJQfwAfgGA4xF4bjabnW21Whob62ILoKNfAsAGEd2PU2ATcNSNiDf0/cE5/xAHxDpgEf0NADaJ6HLUiKgAbvcjpdSGlPJZVJCoAUfdSqkLxWLxTLlc/mkbEgtgET1TSnWklLdtIuIEuN23crlcp16vv7cBSQKgu38AwBYRXQyLSArg3hsjRDxNRE+CQhIF/BN9qVAobFYqle+mkLQAdLd+8K0T0U0TRJoAbvc9fVkJId75gaQRoLv1C2STiPTb7rFLWgE6+g0RncwyYEJEtawCvjDGmpzzp5kD6NfxfD7frtVqB17xen2a7oG3ALBm+oMoFQBEPD+dTvtBfpImDXjIGFvjnD/3c7ksG5MU4HDxWeZa0HB3XhKAXcdxOn5vUi9gnIDXSqm2lHLPK8pkfVyAbSLqm4T5HRs1YB8RO0KIid8g03FRAT4rpbpSyh3TINPxUQB2GGM9zvkn05gg420CJovLZT9ISNA5tgB9ItoOGhFmnh/AcZ/X9xhj65zzV2Eiwsz1A1j2B8dHAOgS0W6YnduY6wkYj8d3lFKn/j66Ea84jtOrVqtfbQSE3YYnYDAY5Eql0hYAnNDv6kKIx2F3anO+J8DmzqLY1goQxVE12ebqDJgcrSjGrs5AFEfVZJt/AF0m+jHzUTtnAAAAAElFTkSuQmCC\");background-repeat:no-repeat;background-position:50%}.jessibuca-container .jessibuca-play-big:hover:after{background-image:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAACEElEQVRoQ+2ZXStEQRjH/3/yIXwDdz7J+i7kvdisXCk3SiFJW27kglBcSFFKbqwQSa4krykuKB09Naf2Yndn5jgzc06d53Znd36/mWfeniVyHsw5PwqB0DOonYEoijYBlOpAFwCMkHwLDS/9mwhEDUCfAAyTXA4tYSLwC6CtCegegH6S56FETAR+AHRoACcBTJAUWa+RloBAXwAYIrnt0yBNgZi7qtbHgw8RFwLC/QFglOScawlXAjH3gUqrE1cirgVi7mkAYyS/0xbxJSDcdwAGSa6nKeFTIOZeUyL3aYiEEBDuLwDjJGf+KxFKIOY+BdBL8iipSGiBmHtWbbuftiJZERBuOfgGSK7aSGRJIObeUml1ayKSRQHhlgtkiaTcdltGVgUE+ppkV54FaiS78yrwqlLoOI8Cch2XV548W7WRpTVwA6DP9kGUFYEpAOUkT9LQAvtq1M+0udKkQSgBqSlJWWYxKXj8vRACK+o6bbRIdYI+Ba7U7rKjg7L53JdAhWTZBsy0rWuBXZUuNVMg23auBF7UIl2yBbJt70JAoKV6/WwLk6R9mgKSJlJ1kLTxFmkJyCla8UZd15GJQKvyumyJ8gy8DAEvfZoINPqD41EtUjmUgoaJwAaAnjrKebVI34OSq85NBNqlCAWgE0CV5GEWwI3vQlmCbcSinYFCwPEIFDPgeIC1P1/MgHaIHDf4Aydx2TF7wnKeAAAAAElFTkSuQmCC\")}.jessibuca-container .jessibuca-recording{display:none;position:absolute;left:50%;top:0;padding:0 3px;transform:translateX(-50%);justify-content:space-around;align-items:center;width:95px;height:20px;background:#000;opacity:1;border-radius:0 0 8px 8px;z-index:1}.jessibuca-container .jessibuca-recording .jessibuca-recording-red-point{width:8px;height:8px;background:#ff1f1f;border-radius:50%;animation:magentaPulse 1s linear infinite}.jessibuca-container .jessibuca-recording .jessibuca-recording-time{font-size:14px;font-weight:500;color:#ddd}.jessibuca-container .jessibuca-recording .jessibuca-icon-recordStop{width:16px;height:16px;cursor:pointer}.jessibuca-container .jessibuca-zoom-controls{display:none;position:absolute;left:50%;top:0;padding:0 3px;transform:translateX(-50%);justify-content:space-around;align-items:center;width:150px;height:30px;background:#000;opacity:1;border-radius:0 0 8px 8px;z-index:1}.jessibuca-container .jessibuca-zoom-controls .jessibuca-zoom-narrow{width:16px;height:16px;cursor:pointer}.jessibuca-container .jessibuca-zoom-controls .jessibuca-zoom-tips{font-size:14px;font-weight:500;color:#ddd}.jessibuca-container .jessibuca-zoom-controls .jessibuca-zoom-expand,.jessibuca-container .jessibuca-zoom-controls .jessibuca-zoom-stop2{width:16px;height:16px;cursor:pointer}.jessibuca-container .jessibuca-loading{display:none;flex-direction:column;justify-content:center;align-items:center;position:absolute;z-index:20;left:0;top:0;right:0;bottom:0;width:100%;height:100%;pointer-events:none}.jessibuca-container .jessibuca-loading-text{line-height:20px;font-size:13px;color:#fff;margin-top:10px}.jessibuca-container .jessibuca-controls{background-color:#161616;box-sizing:border-box;display:flex;flex-direction:column;justify-content:flex-end;position:absolute;z-index:40;left:0;right:0;bottom:0;height:38px;width:100%;padding-left:13px;padding-right:13px;font-size:14px;color:#fff;opacity:0;visibility:hidden;transition:all .2s ease-in-out;-webkit-user-select:none;user-select:none;transition:width .5s ease-in}.jessibuca-container .jessibuca-controls .jessibuca-controls-item{position:relative;display:flex;justify-content:center;padding:0 8px}.jessibuca-container .jessibuca-controls .jessibuca-controls-item:hover .icon-title-tips{visibility:visible;opacity:1}.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-face,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-face-active,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-fullscreen,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-fullscreen-exit,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-icon-audio,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-microphone-close,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-pause,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-performance,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-performance-active,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-play,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-ptz,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-ptz-active,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-quality-menu,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-record,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-record-stop,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-scale-menu,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-screenshot,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-volume,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-zoom,.jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-zoom-stop{display:none}.jessibuca-container .jessibuca-controls .jessibuca-icon-audio,.jessibuca-container .jessibuca-controls .jessibuca-icon-mute{z-index:1}.jessibuca-container .jessibuca-controls .jessibuca-controls-bottom{display:flex;justify-content:space-between;height:100%}.jessibuca-container .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-left,.jessibuca-container .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-right{display:flex;align-items:center}.jessibuca-container.jessibuca-controls-show .jessibuca-controls{opacity:1;visibility:visible}.jessibuca-container.jessibuca-controls-show-auto-hide .jessibuca-controls{opacity:.8;visibility:visible;display:none}.jessibuca-container.jessibuca-hide-cursor *{cursor:none!important}.jessibuca-container .jessibuca-icon-loading{width:50px;height:50px;background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%;animation:rotation 1s linear infinite}.jessibuca-container .jessibuca-icon-screenshot{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAE5UlEQVRoQ+1YW2sdVRT+1s7JxbsoVkEUrIIX0ouz15zYNA+N1RdtQfCltlUfvLbqL/BCwZ8grbHtizQqPojgBSr0JkiMmT2nxgapqBURtPVCq7HxJCeZJVPmxDlzZubMmXOSEsnAvOy917fXt9e39tp7E5b4R0vcfywTuNgRbBgBx3HuJqLVzPzmYjprjHkcwAlmLqXNm4XAISLaSESPaq2HF4OE67rbRGRYRA7btn1fbgLGmKsA/Azg0gBkGzO/vZAkHMd5hIiqc5wHcCMz/5k0Z2oExsfHV1QqldPAf8lORNu11m8tBAljzFYAYWxRSl1vWdZvuQj4RsYYF4AVBlgIOVVlE55HRIxt23ZuCfmGjuOsJ6LPoiAistW27XfaEYmIbOYhPc9bXywWR1oiEJDYQkR1zrYjEjGyqfqbKd8a7kJVtLgQ+30i8pht2wfyRKIdmJkJBPkQTbILfudJ7CTZNBvVpggEcgpvc/ML38zESbLJsxBNE/A9biX0rdjGyTQXgbxyapdsarb0PMlXtWnGoXbKpm0Essqp3bJpK4E0OXmed3+hUBDP8w5FI91M0rdcyLLILElOCbaZilSWeXMncRx4klTCY1spfG3dhZJWx3GcDUR0EEB3ZMw0ET2gtT6SZWWzjmlrBIJCl0hAKfWgZVmHszqXZVxbCSxpCS2JJA6umIhe8ZKKVLPbaBJ+S9toqVRa53nedgAbAKwIwH4FcAzAa0R0l4i8F7PPz189k6RFRA+LyNcAXojDV0oNW5b1eW4Cxpg9AHZkSaaa6hhzb065uDSCH2LmRB8Sk9gY4293g43Qo/1pV80m8yQMfZSZ781cB1zXHRKRZ2IMpgD8A+DamL4ZItqitX4/jbQx5iEA7wLoihn3V/ACckWMJN/QWj9b1x5tGBsbW6uUOh5pPy0iL3Z2dn6ilJqanp5ep5TaJSLhF4NppdRNaU8gPmapVLrO87yfIoXuWyJ6uVKp+HmFjo6OQSJ6FcBtYT+UUmstyxqvkWuUgDFmP4AnQu2/e563qlgs+u9DNZ8xZhRAX7VRRPbath0XuXk7Y8xeAE+FgL6fnJzsHRwcLIfBR0ZGLunq6poAsDLUvp+Zw7b1r9PGmJMAbg8Z7WDmoThZuK67WkS+DD18fcPMdzSQUBR/EzN/nIC/SUQ+DPXV4dclsTHmHAD/SfHCNzc3t7Kvr++HJKeMMacA3BL0nyuXyzcPDAxMxo0fHR29slAo/Ajg6qD/fE9Pzw29vb1/x42fmJi4vFwu+5G/LOg/y8zXNJLQ2dAES5JANMQ7mfn1jBI6ycx3NiMhItqstf4oAX+ziHwQ6qvDj5NQNIn/ALCKmX+JSeIvABRD7fuY+ekGBPYBeDI05tTMzExvf3+/vz2Hk91/ET8RSeI6/DoCpVJpjed5fmKGvzMAXpqdnT3oed5Ud3d3v4jsAqBr9Ei0Rmv9VRqBBPzvROQVETnq2xJRdRu9tRF+bCVOKWT+Kvl/TSIFk6SW/LAjKfjV5K8rZABi8dOOEv7FI7Z8x6zwEWbemLbyMfJr5qiSiJ96oclymBOR3bZtP9+M89WxxpjdAHY2sN3DzM8ljWl4I3Nd9x7/OE1ENcdpETnmH3e11n41zv0l4J8RkU+J6AAz+xtF4teQQG7PFslwmcAiLfSyhC72Qv9/I/Avns2OT7QJskoAAAAASUVORK5CYII=\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-screenshot:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAED0lEQVRoQ+2ZycsdRRTFf2ejqHFAMQqiYBTUoElUHLNx3GgCgpuYRF2o0UT9CxwQ/BMkMSbZSKLiQgQHUDCJgjiAxiEiESdEcJbEedgcKaj3UV+/6q7u/jovPPkK3qbr1ql76p5bt6qemPKmKfefeQKHOoLFCNg+H1gi6fFJOmv7VmCvpD1N87Yh8ApwNXCzpB2TIGF7DRDm2inpmt4EbB8LfAMcGUHWSHryYJKwfRMwmuMP4BRJv9TN2RgB2wuB72BWsq+V9MTBIGF7NZBiGzhJ0o+9CIRBtt8FLqgADC6nRDbpVO9Iuqi3hCKB5cDrGZDVkp4aIhIV2aSQyyW9MScCkcQqIOfsnCORkc3I31b5VtyFRmg1IQ7dt0ja3icSQ2C2JhAjUU2ykd+dE7tBNp2i2olAJJFuc+nCt564QTadF6IzgUhiVGiqyinKaQjZpJP2ItBXTkPJZhACXeU0pGwGI9BWTkPLZlACBTldG4o5EA6E1dY66edcyNrs8Q36zg1vVaTazNs7iXPgDVJJzYs7VRvHRzaDEohyugJ4CTi84sg/wHWSdnVxsGQ7aQLXS9pZcqpL/6AEplpCU5HE8YpJ9YrXUKQ6baN1+HPaRm1fBqwFQnKGK2ZoPwCvAo8Ai4FnMpPMHMwapHUj8DFwbw3+Dklv9iZgexOwvktSRduxU2VDlErwmyXV+lCbxLbDdndlCT3TX3vV7JgnKfRuSVflfMkSsL0ZuDMz4E/gL+CETN+/wCpJzzaRtn0D8DRwWMbu1/gCcnSm7zFJd1W/jxGwvQx4r2IYnlbuA14GAomQFw8B6YtBKFSnNj2BxEJ3IvB1pdB9CjwQ8yqYhcg/DJxZ8WOZpA/SbzkC24DbEqOfgPMkBRKzmu23gEuSj1sk5SI3Y2J7C3BHMuZz4FxJf6fgto8APgIWJd+3SUrHjr9O294HnJUMWi8pSGqs2V4CvJ88fH0i6eyChKr4KyS9WIO/Ang+6RvDz0XgABCeFEdtkaQv65yy/QVweuwPY0+T9FuNQ8cAXwHHxf7wdHiypN9r7BfEl8GjYv9+SceXJLQ/mSDYTh2Baog3SHq0pYT2STqno4RWSnqhBn8l8FzSN4bfJol/jkn8bXUS228DFyfft0paVyCwFbg9sQkSDEkctueZZju8iO+tJPEYfo7A0piYKd73wP3xnB+20cvjNnphxdmlkj4sEMjhfwY8COyOY0fb6Bkl/K6FLKxS+M1KpDhJY8mvrG5doRwlf66QZfGbjhLh4pEt35kV3iUp/IvTunU8qtTil/7gaHOY2yjpntaez9b5RmBDYewmSXfX2RRvZLYvbThOh+NuqMa9Ww1+yLnXgO2SwkZR24oEens2oYHzBCa00PMSOtQL/f+NwH+Hg8hAnbrYgQAAAABJRU5ErkJggg==\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-play{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAACgklEQVRoQ+3ZPYsTQRjA8eeZZCFlWttAwCIkZOaZJt8hlvkeHrlccuAFT6wEG0FQOeQQLCIWih6chQgKgkkKIyqKCVYip54IWmiQkTmyYhFvd3Zn3yDb7szu/7cv7GaDkPEFM94PK0DSZ9DzDAyHw7uI2HRDlVJX5/N5r9FoHCYdr/fvCRiNRmpJ6AEidoUQ15NG+AH8BgD2n9AHANAmohdJQfwAfgGA4xF4bjabnW21Whob62ILoKNfAsAGEd2PU2ATcNSNiDf0/cE5/xAHxDpgEf0NADaJ6HLUiKgAbvcjpdSGlPJZVJCoAUfdSqkLxWLxTLlc/mkbEgtgET1TSnWklLdtIuIEuN23crlcp16vv7cBSQKgu38AwBYRXQyLSArg3hsjRDxNRE+CQhIF/BN9qVAobFYqle+mkLQAdLd+8K0T0U0TRJoAbvc9fVkJId75gaQRoLv1C2STiPTb7rFLWgE6+g0RncwyYEJEtawCvjDGmpzzp5kD6NfxfD7frtVqB17xen2a7oG3ALBm+oMoFQBEPD+dTvtBfpImDXjIGFvjnD/3c7ksG5MU4HDxWeZa0HB3XhKAXcdxOn5vUi9gnIDXSqm2lHLPK8pkfVyAbSLqm4T5HRs1YB8RO0KIid8g03FRAT4rpbpSyh3TINPxUQB2GGM9zvkn05gg420CJovLZT9ISNA5tgB9ItoOGhFmnh/AcZ/X9xhj65zzV2Eiwsz1A1j2B8dHAOgS0W6YnduY6wkYj8d3lFKn/j66Ea84jtOrVqtfbQSE3YYnYDAY5Eql0hYAnNDv6kKIx2F3anO+J8DmzqLY1goQxVE12ebqDJgcrSjGrs5AFEfVZJt/AF0m+jHzUTtnAAAAAElFTkSuQmCC\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-play:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAACEElEQVRoQ+2ZXStEQRjH/3/yIXwDdz7J+i7kvdisXCk3SiFJW27kglBcSFFKbqwQSa4krykuKB09Naf2Yndn5jgzc06d53Znd36/mWfeniVyHsw5PwqB0DOonYEoijYBlOpAFwCMkHwLDS/9mwhEDUCfAAyTXA4tYSLwC6CtCegegH6S56FETAR+AHRoACcBTJAUWa+RloBAXwAYIrnt0yBNgZi7qtbHgw8RFwLC/QFglOScawlXAjH3gUqrE1cirgVi7mkAYyS/0xbxJSDcdwAGSa6nKeFTIOZeUyL3aYiEEBDuLwDjJGf+KxFKIOY+BdBL8iipSGiBmHtWbbuftiJZERBuOfgGSK7aSGRJIObeUml1ayKSRQHhlgtkiaTcdltGVgUE+ppkV54FaiS78yrwqlLoOI8Cch2XV548W7WRpTVwA6DP9kGUFYEpAOUkT9LQAvtq1M+0udKkQSgBqSlJWWYxKXj8vRACK+o6bbRIdYI+Ba7U7rKjg7L53JdAhWTZBsy0rWuBXZUuNVMg23auBF7UIl2yBbJt70JAoKV6/WwLk6R9mgKSJlJ1kLTxFmkJyCla8UZd15GJQKvyumyJ8gy8DAEvfZoINPqD41EtUjmUgoaJwAaAnjrKebVI34OSq85NBNqlCAWgE0CV5GEWwI3vQlmCbcSinYFCwPEIFDPgeIC1P1/MgHaIHDf4Aydx2TF7wnKeAAAAAElFTkSuQmCC\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-pause{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAABA0lEQVRoQ+1YwQqCUBAcfWXXsLr2AXWTPXno8yVB8AP6Aa3oHI+kCDqYaawJljSe133uzO44bx0M/HEG/v1gAd9mkAyQgY4I/F8LJUlyrQFtD2AtIkcNoFEU+Z7n7QD4DfFHEVlocrVmgAUAIAOl3mILPcDgEFcUhyrUKMGUUcroc3NQRimj9XJBGaWMvvPydKN0o6/9QTdKN6rZANxj6EbpRulGuZnjYqs8BbyR8Ub2Izeys+u6yyAIDpo/ehzHM2NMDsA0xFsRmWhyfTIDWSXxCEBmrd2EYXjSHJqm6bQoii2AOYBL5Z0xgFxEVppcrQvQJO0zhgX0iXbdWWSADHRE4AZQ731AhEUeNwAAAABJRU5ErkJggg==\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-pause:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAA7klEQVRoQ+2YSwrCQBBEX6HiVvxsPYDewfN7By/gD9ciQkvERQwJdBSiYs0mEDo96aruombEjy/9+P/jAj7NoBkwA28i8H8tFBFRA9oeWEo6ZgCNiDGwAYpn3TpKmmVytWbABQBmoNRbbqEHGB7iiuJYhRol2DJqGX1uDsuoZdRmLuNZSzGWUcuoZdRHSp/IylNgK2ErYSthK3FHwLcSvpXIjoLt9Jfa6TMwl3TIMBkRE2AH9BriL5KGmVyvWIltJXEfKN6tJJ0ym0bECFgDU+Ba+WZQFCdpkcnVuoBM0i5jXECXaNftZQbMwJsI3AAPN3dAQflHegAAAABJRU5ErkJggg==\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-record{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAC+UlEQVRoQ+1ZS2sTURT+zlDJYE3XSq219QHVuEjnJDT+Bff9Abqw2voAEfGxqygUqWhVFHGl/yMLu9BwByxk5SNI66ML6U7axjhHbmhgWiftncxoOiV3FcI53z3f/e65594zhIQPSnj86BBot4IdBToKRFyBnbeFlFIScVEiuYvIWC6Xe2YK8pcC7SYA4CMzH4mDQBXAqilQBDsLQLfPf9FxnF4i8kwwmypARI+Wl5dvmIBEsUmlUkNE9NaHsVCpVAZGR0d/m+A2JSAid3K53E0TkCg2pVKpz7KseR/GfKVSGYxMAMA0M1+JEpyJb6lUOm5ZVnkrAsVisaunp+esiByr1Wp3R0ZGvmifzZK4XQQWHMc52MgBpdQuAOcAXABwuB400ZTjONdaIjA7O5u2bVsnWU1EujzP+5nP5xdMVjvIJkCBD8x8VCm1G8AYgAkAAxt8Z5j5YmgCSqlTAJ4D2OcD/AXgATNfbYVEAIFPIvKKiE4D6GuCea8xX6gtpJT6DmBvECgRFRzHeROWRAABE4iWCbwHEFhkPM/L5vP5dyaz+23+KwHXdR3P854S0YG1ILSCuthNMfNM2OC1/RYENLY+ygcBnPfht6ZAA6BYLNr6dyqVokKhsGpaNQ2TWJstreXaE2aed133sojcj41AKyvdzCdAgSXLsk4MDw9/a/i4rntbRPxFNZoC/5jAV2be759DKTUJ4FZSFFi0bbs/k8noy2R9dAjEuWU2YgXkQOK3kD6BMsysi2Z9JC2Jdcw/ALzwPO+xvmcl7Rj177JVEbkO4BARjSflFDJJuW1dBxJPoCIiL4noDIB1BS0pW6j+oJmbm+uuVqvjRKQfLr0bZHnIzJf0f6HeAybahrUJqAPruhLlcnnPysqKfpXp11n/Gv62zoHAroS+AafT6QkiGrIsazKbzX7eVIHEt1US39gCkOzWYthkjNE+tuZujDGZQ8XRXn8N4KT5lLFZ6uaYPt+nwyDuvC80YdhvB9uOAu1WoaNAR4GIK/AHvdr+QAexB7EAAAAASUVORK5CYII=\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-record:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAACfUlEQVRoQ+2ZSYsUQRCFvycK4nJXXEbHBdwO4kn/gv9CD467ICIutxEFkREdFUU86T/xojcPntyQcT2INw+uISFVkD1Wd2dWlU7nUHlqisiX+fJFZGREi8yHMt8/HYG5VrBToFOg4QnMPxcyM2t4KE2nT0i6EwvylwIjQOCFpE1tEPgGfI0FamC3AFgazP8IrJL0KwZzkAI3gLMxIA1ttgCPA4w3wHpJP2NwBxG4KOlcDEgTGzNbA8wEGP57vA0CU5JONtlczFwz2wY8HUbAzBYCB4CtwCVJb33OIAXmioC70LoyBsxsEXAQOApsLIhelnS6FgEzW+5BBvwA/FS+SPJFa40KBZ5L2mxmS4AJ4IjHxCzwaUnHkgmY2V7gLrAyAPwOXJN0qg6DCgIvgQfAPsDjo2pcKddLciEz+wCs6AO6W9KjVBIVBGIgahN4BvRLMjslPYlZPbT53wR2AbeBtcUmXEFPdh5U06mbd/shBBzbr/Jx4FCAX0+BEsDMFocEYrNmFcE+BD4XsXZL0oyZnQCutkagzkn3m1NBwDe/Q9L74MAuFEqUn5op8I8JvJO0elacTALnc1HAH3Njkvwx+WeYWUegTa/pwaqIgexdyIN4uyRPmqULZRXEvulPwD3gpr+zcrtGQxfzRHYG2AAczuUWiom3kc4D2RN4BdwH9gM9CS0XFyoLGu9UuN974eIFVDiuSzruH5LqgRhtU20q8kBPV8LMlhVVmVdnYwX+SMdAZVeieAF7eeltmElJr4cpkH1bJfvGVvatxdR4bMu+teZuWxtKxWncXn8I7EldtQV7vz79fp9KwZp//9CksB8F206BuVahU6BToOEJ/Ab7+KdABdTt8AAAAABJRU5ErkJggg==\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-recordStop{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-recordStop:hover{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-fullscreen{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-fullscreen:hover{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-fullscreenExit{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAADd0lEQVRoQ+2Zz2sdVRTHv+fJBDW6anDVXen6wZszYxYBiYgtFGst3VSDunKjpS0GpUlqfjVpsVVs6aaL0or4YxMVFCJZ2ZLdPUP+gq5bQnTxtNAkfTnlhnnlkmQy9yV9780rudt77tzv5/y4v4bQ4Y06XD/2ANodwec/AiJygJnvtdvTWfPnRkBEJAiCN8rl8kMfiPn5+Ve7u7v3rays0Orq6lJfX99/PuN2auMDoAD+BvA2M6/mTWSMOUtE48D6AjHGzN/kjdlNvy+AnWOOmQ/lTSYiEwDOWzsimgrDcCRvzG76GwGw8/zJzO9sN6GInAMwbW1UdSSKoqndCMwb6wNwGsB39Q+p6h/M/C4R2dTa1AoHYBWKyCkA1+pqiWi2Wq0e7e/vf7yRoJAAKcQggMtuJKIoOtoxACnE0/xOi/SXMAxPuhCFjUBdpIjYVWXSEf0TM3/g9BeriDMKdSPEz8z8vrU1xgwT0YXCrEJZy1iSJKOqOub0/8jMA0mSfKKqNwoPkHp7ioiGHIhRIvpHVa93BEBa2JcAfOlALAHo6RgAKzRJkk9V1S6xL7kpV4idOM31taxaIKJHqmpPnMMA9hcOQES2PDJkAT1XAAC+ZebPfWB3auNzmLObVsNRUNUXVHUujuM7OxXnMy4XwOcj29mIyOuq+lapVGrYCelKpkEQ3CyXy4tbzdN0AGPMxr2iYZ+sra3FcRybtgCIiK2BKw2rdgaUSqWoUqlIkQAepFDdAF7cBq5ERI9rtdr1OI7tmE2t6SmUEYFHAEaexYW/1QC2EF+ru5GIvg7D0D2GNJxprQY4o6qv1I/b6SpzOYqiLxpWng5oOQAzXxWRWwA+dkRfYOb1p5hGW6sBJpn5KytSRG4D+KguWFXHoyhy7xdeLC0F2ChSRL4H8OFuINoKYIUbY34gogHH3eeZef1K6tPaDpCm068A3nMEDzHzxY4BUNWSiPxORO6z5aDPPlGICNQ9bYyZIaLjjudzIQoFkKbTbwCO+UI0HcB9J/LdeY0xs0R02IGYYObRrWqiFQCfEZEtSHsfmGZm+4qxbbM/hQD8BeBNa0hEM2EYnmgLgP3lFARBT1dXly4vL//b29tbzQNIU+llAHeJaLFSqRzJes5vegR8xGbZLCwsHKzVav8z8/0sm0ID+MDvAfh4qZk2exFopnd9vv0ELrXBQO7fD10AAAAASUVORK5CYII=\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-fullscreenExit:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAC/ElEQVRoQ+2Zy49NQRCHvx+ReK6IlZ34E7CUiCAR4xEbTLCyQRATYswwb2IQZDYWgojHZpCQECts+ResiQwLj0RClNSkb9Lu3HtPz7mZc8+V6eXt6tP1VVV3VdcVbT7U5vozC9BqD/7/HjCzlZLet9rS9fbP9ICZvQPWSfqRAmFmS4ClMHm+JiR9S1mXVyYFwIBXwEZJv7I2MrPjQH8A6JN0OWtNM/OpAL7HS0mbsjYzswGgN8gNS+rJWtPM/HQAfJ9nkrY22tDMTgMjQaZH0nAzCmatTQE4ClyNPvQU2CbJQ2vKKB2Aa2hmR4DrkbbPgQ5Jv6sJSgkQILqA0dgTkjraBiBAxPHtPz2UtDuGKK0HKkqamd8qg5HS9yXtjebLdYjrHNRqiAeS9gQvnQGGSnML1bvGzOwc0BfN35PUaWYHgRulBwjW9ju+O4JwqM/AWFsABIgLwKkIYgJY1jYAAeJQuGIXVIVcKTKxh8WfBin9J+AVpx/eFWUEqFkyNACKp0rhgWYArkg6kQibSyylmPOklQdibijBX+fSLHFRJkDid+qKmdlaYENOI0zeEcBNSZ9qbVIEQHWuyGOTNZLetgrAz8ClPFpHa1ZL8rf5lFGEB2oBfAxQi4D5DeDmAP7mGJPka0oD4LnDr9imH/xFe8AP4vLIjBclxWXItCOtaIBjwOKo3HaFRyWdnLbmYUHhAJKumdkt4ECk9JCkSitmWixFAwxKOjt5uZvdBvZH2vZLit8XSSBFA/yjpJndAfY1A9FSgOCJu0BnBNErqfIkzfRCywECxCNgR6Rtt6TzmdqHBmyKXG4ZM4sTWc04NzNPWE+AuG3ZlZInSuGBinXMbBzYGVkrE6JUACGcHgPbUyGKAIj7REmZ18y897o5ghiQ5E/bltRChwE/kF7Xj0jyLkbDYWbzgBfA+iA4LmlXqwD8LydvszjAF0lfswBCKC0E3gBeP22p186f8RBKUbaejJmtAr5L+lBPptQAKfCzAClWmkmZWQ/MpHVTvv0X9iFAQGQyevIAAAAASUVORK5CYII=\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-audio{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAACrUlEQVRoQ+2ZPYgTURCAZzbBXJnCeL2Cnb87b9MEtPBUrrMQFAtrtT5/ClGs9LBWWz0RtbBUFCF4oJDsbO68wsLA2YqQSmLlvpEHu7IuMdlLcus+yUKKhJfZ+ebnvZl5CJY/aLn+MAP41x7M1QPMfFtr/crzvHfTAs8FoNPp1LTWzwHgqIg0lFLvrQHwfX8BER8DwC6jNCIecF13wwoA3/dvIuKNpLJa60Oe560XGoCZd4rICiKeTCtaeABmPg4AJmRqg6xcaABmvg4At4aFRyEBhoVM4UMoCplHADCfJTEL5YEsIVNID5iQAYCHALCYxeq5b6PMfF5EBAAEESthGK7W6/XPRpFWq7W3VCqtZg2ZcT3g+/6i4zjzIlLSWn/yPO/DIGMNLCWY2Sj/+xGRK0qpZfNDEASnROTFVi0fr8+aA8z8Ld6KEfGt67oLYwMAwEUium8EREn7OgeAjwCwPyo/nrque3YSgAtE9GDaAM1mc65arc4Zuf1+P2w0Gt9jJZl5DQAORt+fENG5wgEw8zUAMB/zbBBRwyqAIAjuiMjlSOlNItpjFUCqWl0josMzgChR/9hGAWBbknjmAdPhDdqa0gfZzAMJKyVP4v8hhJYRcSni+0JEu63ahZj5anyQici6UuqIVQDdbrfS6/UqRulyufyTiH5sF8AlIro37VpoWEHIzGZ2tM+sEZFnSqkzk9RCS0R01wjIsZz+mug53hDRia0AnI4bGgDYISItz/M2jYC8Gpp2u30MEWuO4zha665Sqp0ZYFStX/iWchRAItFGzoHSsrJ2ZFl1mHg6bfVYJeGJv85CC++BpIJZ5kSFC6G0ha0e7mYJqcJ7IOkRay84UhD2XjHFIFZf8iW9YcYoYRi+tO6aNeupOs66iU/icV46zf/MAKZpzXFk/QL+JG1PUPhRiQAAAABJRU5ErkJggg==\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-audio:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAACSElEQVRoQ+2Zu4sUQRCHf5+C+gf4yBXMfMYHGvjCzEBQDIzV+HwEohipGKupD0QNDE8UEwUFTe68wEDhTMVUMFJ+0tArzbjs9u3Ojt0wBR0M9MzUV1XdXVWNKhcq1189wP/2YKcesH1d0nPgdVvgnQDY3iTpqaT9kuaAt9UA2D4o6aGkzVHpXcByFQC2r0q60lB2D7BUNIDtjZIeSDoyRNGyAWwfiiET4n6YlAtg+7Kka2PCozyAMSHT5CkLIIbMfUlbMhdmOQCZIVOeB2LI3JN0NNPq6bTZe8D2aUmOY72kN8DnoIXt7eF5FSEzkQdsB+OEsFwr6RPwbpixhqYStoPyqVwAbkaAY5KeTWD5wStZHrD9XdJgK34FhBP9H8kFOAvciQBhn3/RAcBHSTvjfx4DJ6cBOAPcbRvA9gZJYQT5DfwYKGl7UdLu+PwIOFUiwCVJYQRZBuZqA7gh6XxUegXYVhtAmq0uAnt7gLhQm9vorBZx74Hcc6D3QLKH/z2JGyVnlYs4pCfzEe4rsLW2XehicpAtAftqAwiZbhhBfgE/ZwVwDrjddi40KiG0HXpHO+KcJ8CJaXKheeBWBOgqnf6W1BwvgcOrATieFDTrJL0HViJAVwXNgVgPrJH0BfiQDTDKtREiNK7KLSnHASQLLacP1PxcVkWWq8PU3emq2yqJJ0b1Qsv2QKpdZp+orBBqmrfq5m5mSJXtgUZI1XnB0YCo94opCal6L/ka3ghtlIXqrllzT9VJ5k19Ek/y0zbf6QHatOYk3/oDujC8QMWgjf4AAAAASUVORK5CYII=\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-mute{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-mute:hover{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-ptz{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAL50lEQVRoQ81aaXMU1xU993XPjBZGi2VDbHDAbMaYaB0JGbAjHO9OUk4csJNKKpX8inzKj8nmCsQbNgRvETsCDQhJQEyQxY4xq6TRNjPd76bO1GtnkMEIzVTKr4oC1/Ryz3v33nPObQvKvNLpdMzzvCVBEDxhjGkAMCoiX1hrz6ZSqdEyvw5S7gceP3583uTkZKOIrAXwsIjcUtV+z/OOtba2Xi73+8oKoLu7uyKZTK4A8LyIvKyqSxyA3dbaj1S1b+3atTfKCaJsALq7u/1kMrlYVX8I4FUR4d9MoTyAIwA+AdCdy+X6161bd7NcIMoC4Pjx4/HJyclFTBsReRXABgCLi4IcU9UTIrJbRD5R1YG2trYbIqKlAikJgKrKwMBAVS6XW2SMSanqRhf8cgDejOAyAAjiM1Xd4/v+ierq6usrVqzIlgKiJADpdLpKRJg2HQBeAMDCXQQgcZegxgGcFJH9qvpZEAT9U1NTVzZu3BjMFcScATDna2trF6rqWlVl8D8CsKQokByAEIABEHN/82fu+AkA26N0KqW9zhmA2/0nVPV5AC8C4ClUOQAjAL4EMAmgAsCDrqB99zt/+5ggfN8/0NTUdHmu9VASAADLXNd5QUQ6ATwEIMciNcYcsdZeEZF6VW0WkR8AqHdd6XMR+dRay4Lua29v/+r/DoAplEgkanzfX2WMeZYnISLLAHD3/6WqO40xZ8IwnG+MedH9zhS7CmA/22oYhmnP875KpVI8qTmtOZ9A9LZ0Ol1rjGkKw/BpY8xSVR1hkQZBsJukdfr06cTY2FiXqnYB+D6AKwB6PM/rbW5uPi8idk6Ru5tKBsDnHDp0qCEWiy0Kw5DpkvN9/1JLSwuDK/T5/v7++fl8/jEAtSIyFobhpfr6+qultlA+uywAinfQMbJkMhnt6uri7hZA7Nq1q8ALpbTMO53UPQGoqtm6dats2rTJzqbQ2J2stTWqWun7vhcEQSgiU7lcbmL9+vUTs0kZEuSRI0d8bsK9AN8VAIVZZWUlj7wqFotlR0dHb27cuHH6TrtAkIODg7XZbHahMYap8rCqJlXVcwFPqupVY8xFVT1XUVFxY82aNeSJO659+/YlKysrF1hrPc/zbg4NDd3cvHkzOeUb644A+vv7q3O53GMispxtEMC1IAhOdHR0nJ15Clu2bPGWL1++IAiC1SLSaoxpYbGqao0jL1XVKRG5CODfIpJW1ZOxWOxCU1PTxMyI+O58Pv84ALbdShFhJztpjLmSSqUoDG9b3wDArjE6OroSwNMAGAwD4cv3+r7f6/v+tWj3HBvPV9VGpreqrgew2t3DF/GFERNTC50FcFRV9xljDtTU1AxHhcxTPHjwYF08Hl8hIk+pajuAagBfRO9ubm6+9K0A6KaMMSustQVJDICBxQFconZR1Y+DIDgayeGenp4Fnue1isizAPiHwCsBUPNfVdWMiFAXzXdMzEK+BuCgiLwvInuHhoYuMj3cxj2pqs+55z3pNBWv3yUiH6hqOpVKXS8G8fUJMOfnzZu32BjD4F9QVUriBe7iCVXda4x5N5/P7+js7Lzodr/ZWvsKgJcBNLlrh53+Pw1gzG0A66K16HTOAPiAIFT1CLUQ+YSBW2vfcADI6lzsZAOquoMbaIw5Njw8PB7VRAEA0Y+MjNBJraeTcqrye0VIWbwHVfUdEdmWSqXODwwM1Gez2ZdEZLPbfabaSb6ExsUYczoIgmnP85hC3xeRZ6y1L4oI01JF5LCqvu153s6RkZEzyWSyzrH1JgDcxAeK3k8V26+qn3qe9xGAy62trecKPJBOp8mOD6rqOoeckvgRdzNlLm9m7h4QkX/6vn/41KlTN5YuXbpEVV8XkTcBNDNtKB8A/INMXHzULMwgCHgCP1ZVbhD9wlcAuKtb4/F4r4jEc7kcn0PG5uk/4bQTxSDXTREZdCLwi7a2tr9HAF5TVR4xBRlfwqOLUospcEZVD1G7xGKxg7du3Sp42pqamifdcb/uZPRJAFuMMW+3trby37eto0ePPmStfV5V33R2kyezW1X/QlFXXV2dGR8fr/d9n5lAAKwpdiKmcRQPZUq/tXa4vb399xGAP4jIarczlL3Fi8IrLSI7jDHbW1paeBLg5CGbzbao6i8AvOaKNA3grwDeT6VSlMu3LcfQ7Gy/BfAT16kOAviTtfbDjo4OaiTwunnz5m1wqfkcAG5uJMN5yS1mRCqV4mYXUuiPIkJdz6OtLXorJQBl7mEAH6rqh1FgrlcTAFPoZyQuAH0A/hYEwTss8pkADhw4UBmLxbpE5DcAWPjsVvtF5M+uMTClCuvw4cPrjDFvOJ+x1Bmi6GeqXQJgLYGU/WtV5UV0VezhJK5oEe0pEdkjIh97njfoed5IIpGQsbGxxwkAAF9E4mFnedda+/bExMTRYtam6c9ms5TalNW8J+XMzqcA3orH47tzuRxrjZ3oEccnjIfXcXMifz3KGZOIDKdSqd9FJ0A9P59ymJ3C3RR1ANI9byKD7jHG7Jqenu67ePHiKNnXWvtTVf2lMzO0ij3OKnar6hB1vpPTlNkdIvKSa88ctwypKlvptkwm059MJhOqusY9izXAtsz850mxBjggi4qYNfBWAYDLTTLeKgJQ1ZdcVyluYwRRIB9r7faOjo4LFG0sNhH5uarSUnKMwlFJr6pyfHIMwHURqbPWFgJT1acAPOqIbheA96y1e9vb2y/19fU1qCqNEeuKbTTiAcZJEVhoo8YYdrr/tdEoV1iYU1NTpHGac/pcttOoJqbc7r7ned42FjMVY29v72PGGBYmWZtdgzvLodV/mHqqektEkrSe7g/bc05EWC/vMS1HR0dPMd3S6TRbOYv2VyLCVsr7uEhk3PkdnO6RyDKZzESkUm/TQiy0iooKtkeC4ElQGlBKUBZQv3yUz+f3d3Z2FgrOGfvl1tpnjDGvqCrbXp3TQBzkkgB5P0mOk4lpVSVT81k7Y7FYX2NjI+sMVKBVVVUtjtkJgPaTrZadcI9Lt967SonoJNhhstnsas/zuqy1jcYYavvLqnqADWJ8fPzcjALlMHe5MYbp0aqqK0WEx08CYgDcQYo6EhFPbkBEjoZh2N/e3n418gfFwtBa2yki1EJsn0PsVhSS9xRzEYienp6aWCxGUcdgalWVgup4XV3d2TvZQLd7j6rqMmstJTiHW0wJCjkGzxE7BeEZz/OGcrnchfPnz1+fqfGpSFkL1lp2OHY2AhhW1c9nLacjEEwP3/frwzCszOfz077v3/y26QG7TSaT4Wkx8AZXvAQQGGMy3ARjzA1r7UhbWxv9wR3noqytwcHBunw+3xAEgaGhGR4evnVfhqaYhPhA18YowGY1jC3qbLF4PB5WVlZO3q+B5zMYx5wt5Uwm/a7+9z1N/WwCZ7p5nkdnVhsEQWCtvR51Kt7f19fHlFgoItWe541ba6+2tbWxqEuaCRWIbDYBfts1LvdXhWHIzkHhNU6Tks/nD9G50TMvW7ZsnZMH5AEKvSOxWOxYU1MTW2RJa84AojzneJ3+2ZEQZ6XjIkKW5ejwrO/7D7gBMMmR3oMC8evxekNDw8j91kcx4jkDIOnF4/HFzoAzOBp6ujjqp17H3F+6jkRR1ubkwRQ1jYjsFJHubDZ7opRPTiUBqKioWBmGIW0ipTin05F7IvHR8o06IlzoXB7ZmOuCE33bVbVnJrveT07NGQBTqKqq6lHP855xKpNaiNMHLlpRTpx5GpQSVJRR8BxQ0aRvo3/O5XKDGzZs4MhlTmvOAPg2MnY8Hl9prV3n/ESUJjO/j0XBUfNT6LEGPuW3gbsx7GzRlASAHWbVqlU12WyW34OphSjCmEqUzDMXd5lemV5hL+tgYmLiWldXV3a2BHknUCUBiB5IHnCujoXMb8TR15rokugL5Z4wDD9JJBIDjY2N10oJPHpwWQDwYW4wRlX6nDNFPBHK6OhDN83ILmttfylFO/MUygaAD6Ypmp6ejsaDNCfsPjf5XZi8QCNTzuD5zrIC4AP5tUZE1hhjCgUtInRo9ACD3/n/2YMASHCJRGKJtZYDKlpSeoEzQRCc6+zs5KCsrOu/zrEzi6BNfKAAAAAASUVORK5CYII=\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-ptz:hover{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-ptzActive{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-ptzActive:hover{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-performance{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAABWRJREFUaEPtmX+IVFUUx7/nTctgP6Q2M4MKFUyyqOaet6ytsVm0RUFZWZtbEERUEkUkipV/aFAQpRVoP6kIijRFMwjMfpCmbsu+d99su2tGm/SLoqKsltB1Z+edOMt78XZznR87Ywzs/Wdm3rv33e/n/LpnZgg1PqjG9WMC4P/24IQHYg9Ya18CcDeAe5j55WPlmYp4oLe398TBwcH9IjIVwJPMvLymALLZ7IIwDLeqaCJ6xRhzV00BWGvXArgvEr2FmRfWGsAXAM6NRO9k5vk1A+D7/iVEtCshuIeZL6gZAGvtSgCrAOwGoDA/GmPOrCWAnQCawzB81HGclSIy4LrupJoAsNZq3Gv869AkXqdvmLki5bkYI4xrI2util4rIt8Q0UMA3tZNReQ013V/K0bAeOeMF2AzgBu19ovIegAfR4LmMPO+8YorZn3ZAHv27JmaTqf3EVE9EbWFYbiXiLqjTZuZOVmZitFS1pyyATzPa3Mc5y0AA0R0dhiGxxHRT5GKhcy8pSxFJS4qCqCnp+f0XC53qjEmTlhYa1/Uxg3ANma+pq+vL93f3z8Q7T9mQ2etZWa2Jeocc3pBgCAIrhORd4loL4BWhRARJwgChZktIstc112tO1hrJeqHHjbGPDF6V8/zVmmp1ZLb0NCgZ8e4x1EBPM9rcRxHm7Tjo+qy1HXdNUEQXCEiH+o1x3EymUymKwI4CEDPgNXMvGy0OmvtZwDmEtEBIpqbyWT6xkswJoDnefMi8VMSmww3atbaxwCsIKIuY0wmvm+t/R7AWQBeY+Y7k+KCIHBFxEtcW8fM91cFwPO8DBFp2KgYHQ8CeIaIfjHGTPN9fzcRzdNrzLwkAaCxbQBsZeYbkuKstSsAKLiG2bDhhoaGLmpsbPx8PBAjPKAxGsXwIiKaHYVNaxiGfalUKquf8/l8Jn4P4Fpmfi8W4Pv+diK6EsAuZm4eBaBlVXulV0VkAYApRLTeGHNrPC/evxBQMn9GAMRJGD9ARFpd190UxfcfAE6OvQHg18OHD09vamo6lPDAmwBu04Q3xpwfXw+C4EIRGc6TVCrVmM/nFeCR6P7FzNxhrf0KwKxC4olohzHmsnjeCIAgCD6Jb4Rh+HwsPgJ4B8D1Gh76SkQbjDFtyQ1933+WiB4QkZ9d1z0jAbBcRLQqDTFzXUdHx+S6urofAEwGsN1xnDVhGH4QeX9HIYgxAY62MAiCJSKyBsCfkSf+U+sTcT7IzOmEZ1TUpQA2MXNrZJCnACyN5rQDaALwHTNPLwSQvF/wHIgnd3Z2NqdSKW2d4zGLmb9OPiwIgsUi8oJeizvSrq6u8/L5fG9k3RZjzEcJzwyIyL+gAEo+wYsGaG9vn5ROp7VV0Dz4lJnVoiOGtfYWABuSAL7vLyUitfYIr0Re0Or2dPSQg8x8QinWHzZKKQustRsB3DzWSZrNZlviWI5bamutdqiXH6m0RhDDp3c51i8ZQBd4nje/oaHhiIk26rCaE4Zh6DjOl4UEZrPZ6ZlM5ttSjBnPLckDhTbo7u6emcvl9kfz9BxgPewAHGLm4Xak0qPSAKfkcrkDscVFZDERtQDYzMw3VVp8WSFUSETiMNRWW38v1XEHM79eaG059yvqARXg+34/EZ2kzR6AxwH8zcz6uSqj4gDWWs2BmUS0TUSuBrCRmbW8VmVUA6ATQENCbdXCp1o58D6AqyKAv+rr66fNmDEj/qpZcS9UwwP688qiYeuMapcrrr7Uk7gYAdba5wDcGwHcbox5o5h15c6phgfir5sHcrncOY2Njb+XK66YddUA0PjXPDgm/5VVHKAYq1VyzgRAJa1ZzrMmPFCO1Sq5puY98A+NFCdPMfR+nQAAAABJRU5ErkJggg==\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-performance:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAABGRJREFUaEPtmXvI3XMcx19vkVxzN4WWGhlhRq7NyIhymTG3UpJLItGW2x+sKLGZMtdGioytDaXmmg0hkrnLJbcIuadNkrfeT9/f+j3H8+yc85znN516Pv+cc37n+/t+36/v5/L9nN8RfW7qc/2MAfzfHhzzQOUB2/cAFwAXSrp3fXlmVDxge3PgM2AH4GZJV/YbwEnA40X0Qknn9xvA7cAlRfQySTP6DeADYM8ieqWkqX0DYPtw4KWa4Hcl7dNPANcB1wMvA4H5RtLO/QSwEpgCzAEC86ekTfoCwHbiPvEfSxIvyBtJo1KeO9mEnhayHdGpQJ8DVwGPlkW3l/RjJwJ6HdMrwFLgFGAhsAh4vgiaKOnDXsV1cv+IAWzn1I3IbYAzgfeBd8qiUyTVK1MnWkY0pheAiH44SQvsCmwIfFtUzJC0bESKurypIwDbOwLbSqoSFtt3p3EDlks63vbGBSYShm3obE+W9GaXOocd3hbA9onAEyVEZgbC9gal+uwBzJY0NyvYdlnpakk3ta5qO+dFSu0cSXnfs60TwPa00qRtWlaaJWme7aOBZ8u1SZJWFYDVQM6AuZJmDwHwKnAw8HNeJX3SK8GwALYPK+K3qy0y0KjZvgG4FlglaVL1ve2vgF2A+yWdVxdn+wDgjdq1BZIubQTAdkQlbCImdjkwH/he0jjbaRsCOF/SFTWAxPb+AZc0vQUgwAFPmFUbt5+kt3uBGOSBEqOZ7wwg8R2bCcTVb1UhU3t/gqQnawBPA8ekuZOU9mKt2U5ZTa90H5DfD/HsIkln1e7vKC/q+dMKUCVhNWeSdkmJ71+ArWre+AEYL2lNTcBDwNlJeEl7167vm3Arnw8qANeUz4dIes32x8CEDryxQtKR1bhWgBdqE9xZiS8AjwEnl7zI6yOSchbUd/k24DLgO0k71QDyEzNV6W9JG9neEvgayGu8Ng94poxf0Q5iWIB13Wg7sZ6Ffi2e+E+tt13F+V+Sci4MmO2IOgJYIikhmWu3ALPKkFeAQ4EvJY1vB1D/vu05UBORmE7rXNkESZ+2eOAi4K5cqzpS23sB75Vx0yQ9V5szp/haUKDrE7wbgNT3tArJgxclZUcHme3TE1otANnl7PYgrxQvpLrdWiZZLWmzbnZ/YJ1ubrC9GDhtuJO0HHxVLA+01LbToR41VGktEFXh6Hr3uwYoC06VNGSitRxWE4F/gI/KJg0r0Haq2RfdbGY1tisPtFvA9m7lAVeGJmcmlwNwjaSqHWk3TVffjzbA1qXPiYg8G0pSp59aKunUrpR1OHhUAVpiOq12npfGzpX0QIeauhrWBMDvwBal2bsR+ENSPjdiTQDkIW9yYTlwHLBYUsprI9YEwOvAgTW1jYXPiMpou220/RRwbBn3GzBOUk7cRqwJD+TxStrx2KB2uQmCJgDuAC4uYs+R9GATwqs5mwCofm7md+/ukn7qN4DEf/JgvfxXNuoeaHK3h5p7DGB973jremMeGPNAjzvwL2DsnUCOKLhRAAAAAElFTkSuQmCC\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-performanceActive{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-performanceActive:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAABdtJREFUaEPtmXtsFFUUxr8zW6wo1CIzW0jEIAka1KgVDO3OloexEk0UFQXRxIQYhRiIwUBA9tHHXSIRsCbgM2hMNBYhYEmMgI/w2J1txRDxgRrR+CAq3dkCGgJVtnPMnX1029Dus5hNOv/szsy5c77fPefce2aXUOIHlbh+DAP83xEcjkAyAj7DfA3AkwAWC117/WJFpigRaNgXGWVdQj8BcAJ4XujaqpIC8BvRuQxuS4jeInTtiZIC8IUim0C01BZNtFO41HmlBWCY3wKYkhB9QOjarJIB8AQjbkWhYK9g+lro6k0lA+A1zAYCGpk5RERuEP0uXOpVJQPgN8wDDMxgy2oiRWkAuFvozpElAeBtj04hi2X+g4mWEvNm+V3oWlGW52wmoSBHvnB0KZg3gflnOByrYVnvSaeO8nKtcVpFNBsBhdoUBhCK7ADRAwC2MKiVwJ/a0VDo+kCt+l2h4rIZnzdAo3HC2QOHFHklgIUgx1Fwz1e2U+YZwu1MW5mykZKfTd4AnqC5UFHwLoDuWE/sakJZmcOBP+L6rXkBd9XO/CTlNiorgDUdnVUjUDa2qWasXbDy8IfNV5mxGMy7hdt597IPj5VXXlHZnbg9YEPnC5pTRZ12ODeZA1tnBPC2m/eShV0AHVUcNF9CNDArVjgqYa4DY6VwaxukC59hsu2K6FnhUtf1d+sNdjbKpVYuuYG6qsZiQAwK4A911jMpskm7zE4NYEVA1zZ626N3kMUfy2sKyqqb9DFHEgBnAYwEY4Nwayv7C/Qb0XYG1wB0kmNWTWCm81ihEAMC+A526nDY4tWUk0Sj5jeiAQZ7CDjSrGvVyfu+kPkbCBMAelPo6uPp4jwhc5pC+Dx1jXmzcDuXDQmALxyphkW74mLsqV8OQguATqFr43yhSAhEOhNaAi7tmbS6OMyMW0HUJlzq/enivEbUQ+BAPJCJd3HLukXUVX1ZCESfCMgctVNYUR6289tOZ54fYxxzgL6Q5z3g6uR3JtwTcGkfpCJgRPYCdCeAoNC1GenC/IYZZMBNhDfY4rkgUhloDejaI0m7pP9MQOn10wcgVYSJJ0jxzS7n9kR+nwJQmRaNyBnqntjimnAuJcAw3yHgUVnwQldvTIF9dupmxGJ2nShE0y3LkgBr7HOHUttUM7bDZ5g/AJicSTwI+4VLm5206wsQNvf13uCXk+LjANH3Ab4PoLb4J7YKXVvYN00iLxLoaTCfEG7n+F6w6CoCrwMoJnR1RENHV4XVYx0HUAHwXmLHRibrI9uesD8TxIAAgw30GabM9Y0ATtuRuMDLu9eIeAgk8/xfoWvlvallSlEzibC92aXNtyckbK4HY0W8xDhMIBdAvwpdnZgJIP1+xn0gaewxIjMU0IHkuUI8ucnl/DH9Yb52cwksvCKvJTtSX6jrBpD1jZ0uCtU31aqfpIHJjS8FygrNC9SqOe3gWQMsDx8fOYovla1CJQEHm3VtZv+Z8ociC5hoa1+AzhUgZX3/qEgbf7u5nC28kHjOWaFrl+cy+/GMy+HwhsxtRHhooJ3U39FVzz3xXE621D7DlB3q7QDahK71WVrjtRXfvfPtn3ICkI68QXNWoE67YKGlb1aypUYPW0T43hY4SHo0tP85sal2/C85zGXKNGeAwZw0HDo9yTp/Xv7AZbfUUBxTwVYLA+cCuma3I8U+igqwOnh6zAjl/MlkShBoCYjqAdohdPXBYovPuQayEZC2GS4GIH8vlaW2SOjqW9mMz9WmqBFIFOXfAEZDIQ8sXgvgjNC10bkKy9Z+KABkDUwCYTcYd4GwTbi0BdkKytVuKAAOAbitVwgvErpzSNJniGogugfgOfHUx1/KP2fGNc2+JvmqmesEZ7Qfigi0ApDtOIjQ2uzqbZczqsnDYAgAoi8B/JTUYoEeW6urb+ehK+shRQdIvm7K995Y2SXXPje9oitrNXkYFh8g3DmHWdlzsf4rKzpAHpNY0JBhgIKmrwiDhyNQhEks6BElH4H/AMC5Nk/4iSwzAAAAAElFTkSuQmCC\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-face{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAAA8lJREFUaEPtWU1oXUUU/s68F4TuFERcWCtSlCourCCBpJlzXxSUuGyQQKFWUHSniAiC2o2lqAgt+G8KYhe2uFHQRXwzk5utQhvBHyw1oO4KXUgW8nLnyMALPGPuncm79zW0vNnOOXO+73znzpmZS7jOB13n+DEmsNsKjhUYK1AzAzd+CXW73TeqkqSU+oSZ/6yTSGutrvJnZlc2X6lAAK+Uej0CjqsCxIjVjZFKgMuA1AEf1gzZ996XKtBPYGmSkgnUBRpTYrv5fmlZAGMCO6pz59wjInIfgHsB3ENEq0VR/KKU+o2Zv0tVY1cUcM69LCInS3cNokWt9dMpJK45AWvt7wD2ich57/3pVqv1BzOvLS0t7W2323tF5G0iehjAFWa+NUbimhJwzn0lIk8AOMnMr5SBc859KiLHvPfHO51OZY+pTWBzi0sINAfgawBdZp5NyOw3AB4jokNa65Uq+36fKG2WjRwljDEfEdFkf7u7EiNgjDlIRN+LyJksy47F7KvmGyHgnPvJe38hy7KFVDDGmItEtIeZ96f6bGdXm0C3271TKbUG4B1mfikVjLX2DICj7Xb77unp6cupflvtahNYXl6+y3t/mXawPQYQzrnPROQIgP3MfGnXCPTPM2H7/IeZQ+NKGtbaAPomZr4jyaHEqLYCYV1jzFkiWlBKHZiZmfk5Bshaez+AH0O/yLJsPmY/8o/YGLNARGdTARljzhHRYQBHmPnzXSfQL6PQvE7ESAyAr2x4qaQaKaHNYM65D0XkmfCNAjgOYC0cJfI8P9Dr9eZbrdakiDwK4AdmfigV5MhLKAQIIIuiWAQQzjqxcYmITmmtT8cMY/ONKOCcO+y9/4CIbgFwVUQ+VkpdEJGDAELXXRWR1bBTEdELIvJgH9gXzPxkDORIFQjgReRcCBJ6QVEUr3U6nb+qgg7eg4noXa31i8OSqKVAnucPFEVxsQ/+Ta31q6lArLVHAYRuHIg/r7V+P9V30K6SgLV2HwA9MTHx5dTU1N9bA1hr3wIQjg/fMvPjOwUwoN6v6+vrk3Nzc1cH18jz/PZer/ds1dPN0Jf6lZWVmzc2NkLTuq0oikOzs7OVx+IycsaYRSJ6arv7Qe37wECt/u9OvJm92L4fU2VABReCDNqPlIAx5j0ieo6I5rXW52NAq+attRLmmfk/FTFSAnUAp/qOCVR9A6lZrGPXqAJlQJp4coy8TjfytFiVyB292m1daKSv0yHYqP8PJLxOCzOHk+22o9ZRok59N+U7JtBUJoddZ6zAsJlrym+sQFOZHHadfwF5DxJPm75v8wAAAABJRU5ErkJggg==\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-face:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAAAx1JREFUaEPtmUuoTVEYx3//kTKjJAOvdKNLBiiZyC0UMSQp5VHEjCSlPCYkpChv95YYIBOKCVGmlEd5RCjMlIGR0V9fbTr3Onvvdffex0Xnqz3aa539f3xrfd9aR/zjoX8cP10CI+1g14GuAzUV+P9TyPb+EpEuSPpUR0jbi4rmS3qQ977QgQz8vhJwfUUfKCNW9xupBPpyFShQpwx8vM/UL3IgBMwVKZlAHZVTiLQbk5G73yVQpECOckuAmcAMYDrwDHgFvJF0N9WREXHA9i7gcAHIfkmbUkj8cQK23wNTgOvASeCjpA+2JwHxHAXmA18kjSsj8UcJ2L4JrAz1Je3OA2f7IrAROCCpsMY0QSC2t0UJH1oB3ALuSVqcoOxtYBmwUNLDovFZncgtlo20ErbPAQuyxf4lgcBc4BEwICncqBxNEXgBPJG0NhWJ7afAaEk9qXPajatNwPZk4ANwTNLOVDC2B4D1wDRJ71LnDR3XBIGpQABI3h6zFuISsA7okfR2xAhkYGL7/C4pCldS2A7QoyRNTJqQM6i2AxmBK0Dkf6+kl2WAbM8Cnke9kLS6bHzR+6YIBPggkQTI9jVgVaSQpMsjTiBzIYrXoTISLeALC14qqUYc+Pkx22eBzUCcoA7E7pS1Er1ApErUiqXAY0nzUkF2PIUyBwJkf9brlGGLBXxCUvRLtaIRB2xHPp8BxgJfgfNR2ICouPFEOx3Pd2A7MCdDfVXSmjoMahPIwMeijAgH9kr6XARqyDn4uKQdVUnUImB7NhAtQcRBSXtSgdiOKhzVOGKbpNOpc1vHlZ2Jo7ePjvSGpG9DP2D7CBDtwx1Jy4cLoMW917HAJUX6/QrbE4AtQLVutMXq324FbI8BomiNT2mL88jZjrTb0O580MR5IA4cba81WtRLKl4FBGIDiDX0QNKg65tOEzgFbI39XVIcISuHbcdkSYNSuqMEKqMdxsQugaJFPAwhKw9t1IE8FE1cOZbcTjdytVik4t97Ox2oO/3/QMLttCVFZ9s2arUSlZO7wYldAg2KWemnug5Ukq3BSV0HGhSz0k/9AN8KmkDYgiFSAAAAAElFTkSuQmCC\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-faceActive{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAAA+1JREFUaEPtWV1oXEUU/s69/oAvzd6tiA/WajPZWEsfTEHyUlpQQdHHBgkU2oqWncUHRWpBaJsXpagUmmY28ScBsQ9afFHQF8WCrxbaCk27dxsj6pPZuS0VITY7R2bbYFKzc+92dhMqe9+WOWfO951zZs6Zs4Q7/KM7HD+6BNY6gt0IdCPg6YH/fwpFY5eOOJ10T/CRfln85uPIntF4h0v/yqvidLN1ZwQa4Ck47Nrc1LHTZSCNmK+NTAQsyGZAfMDbPa33g8A0jwAFh11OykzAF2haJFZab5AL8X2XQKt5Ho1Xnoahx8HUz8QFYj7PAV0MOIhrctO3WaOxJhHIlasHiPloU5CMSV0SL2UhseoEIlX9GeCNAE4xzCiT+fVK8bHZ3MTlDVjABkL9PRA9CWBOS3F/GolVJZBX8ZcMvEDA0ZoUB5uBi8bij0HYBzYjulRw1hhvAotXXJqhXPny88TmKxB9p4u9T6V5NlLx1wCeZYTbE/noDy75Rp1wFMu2tBJROf4AjMHrodl5bX9hLo3AelUdMOAfAUxpKfalybvW20NAxRfAfFaX+oazgolU5RyD7kukEFl1VpLzJtBz4sLDQXD3LBjv65J4IyuYqFydAvOeOsymq7Iwk1XvVjlvAutGLz4ShuEMWrgeLYicij8hYHfIJP4o9VbXjIA1fOP6NPNa9vVnBZJXcZUZ9+qSeCirTkdSyG6aV5WTDBom5s21Ut90GqBcubqFmH+y9UJLMZQm3/FDnFOVYQKdzAooUvHnAHYxsDuR4tM1J9DI6XJ8kBjvpJFYBJ9W8LKS8j7ESw1FqjIB0CsMnOY6RnDXwqxtJaLxeDPqZggUDAJ4hoEziRTbsoLseAo1DrIFaTAJwPY6zo+BagA6XpO9o2myaettiUCk4l0AjwMUAUiI+UOD8CzBDDBhwLbTAJ1nwjwIrxHjiZvAPtNSvJgGsqMRuAEe9lAChEmCOVQrFn53GV32DiYc00Xx+u2S8IpATs1sJdTPWeMMvJ1I8VZWIPmxyh4mmmroEmRSFOWsukvlnAR6ytMbQxPuoD/NF3Nv9l+71UCkKu8CZNuHb7QUz7UK4N/o0aU6/hq8KrcmS/dYPzH7oFmY33/b3ehiqFd6Uq5Tv+RC/nsahAcYZnsiC862uBm5SMX24O9d6X3g/R5wEViS+17VdHEfe/UmUiwb33SUQF7FioEigCEtxalW02d5/YjZ/tZSLEvpjhLwAZxVt0vAdQayetFHrq0RaAakHSNH13S6LaNFlxdbndr9p5Z4TsBTK3Gn/x9InU4HAeuiGGnmxFQCPjm8GrpdAqvh5Y62010Cnh7ongFPB3qr/wPHMTZPXfm7BQAAAABJRU5ErkJggg==\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-faceActive:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAAA/pJREFUaEPtWVtoHFUY/v6zWQVf1DonpYJtRYqlig9G1N1JSgMqKPrYIIFCraDom1Ik2J0kuzNe6gXBgncTEPtgiy8K+qIY2Z21DxXaCl6w1ID3zDQVBCVmd345m0a2YXfOyc5sQmX39fz/+b/LmXP5l3CR/+gix48egfV2sOdAz4GECvz/l1Ch/PtknEiZbN9bxduv+imJkIVysCsu3xuSM+3GYx1Q4EmIibjJOcJwXAEdsaQ1jAgokO2AJAGv5lxSP2rrgBIwTiRjAkmB6pxoNa7IkcBnPQKrXefjlbN3MqIbCNjOAteD6RQD30Lgey9nfWLqxro44PjhEwAfbA+SplzbetCExJoTcPzwB4C3MuMogQ+JTP3HYm7T7ER5fnMNtc2C6AUQbgMQuraUOhJrSsCpBh+AcR+BD5bs/rF24Bw/fBvgfRxFRW9oY+wZkwKBpS1OW6ga3EuMD0H0qZu37tAp61SDj8C4G5zZ6Q5uKMfFq3Mi7rBM5SpR8IM3AM71/VMbnhy+OtQSKAcDEDjOoGnPtvbp4uPGUyHgVMOvmfmEZ8tRUzCFytxJIrrMteU205xWcYkJHPB/2SKQnSXgxZIt95uCcfxwGuC9Ipu9rnjrFWdM81bGJSZQ+Py3a6kvcwYw3x4ViHE/fIfBewRdsq2Yv/z0uhFQhc9vnwuuLbebAnH8QIG+1LXlNaY5XVlCDQKV4DAIoyxoh5ezvtEBmvTnb6yj/pU6L7xBOaKLX4OPOBgF47ApoEIlOEKE3QDtcW3r3XUn0HChGo6B+RkdiWXwugPPlFTij7i5kOMHrwN4CIQZrqOY6avNNq4Sx87uqC/WRkhkcgDfBeBL15a3mILs+hJSBRTIKOIpMKu7jubHpwni5ZJtHdJF6sZTcWC8OrebmV4DsIGBcwS8SYQTYAwwYaBxneboFJFYIOLHmHGzAsbAe54t79eB7KoD58EfaRQhmoqA8afy1s9xRZvfwUR4qZSXj3dKIpEDE8fmb4rq9ZNLxelp17YOmAJx/Lm9AE03MkGPlmzrVdPc5rhYAhNf/Lo1ijK7Fpjef25Q/rmygFMJngdhPwgfu3l5z2oBNLn33WL0V+7ZoS3nmud48niwSfwdPdzxbXTZ6lZPyrHyH1dmxaI6tDaCeac72B97LW5HruDPTRHogVbvgxTeA0t9oVYEltXT7fs6V/5zgTDj5uUF7ZvuEvCDVxh4hIhHSvn+ozqgceOOH7Aad215wZLuKoEkgE1zewTiPmJTFZPEpepAOyBptBzjutOptBbjVFxt127lXF3tTqti3f5/QNedhhDs2bLYTsREV4kk6zut3B6BtJTsdJ6eA50ql1Zez4G0lOx0nn8BCGZET2pBy4cAAAAASUVORK5CYII=\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-zoom{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-zoom:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAABH1JREFUaEPVmVuIVlUUx/8/IowoArtSEUWRQpCEUBEE1UM9mEFQEUbahSwLMi2MCMwyoiwzDMy0EDKQkq6YUD3UQw8+pEF0UR8KpSi70QWhoFjxn/YZvjlzvjNnn/NN87ngMMPMXnv//nudvfba+6BDwCJiOvBLFSrDzh8RKyTdIOke4J0y76EgYKakTZIulLQUWNMrYugFGDYiDpP0sqTrJa0HFhUixgmIiFOBb4bx1YqIJyQtk/SRXytg/xgBEWFl6yRdCnw4VSIi4kxJfs6SNCM9Z0s6o4fpYWBFWcBuSXuBqyYb3pFOkAWsfxrWoEeWxg9JX0naJ+lYSbOKSR4VkFb7Q5LmAtsmQ0BEXCtpcQI/qTTGT5K+TqCG3Z+ADb0POBgRcyW9LWlk9u3fK8B5djdwUW/HETFN0nF9Hs9G8T+nuS/qhEfE5ZKW9EAa2I8BK/N80V9EWPB2SX8D549ZxBHxgqRbJX0g6Y8EVcD5Zz/7XdL3kg5IumMiAV2iGhEbJN1WXp8jEYgIQ5zYM4CB/Lfv0uPf/fyQYP3/A8DPXaByfCPC62ANsHTcPhAR50ryLueFdTHgNDVUFhHHAz/23YkjwjvdG5L8rl0BvDfZCtKivlPS0ZK2FQszZ9xyGr1M0luSjpJ0DfBaTmc5bRP8qyWfGcDenH6qduIiVb0JXN2TBU6RNA1wiutkfeDd5wlVr0ndYJW1UFU5ERGfSTpH0iuSFgB/tVFRA/8I4H0oyxoXcykLFJ0/ADyeNdJ/2c4bWfm1cTePAQ/m9uf2bQXsAmbnDFgDvwq4P6evcWm0iXMpAr+5JgH+aejbb+afBu5t0ke/Nm0j4P5mAnsmGrxm5tcCros6WRcBcwDXJn2tBn4dcFcn8uTcRcBiYG0/iBr4jcBC+0XEaT6UdBHSRUDfV6AGfhNwSypdHnXpLuk5wLtxK+siYDswpzxqDfxmYH4qWTan01bhvgR4po2CLgL2AL4xGLUa+C3AvIhwqWL4k0uws4BP/28BTqFOpU6pdZvUVuC6iLgy3SwcUwJdCSxvA2+fLhGw/2xgV83Mu83nkp6XtFrS4SXQ1cB9beEHIWB9OhL6uiPXOi3eYrCuEciFLtq/BCxIkbvRkXSNBPi8nGVTIaBYE1XlRfZ91FQIKNZE1SY4mPNAVQxLxVxWmBs2blVST0UEqvRsAG5vKHRMs2EQMLIm0l6SXRsNgwCzb5V0RJvaKEeAL7GmtwlzC5/GtVGOgB2SLmgB08ZlHrCliWOOAH8h8beqybblwMqmg+QI8HV29rVHU5DUbhnwZI5PYwEpS7wuafSyK2egBm3vBp5t0K5dGk0C/BXl3fSBInesuvYLgY1tOsyKQBLhCDgSg7L5gA85rSxbQBLR754nB+KgpJsB7wGtrZWAAYj4NsG/35o8ObYW0CNilaTTM0A+keR3/uMMn75NOwlIIgzv9HrTBEC/SnrKR0vgz0HAu4/OAgqQiLCASySdJ8mfrArzB/Odkl4EvhwUeNHPwAT0gkWEbx4sZMcgZ7tK/L/0u8tAh/gBxwAAAABJRU5ErkJggg==\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-zoomStop{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAABC5JREFUaEPVmVvIZ1MYh59fSskFF8bxhhxKo+FGcyGFG7mZDBmZ0Mw4XDhlUmqSGOZiChFTyiFEhpliNBNRmAunuJBxmowy5VgiZ0W8eqe1p2X7773ftff6fKza7f/3rXe97+/Z67yW+J8nzYd+M3sP2CFp+dT4kwDM7GbgI0mPR4WY2d3A1cAqSQ9Fy3XZjQYws2OAXcnxGknrh8SY2VnAs8BmScuG7CP5owHcuZktBh4ATgDulXRFX1Az+w74EVgi6e3c1sz2AQ4BDk1P8zt/r5W0PS83CSBB7A/cD1wAbANWSPqmDWJmLwJnAM8AOzOxLrB5HKJJvwKftZ4XqgMkiMOBtcClwFfAIklft76wZX97LbTFfZ7/b9ZHmFW74Rows4OBY7PH+4A/RwMHtJwvlbSlBXBJam5bJC2NtO+IzUwAM/MO1ohr3ke0HP4OvAt8mDrzx8Bj3pwkXT4ruJmdB2ya006chsabWm1xRxLrbxe6S5K/9yYzWwfcAJwq6ZWur1cb4h81YGaHAWf7RONfV9K3kao0M7d7S9KZQ/YZxGpJdw3Z9+WH+8DA8Hg+8IR3YkkPRgSZ2ZFuJ2l3xL7LphbAy8BRPh9I+qlUkJldBVwPvArcKumDqI9aACuA3e0xOiJiRp/bLun0SNk9NRg1nAu7GeI9zMOSVkbjFQGkduvV/CnwnCSfvEalDvHua5mkzVGnpQC++myG2J99UpP0ZTRYY1dLfHETmhF4uaSNJQA1xdcAuEVSPun1stQWXwNgkySfAwbTXIivAeDbwhOH1M+V+BoAvwELJP3QBTEk3swWAPtK8uV0cZoyCjXBFkt6c1bkgPh8VNs4ZpNfA8B3YI+0AQrFN8UXliwjajQh97Fe0pocYKT4rZKWlLahGjXwtx1Wj/hrJN3Tke97i3Ml+RK+KNUA2CnpeI/aI96zm2VHe974Iol/o0h5Mq4B4K58C7owW2ZEtXwPnCPpJTPbs2UtHY1qAUQF53a+p3bx28zMN0PNhFg0Gs0nQNMnNgBX5mSSwrrChoE2XloLXX2iaDSaT4Au4H9tP1D6xSP2ReJrTWQRYRGbveLNbD9JfjY6mP5LTSjvE78At0nytVJvKgVYBYTOfYYCR/Ijo1EpwCLgnUjwCjavSTplyE8RQBpK/dj8oCHHE/O9/V8o6akhP2MAnk5np0O+x+b72sjF+2nfYBoDcBLgzg8c9F5u8D5wUfv6qc9NMUBqRtcCd5br6y3hR/IXS/qkxO8ogATxZFqFlsTrst2a7tZCR/m5k9EACeI+4LKJBI8CKyX9McbPJIAEcTtw3ZjgwAZJfuk9Ok0GSBD56UJUzDpJN0aNu+yqACSI09KOzN99yW/q7/Bd2FTxXr4aQCPGzHzPe3J6/GrWk98Jvw48H72CisJVB8gDm9lxwJ/tG82ouIjdX/SjzEC2QOtuAAAAAElFTkSuQmCC\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-zoomStop:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAABXBJREFUaEPVmVtsFFUYx//fLIUYTexuC1svJGjnFAkN+kJ4MCboi/GFcIklEjQFi7ozlHhJTIgxgPJA4jXAzgbBeI0gJIqBQDRReAA1+kAsaktnFRIWJIGdLRQktJ35zPSi2+3uzjk7g+i87Z7/+b7/71znzCH8zx+6Ef4Tlv0zmLscs2VZ2PyhABLpE+uZqLdgtHwiayRu9W4mUCfAKx2j5T3ZepV0NQNMTWd1l9j2AzNhbSElNgWZiVvZRwh8AMAexxBtQXqZ8poB/OAN207OY3doB4BWAjJ5QxjVkiYsuw+Mfk/Dgr6UODZOu5tjjf2nk7h6rcmF10QaJQnUxERJMDcxkGQXG/o6xeHieqEA/EDJD8/dPHjl8nYwP0aE/QPuUHv/6ln5UpAGy/6agYeY8IXG6Bk25nETEZK+OYCSAMeK6l0FkGMgB0IOjBy7+CpyAD9h45ae271YbAOADoDODQzxnMtrxPliiIRlc9Hvft/cmDEQ5djzzvi/WeOcO+TlyjVCud6V7oFkJjttYGhIaJomPCJBDJ0BnQjNAG4tDu65tKivU987DiBtPwnCDgb2FgyxSGZ8y2jKAiQydhuxpzNrvjkdIybvKAk4yITjmodu1uA3b5YYH4Nou5PSnyqXPGHZjwLYfV0nsb80grR1JWOxC8BxAnV5QHYSwz5v6tlik/F070YieolZe6BgNh+p1HpRQ0zogcZtp25zvcGFAHW5dVO6L3VMd2S6MmHZvu5HxxAPB+mLIJ5zDPF2kL5aufQcqLo8prNLQbwLjA7HFO/KGKrPdM/wdX2pWadk9JU0kQDELfsQAXfF+FrrebP1sqqhhnR2NRO/CPBRaPSq84z4VTZGJAAN6d5216NTpWu0jInSOcfA4YIhHpSp62siAZBNVqors2AARO87KX2FbEwlAH/cajzpKIDTIBx0UsLfvGp6ypofidTmGGKPbFAlgJKkV7RYnbjw9Iw/ZJON6aIyrzyEJoxX5mUFs2WnCkCU5kMDAHjFMUTxpleVJWrz4QEYux1TLJXpgethPjwAqMsx9HuDAK6X+fAAhAEMYqqzRlyqBBFk/pbN9tQpdd7kfGrmmaCGKFceZhUajkcUm5dP3f1DueBB5seVM++s5ZAfHgBee96Y+YHUJlW0zpeF0zBb5TUi/BDye4CxKW+KtcUASi0/WpGAfXlDLFAdRqF7oPSEVck8gdbkDX1LuXL/MAS4SwrGPf65Q+kJDQBGj2OKWX7WKi0PsDfy2jH+sOT/cxbAEscQ3ys5/6fn5KtVGxpgb3YZc0HBLxLR4nxK/6Yhc2L4yKq6GoXvgSCLlcsHmbTFhVTz/oSV3QXwyIaouBrdMICxORG37K0EmMWcjiGkfUkLA8e4ak9UmBOqq9GNA6gM/K+dB1TbXEavZD6SjUzGlaTmb/N3vnn6ptzz0/1vo4HPf2cIjZsT9CfYfc0xZ64PIlADyNgrwZD67hOUWKZcZjVSAohbv88huD/JJI9A861jiPuD4igBDC+llu1/Nm8MChyunK4S0/K82fxZUBxlgLiV/ZzAC4MChyg/qzEtv2Dqh2RiKAPUp3vv04j84PUyCRQ1v3iExydcP1UJogwwOoyeBfCWorkAOR1x6yY9cXHVjJMqcWsCGHmtsD8FIaqbxn2Dk6+1X+polfqUXwxYM8AoxDsgrFJpsVItAx8VGo+tQFubW0ucUACjEK+D8EItyZmxtWCKzlrqjtUJDTACMeFaSsITbXQM/WUJYVVJJAB+hvot9nyKYR0B86tmZD5AmvaGfwoLa96vHxnAmJlExl4HprkAzwUwbfh/Hr4T/g6ML2WvoGThIgcoTty49bcWIvZKbzRlzcno/gK3l1tPCk17NAAAAABJRU5ErkJggg==\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-close{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAAA2FJREFUaEPtmdtqE1EUhvdKOq0gDSiCQkEoCAW1DcyBhgpCQJAKKYI4eQJv2oeofQi98gXaWpAKiiBEBEvSOdBpoyAIguKFIAoBwWQOW1aZKZuQSeawJ00hczfJPnz/+tearNkBcsYvOOP8ZCzgtB0cOzB2IGUEBqaQpmmPcY98Pr8liuKnlPtFmm6a5nVK6RoAfHddt64oyruwiX0FmKa5TCl9hZMB4CMhRM1aBMITQrYopTdwX0rpM1mWH6UWMAwR3fA+9FNJktYSCcBJhmFsEUIeBgtk5UQIfBMAqv1cH1gDwxARAm95nldVFOVzv8KJJCBLESHwJiGkKknSl0FVH1lAFiJC4DXHcaqLi4tfB8Ef12WUQewYXjURAl+nlFZlWf4WlSu2AB5O9IKnlH7odDrVpaWlH1HhEzkQLJ7UiZDIv5+cnFTn5+d/xoFPJSCJEyHwNUqpKsvyr7jwqQXEEREC/1YQBHVhYeFPEnguAqKICIF/Y9u2WiqVWknhuQnoJ8KHO+lt8B77K4x8sVj8mwaeq4A+IhD4uDHzr5etVkstl8v/0sJzF9BLBAtJKX2BHa0syzYP+EwE9BGxs7u7q25sbHi84DMRsL6+nltZWcEO9kEX6OgL0HVdwJcRALjfK8ojnUK1Wu1coVDAyFcY+G1CSK7LjdErYsuyzruui4/Keyy8JEkqplSlUtlhXRmpx2i9Xi8IgoCRv9sNH9xjagHATpc7p/9Ddnh4eMG2bYS/EwYffI4pNj09jU6wLp1eK6Hr+iUAQPjyIPjge0w1x3HQCdat4Tdz+/v7V/L5/CYh5HZU+GCcn3IognVteO30wcHBjOd5m5TSW3Hhg/F+6qGIE/eG8kKj6/pVAMDIl5LCM4WNKYgiWBeze6W0LGvWdV2MvJIWPph/dHR0ud1uY2GzbvJ/qTcM4xohBCMv8oIP1tnb25uZmpp63uUqv2MVy7LmHMdB+CJveCadMDVRBOtu+oMt/5QY4W9mBR+s22g0ZicmJlAE63K6o0XDMJ4QQlazhg/W91MVRbBuJz/c1XV9FQBQBF7b2Nvw7OV7raVp2lwul0MRx66nOl5vNpsX2+32MgD8FkXxddbwwfrc/uAYFnCafRIdLabZkPfcsQDeEY273tiBuBHjPf7MO/Af3d0KT6EhkZgAAAAASUVORK5CYII=\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-close:hover{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAAApxJREFUaEPtmV2nVVEUht8REREnUUREREVEREREioh0+gXd1J/oT9RVf6BziogSUSIOEVEREeVcRIqIiN68jM1w7Lm+5pz7g7Wu9tdc83nmO9beY81tWPLDlpwfo8C8ExwTGBPIXIHWEiJ5y+dYM7MPmfN1Gk7yCICbAL4C2DCzF6mBjQIkLwB47IPfA1itLeHwawCO+rx3zex6CQGdo6rEFHjNecfMlMbUo0sJaTWuhtFVJBLw7wBca0q9VUDgJKtKJODfOvzHpgunk0BNiQT8G4f/1HbVdxaoIZGAf+3wn9vg9X4vgZISCfgNh//SBX6QQAmJBPwrh9/sCj9YIEciAf/Sf2O+9YHPEhgikYB/7vDf+8JnC/SRSMA/c/ifQ+CLCHSRSMA/dfhfQ+GLCTRJOFzsbfSS+iv1Vb9z4IsKNEjorUljpsePHP5PLnxxgYRE5Hzo8H9LwFcRaJB44PD/SsFXESC5DYBq/soW0MUXILnd4S8nVnlxS4jkDoe/FODXASiRmMbiXcQkdzr8xQhvZqteUiqfmMrifI2S3OXw57fCT557aUkipjP/HzKSKw5/LgUfJFRikogpza+VILnH4c+2wQcJlZokYlqzb+ZI7gNwD8CZrvBBQiUniZja7Nppkvsd/nRf+CCh0pNETK/+DQ3JAw5/aih8kFAJSiKmWO+WkuRBhz+ZCx8k9rpETLP8TT3JQw5/ohR8kFBJ3gcQUy23rULysMMfLw0fJFSakojp5m9s+Z2Uvm2O1YIPEipRScSU87YWSd4GcKM2fJBQqUoipj18c5ek4CWhY129Tcleftq5vGQlMUk9a3t9NwD9R/DDzJ7Uhg9JlPmDY1bAOfP03hvNmazG2FGgxqr2OeeYQJ/VqvHZpU/gPw7jX0B+RCgyAAAAAElFTkSuQmCC\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-narrow{background:url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAAXNSR0IArs4c6QAABNlJREFUaEPtmWmolVUUhp+XaJ5LpKQif0RkQpNE4B8bKKJBtEGlogFEi8AGG6gQ+lEWJZUQhkQWlA0alvWjsoIgApGgICusKKzIBiMaqag3lnzKOefu79v7fOdE90ILLpd7v7Xevd49rLX22mKMi8a4//xP4L9ewb5WwPYc4DZg0hAcfwhYJOnbQbCKCNg+AHgYmDHIYAnb74H5kla1xc0SsD0FWAsc3HaQArslkhYW6I1QaSRg+1Tg1ULgL4FPgfj9J7APcAhwFLB7AcZKSRcV6HWp1BKwfTzwdgbwG+Ax4Hlgg6Q/evVtx8pNBWYB52fwVki6oh8SSQK29wK+APatAXN1mJdK+rl0QNuTgduBmQ02CyUtKcWsI7AOOK0G5D1gjqT43UpszwWWNxhPlrSxBHwEAdvnAatrjN8ETpEUe3wgsT0NeB2SyXSjpFitrKQIfAUclLD8EDha0t9Z1EIF26cDL9eoz5L0TA4qRSD2d0omSvosB9jvd9uLqnPRa7pJ0pE5vFICt0hanANr+932JuCIhP1USW814ZYQ2CppXFvnSuxsn1uF4l71ByVdPSiBOyXdWuLIIDq2P68SXydMdhuVrMCxkt4dxLkSW9sR+69L6B4mKcglJUdgi6RkDWQ7ttVZwH5V6ZBb6Z2BTyS9kFK0PR14LvHtTEkvtSXwmqQRCa0qM6JG2r9kdnt0wpmzJf3V+X/bUTO9n8CbKykq4VYr8LikS3otba8HTmzh/HaTeZK6MnG1opsThd8Nku5tSyBZXNn+DjhwAAIjoovtqLuCQFSxnXKzpLvbElgl6cLECsTsRT3TVqZJeqNnC00AIlHGWemUBZKWtiWwXtJJCQK7ASuAiN+7ArnyIoJFZPivgTskxXWyS6qL04aEo7MlPd2WwC/AeEm/pgBsjwf26IeApN9rsC4HHkl8myKp9l6SC6OB1xjG2u6hxArELPdu1x/jKls3gYFRQiB5DobleODY3hOIwBBbs1PWSYqKtVZKCITxBElRZv8r0lCRXpk6L51OlBJYKyky5dDFdmTyONy79IBHohsn6YdhrEBgXCzpiWEzsB23spMTuMslzcuNl1qBR4FLawyz9XluwM7vtu8DrknYRLcu7sXR9WiUFIG9ga2JhBJAEe8jKr2SA859tx3lwfU1esskXZXDiO91XYloezzbAHCjpHtKBujVsX0osKyqZOsgYgKjXmryYZttU2PrfmBBg5ORNSOrRlMrK1XSmw9ECzFWuURmSlrTpJhrLT5VddSaMKJbETV+3F0/qCJKlA1RYhwee7k6pOc0NMqa8BtJlDR3o+a5rGS6Kp3InkEgirIoM4YhtSSyBGJ02zcBdw3DkwEwkiSKCFQkoip9YMCLTKf/0VONd4Eo4kplhqSua2cxge0j2I4ccS1wTOmoPXo/AZEQF0vabDsKuNpyOTHGdEnxXrFN+ibQQeQMIA5mZNHck1MUahG1IqKskRR/75Dq6WplHxMySVIEjPYEehyIrtrE6ieuhjsBvwFbgI+A6O/EzNeK7dnAk4UkVku6YGgECgfNqtmOR5AI3Tn5WNK2VmTrLZQboe33wjPxjqTjRiWBcKqAxI5XnFG3Ah1BIvZ46n2gq9k2aglUKxEPjdEvPaGqkF+U1JVQRzWBknM05gn8A3BFtUAnWz1iAAAAAElFTkSuQmCC\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-narrow:hover{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-expand{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-icon-expand:hover{background:url(\"data:image/png;base64,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\") no-repeat 50%;background-size:100% 100%}.jessibuca-container .jessibuca-quality-icon-text,.jessibuca-container .jessibuca-scale-icon-text{font-size:14px;width:30px;height:20px;line-height:20px;cursor:pointer}.jessibuca-container .jessibuca-speed{font-size:14px;color:#fff}.jessibuca-container .jessibuca-quality-menu-list,.jessibuca-container .jessibuca-scale-menu-list{position:absolute;left:50%;bottom:100%;visibility:hidden;opacity:0;transform:translateX(-50%);transition:visibility .3s,opacity .3s;background-color:rgba(0,0,0,.5);border-radius:4px;overflow:hidden}.jessibuca-container .jessibuca-quality-menu-list.jessibuca-quality-menu-shown,.jessibuca-container .jessibuca-quality-menu-list.jessibuca-scale-menu-shown,.jessibuca-container .jessibuca-scale-menu-list.jessibuca-quality-menu-shown,.jessibuca-container .jessibuca-scale-menu-list.jessibuca-scale-menu-shown{visibility:visible;opacity:1}.jessibuca-container .icon-title-tips{pointer-events:none;position:absolute;left:50%;bottom:100%;visibility:hidden;opacity:0;transform:translateX(-50%);transition:visibility .3s ease 0s,opacity .3s ease 0s;background-color:rgba(0,0,0,.5);border-radius:4px}.jessibuca-container .icon-title{display:inline-block;padding:5px 10px;font-size:12px;white-space:nowrap;color:#fff}.jessibuca-container .jessibuca-quality-menu{padding:8px 0}.jessibuca-container .jessibuca-quality-menu-item,.jessibuca-container .jessibuca-scale-menu-item{box-sizing:border-box;display:block;height:25px;line-height:25px;margin:0;padding:0 10px;cursor:pointer;font-size:14px;text-align:center;width:50px;color:hsla(0,0%,100%,.5);transition:color .3s,background-color .3s}.jessibuca-container .jessibuca-quality-menu-item:hover,.jessibuca-container .jessibuca-scale-menu-item:hover{background-color:hsla(0,0%,100%,.2)}.jessibuca-container .jessibuca-quality-menu-item:focus,.jessibuca-container .jessibuca-scale-menu-item:focus{outline:none}.jessibuca-container .jessibuca-quality-menu-item.jessibuca-quality-menu-item-active,.jessibuca-container .jessibuca-quality-menu-item.jessibuca-scale-menu-item-active,.jessibuca-container .jessibuca-scale-menu-item.jessibuca-quality-menu-item-active,.jessibuca-container .jessibuca-scale-menu-item.jessibuca-scale-menu-item-active{color:#2298fc}.jessibuca-container .jessibuca-volume-panel-wrap{position:absolute;left:50%;bottom:100%;visibility:hidden;opacity:0;transform:translateX(-50%) translateY(22%);transition:visibility .3s,opacity .3s;background-color:rgba(0,0,0,.5);border-radius:4px;height:120px;width:50px;overflow:hidden}.jessibuca-container .jessibuca-volume-panel-wrap.jessibuca-volume-panel-wrap-show{visibility:visible;opacity:1}.jessibuca-container .jessibuca-volume-panel{cursor:pointer;position:absolute;top:21px;height:60px;width:50px;overflow:hidden}.jessibuca-container .jessibuca-volume-panel-text{position:absolute;left:0;top:0;width:50px;height:20px;line-height:20px;text-align:center;color:#fff;font-size:12px}.jessibuca-container .jessibuca-volume-panel-handle{position:absolute;top:48px;left:50%;width:12px;height:12px;border-radius:12px;margin-left:-6px;background:#fff}.jessibuca-container .jessibuca-volume-panel-handle:before{bottom:-54px;background:#fff}.jessibuca-container .jessibuca-volume-panel-handle:after{bottom:6px;background:hsla(0,0%,100%,.2)}.jessibuca-container .jessibuca-volume-panel-handle:after,.jessibuca-container .jessibuca-volume-panel-handle:before{content:\"\";position:absolute;display:block;left:50%;width:3px;margin-left:-1px;height:60px}.jessibuca-container.jessibuca-fullscreen-web .jessibuca-controls{width:100vh}.jessibuca-container.jessibuca-fullscreen-web .jessibuca-play-big:after{transform:translate(-50%,-50%) rotate(270deg)}.jessibuca-container.jessibuca-fullscreen-web .jessibuca-loading{flex-direction:row}.jessibuca-container.jessibuca-fullscreen-web .jessibuca-loading-text{transform:rotate(270deg)}.jessibuca-container-playback .jessibuca-controls{height:48px}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center{flex:1;display:flex;box-sizing:border-box;justify-content:space-between;font-size:12px}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time{box-sizing:border-box;flex:1;position:relative;height:100%}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-inner{width:300px;height:100%;overflow-y:hidden;overflow-x:auto}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-current-time{position:absolute;left:0;top:0;height:15px;width:1px;background-color:red;text-align:center;z-index:1}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-current-time-text{position:absolute;box-sizing:border-box;padding:0 5px;width:60px;left:-25px;top:15px;border:1px solid red;height:15px;line-height:15px;cursor:move;background-color:#fff;color:#000;-webkit-user-select:none;user-select:none}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll{position:relative;width:1440px;margin:0 auto}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll.one-hour{width:1440px}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll.half-hour{width:2880px}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll.ten-min{width:8640px}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll.five-min{width:17280px}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll.one-min{width:86400px}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-list{position:relative;background-color:#ccc;height:48px}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-day{height:100%;overflow:hidden}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-one-wrap{height:8px;z-index:1}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-second-wrap{height:25px}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-btns{display:flex;align-items:center}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute-one,.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-second-one{float:left;width:1px;height:8px;margin:0;cursor:default;position:relative;z-index:1}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute-one.active,.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-second-one.active{background-color:orange;cursor:pointer}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute-one.start,.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-second-one.start{background-color:#999}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute-one:hover .jessibuca-playback-time-title-tips,.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-second-one:hover .jessibuca-playback-time-title-tips{visibility:visible;opacity:1}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-title-tips{pointer-events:none;position:absolute;left:0;top:100%;visibility:hidden;opacity:0;transform:translateX(13%);transition:visibility .3s ease 0s,opacity .3s ease 0s;background-color:#000;border-radius:4px;z-index:1}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-title-tips.jessibuca-playback-time-title-tips-left{transform:translateX(-100%)}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-title-tips .jessibuca-playback-time-title{display:inline-block;padding:2px 5px;font-size:12px;white-space:nowrap;color:#fff}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-hour,.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute{float:left;position:relative;width:60px;box-sizing:border-box;border-top:1px solid #999;-webkit-user-select:none;user-select:none;text-align:left;height:25px;line-height:25px}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-hour:first-child,.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute:first-child{border-left:0}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-hour:first-child .jessibuca-playback-time-hour-text,.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute:first-child .jessibuca-playback-time-hour-text{left:0}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-hour:after,.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute:after{content:\"\";position:absolute;left:0;top:-8px;width:1px;height:14px;background-color:#999}.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-hour-text,.jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute-text{position:absolute;left:-13px}.jessibuca-container-playback .jessibuca-playback-expand.disabled .jessibuca-icon-expand,.jessibuca-container-playback .jessibuca-playback-narrow.disabled .jessibuca-icon-narrow{cursor:no-drop}.jessibuca-container-playback.jessibuca-fullscreen-web .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-playback-time-inner{overflow-y:auto}.jessibuca-zoom-control{cursor:grab}.jessibuca-performance-panel{position:absolute;z-index:10000;left:0;top:0;padding:5px;font-size:10px;background:rgba(0,0,0,.2);color:#fff;max-height:100%;overflow-y:auto;display:none}.jessibuca-performance-panel .jessibuca-performance-item{display:flex;align-items:center;margin-top:3px;color:#fff}.jessibuca-performance-panel .jessibuca-performance-item-block{height:10px}\n/*# sourceMappingURL=data:application/json;base64,{"version":3,"sources":["style.scss"],"names":[],"mappings":"AAAA,oBACE,GACE,8BAAiC,CACnC,GACE,+BAAmC,CAAE,CAEzC,wBACE,GACE,wBAAyB,CACzB,+BAAkC,CACpC,IACE,wBAAyB,CACzB,mCAAsC,CACxC,GACE,wBAAyB,CACzB,+BAAkC,CAAE,CAExC,qCACE,cAAe,CACf,UAAW,CACX,WAAY,CACZ,oBAAuB,CAEzB,6CACE,iBAAkB,CAClB,WAAY,CACZ,YAAa,CACb,iBAAkB,CAClB,SAAU,CACV,kBAAmB,CACnB,8nsBAAwD,CACxD,yBAA0B,CAC1B,qCAA2C,CAC3C,UAAW,CACX,YAAe,CACf,yEACE,kBAAmB,CACnB,SAAY,CAEhB,8CACE,iBAAkB,CAClB,SAAU,CACV,WAAY,CACZ,YAAa,CACb,klnBAA+D,CAC/D,yBAA4B,CAC5B,yEACE,wBAA2B,CAC7B,2EACE,wBAA2B,CAC7B,2EACE,uBAA0B,CAC5B,2EACE,kBAAmB,CACnB,SAAY,CAEhB,4CACE,iBAAkB,CAClB,SAAU,CACV,QAAS,CACT,UAAW,CACX,WAAY,CACZ,eAAmB,CACnB,iBAAkB,CAClB,2BAAmC,CACnC,uEACE,SAAY,CACd,qEACE,QAAW,CACb,wEACE,SAAY,CACd,uEACE,QAAW,CAEf,0CACE,cAAe,CACf,iBAAkB,CAClB,OAAQ,CACR,QAAW,CAEb,6CACE,SAAU,CACV,QAAS,CAET,4BAAiC,CAAjC,6BAAmC,CAErC,gDACE,QAAS,CACT,UAAW,CAEX,4BAA+B,CAA/B,2BAAiC,CAEnC,+CACE,SAAU,CACV,WAAY,CAEZ,4BAA8B,CAA9B,0BAAgC,CAElC,+CACE,SAAU,CACV,QAAS,CAET,4BAAgC,CAAhC,4BAAkC,CAEpC,uCACE,iBAAkB,CAClB,UAAW,CACX,MAAO,CACP,KAAM,CACN,OAAQ,CACR,QAAS,CACT,WAAY,CACZ,UAAW,CACX,uBAAkC,CAClC,2BAA4B,CAC5B,uBAAwB,CACxB,mBAAsB,CAExB,yCACE,iBAAkB,CAClB,YAAa,CACb,WAAY,CACZ,UAAW,CACX,yBAAgC,CAChC,+CACE,cAAe,CACf,UAAW,CACX,iBAAkB,CAClB,QAAS,CACT,OAAQ,CACR,8BAAgC,CAChC,aAAc,CACd,UAAW,CACX,WAAY,CACZ,k9BAA2C,CAC3C,2BAA4B,CAC5B,uBAA6B,CAC/B,qDACE,0zBAAmD,CAEvD,0CACE,YAAa,CACb,iBAAkB,CAClB,QAAS,CACT,KAAM,CACN,aAAc,CACd,0BAA2B,CAC3B,4BAA6B,CAC7B,kBAAmB,CACnB,UAAW,CACX,WAAY,CACZ,eAAmB,CACnB,SAAU,CACV,yBAA8B,CAC9B,SAAY,CACZ,yEACE,SAAU,CACV,UAAW,CACX,kBAAmB,CACnB,iBAAkB,CAClB,yCAA4C,CAC9C,oEACE,cAAe,CACf,eAAgB,CAChB,UAAgB,CAClB,qEACE,UAAW,CACX,WAAY,CACZ,cAAiB,CAErB,8CACE,YAAa,CACb,iBAAkB,CAClB,QAAS,CACT,KAAM,CACN,aAAc,CACd,0BAA2B,CAC3B,4BAA6B,CAC7B,kBAAmB,CACnB,WAAY,CACZ,WAAY,CACZ,eAAmB,CACnB,SAAU,CACV,yBAA8B,CAC9B,SAAY,CACZ,qEACE,UAAW,CACX,WAAY,CACZ,cAAiB,CACnB,mEACE,cAAe,CACf,eAAgB,CAChB,UAAgB,CAKlB,yIACE,UAAW,CACX,WAAY,CACZ,cAAiB,CAErB,wCACE,YAAa,CACb,qBAAsB,CACtB,sBAAuB,CACvB,kBAAmB,CACnB,iBAAkB,CAClB,UAAW,CACX,MAAO,CACP,KAAM,CACN,OAAQ,CACR,QAAS,CACT,UAAW,CACX,WAAY,CACZ,mBAAsB,CAExB,6CACE,gBAAiB,CACjB,cAAe,CACf,UAAW,CACX,eAAkB,CAEpB,yCACE,wBAAyB,CACzB,qBAAsB,CACtB,YAAa,CACb,qBAAsB,CACtB,wBAAyB,CACzB,iBAAkB,CAClB,UAAW,CACX,MAAO,CACP,OAAQ,CACR,QAAS,CACT,WAAY,CACZ,UAAW,CACX,iBAAkB,CAClB,kBAAmB,CACnB,cAAe,CACf,UAAW,CACX,SAAU,CACV,iBAAkB,CAClB,8BAAgC,CAChC,wBAAiB,CAAjB,gBAAiB,CACjB,4BAA+B,CAC/B,kEACE,iBAAkB,CAClB,YAAa,CACb,sBAAuB,CACvB,aAAgB,CAChB,yFACE,kBAAmB,CACnB,SAAY,CAuCd,6rDACE,YAAe,CACnB,6HACE,SAAY,CACd,oEACE,YAAa,CACb,6BAA8B,CAC9B,WAAc,CAId,2LAFE,YAAa,CACb,kBAGqB,CAE3B,iEACE,SAAU,CACV,kBAAqB,CAEvB,2EACE,UAAY,CACZ,kBAAmB,CACnB,YAAe,CAEjB,6CACE,qBAAyB,CAE3B,6CACE,UAAW,CACX,WAAY,CACZ,kgFAAyD,CACzD,yBAA0B,CAC1B,qCAAwC,CAE1C,gDACE,0wDAA4D,CAC5D,yBAA4B,CAC5B,sDACE,8+CAAkE,CAClE,yBAA4B,CAEhC,0CACE,09BAAsD,CACtD,yBAA4B,CAC5B,gDACE,k0BAA4D,CAC5D,yBAA4B,CAEhC,2CACE,8dAAuD,CACvD,yBAA4B,CAC5B,iDACE,kcAA6D,CAC7D,yBAA4B,CAEhC,4CACE,0nCAAwD,CACxD,yBAA4B,CAC5B,kDACE,s9BAA8D,CAC9D,yBAA4B,CAEhC,gDACE,kpEAA6D,CAC7D,yBAA4B,CAC5B,sDACE,8qFAAmE,CACnE,yBAA4B,CAEhC,gDACE,8jFAA4D,CAC5D,yBAA4B,CAC5B,sDACE,0iEAAkE,CAClE,yBAA4B,CAEhC,oDACE,kyCAAiE,CACjE,yBAA4B,CAC5B,0DACE,8nCAAuE,CACvE,yBAA4B,CAEhC,2CACE,shCAAuD,CACvD,yBAA4B,CAC5B,iDACE,84BAA6D,CAC7D,yBAA4B,CAEhC,0CACE,0lHAAsD,CACtD,yBAA4B,CAC5B,gDACE,ssFAA4D,CAC5D,yBAA4B,CAEhC,yCACE,kmIAAqD,CACrD,yBAA4B,CAC5B,+CACE,klGAA2D,CAC3D,yBAA4B,CAEhC,+CACE,k5IAA4D,CAC5D,yBAA4B,CAC5B,qDACE,slIAAkE,CAClE,yBAA4B,CAEhC,iDACE,s8DAA6D,CAC7D,yBAA4B,CAC5B,uDACE,8mDAAmE,CACnE,yBAA4B,CAEhC,uDACE,0kEAAoE,CACpE,yBAA4B,CAC5B,6DACE,kmEAA0E,CAC1E,yBAA4B,CAEhC,0CACE,k6CAAsD,CACtD,yBAA4B,CAC5B,gDACE,0rCAA4D,CAC5D,yBAA4B,CAEhC,gDACE,k9CAA6D,CAC7D,yBAA4B,CAC5B,sDACE,k+CAAmE,CACnE,yBAA4B,CAEhC,0CACE,khEAAsD,CACtD,yBAA4B,CAC5B,gDACE,kpDAA4D,CAC5D,yBAA4B,CAEhC,8CACE,siDAA2D,CAC3D,yBAA4B,CAC5B,oDACE,s9DAAiE,CACjE,yBAA4B,CAEhC,2CACE,sxCAAuD,CACvD,yBAA4B,CAC5B,iDACE,8gCAA6D,CAC7D,yBAA4B,CAEhC,4CACE,0wDAAwD,CACxD,yBAA4B,CAC5B,kDACE,8mEAA8D,CAC9D,yBAA4B,CAEhC,4CACE,kgFAAwD,CACxD,yBAA4B,CAC5B,kDACE,klEAA8D,CAC9D,yBAA4B,CAEhC,kGACE,cAAe,CACf,UAAW,CACX,WAAY,CACZ,gBAAiB,CACjB,cAAiB,CAEnB,sCACE,cAAe,CACf,UAAa,CAEf,kGACE,iBAAkB,CAClB,QAAS,CACT,WAAY,CACZ,iBAAkB,CAClB,SAAU,CACV,0BAA2B,CAC3B,qCAA2C,CAC3C,+BAAoC,CACpC,iBAAkB,CAClB,eAAkB,CAClB,oTACE,kBAAmB,CACnB,SAAY,CAEhB,sCACE,mBAAoB,CACpB,iBAAkB,CAClB,QAAS,CACT,WAAY,CACZ,iBAAkB,CAClB,SAAU,CACV,0BAA2B,CAC3B,qDAA2D,CAC3D,+BAAoC,CACpC,iBAAoB,CAEtB,iCACE,oBAAqB,CACrB,gBAAiB,CACjB,cAAe,CACf,kBAAmB,CACnB,UAAc,CAEhB,6CACE,aAAgB,CAElB,kGACE,qBAAsB,CACtB,aAAc,CACd,WAAY,CACZ,gBAAiB,CACjB,QAAS,CACT,cAAe,CACf,cAAe,CACf,cAAe,CACf,iBAAkB,CAClB,UAAW,CACX,wBAA+B,CAC/B,yCAAiD,CACjD,8GACE,mCAA4C,CAC9C,8GACE,YAAe,CACjB,4UACE,aAAgB,CAEpB,kDACE,iBAAkB,CAClB,QAAS,CACT,WAAY,CACZ,iBAAkB,CAClB,SAAU,CACV,0CAA2C,CAC3C,qCAA2C,CAC3C,+BAAoC,CACpC,iBAAkB,CAClB,YAAa,CACb,UAAW,CACX,eAAkB,CAClB,mFACE,kBAAmB,CACnB,SAAY,CAEhB,6CACE,cAAe,CACf,iBAAkB,CAClB,QAAS,CACT,WAAY,CACZ,UAAW,CACX,eAAkB,CAEpB,kDACE,iBAAkB,CAClB,MAAO,CACP,KAAM,CACN,UAAW,CACX,WAAY,CACZ,gBAAiB,CACjB,iBAAkB,CAClB,UAAW,CACX,cAAiB,CAEnB,oDACE,iBAAkB,CAClB,QAAS,CACT,QAAS,CACT,UAAW,CACX,WAAY,CACZ,kBAAmB,CACnB,gBAAiB,CACjB,eAAkB,CAClB,2DACE,YAAa,CACb,eAAkB,CACpB,0DACE,UAAW,CACX,6BAAsC,CACxC,qHACE,UAAW,CACX,iBAAkB,CAClB,aAAc,CACd,QAAS,CACT,SAAU,CACV,gBAAiB,CACjB,WAAc,CAElB,kEACE,WAAc,CAEhB,wEACE,6CAAiD,CAEnD,iEACE,kBAAqB,CAEvB,sEACE,wBAA2B,CAE7B,kDACE,WAAc,CACd,wGACE,MAAO,CACP,YAAa,CACb,qBAAsB,CACtB,6BAA8B,CAC9B,cAAiB,CACjB,0IACE,qBAAsB,CACtB,MAAO,CACP,iBAAkB,CAClB,WAAc,CAChB,gJACE,WAAY,CACZ,WAAY,CACZ,iBAAkB,CAClB,eAAkB,CACpB,kJACE,iBAAkB,CAClB,MAAS,CACT,KAAM,CACN,WAAY,CACZ,SAAU,CACV,oBAAqB,CACrB,iBAAkB,CAClB,SAAY,CACd,uJACE,iBAAkB,CAClB,qBAAsB,CACtB,aAAc,CACd,UAAW,CACX,UAAW,CACX,QAAS,CACT,oBAAqB,CACrB,WAAY,CACZ,gBAAiB,CACjB,WAAY,CACZ,qBAAsB,CACtB,UAAW,CAEX,wBAAyB,CAEzB,gBAAmB,CACrB,iJACE,iBAAkB,CAClB,YAAa,CACb,aAAgB,CAChB,0JACE,YAAe,CACjB,2JACE,YAAe,CACjB,yJACE,YAAe,CACjB,0JACE,aAAgB,CAClB,yJACE,aAAgB,CACpB,+IACE,iBAAkB,CAClB,qBAAsB,CACtB,WAAc,CAChB,qIACE,WAAY,CACZ,eAAkB,CACpB,0IACE,UAAW,CACX,SAAY,CACd,6IACE,WAAc,CAChB,0IACE,YAAa,CACb,kBAAqB,CACvB,wRACE,UAAW,CACX,SAAU,CACV,UAAW,CACX,QAAS,CACT,cAAe,CACf,iBAAkB,CAClB,SAAY,CACZ,sSACE,uBAAwB,CACxB,cAAiB,CACnB,oSACE,qBAAwB,CAC1B,4WACE,kBAAmB,CACnB,SAAY,CAChB,4IACE,mBAAoB,CACpB,iBAAkB,CAClB,MAAO,CACP,QAAS,CACT,iBAAkB,CAClB,SAAU,CACV,yBAA0B,CAC1B,qDAA2D,CAC3D,qBAAuB,CACvB,iBAAkB,CAClB,SAAY,CACZ,oLACE,2BAA8B,CAChC,2KACE,oBAAqB,CACrB,eAAgB,CAChB,cAAe,CACf,kBAAmB,CACnB,UAAc,CAClB,8QACE,UAAW,CACX,iBAAkB,CAClB,UAAW,CACX,qBAAsB,CACtB,yBAA0B,CAE1B,wBAAyB,CAEzB,gBAAiB,CACjB,eAAgB,CAChB,WAAY,CACZ,gBAAmB,CACnB,sSACE,aAAgB,CAChB,4WACE,MAAS,CACb,0RACE,UAAW,CACX,iBAAkB,CAClB,MAAO,CACP,QAAS,CACT,SAAU,CACV,WAAY,CACZ,qBAAwB,CAC5B,wRACE,iBAAkB,CAClB,UAAa,CAKnB,kLACE,cAAiB,CAEnB,8IACE,eAAkB,CAEpB,wBACE,WAAc,CAEhB,6BACE,iBAAkB,CAClB,aAAc,CACd,MAAO,CACP,KAAM,CACN,WAAY,CACZ,cAAe,CACf,yBAA8B,CAC9B,UAAW,CACX,eAAgB,CAChB,eAAgB,CAChB,YAAe,CACf,yDACE,YAAa,CACb,kBAAmB,CACnB,cAAe,CACf,UAAc,CAChB,+DACE,WAAc","file":"style.scss","sourcesContent":["@keyframes rotation {\n  from {\n    -webkit-transform: rotate(0deg); }\n  to {\n    -webkit-transform: rotate(360deg); } }\n\n@keyframes magentaPulse {\n  from {\n    background-color: #630030;\n    -webkit-box-shadow: 0 0 9px #333; }\n  50% {\n    background-color: #a9014b;\n    -webkit-box-shadow: 0 0 18px #a9014b; }\n  to {\n    background-color: #630030;\n    -webkit-box-shadow: 0 0 9px #333; } }\n\n.jessibuca-container .jessibuca-icon {\n  cursor: pointer;\n  width: 16px;\n  height: 16px;\n  display: inline-block; }\n\n.jessibuca-container .jessibuca-ptz-controls {\n  position: absolute;\n  width: 156px;\n  height: 156px;\n  visibility: hidden;\n  opacity: 0;\n  border-radius: 78px;\n  background: url(\"../assets/ptz-bg.png\") no-repeat center;\n  background-size: 100% 100%;\n  transition: visibility 300ms, opacity 300ms;\n  right: 43px;\n  bottom: 135px; }\n  .jessibuca-container .jessibuca-ptz-controls.jessibuca-ptz-controls-show {\n    visibility: visible;\n    opacity: 1; }\n\n.jessibuca-container .jessibuca-ptz-bg-active {\n  visibility: hidden;\n  opacity: 0;\n  width: 156px;\n  height: 156px;\n  background: url(\"../assets/ptz-bg-active.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-ptz-bg-active.jessibuca-ptz-bg-active-up {\n    transform: rotate(-90deg); }\n  .jessibuca-container .jessibuca-ptz-bg-active.jessibuca-ptz-bg-active-left {\n    transform: rotate(180deg); }\n  .jessibuca-container .jessibuca-ptz-bg-active.jessibuca-ptz-bg-active-down {\n    transform: rotate(90deg); }\n  .jessibuca-container .jessibuca-ptz-bg-active.jessibuca-ptz-bg-active-show {\n    visibility: visible;\n    opacity: 1; }\n\n.jessibuca-container .jessibuca-ptz-control {\n  position: absolute;\n  left: 53px;\n  top: 53px;\n  width: 50px;\n  height: 50px;\n  background: #FFFFFF;\n  border-radius: 50%;\n  transition: left 300ms, top 300ms; }\n  .jessibuca-container .jessibuca-ptz-control.jessibuca-ptz-control-left {\n    left: 33px; }\n  .jessibuca-container .jessibuca-ptz-control.jessibuca-ptz-control-up {\n    top: 33px; }\n  .jessibuca-container .jessibuca-ptz-control.jessibuca-ptz-control-right {\n    left: 73px; }\n  .jessibuca-container .jessibuca-ptz-control.jessibuca-ptz-control-down {\n    top: 73px; }\n\n.jessibuca-container .jessibuca-ptz-arrow {\n  cursor: pointer;\n  position: absolute;\n  width: 0;\n  height: 0; }\n\n.jessibuca-container .jessibuca-ptz-arrow-up {\n  left: 71px;\n  top: 15px;\n  border: 7px solid transparent;\n  border-bottom: 10px solid #FFFFFF; }\n\n.jessibuca-container .jessibuca-ptz-arrow-right {\n  top: 71px;\n  right: 15px;\n  border: 7px solid transparent;\n  border-left: 10px solid #FFFFFF; }\n\n.jessibuca-container .jessibuca-ptz-arrow-down {\n  left: 71px;\n  bottom: 15px;\n  border: 7px solid transparent;\n  border-top: 10px solid #FFFFFF; }\n\n.jessibuca-container .jessibuca-ptz-arrow-left {\n  left: 15px;\n  top: 71px;\n  border: 7px solid transparent;\n  border-right: 10px solid #FFFFFF; }\n\n.jessibuca-container .jessibuca-poster {\n  position: absolute;\n  z-index: 10;\n  left: 0;\n  top: 0;\n  right: 0;\n  bottom: 0;\n  height: 100%;\n  width: 100%;\n  background-position: center center;\n  background-repeat: no-repeat;\n  background-size: contain;\n  pointer-events: none; }\n\n.jessibuca-container .jessibuca-play-big {\n  position: absolute;\n  display: none;\n  height: 100%;\n  width: 100%;\n  background: rgba(0, 0, 0, 0.4); }\n  .jessibuca-container .jessibuca-play-big:after {\n    cursor: pointer;\n    content: '';\n    position: absolute;\n    left: 50%;\n    top: 50%;\n    transform: translate(-50%, -50%);\n    display: block;\n    width: 48px;\n    height: 48px;\n    background-image: url(\"../assets/play.png\");\n    background-repeat: no-repeat;\n    background-position: center; }\n  .jessibuca-container .jessibuca-play-big:hover:after {\n    background-image: url(\"../assets/play-hover.png\"); }\n\n.jessibuca-container .jessibuca-recording {\n  display: none;\n  position: absolute;\n  left: 50%;\n  top: 0;\n  padding: 0 3px;\n  transform: translateX(-50%);\n  justify-content: space-around;\n  align-items: center;\n  width: 95px;\n  height: 20px;\n  background: #000000;\n  opacity: 1;\n  border-radius: 0px 0px 8px 8px;\n  z-index: 1; }\n  .jessibuca-container .jessibuca-recording .jessibuca-recording-red-point {\n    width: 8px;\n    height: 8px;\n    background: #FF1F1F;\n    border-radius: 50%;\n    animation: magentaPulse 1s linear infinite; }\n  .jessibuca-container .jessibuca-recording .jessibuca-recording-time {\n    font-size: 14px;\n    font-weight: 500;\n    color: #DDDDDD; }\n  .jessibuca-container .jessibuca-recording .jessibuca-icon-recordStop {\n    width: 16px;\n    height: 16px;\n    cursor: pointer; }\n\n.jessibuca-container .jessibuca-zoom-controls {\n  display: none;\n  position: absolute;\n  left: 50%;\n  top: 0;\n  padding: 0 3px;\n  transform: translateX(-50%);\n  justify-content: space-around;\n  align-items: center;\n  width: 150px;\n  height: 30px;\n  background: #000000;\n  opacity: 1;\n  border-radius: 0px 0px 8px 8px;\n  z-index: 1; }\n  .jessibuca-container .jessibuca-zoom-controls .jessibuca-zoom-narrow {\n    width: 16px;\n    height: 16px;\n    cursor: pointer; }\n  .jessibuca-container .jessibuca-zoom-controls .jessibuca-zoom-tips {\n    font-size: 14px;\n    font-weight: 500;\n    color: #DDDDDD; }\n  .jessibuca-container .jessibuca-zoom-controls .jessibuca-zoom-expand {\n    width: 16px;\n    height: 16px;\n    cursor: pointer; }\n  .jessibuca-container .jessibuca-zoom-controls .jessibuca-zoom-stop2 {\n    width: 16px;\n    height: 16px;\n    cursor: pointer; }\n\n.jessibuca-container .jessibuca-loading {\n  display: none;\n  flex-direction: column;\n  justify-content: center;\n  align-items: center;\n  position: absolute;\n  z-index: 20;\n  left: 0;\n  top: 0;\n  right: 0;\n  bottom: 0;\n  width: 100%;\n  height: 100%;\n  pointer-events: none; }\n\n.jessibuca-container .jessibuca-loading-text {\n  line-height: 20px;\n  font-size: 13px;\n  color: #fff;\n  margin-top: 10px; }\n\n.jessibuca-container .jessibuca-controls {\n  background-color: #161616;\n  box-sizing: border-box;\n  display: flex;\n  flex-direction: column;\n  justify-content: flex-end;\n  position: absolute;\n  z-index: 40;\n  left: 0;\n  right: 0;\n  bottom: 0;\n  height: 38px;\n  width: 100%;\n  padding-left: 13px;\n  padding-right: 13px;\n  font-size: 14px;\n  color: #fff;\n  opacity: 0;\n  visibility: hidden;\n  transition: all 0.2s ease-in-out;\n  user-select: none;\n  transition: width .5s ease-in; }\n  .jessibuca-container .jessibuca-controls .jessibuca-controls-item {\n    position: relative;\n    display: flex;\n    justify-content: center;\n    padding: 0 8px; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item:hover .icon-title-tips {\n      visibility: visible;\n      opacity: 1; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-microphone-close {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-icon-audio {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-play {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-pause {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-fullscreen-exit {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-screenshot {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-ptz {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-performance {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-face {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-quality-menu {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-scale-menu {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-volume {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-ptz-active {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-performance-active {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-face-active {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-record {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-fullscreen {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-record-stop {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-zoom {\n      display: none; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-item.jessibuca-zoom-stop {\n      display: none; }\n  .jessibuca-container .jessibuca-controls .jessibuca-icon-audio, .jessibuca-container .jessibuca-controls .jessibuca-icon-mute {\n    z-index: 1; }\n  .jessibuca-container .jessibuca-controls .jessibuca-controls-bottom {\n    display: flex;\n    justify-content: space-between;\n    height: 100%; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-left {\n      display: flex;\n      align-items: center; }\n    .jessibuca-container .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-right {\n      display: flex;\n      align-items: center; }\n\n.jessibuca-container.jessibuca-controls-show .jessibuca-controls {\n  opacity: 1;\n  visibility: visible; }\n\n.jessibuca-container.jessibuca-controls-show-auto-hide .jessibuca-controls {\n  opacity: 0.8;\n  visibility: visible;\n  display: none; }\n\n.jessibuca-container.jessibuca-hide-cursor * {\n  cursor: none !important; }\n\n.jessibuca-container .jessibuca-icon-loading {\n  width: 50px;\n  height: 50px;\n  background: url(\"../assets/loading.png\") no-repeat center;\n  background-size: 100% 100%;\n  animation: rotation 1s linear infinite; }\n\n.jessibuca-container .jessibuca-icon-screenshot {\n  background: url(\"../assets/screenshot.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-screenshot:hover {\n    background: url(\"../assets/screenshot-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-play {\n  background: url(\"../assets/play.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-play:hover {\n    background: url(\"../assets/play-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-pause {\n  background: url(\"../assets/pause.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-pause:hover {\n    background: url(\"../assets/pause-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-record {\n  background: url(\"../assets/record.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-record:hover {\n    background: url(\"../assets/record-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-recordStop {\n  background: url(\"../assets/record-stop.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-recordStop:hover {\n    background: url(\"../assets/record-stop-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-fullscreen {\n  background: url(\"../assets/fullscreen.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-fullscreen:hover {\n    background: url(\"../assets/fullscreen-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-fullscreenExit {\n  background: url(\"../assets/exit-fullscreen.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-fullscreenExit:hover {\n    background: url(\"../assets/exit-fullscreen-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-audio {\n  background: url(\"../assets/audio.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-audio:hover {\n    background: url(\"../assets/audio-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-mute {\n  background: url(\"../assets/mute.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-mute:hover {\n    background: url(\"../assets/mute-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-ptz {\n  background: url(\"../assets/ptz.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-ptz:hover {\n    background: url(\"../assets/ptz-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-ptzActive {\n  background: url(\"../assets/ptz-active.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-ptzActive:hover {\n    background: url(\"../assets/ptz-active-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-performance {\n  background: url(\"../assets/performance.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-performance:hover {\n    background: url(\"../assets/performance-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-performanceActive {\n  background: url(\"../assets/performance-active.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-performanceActive:hover {\n    background: url(\"../assets/performance-active-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-face {\n  background: url(\"../assets/face.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-face:hover {\n    background: url(\"../assets/face-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-faceActive {\n  background: url(\"../assets/face-active.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-faceActive:hover {\n    background: url(\"../assets/face-active-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-zoom {\n  background: url(\"../assets/zoom.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-zoom:hover {\n    background: url(\"../assets/zoom-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-zoomStop {\n  background: url(\"../assets/zoom-stop.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-zoomStop:hover {\n    background: url(\"../assets/zoom-stop-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-close {\n  background: url(\"../assets/close.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-close:hover {\n    background: url(\"../assets/close-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-narrow {\n  background: url(\"../assets/narrow.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-narrow:hover {\n    background: url(\"../assets/narrow-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-icon-expand {\n  background: url(\"../assets/expand.png\") no-repeat center;\n  background-size: 100% 100%; }\n  .jessibuca-container .jessibuca-icon-expand:hover {\n    background: url(\"../assets/expand-hover.png\") no-repeat center;\n    background-size: 100% 100%; }\n\n.jessibuca-container .jessibuca-quality-icon-text, .jessibuca-container .jessibuca-scale-icon-text {\n  font-size: 14px;\n  width: 30px;\n  height: 20px;\n  line-height: 20px;\n  cursor: pointer; }\n\n.jessibuca-container .jessibuca-speed {\n  font-size: 14px;\n  color: #fff; }\n\n.jessibuca-container .jessibuca-quality-menu-list, .jessibuca-container .jessibuca-scale-menu-list {\n  position: absolute;\n  left: 50%;\n  bottom: 100%;\n  visibility: hidden;\n  opacity: 0;\n  transform: translateX(-50%);\n  transition: visibility 300ms, opacity 300ms;\n  background-color: rgba(0, 0, 0, 0.5);\n  border-radius: 4px;\n  overflow: hidden; }\n  .jessibuca-container .jessibuca-quality-menu-list.jessibuca-quality-menu-shown, .jessibuca-container .jessibuca-quality-menu-list.jessibuca-scale-menu-shown, .jessibuca-container .jessibuca-scale-menu-list.jessibuca-quality-menu-shown, .jessibuca-container .jessibuca-scale-menu-list.jessibuca-scale-menu-shown {\n    visibility: visible;\n    opacity: 1; }\n\n.jessibuca-container .icon-title-tips {\n  pointer-events: none;\n  position: absolute;\n  left: 50%;\n  bottom: 100%;\n  visibility: hidden;\n  opacity: 0;\n  transform: translateX(-50%);\n  transition: visibility 300ms ease 0s, opacity 300ms ease 0s;\n  background-color: rgba(0, 0, 0, 0.5);\n  border-radius: 4px; }\n\n.jessibuca-container .icon-title {\n  display: inline-block;\n  padding: 5px 10px;\n  font-size: 12px;\n  white-space: nowrap;\n  color: white; }\n\n.jessibuca-container .jessibuca-quality-menu {\n  padding: 8px 0; }\n\n.jessibuca-container .jessibuca-quality-menu-item, .jessibuca-container .jessibuca-scale-menu-item {\n  box-sizing: border-box;\n  display: block;\n  height: 25px;\n  line-height: 25px;\n  margin: 0;\n  padding: 0 10px;\n  cursor: pointer;\n  font-size: 14px;\n  text-align: center;\n  width: 50px;\n  color: rgba(255, 255, 255, 0.5);\n  transition: color 300ms, background-color 300ms; }\n  .jessibuca-container .jessibuca-quality-menu-item:hover, .jessibuca-container .jessibuca-scale-menu-item:hover {\n    background-color: rgba(255, 255, 255, 0.2); }\n  .jessibuca-container .jessibuca-quality-menu-item:focus, .jessibuca-container .jessibuca-scale-menu-item:focus {\n    outline: none; }\n  .jessibuca-container .jessibuca-quality-menu-item.jessibuca-quality-menu-item-active, .jessibuca-container .jessibuca-quality-menu-item.jessibuca-scale-menu-item-active, .jessibuca-container .jessibuca-scale-menu-item.jessibuca-quality-menu-item-active, .jessibuca-container .jessibuca-scale-menu-item.jessibuca-scale-menu-item-active {\n    color: #2298FC; }\n\n.jessibuca-container .jessibuca-volume-panel-wrap {\n  position: absolute;\n  left: 50%;\n  bottom: 100%;\n  visibility: hidden;\n  opacity: 0;\n  transform: translateX(-50%) translateY(22%);\n  transition: visibility 300ms, opacity 300ms;\n  background-color: rgba(0, 0, 0, 0.5);\n  border-radius: 4px;\n  height: 120px;\n  width: 50px;\n  overflow: hidden; }\n  .jessibuca-container .jessibuca-volume-panel-wrap.jessibuca-volume-panel-wrap-show {\n    visibility: visible;\n    opacity: 1; }\n\n.jessibuca-container .jessibuca-volume-panel {\n  cursor: pointer;\n  position: absolute;\n  top: 21px;\n  height: 60px;\n  width: 50px;\n  overflow: hidden; }\n\n.jessibuca-container .jessibuca-volume-panel-text {\n  position: absolute;\n  left: 0;\n  top: 0;\n  width: 50px;\n  height: 20px;\n  line-height: 20px;\n  text-align: center;\n  color: #fff;\n  font-size: 12px; }\n\n.jessibuca-container .jessibuca-volume-panel-handle {\n  position: absolute;\n  top: 48px;\n  left: 50%;\n  width: 12px;\n  height: 12px;\n  border-radius: 12px;\n  margin-left: -6px;\n  background: #fff; }\n  .jessibuca-container .jessibuca-volume-panel-handle::before {\n    bottom: -54px;\n    background: #fff; }\n  .jessibuca-container .jessibuca-volume-panel-handle::after {\n    bottom: 6px;\n    background: rgba(255, 255, 255, 0.2); }\n  .jessibuca-container .jessibuca-volume-panel-handle::before, .jessibuca-container .jessibuca-volume-panel-handle::after {\n    content: '';\n    position: absolute;\n    display: block;\n    left: 50%;\n    width: 3px;\n    margin-left: -1px;\n    height: 60px; }\n\n.jessibuca-container.jessibuca-fullscreen-web .jessibuca-controls {\n  width: 100vh; }\n\n.jessibuca-container.jessibuca-fullscreen-web .jessibuca-play-big:after {\n  transform: translate(-50%, -50%) rotate(270deg); }\n\n.jessibuca-container.jessibuca-fullscreen-web .jessibuca-loading {\n  flex-direction: row; }\n\n.jessibuca-container.jessibuca-fullscreen-web .jessibuca-loading-text {\n  transform: rotate(270deg); }\n\n.jessibuca-container-playback .jessibuca-controls {\n  height: 48px; }\n  .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center {\n    flex: 1;\n    display: flex;\n    box-sizing: border-box;\n    justify-content: space-between;\n    font-size: 12px; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time {\n      box-sizing: border-box;\n      flex: 1;\n      position: relative;\n      height: 100%; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-inner {\n      width: 300px;\n      height: 100%;\n      overflow-y: hidden;\n      overflow-x: auto; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-current-time {\n      position: absolute;\n      left: 0px;\n      top: 0;\n      height: 15px;\n      width: 1px;\n      background-color: red;\n      text-align: center;\n      z-index: 1; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-current-time-text {\n      position: absolute;\n      box-sizing: border-box;\n      padding: 0 5px;\n      width: 60px;\n      left: -25px;\n      top: 15px;\n      border: 1px solid red;\n      height: 15px;\n      line-height: 15px;\n      cursor: move;\n      background-color: #fff;\n      color: #000;\n      -ms-user-select: none;\n      -webkit-user-select: none;\n      -moz-user-select: none;\n      user-select: none; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll {\n      position: relative;\n      width: 1440px;\n      margin: 0 auto; }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll.one-hour {\n        width: 1440px; }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll.half-hour {\n        width: 2880px; }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll.ten-min {\n        width: 8640px; }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll.five-min {\n        width: 17280px; }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-scroll.one-min {\n        width: 86400px; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-time-list {\n      position: relative;\n      background-color: #ccc;\n      height: 48px; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-day {\n      height: 100%;\n      overflow: hidden; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-one-wrap {\n      height: 8px;\n      z-index: 1; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-second-wrap {\n      height: 25px; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-controls-playback-btns {\n      display: flex;\n      align-items: center; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute-one, .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-second-one {\n      float: left;\n      width: 1px;\n      height: 8px;\n      margin: 0;\n      cursor: default;\n      position: relative;\n      z-index: 1; }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute-one.active, .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-second-one.active {\n        background-color: orange;\n        cursor: pointer; }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute-one.start, .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-second-one.start {\n        background-color: #999; }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute-one:hover .jessibuca-playback-time-title-tips, .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-second-one:hover .jessibuca-playback-time-title-tips {\n        visibility: visible;\n        opacity: 1; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-title-tips {\n      pointer-events: none;\n      position: absolute;\n      left: 0;\n      top: 100%;\n      visibility: hidden;\n      opacity: 0;\n      transform: translateX(13%);\n      transition: visibility 300ms ease 0s, opacity 300ms ease 0s;\n      background-color: black;\n      border-radius: 4px;\n      z-index: 1; }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-title-tips.jessibuca-playback-time-title-tips-left {\n        transform: translateX(-100%); }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-title-tips .jessibuca-playback-time-title {\n        display: inline-block;\n        padding: 2px 5px;\n        font-size: 12px;\n        white-space: nowrap;\n        color: white; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-hour, .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute {\n      float: left;\n      position: relative;\n      width: 60px;\n      box-sizing: border-box;\n      border-top: 1px solid #999;\n      -ms-user-select: none;\n      -webkit-user-select: none;\n      -moz-user-select: none;\n      user-select: none;\n      text-align: left;\n      height: 25px;\n      line-height: 25px; }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-hour:first-child, .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute:first-child {\n        border-left: 0; }\n        .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-hour:first-child .jessibuca-playback-time-hour-text, .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute:first-child .jessibuca-playback-time-hour-text {\n          left: 0; }\n      .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-hour:after, .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute:after {\n        content: '';\n        position: absolute;\n        left: 0;\n        top: -8px;\n        width: 1px;\n        height: 14px;\n        background-color: #999; }\n    .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-hour-text, .jessibuca-container-playback .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-center .jessibuca-playback-time-minute-text {\n      position: absolute;\n      left: -13px; }\n\n.jessibuca-container-playback .jessibuca-playback-narrow.disabled .jessibuca-icon-narrow {\n  cursor: no-drop; }\n\n.jessibuca-container-playback .jessibuca-playback-expand.disabled .jessibuca-icon-expand {\n  cursor: no-drop; }\n\n.jessibuca-container-playback.jessibuca-fullscreen-web .jessibuca-controls .jessibuca-controls-bottom .jessibuca-controls-playback-time-inner {\n  overflow-y: auto; }\n\n.jessibuca-zoom-control {\n  cursor: grab; }\n\n.jessibuca-performance-panel {\n  position: absolute;\n  z-index: 10000;\n  left: 0;\n  top: 0;\n  padding: 5px;\n  font-size: 10px;\n  background: rgba(0, 0, 0, 0.2);\n  color: #fff;\n  max-height: 100%;\n  overflow-y: auto;\n  display: none; }\n  .jessibuca-performance-panel .jessibuca-performance-item {\n    display: flex;\n    align-items: center;\n    margin-top: 3px;\n    color: white; }\n  .jessibuca-performance-panel .jessibuca-performance-item-block {\n    height: 10px; }\n"]} */";
    styleInject(css_248z$1);

    // todo: 待定
    var hotkey = ((player, control) => {
      const {
        events: {
          proxy
        }
      } = player;
      const keys = {};

      function addHotkey(key, event) {
        if (keys[key]) {
          keys[key].push(event);
        } else {
          keys[key] = [event];
        }
      } //


      addHotkey(HOT_KEY.esc, () => {
        if (player.fullscreen) {
          player.fullscreen = false;
        }
      }); //

      addHotkey(HOT_KEY.arrowUp, () => {
        player.volume += 0.05;
      }); //

      addHotkey(HOT_KEY.arrowDown, () => {
        player.volume -= 0.05;
      });
      proxy(window, 'keydown', event => {
        if (control.isFocus) {
          const tag = document.activeElement.tagName.toUpperCase();
          const editable = document.activeElement.getAttribute('contenteditable');

          if (tag !== 'INPUT' && tag !== 'TEXTAREA' && editable !== '' && editable !== 'true') {
            const events = keys[event.keyCode];

            if (events) {
              event.preventDefault();
              events.forEach(fn => fn());
            }
          }
        }
      });
    });

    class Control {
      constructor(player) {
        this.player = player;
        template(player, this);
        property(player, this);
        observer$1(player, this);
        events(player, this);

        if (player._opt.hotKey) {
          hotkey(player, this);
        }

        this.player.debug.log('Control', 'init');
      }

      destroy() {
        if (this.$performancePanel) {
          this.$performancePanel.innerHTML = '';
        }

        if (this.$poster) {
          this.player.$container.removeChild(this.$poster);
        }

        if (this.$loading) {
          this.player.$container.removeChild(this.$loading);
        }

        if (this.$controls) {
          this.player.$container.removeChild(this.$controls);
        }

        if (this.$playBig) {
          this.player.$container.removeChild(this.$playBig);
        }

        if (this.$recording) {
          this.player.$container.removeChild(this.$recording);
        }

        if (this.$ptzControl) {
          this.player.$container.removeChild(this.$ptzControl);
        }

        if (this.$zoomControls) {
          this.player.$container.removeChild(this.$zoomControls);
        }

        this.player.$container.classList.remove('jessibuca-controls-show-auto-hide');
        this.player.$container.classList.remove('jessibuca-controls-show');
        this.player.debug.log('control', 'destroy');
      }

      autoSize() {
        const player = this.player;
        player.$container.style.padding = '0 0';
        const playerWidth = player.width;
        const playerHeight = player.height;
        const playerRatio = playerWidth / playerHeight;
        const canvasWidth = player.video.$videoElement.width;
        const canvasHeight = player.video.$videoElement.height;
        const canvasRatio = canvasWidth / canvasHeight;

        if (playerRatio > canvasRatio) {
          const padding = (playerWidth - playerHeight * canvasRatio) / 2;
          player.$container.style.padding = `0 ${padding}px`;
        } else {
          const padding = (playerHeight - playerWidth / canvasRatio) / 2;
          player.$container.style.padding = `${padding}px 0`;
        }
      }

    }

    var css_248z = ".jessibuca-container{position:relative;width:100%;height:100%;overflow:hidden}.jessibuca-container.jessibuca-fullscreen-web{position:fixed;z-index:9999;left:0;top:0;right:0;bottom:0;width:100vw!important;height:100vh!important;background:#000}\n/*# sourceMappingURL=data:application/json;base64,eyJ2ZXJzaW9uIjozLCJzb3VyY2VzIjpbInN0eWxlLnNjc3MiXSwibmFtZXMiOltdLCJtYXBwaW5ncyI6IkFBQUEscUJBQ0UsaUJBQWtCLENBQ2xCLFVBQVcsQ0FDWCxXQUFZLENBQ1osZUFBa0IsQ0FDbEIsOENBQ0UsY0FBZSxDQUNmLFlBQWEsQ0FDYixNQUFPLENBQ1AsS0FBTSxDQUNOLE9BQVEsQ0FDUixRQUFTLENBQ1QscUJBQXVCLENBQ3ZCLHNCQUF3QixDQUN4QixlQUFrQiIsImZpbGUiOiJzdHlsZS5zY3NzIiwic291cmNlc0NvbnRlbnQiOlsiLmplc3NpYnVjYS1jb250YWluZXIge1xuICBwb3NpdGlvbjogcmVsYXRpdmU7XG4gIHdpZHRoOiAxMDAlO1xuICBoZWlnaHQ6IDEwMCU7XG4gIG92ZXJmbG93OiBoaWRkZW47IH1cbiAgLmplc3NpYnVjYS1jb250YWluZXIuamVzc2lidWNhLWZ1bGxzY3JlZW4td2ViIHtcbiAgICBwb3NpdGlvbjogZml4ZWQ7XG4gICAgei1pbmRleDogOTk5OTtcbiAgICBsZWZ0OiAwO1xuICAgIHRvcDogMDtcbiAgICByaWdodDogMDtcbiAgICBib3R0b206IDA7XG4gICAgd2lkdGg6IDEwMHZ3ICFpbXBvcnRhbnQ7XG4gICAgaGVpZ2h0OiAxMDB2aCAhaW1wb3J0YW50O1xuICAgIGJhY2tncm91bmQ6ICMwMDA7IH1cbiJdfQ== */";
    styleInject(css_248z);

    var observer = (player => {
      const {
        _opt,
        debug,
        events: {
          proxy
        }
      } = player;

      if (_opt.supportDblclickFullscreen) {
        proxy(player.$container, 'dblclick', e => {
          const target = getTarget(e);
          const nodeName = target.nodeName.toLowerCase();

          if (nodeName === 'canvas' || nodeName === 'video') {
            player.fullscreen = !player.fullscreen;
          }
        });
      } //


      proxy(document, 'visibilitychange', () => {
        player.visibility = "visible" === document.visibilityState;
        debug.log('visibilitychange', document.visibilityState);

        if (_opt.hiddenAutoPause) {
          debug.log('visibilitychange', 'hiddenAutoPause is true ', document.visibilityState, player._isPlayingBeforePageHidden);

          if ("visible" === document.visibilityState) {
            if (player._isPlayingBeforePageHidden) {
              player.play();
            }
          } else {
            player._isPlayingBeforePageHidden = player.playing; // hidden

            if (player.playing) {
              player.pause();
            }
          }
        }
      });
      proxy(window, 'fullscreenchange', () => {
        //
        if (player.keepScreenOn !== null && "visible" === document.visibilityState) {
          player.enableWakeLock();
        }
      });
    });

    class MP4$1 {
      static init() {
        MP4$1.types = {
          avc1: [],
          avcC: [],
          hvc1: [],
          hvcC: [],
          btrt: [],
          dinf: [],
          dref: [],
          esds: [],
          ftyp: [],
          hdlr: [],
          mdat: [],
          mdhd: [],
          mdia: [],
          mfhd: [],
          minf: [],
          moof: [],
          moov: [],
          mp4a: [],
          mvex: [],
          mvhd: [],
          sdtp: [],
          stbl: [],
          stco: [],
          stsc: [],
          stsd: [],
          stsz: [],
          stts: [],
          tfdt: [],
          tfhd: [],
          traf: [],
          trak: [],
          trun: [],
          trex: [],
          tkhd: [],
          vmhd: [],
          smhd: []
        };

        for (let name in MP4$1.types) {
          if (MP4$1.types.hasOwnProperty(name)) {
            MP4$1.types[name] = [name.charCodeAt(0), name.charCodeAt(1), name.charCodeAt(2), name.charCodeAt(3)];
          }
        }

        let constants = MP4$1.constants = {};
        constants.FTYP = new Uint8Array([0x69, 0x73, 0x6F, 0x6D, // major_brand: isom
        0x0, 0x0, 0x0, 0x1, // minor_version: 0x01
        0x69, 0x73, 0x6F, 0x6D, // isom
        0x61, 0x76, 0x63, 0x31 // avc1
        ]);
        constants.STSD_PREFIX = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x01 // entry_count
        ]);
        constants.STTS = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00 // entry_count
        ]);
        constants.STSC = constants.STCO = constants.STTS;
        constants.STSZ = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00, // sample_size
        0x00, 0x00, 0x00, 0x00 // sample_count
        ]);
        constants.HDLR_VIDEO = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00, // pre_defined
        0x76, 0x69, 0x64, 0x65, // handler_type: 'vide'
        0x00, 0x00, 0x00, 0x00, // reserved: 3 * 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x56, 0x69, 0x64, 0x65, 0x6F, 0x48, 0x61, 0x6E, 0x64, 0x6C, 0x65, 0x72, 0x00 // name: VideoHandler
        ]);
        constants.HDLR_AUDIO = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00, // pre_defined
        0x73, 0x6F, 0x75, 0x6E, // handler_type: 'soun'
        0x00, 0x00, 0x00, 0x00, // reserved: 3 * 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x53, 0x6F, 0x75, 0x6E, 0x64, 0x48, 0x61, 0x6E, 0x64, 0x6C, 0x65, 0x72, 0x00 // name: SoundHandler
        ]);
        constants.DREF = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x01, // entry_count
        0x00, 0x00, 0x00, 0x0C, // entry_size
        0x75, 0x72, 0x6C, 0x20, // type 'url '
        0x00, 0x00, 0x00, 0x01 // version(0) + flags
        ]); // Sound media header

        constants.SMHD = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00 // balance(2) + reserved(2)
        ]); // video media header

        constants.VMHD = new Uint8Array([0x00, 0x00, 0x00, 0x01, // version(0) + flags
        0x00, 0x00, // graphicsmode: 2 bytes
        0x00, 0x00, 0x00, 0x00, // opcolor: 3 * 2 bytes
        0x00, 0x00]);
      } // Generate a box


      static box(type) {
        let size = 8;
        let result = null;
        let datas = Array.prototype.slice.call(arguments, 1);
        let arrayCount = datas.length;

        for (let i = 0; i < arrayCount; i++) {
          size += datas[i].byteLength;
        }

        result = new Uint8Array(size);
        result[0] = size >>> 24 & 0xFF; // size

        result[1] = size >>> 16 & 0xFF;
        result[2] = size >>> 8 & 0xFF;
        result[3] = size & 0xFF;
        result.set(type, 4); // type

        let offset = 8;

        for (let i = 0; i < arrayCount; i++) {
          // data body
          result.set(datas[i], offset);
          offset += datas[i].byteLength;
        }

        return result;
      } // emit ftyp & moov

      /**
       * ftyp box与Moov box绑定，描述数据的类型、兼容协议以及视频参数
       * @param meta
       * @returns {Uint8Array}
       */


      static generateInitSegment(meta) {
        let ftyp = MP4$1.box(MP4$1.types.ftyp, MP4$1.constants.FTYP);
        let moov = MP4$1.moov(meta);
        let result = new Uint8Array(ftyp.byteLength + moov.byteLength);
        result.set(ftyp, 0);
        result.set(moov, ftyp.byteLength);
        return result;
      } // Movie metadata box


      static moov(meta) {
        let mvhd = MP4$1.mvhd(meta.timescale, meta.duration);
        let trak = MP4$1.trak(meta);
        let mvex = MP4$1.mvex(meta);
        return MP4$1.box(MP4$1.types.moov, mvhd, trak, mvex);
      } // Movie header box


      static mvhd(timescale, duration) {
        return MP4$1.box(MP4$1.types.mvhd, new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00, // creation_time
        0x00, 0x00, 0x00, 0x00, // modification_time
        timescale >>> 24 & 0xFF, // timescale: 4 bytes
        timescale >>> 16 & 0xFF, timescale >>> 8 & 0xFF, timescale & 0xFF, duration >>> 24 & 0xFF, // duration: 4 bytes
        duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, 0x00, 0x01, 0x00, 0x00, // Preferred rate: 1.0
        0x01, 0x00, 0x00, 0x00, // PreferredVolume(1.0, 2bytes) + reserved(2bytes)
        0x00, 0x00, 0x00, 0x00, // reserved: 4 + 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, // ----begin composition matrix----
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // ----end composition matrix----
        0x00, 0x00, 0x00, 0x00, // ----begin pre_defined 6 * 4 bytes----
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // ----end pre_defined 6 * 4 bytes----
        0xFF, 0xFF, 0xFF, 0xFF // next_track_ID
        ]));
      } // Track box


      static trak(meta) {
        return MP4$1.box(MP4$1.types.trak, MP4$1.tkhd(meta), MP4$1.mdia(meta));
      } // Track header box


      static tkhd(meta) {
        let trackId = meta.id,
            duration = meta.duration;
        let width = meta.presentWidth,
            height = meta.presentHeight;
        return MP4$1.box(MP4$1.types.tkhd, new Uint8Array([0x00, 0x00, 0x00, 0x07, // version(0) + flags
        0x00, 0x00, 0x00, 0x00, // creation_time
        0x00, 0x00, 0x00, 0x00, // modification_time
        trackId >>> 24 & 0xFF, // track_ID: 4 bytes
        trackId >>> 16 & 0xFF, trackId >>> 8 & 0xFF, trackId & 0xFF, 0x00, 0x00, 0x00, 0x00, // reserved: 4 bytes
        duration >>> 24 & 0xFF, // duration: 4 bytes
        duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, 0x00, 0x00, 0x00, 0x00, // reserved: 2 * 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // layer(2bytes) + alternate_group(2bytes)
        0x00, 0x00, 0x00, 0x00, // volume(2bytes) + reserved(2bytes)
        0x00, 0x01, 0x00, 0x00, // ----begin composition matrix----
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // ----end composition matrix----
        width >>> 8 & 0xFF, // width and height
        width & 0xFF, 0x00, 0x00, height >>> 8 & 0xFF, height & 0xFF, 0x00, 0x00]));
      }

      static mdia(meta) {
        return MP4$1.box(MP4$1.types.mdia, MP4$1.mdhd(meta), MP4$1.hdlr(meta), MP4$1.minf(meta));
      } // Media header box


      static mdhd(meta) {
        let timescale = meta.timescale;
        let duration = meta.duration;
        return MP4$1.box(MP4$1.types.mdhd, new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        0x00, 0x00, 0x00, 0x00, // creation_time
        0x00, 0x00, 0x00, 0x00, // modification_time
        timescale >>> 24 & 0xFF, // timescale: 4 bytes
        timescale >>> 16 & 0xFF, timescale >>> 8 & 0xFF, timescale & 0xFF, duration >>> 24 & 0xFF, // duration: 4 bytes
        duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, 0x55, 0xC4, // language: und (undetermined)
        0x00, 0x00 // pre_defined = 0
        ]));
      } // Media handler reference box


      static hdlr(meta) {
        let data = null;

        if (meta.type === 'audio') {
          data = MP4$1.constants.HDLR_AUDIO;
        } else {
          data = MP4$1.constants.HDLR_VIDEO;
        }

        return MP4$1.box(MP4$1.types.hdlr, data);
      } // Media infomation box


      static minf(meta) {
        let xmhd = null;

        if (meta.type === 'audio') {
          xmhd = MP4$1.box(MP4$1.types.smhd, MP4$1.constants.SMHD);
        } else {
          xmhd = MP4$1.box(MP4$1.types.vmhd, MP4$1.constants.VMHD);
        }

        return MP4$1.box(MP4$1.types.minf, xmhd, MP4$1.dinf(), MP4$1.stbl(meta));
      } // Data infomation box


      static dinf() {
        let result = MP4$1.box(MP4$1.types.dinf, MP4$1.box(MP4$1.types.dref, MP4$1.constants.DREF));
        return result;
      } // Sample table box


      static stbl(meta) {
        let result = MP4$1.box(MP4$1.types.stbl, // type: stbl
        MP4$1.stsd(meta), // Sample Description Table
        MP4$1.box(MP4$1.types.stts, MP4$1.constants.STTS), // Time-To-Sample
        MP4$1.box(MP4$1.types.stsc, MP4$1.constants.STSC), // Sample-To-Chunk
        MP4$1.box(MP4$1.types.stsz, MP4$1.constants.STSZ), // Sample size
        MP4$1.box(MP4$1.types.stco, MP4$1.constants.STCO) // Chunk offset
        );
        return result;
      } // Sample description box


      static stsd(meta) {
        if (meta.type === 'audio') {
          // else: aac -> mp4a
          return MP4$1.box(MP4$1.types.stsd, MP4$1.constants.STSD_PREFIX, MP4$1.mp4a(meta));
        } else {
          if (meta.videoType === 'avc') {
            //
            return MP4$1.box(MP4$1.types.stsd, MP4$1.constants.STSD_PREFIX, MP4$1.avc1(meta));
          } else {
            //
            return MP4$1.box(MP4$1.types.stsd, MP4$1.constants.STSD_PREFIX, MP4$1.hvc1(meta));
          }
        }
      }

      static mp4a(meta) {
        let channelCount = meta.channelCount;
        let sampleRate = meta.audioSampleRate;
        let data = new Uint8Array([0x00, 0x00, 0x00, 0x00, // reserved(4)
        0x00, 0x00, 0x00, 0x01, // reserved(2) + data_reference_index(2)
        0x00, 0x00, 0x00, 0x00, // reserved: 2 * 4 bytes
        0x00, 0x00, 0x00, 0x00, 0x00, channelCount, // channelCount(2)
        0x00, 0x10, // sampleSize(2)
        0x00, 0x00, 0x00, 0x00, // reserved(4)
        sampleRate >>> 8 & 0xFF, // Audio sample rate
        sampleRate & 0xFF, 0x00, 0x00]);
        return MP4$1.box(MP4$1.types.mp4a, data, MP4$1.esds(meta));
      }

      static esds(meta) {
        let config = meta.config || [];
        let configSize = config.length;
        let data = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version 0 + flags
        0x03, // descriptor_type
        0x17 + configSize, // length3
        0x00, 0x01, // es_id
        0x00, // stream_priority
        0x04, // descriptor_type
        0x0F + configSize, // length
        0x40, // codec: mpeg4_audio
        0x15, // stream_type: Audio
        0x00, 0x00, 0x00, // buffer_size
        0x00, 0x00, 0x00, 0x00, // maxBitrate
        0x00, 0x00, 0x00, 0x00, // avgBitrate
        0x05 // descriptor_type
        ].concat([configSize]).concat(config).concat([0x06, 0x01, 0x02 // GASpecificConfig
        ]));
        return MP4$1.box(MP4$1.types.esds, data);
      } // avc


      static avc1(meta) {
        let avcc = meta.avcc;
        const width = meta.codecWidth;
        const height = meta.codecHeight;
        let data = new Uint8Array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, width >>> 8 & 255, width & 255, height >>> 8 & 255, height & 255, 0, 72, 0, 0, 0, 72, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 255, 255]);
        return MP4$1.box(MP4$1.types.avc1, data, MP4$1.box(MP4$1.types.avcC, avcc));
      } // hvc


      static hvc1(meta) {
        let avcc = meta.avcc;
        const width = meta.codecWidth;
        const height = meta.codecHeight;
        let data = new Uint8Array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, width >>> 8 & 255, width & 255, height >>> 8 & 255, height & 255, 0, 72, 0, 0, 0, 72, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 255, 255]);
        return MP4$1.box(MP4$1.types.hvc1, data, MP4$1.box(MP4$1.types.hvcC, avcc));
      } // Movie Extends box


      static mvex(meta) {
        return MP4$1.box(MP4$1.types.mvex, MP4$1.trex(meta));
      } // Track Extends box


      static trex(meta) {
        let trackId = meta.id;
        let data = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags
        trackId >>> 24 & 0xFF, // track_ID
        trackId >>> 16 & 0xFF, trackId >>> 8 & 0xFF, trackId & 0xFF, 0x00, 0x00, 0x00, 0x01, // default_sample_description_index
        0x00, 0x00, 0x00, 0x00, // default_sample_duration
        0x00, 0x00, 0x00, 0x00, // default_sample_size
        0x00, 0x01, 0x00, 0x01 // default_sample_flags
        ]);
        return MP4$1.box(MP4$1.types.trex, data);
      } // Movie fragment box


      static moof(meta, baseMediaDecodeTime) {
        return MP4$1.box(MP4$1.types.moof, MP4$1.mfhd(meta.sequenceNumber), MP4$1.traf(meta, baseMediaDecodeTime));
      } //


      static mfhd(sequenceNumber) {
        let data = new Uint8Array([0x00, 0x00, 0x00, 0x00, sequenceNumber >>> 24 & 0xFF, // sequence_number: int32
        sequenceNumber >>> 16 & 0xFF, sequenceNumber >>> 8 & 0xFF, sequenceNumber & 0xFF]);
        return MP4$1.box(MP4$1.types.mfhd, data);
      } // Track fragment box


      static traf(meta, baseMediaDecodeTime) {
        let trackId = meta.id; // Track fragment header box

        let tfhd = MP4$1.box(MP4$1.types.tfhd, new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) & flags
        trackId >>> 24 & 0xFF, // track_ID
        trackId >>> 16 & 0xFF, trackId >>> 8 & 0xFF, trackId & 0xFF])); // Track Fragment Decode Time

        let tfdt = MP4$1.box(MP4$1.types.tfdt, new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) & flags
        baseMediaDecodeTime >>> 24 & 0xFF, // baseMediaDecodeTime: int32
        baseMediaDecodeTime >>> 16 & 0xFF, baseMediaDecodeTime >>> 8 & 0xFF, baseMediaDecodeTime & 0xFF]));
        let sdtp = MP4$1.sdtp(meta);
        let trun = MP4$1.trun(meta, sdtp.byteLength + 16 + 16 + 8 + 16 + 8 + 8);
        return MP4$1.box(MP4$1.types.traf, tfhd, tfdt, trun, sdtp);
      } // Sample Dependency Type box


      static sdtp(meta) {
        let data = new Uint8Array(4 + 1);
        let flags = meta.flags;
        data[4] = flags.isLeading << 6 | flags.dependsOn << 4 | flags.isDependedOn << 2 | flags.hasRedundancy;
        return MP4$1.box(MP4$1.types.sdtp, data);
      } // trun


      static trun(meta, offset) {
        let dataSize = 12 + 16;
        let data = new Uint8Array(dataSize);
        offset += 8 + dataSize;
        data.set([0x00, 0x00, 0x0F, 0x01, // version(0) & flags
        0x00, 0x00, 0x00, 0x01, // sample_count
        offset >>> 24 & 0xFF, // data_offset
        offset >>> 16 & 0xFF, offset >>> 8 & 0xFF, offset & 0xFF], 0);
        let duration = meta.duration;
        let size = meta.size;
        let flags = meta.flags;
        let cts = meta.cts;
        data.set([duration >>> 24 & 0xFF, // sample_duration
        duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, size >>> 24 & 0xFF, // sample_size
        size >>> 16 & 0xFF, size >>> 8 & 0xFF, size & 0xFF, flags.isLeading << 2 | flags.dependsOn, // sample_flags
        flags.isDependedOn << 6 | flags.hasRedundancy << 4 | flags.isNonSync, 0x00, 0x00, // sample_degradation_priority
        cts >>> 24 & 0xFF, // sample_composition_time_offset
        cts >>> 16 & 0xFF, cts >>> 8 & 0xFF, cts & 0xFF], 12);
        return MP4$1.box(MP4$1.types.trun, data);
      } // mdat


      static mdat(data) {
        return MP4$1.box(MP4$1.types.mdat, data);
      }

    }

    MP4$1.init();

    class MseDecoder extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.isAvc = true;
        this.mediaSource = new window.MediaSource();
        this.sourceBuffer = null;
        this.hasInit = false;
        this.isInitInfo = false;
        this.cacheTrack = {};
        this.timeInit = false;
        this.sequenceNumber = 0;
        this.mediaSourceOpen = false;
        this.dropping = false;
        this.firstRenderTime = null;
        this.$videoElement = null;
        this.mediaSourceAppendBufferFull = false;
        this.mediaSourceAppendBufferError = false;
        this.isDecodeFirstIIframe = false;
        this.prevTimestamp = null;
        this.decodeDiffTimestamp = null;
        this.prevDts = null;
        this.mediaSourceObjectURL = window.URL.createObjectURL(this.mediaSource);
        this.eventListenList = [];

        if (player._opt.mseUseCanvasRender) {
          this.$videoElement = document.createElement('video');
          this.$videoElement.src = this.mediaSourceObjectURL;
          this.initVideoEvents();
        } else {
          this.player.video.$videoElement.src = this.mediaSourceObjectURL;
          this.$videoElement = this.player.video.$videoElement;
        }

        const {
          debug,
          events: {
            proxy
          }
        } = player; // 当 "closed" to "open" 或者 "ended" to "open" 时触发。

        const sourceOpenProxyDestroy = proxy(this.mediaSource, MEDIA_SOURCE_EVENTS.sourceOpen, () => {
          this.mediaSourceOpen = true;
          this.player && this.player.emit(EVENTS.mseSourceOpen);
        }); //当 "open" to "closed" 或者 "ended" to "closed" 时触发。

        const sourceCloseProxyDestroy = proxy(this.mediaSource, MEDIA_SOURCE_EVENTS.sourceClose, () => {
          this.player && this.player.emit(EVENTS.mseSourceClose);
        }); // 当 "open" to "ended" 时触发

        const sourceendedProxyDestroy = proxy(this.mediaSource, MEDIA_SOURCE_EVENTS.sourceended, () => {
          this.player && this.player.emit(EVENTS.mseSourceended);
        });
        this.eventListenList.push(sourceOpenProxyDestroy, sourceCloseProxyDestroy, sourceendedProxyDestroy);

        if (this.player.isPlayer) {
          // 监听 change
          const timeUpdateProxyDestroy = proxy(this.$videoElement, VIDEO_ELEMENT_EVENTS.timeUpdate, () => {
            this._handleUpdatePlaybackRate();

            this.player.handleRender();
          });
          const ratechangeProxyDestroy = proxy(this.$videoElement, VIDEO_ELEMENT_EVENTS.ratechange, () => {
            player.debug.log('MediaSource', 'video playback Rate change', this.$videoElement && this.$videoElement.playbackRate);
          });
          this.eventListenList.push(timeUpdateProxyDestroy, ratechangeProxyDestroy);
        }

        player.debug.log('MediaSource', 'init');
      }

      destroy() {
        this.stop();

        if (this.eventListenList.length) {
          this.eventListenList.forEach(item => item());
          this.eventListenList = [];
        }

        this.mediaSource = null;
        this.mediaSourceOpen = false;
        this.sourceBuffer = null;
        this.hasInit = false;
        this.isInitInfo = false;
        this.sequenceNumber = 0;
        this.cacheTrack = {};
        this.timeInit = false;
        this.mediaSourceAppendBufferFull = false;
        this.mediaSourceAppendBufferError = false;
        this.isDecodeFirstIIframe = false;
        this.prevTimestamp = null;
        this.prevDts = null;
        this.firstRenderTime = null;
        this.dropping = false;

        if (this.$videoElement) {
          if (this.player._opt.mseUseCanvasRender) {
            this.$videoElement.src = '';
            this.$videoElement.removeAttribute('src');
          }

          this.$videoElement = null;
        }

        if (this.mediaSourceObjectURL) {
          window.URL.revokeObjectURL(this.mediaSourceObjectURL);
          this.mediaSourceObjectURL = null;
        }

        this.off();
        this.player.debug.log('MediaSource', 'destroy');
      }

      get state() {
        return this.mediaSource && this.mediaSource.readyState;
      } // source 打开，并且准备接受通过 sourceBuffer.appendBuffer 添加的数据。


      get isStateOpen() {
        return this.state === MEDIA_SOURCE_STATE.open;
      } // 当前 MS 没有和 media element(比如：video.src) 相关联。创建时，MS 就是该状态


      get isStateClosed() {
        return this.state === MEDIA_SOURCE_STATE.closed;
      } // 当 endOfStream() 执行完成，会变为该状态，此时，source 依然和 media element 连接。


      get isStateEnded() {
        return this.state === MEDIA_SOURCE_STATE.ended;
      } // 获得当前媒体播放的时间，既可以设置(get)，也可以获取(set)。单位为 s(秒)


      get duration() {
        return this.mediaSource && this.mediaSource.duration;
      }

      set duration(duration) {
        this.mediaSource.duration = duration;
      }

      initVideoEvents() {
        const {
          proxy
        } = this.player.events;
        const canplayProxyDestroy = (this.$videoElement, () => {
          this.player.debug.log('MediaSource', 'video canplay');
          this.$videoElement.play().then(() => {
            this.player.debug.log('MediaSource', 'video play');
          }).catch(e => {
            this.player.debug.warn('MediaSource', 'video play error ', e);
          });
        });
        const waitingProxyDestroy = proxy(this.$videoElement, VIDEO_ELEMENT_EVENTS.waiting, () => {
          // this.player.emit(EVENTS.videoWaiting);
          this.player.debug.log('MediaSource', 'video waiting');
        });
        const timeUpdateProxyDestroy = proxy(this.$videoElement, VIDEO_ELEMENT_EVENTS.timeUpdate, event => {
          const timeStamp = parseInt(event.timeStamp, 10);
          this.player.emit(EVENTS.videoTimeUpdate, timeStamp);
          this.player.handleRender();
        });
        this.eventListenList.push(canplayProxyDestroy, waitingProxyDestroy, timeUpdateProxyDestroy);
      }

      decodeVideo(payload, ts, isIframe, cts) {
        const player = this.player; // this.player.debug.error('MediaSource', `decodeVideo`, ts, isIframe, cts)

        if (!player) {
          return;
        }

        if (!this.hasInit) {
          // this.player.debug.warn('MediaSource', `decodeVideo has not init , isIframe is ${isIframe} , payload is ${payload[1]}`)
          if (isIframe && payload[1] === 0) {
            const videoCodec = payload[0] & 0x0F;
            player.video.updateVideoInfo({
              encTypeCode: videoCodec
            }); // windows 下面的 360 浏览器是支持 mse 解码播放的。
            // edge 也是支持 mse 解码播放的。

            if (videoCodec === VIDEO_ENC_CODE.h265 && !supportMSEDecodeHevc()) {
              this.emit(EVENTS_ERROR.mediaSourceH265NotSupport);
              return;
            }

            if (!player._times.decodeStart) {
              player._times.decodeStart = now$1();
            }

            this.hasInit = this._decodeConfigurationRecord(payload, ts, isIframe, videoCodec);
          } else {
            this.player.debug.error('MediaSource', `decodeVideo has not init , isIframe is ${isIframe} , payload is ${payload[1]}`);
          }
        } else {
          if (isIframe && payload[1] === 0) {
            const videoCodec = payload[0] & 0x0F;
            let config = {};

            if (videoCodec === VIDEO_ENC_CODE.h264) {
              let data = payload.slice(5);
              config = parseAVCDecoderConfigurationRecord(data); // config = parseAVCDecoderConfigurationRecord$2(payload);
            } else if (videoCodec === VIDEO_ENC_CODE.h265) {
              config = parseHEVCDecoderConfigurationRecord$2(payload);
            }

            const videoInfo = this.player.video.videoInfo;

            if (videoInfo.width && videoInfo.height && (config.codecWidth !== videoInfo.width || config.codecHeight !== videoInfo.height)) {
              this.player.debug.warn('MediaSource', `width or height is update, width ${videoInfo.width}-> ${config.codecWidth}, height ${videoInfo.height}-> ${config.codecHeight}`);
              this.isInitInfo = false;
              this.player.video.init = false;
            }
          }

          if (!this.isDecodeFirstIIframe && isIframe) {
            this.isDecodeFirstIIframe = true;
          }

          if (this.isDecodeFirstIIframe) {
            if (this.firstRenderTime === null) {
              this.firstRenderTime = ts;
            }

            let dts = ts - this.firstRenderTime;

            if (dts < 0) {
              this.player.debug.error('MediaSource', `decodeVideo local dts is < 0 , ts is ${ts} and firstRenderTime is ${this.firstRenderTime}`);

              if (this.prevDts === null) {
                dts = 0;
              } else {
                dts = this.prevDts + 1;
              }
            }

            if (this.prevDts !== null && dts < this.prevDts) {
              this.player.debug.error('MediaSource', `decodeVideo dts is less than prev dts , ts is ${ts} and prev dts is ${this.prevDts}`);
              dts = this.prevDts + 1;
            }

            this._decodeVideo(payload, dts, isIframe, cts);

            this.prevDts = dts;
          } else {
            this.player.debug.warn('MediaSource', 'decodeVideo isDecodeFirstIIframe false');
          }
        }
      }

      _decodeConfigurationRecord(payload, ts, isIframe, videoCodec) {
        let data = payload.slice(5);
        let config = {}; // console.log('_decodeConfigurationRecord', data);

        if (videoCodec === VIDEO_ENC_CODE.h264) {
          config = parseAVCDecoderConfigurationRecord(data); // config = parseAVCDecoderConfigurationRecord$2(payload)
        } else if (videoCodec === VIDEO_ENC_CODE.h265) {
          // config = parseHEVCDecoderConfigurationRecord(data);
          config = parseHEVCDecoderConfigurationRecord$2(payload);
        } // todo：just for recorder


        if (this.player.recorder && this.player._opt.recordType === FILE_SUFFIX.mp4) {
          this.player.recorder.initMetaData(payload, videoCodec);
        } // this.player.debug.log('MediaSource', '_decodeConfigurationRecord', config);


        if (config.codecWidth === 0 && config.codecHeight === 0) {
          this.player.debug.error('MediaSource', '_decodeConfigurationRecord', config);
          this.emit(EVENTS_ERROR.mediaSourceH265NotSupport);
          return false;
        }

        const metaData = {
          id: 1,
          // video tag data
          type: 'video',
          timescale: 1000,
          duration: 0,
          avcc: data,
          codecWidth: config.codecWidth,
          codecHeight: config.codecHeight,
          videoType: config.videoType
        }; // ftyp

        const metaBox = MP4$1.generateInitSegment(metaData);
        this.isAvc = videoCodec === VIDEO_ENC_CODE.h264;
        this.appendBuffer(metaBox.buffer);
        this.sequenceNumber = 0;
        this.cacheTrack = {};
        this.timeInit = false;
        return true;
      } //


      _decodeVideo(payload, dts, isIframe, cts) {
        const player = this.player;
        let arrayBuffer = payload.slice(5);
        let bytes = arrayBuffer.byteLength; // 相对时间戳，用来表示PTS与DTS的差值。
        let nowTime = new Date().getTime();

        if (!this.prevTimestamp) {
          this.prevTimestamp = nowTime;
        }

        const diffTime = nowTime - this.prevTimestamp;
        this.decodeDiffTimestamp = diffTime;

        if (diffTime < 5 || diffTime > 500) {
          player.debug.warn('MediaSource', '_decodeVideo diff time is ', diffTime);
        } // console.log('cts is ', cts, 'dts is ', dts, 'iskeyFrame is ', isIframe, nowTime - this.prevTimestamp)
        // player.debug.log('MediaSource', '_decodeVideo', ts);


        const $video = this.$videoElement;
        const maxDelay = player._opt.videoBufferDelay + player._opt.videoBuffer;

        if ($video.buffered.length > 1) {
          this.removeBuffer($video.buffered.start(0), $video.buffered.end(0));
          this.timeInit = false;
        }

        if (this.dropping && this.cacheTrack.id && dts - this.cacheTrack.dts > maxDelay) {
          player.debug.warn('MediaSource', 'dropping time is ', dts - this.cacheTrack.dts);
          this.dropping = false;
          this.cacheTrack = {};
        } else if (this.cacheTrack.id && dts >= this.cacheTrack.dts) {
          // 需要额外加8个size
          let mdatBytes = 8 + this.cacheTrack.size;
          let mdatbox = new Uint8Array(mdatBytes);
          mdatbox[0] = mdatBytes >>> 24 & 255;
          mdatbox[1] = mdatBytes >>> 16 & 255;
          mdatbox[2] = mdatBytes >>> 8 & 255;
          mdatbox[3] = mdatBytes & 255; // mdat box用来存储视频碎片数据，

          mdatbox.set(MP4$1.types.mdat, 4);
          mdatbox.set(this.cacheTrack.data, 8);
          this.cacheTrack.duration = dts - this.cacheTrack.dts; // todo: just for recorder

          if (this.player.recorder && this.player.recorder.isRecording && this.player._opt.recordType === FILE_SUFFIX.mp4) {
            this.player.recorder.handleAddFmp4Track(this.cacheTrack);
          } // moof
          // moof box仅在流式MP4中使用，用于将多个sample组合成一个fragment。
          // moof 用来描述mdat


          let moofbox = MP4$1.moof(this.cacheTrack, this.cacheTrack.dts);
          let result = new Uint8Array(moofbox.byteLength + mdatbox.byteLength);
          result.set(moofbox, 0);
          result.set(mdatbox, moofbox.byteLength); // appendBuffer

          this.appendBuffer(result.buffer); // player.debug.log('MediaSource', 'decode ts is', dts);

          player.emit(EVENTS.timeUpdate, dts);
          player.updateStats({
            fps: true,
            ts: dts,
            buf: player.demux && player.demux.delay || 0
          });

          if (!player._times.videoStart) {
            player._times.videoStart = now$1();
            player.handlePlayToRenderTimes();
          }
        } else {
          player.debug.log('MediaSource', `timeInit set false , cacheTrack = {} now dts is ${dts}, cacheTrack dts is ${this.cacheTrack && this.cacheTrack.dts}`);
          this.timeInit = false;
          this.cacheTrack = {};
        }

        if (!this.cacheTrack) {
          this.cacheTrack = {};
        }

        this.cacheTrack.id = 1;
        this.cacheTrack.sequenceNumber = ++this.sequenceNumber;
        this.cacheTrack.size = bytes;
        this.cacheTrack.dts = dts;
        this.cacheTrack.cts = cts;
        this.cacheTrack.isKeyframe = isIframe;
        this.cacheTrack.data = arrayBuffer; //

        this.cacheTrack.flags = {
          isLeading: 0,
          dependsOn: isIframe ? 2 : 1,
          isDependedOn: isIframe ? 1 : 0,
          hasRedundancy: 0,
          isNonSync: isIframe ? 0 : 1
        }; //

        if (!this.timeInit && $video.buffered.length === 1) {
          player.debug.log('MediaSource', 'timeInit set true');
          this.timeInit = true;
          $video.currentTime = $video.buffered.end(0);
        }

        if (!this.isInitInfo && $video.videoWidth > 0 && $video.videoHeight > 0) {
          player.debug.log('MediaSource', `updateVideoInfo: ${$video.videoWidth},${$video.videoHeight}`);
          player.video.updateVideoInfo({
            width: $video.videoWidth,
            height: $video.videoHeight
          });
          player.video.initCanvasViewSize();
          this.isInitInfo = true;
        } // use


        if (player._opt.mseUseCanvasRender) {
          // console.log('_decodeVideo mseUseCanvasRender', ts)
          player.video.render({
            $video,
            ts: dts
          });
        }

        this.prevTimestamp = new Date().getTime();
      }

      appendBuffer(buffer) {
        const {
          debug,
          events: {
            proxy
          }
        } = this.player;

        if (this.sourceBuffer === null) {
          const codecs = this.isAvc ? MP4_CODECS.avc : MP4_CODECS.hev;
          this.sourceBuffer = this.mediaSource.addSourceBuffer(codecs);
          const sourceBufferErrorProxyDestroy = proxy(this.sourceBuffer, 'error', error => {
            this.player.emit(EVENTS.mseSourceBufferError, error);
          });
          const updateendProxyDestroy = proxy(this.sourceBuffer, 'updateend', () => {// debug.log('MediaSource', 'this.sourceBuffer updateend');
          });
          this.eventListenList.push(sourceBufferErrorProxyDestroy, updateendProxyDestroy);
        }

        if (this.mediaSourceAppendBufferFull) {
          debug.error('MediaSource', `this.mediaSourceAppendBufferFull is true`);
          return;
        }

        if (this.mediaSourceAppendBufferError) {
          debug.error('MediaSource', `this.mediaSourceAppendBufferError is true`);
          return;
        }

        if (this.sourceBuffer.updating === false && this.isStateOpen) {
          try {
            this.sourceBuffer.appendBuffer(buffer);
          } catch (e) {
            debug.warn('MediaSource', 'this.sourceBuffer.appendBuffer()', e.code, e);

            if (e.code === 22) {
              // QuotaExceededError
              // The SourceBuffer is full, and cannot free space to append additional buffers
              this.stop();
              this.mediaSourceAppendBufferFull = true;
              this.emit(EVENTS_ERROR.mediaSourceFull);
            } else if (e.code === 11) {
              //     Failed to execute 'appendBuffer' on 'SourceBuffer': The HTMLMediaElement.error attribute is not null.
              this.stop();
              this.mediaSourceAppendBufferError = true;
              this.emit(EVENTS_ERROR.mediaSourceAppendBufferError);
            } else {
              debug.error('MediaSource', 'appendBuffer error', e);
              this.player.emit(EVENTS.mseSourceBufferError, e);
            }
          }

          return;
        }

        if (this.isStateClosed) {
          this.player.emit(EVENTS_ERROR.mseSourceBufferError, 'mediaSource is not attached to video or mediaSource is closed');
        } else if (this.isStateEnded) {
          this.player.emit(EVENTS_ERROR.mseSourceBufferError, 'mediaSource is end');
        } else {
          if (this.sourceBuffer.updating === true) {
            this.player.emit(EVENTS.mseSourceBufferBusy); // if (this.$videoElement.paused) {
            //     this.player.debug.warn('MediaSource','mseSourceBufferBusy and $videoElement is paused')
            //     // this.$videoElement.play();
            // }
          }
        }
      }

      stop() {
        this.abortSourceBuffer();
        this.removeSourceBuffer();
        this.endOfStream();
      }

      dropSourceBuffer(isDropping) {
        const $video = this.$videoElement;
        this.dropping = isDropping;

        if ($video.buffered.length > 0) {
          if ($video.buffered.end(0) - $video.currentTime > 1) {
            this.player.debug.warn('MediaSource', 'dropSourceBuffer', `$video.buffered.end(0) is ${$video.buffered.end(0)} - $video.currentTime ${$video.currentTime}`);
            $video.currentTime = $video.buffered.end(0);
          }
        }
      }

      checkSourceBufferDelay() {
        const $video = this.$videoElement;
        let result = 0;

        if ($video.buffered.length > 0) {
          result = $video.buffered.end(0) - $video.currentTime;
        }

        if (result < 0) {
          this.player.debug.warn('MediaSource', `checkSourceBufferDelay end(0) is ${$video.buffered.end(0)} - currentTime is ${$video.currentTime} and  result < 0 and result is ${result}`);
          result = 0;
        }

        return result;
      }

      getDecodeDiffTimes() {
        return this.decodeDiffTimestamp;
      }

      removeBuffer(start, end) {
        if (this.isStateOpen && this.sourceBuffer.updating === false) {
          try {
            this.sourceBuffer.remove(start, end);
          } catch (e) {
            this.player.debug.warn('MediaSource', 'removeBuffer() error', e);
          }
        } else {
          this.player.debug.warn('MediaSource', 'removeBuffer() this.isStateOpen is', this.isStateOpen, 'this.sourceBuffer.updating', this.sourceBuffer.updating);
        }
      }

      endOfStream() {
        if (this.isStateOpen) {
          try {
            this.mediaSource.endOfStream();
          } catch (e) {
            this.player.debug.warn('MediaSource', 'endOfStream() error', e);
          }
        }
      }

      abortSourceBuffer() {
        if (this.isStateOpen) {
          if (this.sourceBuffer) {
            this.sourceBuffer.abort();
            this.sourceBuffer = null;
          }
        }
      }

      removeSourceBuffer() {
        if (!this.isStateClosed) {
          if (this.mediaSource && this.sourceBuffer) {
            try {
              this.mediaSource.removeSourceBuffer(this.sourceBuffer);
            } catch (e) {
              this.player.debug.warn('MediaSource', 'removeSourceBuffer() error', e);
            }
          }
        }
      }

      _handleUpdatePlaybackRate() {
        if (!this.$videoElement) {
          return;
        }

        const $video = this.$videoElement;
        const videoBuffer = this.player._opt.videoBuffer;
        const videoBufferDelay = this.player._opt.videoBufferDelay;
        let maxDelay = (videoBuffer + videoBufferDelay) / 1000;
        const ranges = $video.buffered;
        ranges.length ? ranges.start(0) : 0;
        const buffered = ranges.length ? ranges.end(ranges.length - 1) : 0;
        let time = $video.currentTime;
        const buffer = buffered - time;
        const maxDelayTime = Math.max(MSE_MAX_DELAY_TIME, maxDelay + MSE_DELAY_INCREASE_TIME);

        if (buffer > maxDelayTime) {
          this.player.debug.warn('MediaSource', `handleUpdatePlaybackRate and buffered is ${buffered} and current is ${time} , delay buffer is more than ${maxDelayTime} is ${buffer} and new time is ${buffered}`);
          $video.currentTime = buffered;
          time = $video.currentTime;
        } else if (buffer < 0) {
          this.player.debug.warn('MediaSource', `handleUpdatePlaybackRate and delay buffer is less than 0 is ${buffer} and new time is ${buffered}`);
          $video.currentTime = buffered;
          time = $video.currentTime;
        }

        const rate = this._getPlaybackRate(buffered - time);

        if ($video.playbackRate !== rate) {
          this.player.debug.warn('MediaSource', `handleUpdatePlaybackRate and set playbackRate is ${rate} `);
          $video.playbackRate = rate;
        }
      }

      getDecodePlaybackRate() {
        let result = 0;
        const $video = this.$videoElement;

        if ($video) {
          result = $video.playbackRate;
        }

        return result;
      }

      _getPlaybackRate(buffer) {
        const $video = this.$videoElement;
        const videoBuffer = this.player._opt.videoBuffer;
        const videoBufferDelay = this.player._opt.videoBufferDelay;
        const maxDelay = videoBuffer + videoBufferDelay;
        buffer = buffer * 1000;

        switch ($video.playbackRate) {
          case 1:
            if (buffer > maxDelay) {
              return 1.2;
            }

            return 1;

          default:
            if (buffer <= videoBuffer) {
              return 1;
            }

            return $video.playbackRate;
        }
      }

    }

    // tks: https://github.com/richtr/NoSleep.js
    const WEBM = "data:video/webm;base64,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";
    const MP4 = "data:video/mp4;base64,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"; // Detect iOS browsers < version 10

    const oldIOS = () => typeof navigator !== "undefined" && parseFloat(("" + (/CPU.*OS ([0-9_]{3,4})[0-9_]{0,1}|(CPU like).*AppleWebKit.*Mobile/i.exec(navigator.userAgent) || [0, ""])[1]).replace("undefined", "3_2").replace("_", ".").replace("_", "")) < 10 && !window.MSStream; // Detect native Wake Lock API support


    const nativeWakeLock = () => "wakeLock" in navigator;

    class NoSleep {
      constructor(player) {
        this.player = player;
        this.enabled = false;

        if (nativeWakeLock()) {
          this._wakeLock = null;

          const handleVisibilityChange = () => {
            if (this._wakeLock !== null && document.visibilityState === "visible") {
              this.enable();
            }
          };

          document.addEventListener("visibilitychange", handleVisibilityChange);
          document.addEventListener("fullscreenchange", handleVisibilityChange);
        } else if (oldIOS()) {
          this.noSleepTimer = null;
        } else {
          // Set up no sleep video element
          this.noSleepVideo = document.createElement("video");
          this.noSleepVideo.setAttribute("title", "No Sleep");
          this.noSleepVideo.setAttribute("playsinline", "");

          this._addSourceToVideo(this.noSleepVideo, "webm", WEBM);

          this._addSourceToVideo(this.noSleepVideo, "mp4", MP4);

          this.noSleepVideo.addEventListener("loadedmetadata", () => {
            if (this.noSleepVideo.duration <= 1) {
              // webm source
              this.noSleepVideo.setAttribute("loop", "");
            } else {
              // mp4 source
              this.noSleepVideo.addEventListener("timeupdate", () => {
                if (this.noSleepVideo.currentTime > 0.5) {
                  this.noSleepVideo.currentTime = Math.random();
                }
              });
            }
          });
        }
      }

      _addSourceToVideo(element, type, dataURI) {
        var source = document.createElement("source");
        source.src = dataURI;
        source.type = `video/${type}`;
        element.appendChild(source);
      }

      get isEnabled() {
        return this.enabled;
      }

      enable() {
        const debug = this.player.debug;

        if (nativeWakeLock()) {
          return navigator.wakeLock.request("screen").then(wakeLock => {
            this._wakeLock = wakeLock;
            this.enabled = true;
            debug.log('wakeLock', 'Wake Lock active.');

            this._wakeLock.addEventListener("release", () => {
              // ToDo: Potentially emit an event for the page to observe since
              // Wake Lock releases happen when page visibility changes.
              // (https://web.dev/wakelock/#wake-lock-lifecycle)
              debug.log('wakeLock', 'Wake Lock released.');
            });
          }).catch(err => {
            this.enabled = false;
            debug.error('wakeLock', `${err.name}, ${err.message}`);
            throw err;
          });
        } else if (oldIOS()) {
          this.disable();
          this.noSleepTimer = window.setInterval(() => {
            if (!document.hidden) {
              window.location.href = window.location.href.split("#")[0];
              window.setTimeout(window.stop, 0);
            }
          }, 15000);
          this.enabled = true;
          return Promise.resolve();
        } else {
          let playPromise = this.noSleepVideo.play();
          return playPromise.then(res => {
            this.enabled = true;
            return res;
          }).catch(err => {
            this.enabled = false;
            throw err;
          });
        }
      }

      disable() {
        const debug = this.player.debug;

        if (nativeWakeLock()) {
          if (this._wakeLock) {
            this._wakeLock.release();
          }

          this._wakeLock = null;
        } else if (oldIOS()) {
          if (this.noSleepTimer) {
            debug.warn('wakeLock', 'NoSleep now disabled for older iOS devices.');
            window.clearInterval(this.noSleepTimer);
            this.noSleepTimer = null;
          }
        } else {
          this.noSleepVideo.pause();
        }

        this.enabled = false;
      }

    }

    var hls = createCommonjsModule(function (module, exports) {
    typeof window !== "undefined" &&
    (function webpackUniversalModuleDefinition(root, factory) {
    	module.exports = factory();
    })(commonjsGlobal, function() {
    return /******/ (function(modules) { // webpackBootstrap
    /******/ 	// The module cache
    /******/ 	var installedModules = {};
    /******/
    /******/ 	// The require function
    /******/ 	function __webpack_require__(moduleId) {
    /******/
    /******/ 		// Check if module is in cache
    /******/ 		if(installedModules[moduleId]) {
    /******/ 			return installedModules[moduleId].exports;
    /******/ 		}
    /******/ 		// Create a new module (and put it into the cache)
    /******/ 		var module = installedModules[moduleId] = {
    /******/ 			i: moduleId,
    /******/ 			l: false,
    /******/ 			exports: {}
    /******/ 		};
    /******/
    /******/ 		// Execute the module function
    /******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
    /******/
    /******/ 		// Flag the module as loaded
    /******/ 		module.l = true;
    /******/
    /******/ 		// Return the exports of the module
    /******/ 		return module.exports;
    /******/ 	}
    /******/
    /******/
    /******/ 	// expose the modules object (__webpack_modules__)
    /******/ 	__webpack_require__.m = modules;
    /******/
    /******/ 	// expose the module cache
    /******/ 	__webpack_require__.c = installedModules;
    /******/
    /******/ 	// define getter function for harmony exports
    /******/ 	__webpack_require__.d = function(exports, name, getter) {
    /******/ 		if(!__webpack_require__.o(exports, name)) {
    /******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
    /******/ 		}
    /******/ 	};
    /******/
    /******/ 	// define __esModule on exports
    /******/ 	__webpack_require__.r = function(exports) {
    /******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
    /******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
    /******/ 		}
    /******/ 		Object.defineProperty(exports, '__esModule', { value: true });
    /******/ 	};
    /******/
    /******/ 	// create a fake namespace object
    /******/ 	// mode & 1: value is a module id, require it
    /******/ 	// mode & 2: merge all properties of value into the ns
    /******/ 	// mode & 4: return value when already ns object
    /******/ 	// mode & 8|1: behave like require
    /******/ 	__webpack_require__.t = function(value, mode) {
    /******/ 		if(mode & 1) value = __webpack_require__(value);
    /******/ 		if(mode & 8) return value;
    /******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
    /******/ 		var ns = Object.create(null);
    /******/ 		__webpack_require__.r(ns);
    /******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
    /******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
    /******/ 		return ns;
    /******/ 	};
    /******/
    /******/ 	// getDefaultExport function for compatibility with non-harmony modules
    /******/ 	__webpack_require__.n = function(module) {
    /******/ 		var getter = module && module.__esModule ?
    /******/ 			function getDefault() { return module['default']; } :
    /******/ 			function getModuleExports() { return module; };
    /******/ 		__webpack_require__.d(getter, 'a', getter);
    /******/ 		return getter;
    /******/ 	};
    /******/
    /******/ 	// Object.prototype.hasOwnProperty.call
    /******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
    /******/
    /******/ 	// __webpack_public_path__
    /******/ 	__webpack_require__.p = "/dist/";
    /******/
    /******/
    /******/ 	// Load entry module and return exports
    /******/ 	return __webpack_require__(__webpack_require__.s = "./src/hls.ts");
    /******/ })
    /************************************************************************/
    /******/ ({

    /***/ "./node_modules/eventemitter3/index.js":
    /*!*********************************************!*\
      !*** ./node_modules/eventemitter3/index.js ***!
      \*********************************************/
    /*! no static exports found */
    /***/ (function(module, exports, __webpack_require__) {


    var has = Object.prototype.hasOwnProperty
      , prefix = '~';

    /**
     * Constructor to create a storage for our `EE` objects.
     * An `Events` instance is a plain object whose properties are event names.
     *
     * @constructor
     * @private
     */
    function Events() {}

    //
    // We try to not inherit from `Object.prototype`. In some engines creating an
    // instance in this way is faster than calling `Object.create(null)` directly.
    // If `Object.create(null)` is not supported we prefix the event names with a
    // character to make sure that the built-in object properties are not
    // overridden or used as an attack vector.
    //
    if (Object.create) {
      Events.prototype = Object.create(null);

      //
      // This hack is needed because the `__proto__` property is still inherited in
      // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.
      //
      if (!new Events().__proto__) prefix = false;
    }

    /**
     * Representation of a single event listener.
     *
     * @param {Function} fn The listener function.
     * @param {*} context The context to invoke the listener with.
     * @param {Boolean} [once=false] Specify if the listener is a one-time listener.
     * @constructor
     * @private
     */
    function EE(fn, context, once) {
      this.fn = fn;
      this.context = context;
      this.once = once || false;
    }

    /**
     * Add a listener for a given event.
     *
     * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
     * @param {(String|Symbol)} event The event name.
     * @param {Function} fn The listener function.
     * @param {*} context The context to invoke the listener with.
     * @param {Boolean} once Specify if the listener is a one-time listener.
     * @returns {EventEmitter}
     * @private
     */
    function addListener(emitter, event, fn, context, once) {
      if (typeof fn !== 'function') {
        throw new TypeError('The listener must be a function');
      }

      var listener = new EE(fn, context || emitter, once)
        , evt = prefix ? prefix + event : event;

      if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;
      else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);
      else emitter._events[evt] = [emitter._events[evt], listener];

      return emitter;
    }

    /**
     * Clear event by name.
     *
     * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
     * @param {(String|Symbol)} evt The Event name.
     * @private
     */
    function clearEvent(emitter, evt) {
      if (--emitter._eventsCount === 0) emitter._events = new Events();
      else delete emitter._events[evt];
    }

    /**
     * Minimal `EventEmitter` interface that is molded against the Node.js
     * `EventEmitter` interface.
     *
     * @constructor
     * @public
     */
    function EventEmitter() {
      this._events = new Events();
      this._eventsCount = 0;
    }

    /**
     * Return an array listing the events for which the emitter has registered
     * listeners.
     *
     * @returns {Array}
     * @public
     */
    EventEmitter.prototype.eventNames = function eventNames() {
      var names = []
        , events
        , name;

      if (this._eventsCount === 0) return names;

      for (name in (events = this._events)) {
        if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);
      }

      if (Object.getOwnPropertySymbols) {
        return names.concat(Object.getOwnPropertySymbols(events));
      }

      return names;
    };

    /**
     * Return the listeners registered for a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @returns {Array} The registered listeners.
     * @public
     */
    EventEmitter.prototype.listeners = function listeners(event) {
      var evt = prefix ? prefix + event : event
        , handlers = this._events[evt];

      if (!handlers) return [];
      if (handlers.fn) return [handlers.fn];

      for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {
        ee[i] = handlers[i].fn;
      }

      return ee;
    };

    /**
     * Return the number of listeners listening to a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @returns {Number} The number of listeners.
     * @public
     */
    EventEmitter.prototype.listenerCount = function listenerCount(event) {
      var evt = prefix ? prefix + event : event
        , listeners = this._events[evt];

      if (!listeners) return 0;
      if (listeners.fn) return 1;
      return listeners.length;
    };

    /**
     * Calls each of the listeners registered for a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @returns {Boolean} `true` if the event had listeners, else `false`.
     * @public
     */
    EventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {
      var evt = prefix ? prefix + event : event;

      if (!this._events[evt]) return false;

      var listeners = this._events[evt]
        , len = arguments.length
        , args
        , i;

      if (listeners.fn) {
        if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);

        switch (len) {
          case 1: return listeners.fn.call(listeners.context), true;
          case 2: return listeners.fn.call(listeners.context, a1), true;
          case 3: return listeners.fn.call(listeners.context, a1, a2), true;
          case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;
          case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;
          case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;
        }

        for (i = 1, args = new Array(len -1); i < len; i++) {
          args[i - 1] = arguments[i];
        }

        listeners.fn.apply(listeners.context, args);
      } else {
        var length = listeners.length
          , j;

        for (i = 0; i < length; i++) {
          if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);

          switch (len) {
            case 1: listeners[i].fn.call(listeners[i].context); break;
            case 2: listeners[i].fn.call(listeners[i].context, a1); break;
            case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;
            case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;
            default:
              if (!args) for (j = 1, args = new Array(len -1); j < len; j++) {
                args[j - 1] = arguments[j];
              }

              listeners[i].fn.apply(listeners[i].context, args);
          }
        }
      }

      return true;
    };

    /**
     * Add a listener for a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @param {Function} fn The listener function.
     * @param {*} [context=this] The context to invoke the listener with.
     * @returns {EventEmitter} `this`.
     * @public
     */
    EventEmitter.prototype.on = function on(event, fn, context) {
      return addListener(this, event, fn, context, false);
    };

    /**
     * Add a one-time listener for a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @param {Function} fn The listener function.
     * @param {*} [context=this] The context to invoke the listener with.
     * @returns {EventEmitter} `this`.
     * @public
     */
    EventEmitter.prototype.once = function once(event, fn, context) {
      return addListener(this, event, fn, context, true);
    };

    /**
     * Remove the listeners of a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @param {Function} fn Only remove the listeners that match this function.
     * @param {*} context Only remove the listeners that have this context.
     * @param {Boolean} once Only remove one-time listeners.
     * @returns {EventEmitter} `this`.
     * @public
     */
    EventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {
      var evt = prefix ? prefix + event : event;

      if (!this._events[evt]) return this;
      if (!fn) {
        clearEvent(this, evt);
        return this;
      }

      var listeners = this._events[evt];

      if (listeners.fn) {
        if (
          listeners.fn === fn &&
          (!once || listeners.once) &&
          (!context || listeners.context === context)
        ) {
          clearEvent(this, evt);
        }
      } else {
        for (var i = 0, events = [], length = listeners.length; i < length; i++) {
          if (
            listeners[i].fn !== fn ||
            (once && !listeners[i].once) ||
            (context && listeners[i].context !== context)
          ) {
            events.push(listeners[i]);
          }
        }

        //
        // Reset the array, or remove it completely if we have no more listeners.
        //
        if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;
        else clearEvent(this, evt);
      }

      return this;
    };

    /**
     * Remove all listeners, or those of the specified event.
     *
     * @param {(String|Symbol)} [event] The event name.
     * @returns {EventEmitter} `this`.
     * @public
     */
    EventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {
      var evt;

      if (event) {
        evt = prefix ? prefix + event : event;
        if (this._events[evt]) clearEvent(this, evt);
      } else {
        this._events = new Events();
        this._eventsCount = 0;
      }

      return this;
    };

    //
    // Alias methods names because people roll like that.
    //
    EventEmitter.prototype.off = EventEmitter.prototype.removeListener;
    EventEmitter.prototype.addListener = EventEmitter.prototype.on;

    //
    // Expose the prefix.
    //
    EventEmitter.prefixed = prefix;

    //
    // Allow `EventEmitter` to be imported as module namespace.
    //
    EventEmitter.EventEmitter = EventEmitter;

    //
    // Expose the module.
    //
    {
      module.exports = EventEmitter;
    }


    /***/ }),

    /***/ "./node_modules/url-toolkit/src/url-toolkit.js":
    /*!*****************************************************!*\
      !*** ./node_modules/url-toolkit/src/url-toolkit.js ***!
      \*****************************************************/
    /*! no static exports found */
    /***/ (function(module, exports, __webpack_require__) {

    // see https://tools.ietf.org/html/rfc1808

    (function (root) {
      var URL_REGEX =
        /^((?:[a-zA-Z0-9+\-.]+:)?)(\/\/[^\/?#]*)?((?:[^\/?#]*\/)*[^;?#]*)?(;[^?#]*)?(\?[^#]*)?(#[^]*)?$/;
      var FIRST_SEGMENT_REGEX = /^([^\/?#]*)([^]*)$/;
      var SLASH_DOT_REGEX = /(?:\/|^)\.(?=\/)/g;
      var SLASH_DOT_DOT_REGEX = /(?:\/|^)\.\.\/(?!\.\.\/)[^\/]*(?=\/)/g;

      var URLToolkit = {
        // If opts.alwaysNormalize is true then the path will always be normalized even when it starts with / or //
        // E.g
        // With opts.alwaysNormalize = false (default, spec compliant)
        // http://a.com/b/cd + /e/f/../g => http://a.com/e/f/../g
        // With opts.alwaysNormalize = true (not spec compliant)
        // http://a.com/b/cd + /e/f/../g => http://a.com/e/g
        buildAbsoluteURL: function (baseURL, relativeURL, opts) {
          opts = opts || {};
          // remove any remaining space and CRLF
          baseURL = baseURL.trim();
          relativeURL = relativeURL.trim();
          if (!relativeURL) {
            // 2a) If the embedded URL is entirely empty, it inherits the
            // entire base URL (i.e., is set equal to the base URL)
            // and we are done.
            if (!opts.alwaysNormalize) {
              return baseURL;
            }
            var basePartsForNormalise = URLToolkit.parseURL(baseURL);
            if (!basePartsForNormalise) {
              throw new Error('Error trying to parse base URL.');
            }
            basePartsForNormalise.path = URLToolkit.normalizePath(
              basePartsForNormalise.path
            );
            return URLToolkit.buildURLFromParts(basePartsForNormalise);
          }
          var relativeParts = URLToolkit.parseURL(relativeURL);
          if (!relativeParts) {
            throw new Error('Error trying to parse relative URL.');
          }
          if (relativeParts.scheme) {
            // 2b) If the embedded URL starts with a scheme name, it is
            // interpreted as an absolute URL and we are done.
            if (!opts.alwaysNormalize) {
              return relativeURL;
            }
            relativeParts.path = URLToolkit.normalizePath(relativeParts.path);
            return URLToolkit.buildURLFromParts(relativeParts);
          }
          var baseParts = URLToolkit.parseURL(baseURL);
          if (!baseParts) {
            throw new Error('Error trying to parse base URL.');
          }
          if (!baseParts.netLoc && baseParts.path && baseParts.path[0] !== '/') {
            // If netLoc missing and path doesn't start with '/', assume everthing before the first '/' is the netLoc
            // This causes 'example.com/a' to be handled as '//example.com/a' instead of '/example.com/a'
            var pathParts = FIRST_SEGMENT_REGEX.exec(baseParts.path);
            baseParts.netLoc = pathParts[1];
            baseParts.path = pathParts[2];
          }
          if (baseParts.netLoc && !baseParts.path) {
            baseParts.path = '/';
          }
          var builtParts = {
            // 2c) Otherwise, the embedded URL inherits the scheme of
            // the base URL.
            scheme: baseParts.scheme,
            netLoc: relativeParts.netLoc,
            path: null,
            params: relativeParts.params,
            query: relativeParts.query,
            fragment: relativeParts.fragment,
          };
          if (!relativeParts.netLoc) {
            // 3) If the embedded URL's <net_loc> is non-empty, we skip to
            // Step 7.  Otherwise, the embedded URL inherits the <net_loc>
            // (if any) of the base URL.
            builtParts.netLoc = baseParts.netLoc;
            // 4) If the embedded URL path is preceded by a slash "/", the
            // path is not relative and we skip to Step 7.
            if (relativeParts.path[0] !== '/') {
              if (!relativeParts.path) {
                // 5) If the embedded URL path is empty (and not preceded by a
                // slash), then the embedded URL inherits the base URL path
                builtParts.path = baseParts.path;
                // 5a) if the embedded URL's <params> is non-empty, we skip to
                // step 7; otherwise, it inherits the <params> of the base
                // URL (if any) and
                if (!relativeParts.params) {
                  builtParts.params = baseParts.params;
                  // 5b) if the embedded URL's <query> is non-empty, we skip to
                  // step 7; otherwise, it inherits the <query> of the base
                  // URL (if any) and we skip to step 7.
                  if (!relativeParts.query) {
                    builtParts.query = baseParts.query;
                  }
                }
              } else {
                // 6) The last segment of the base URL's path (anything
                // following the rightmost slash "/", or the entire path if no
                // slash is present) is removed and the embedded URL's path is
                // appended in its place.
                var baseURLPath = baseParts.path;
                var newPath =
                  baseURLPath.substring(0, baseURLPath.lastIndexOf('/') + 1) +
                  relativeParts.path;
                builtParts.path = URLToolkit.normalizePath(newPath);
              }
            }
          }
          if (builtParts.path === null) {
            builtParts.path = opts.alwaysNormalize
              ? URLToolkit.normalizePath(relativeParts.path)
              : relativeParts.path;
          }
          return URLToolkit.buildURLFromParts(builtParts);
        },
        parseURL: function (url) {
          var parts = URL_REGEX.exec(url);
          if (!parts) {
            return null;
          }
          return {
            scheme: parts[1] || '',
            netLoc: parts[2] || '',
            path: parts[3] || '',
            params: parts[4] || '',
            query: parts[5] || '',
            fragment: parts[6] || '',
          };
        },
        normalizePath: function (path) {
          // The following operations are
          // then applied, in order, to the new path:
          // 6a) All occurrences of "./", where "." is a complete path
          // segment, are removed.
          // 6b) If the path ends with "." as a complete path segment,
          // that "." is removed.
          path = path.split('').reverse().join('').replace(SLASH_DOT_REGEX, '');
          // 6c) All occurrences of "<segment>/../", where <segment> is a
          // complete path segment not equal to "..", are removed.
          // Removal of these path segments is performed iteratively,
          // removing the leftmost matching pattern on each iteration,
          // until no matching pattern remains.
          // 6d) If the path ends with "<segment>/..", where <segment> is a
          // complete path segment not equal to "..", that
          // "<segment>/.." is removed.
          while (
            path.length !== (path = path.replace(SLASH_DOT_DOT_REGEX, '')).length
          ) {}
          return path.split('').reverse().join('');
        },
        buildURLFromParts: function (parts) {
          return (
            parts.scheme +
            parts.netLoc +
            parts.path +
            parts.params +
            parts.query +
            parts.fragment
          );
        },
      };

      module.exports = URLToolkit;
    })();


    /***/ }),

    /***/ "./node_modules/webworkify-webpack/index.js":
    /*!**************************************************!*\
      !*** ./node_modules/webworkify-webpack/index.js ***!
      \**************************************************/
    /*! no static exports found */
    /***/ (function(module, exports, __webpack_require__) {

    function webpackBootstrapFunc (modules) {
    /******/  // The module cache
    /******/  var installedModules = {};

    /******/  // The require function
    /******/  function __webpack_require__(moduleId) {

    /******/    // Check if module is in cache
    /******/    if(installedModules[moduleId])
    /******/      return installedModules[moduleId].exports;

    /******/    // Create a new module (and put it into the cache)
    /******/    var module = installedModules[moduleId] = {
    /******/      i: moduleId,
    /******/      l: false,
    /******/      exports: {}
    /******/    };

    /******/    // Execute the module function
    /******/    modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);

    /******/    // Flag the module as loaded
    /******/    module.l = true;

    /******/    // Return the exports of the module
    /******/    return module.exports;
    /******/  }

    /******/  // expose the modules object (__webpack_modules__)
    /******/  __webpack_require__.m = modules;

    /******/  // expose the module cache
    /******/  __webpack_require__.c = installedModules;

    /******/  // identity function for calling harmony imports with the correct context
    /******/  __webpack_require__.i = function(value) { return value; };

    /******/  // define getter function for harmony exports
    /******/  __webpack_require__.d = function(exports, name, getter) {
    /******/    if(!__webpack_require__.o(exports, name)) {
    /******/      Object.defineProperty(exports, name, {
    /******/        configurable: false,
    /******/        enumerable: true,
    /******/        get: getter
    /******/      });
    /******/    }
    /******/  };

    /******/  // define __esModule on exports
    /******/  __webpack_require__.r = function(exports) {
    /******/    Object.defineProperty(exports, '__esModule', { value: true });
    /******/  };

    /******/  // getDefaultExport function for compatibility with non-harmony modules
    /******/  __webpack_require__.n = function(module) {
    /******/    var getter = module && module.__esModule ?
    /******/      function getDefault() { return module['default']; } :
    /******/      function getModuleExports() { return module; };
    /******/    __webpack_require__.d(getter, 'a', getter);
    /******/    return getter;
    /******/  };

    /******/  // Object.prototype.hasOwnProperty.call
    /******/  __webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };

    /******/  // __webpack_public_path__
    /******/  __webpack_require__.p = "/";

    /******/  // on error function for async loading
    /******/  __webpack_require__.oe = function(err) { console.error(err); throw err; };

      var f = __webpack_require__(__webpack_require__.s = ENTRY_MODULE);
      return f.default || f // try to call default if defined to also support babel esmodule exports
    }

    var moduleNameReqExp = '[\\.|\\-|\\+|\\w|\/|@]+';
    var dependencyRegExp = '\\(\\s*(\/\\*.*?\\*\/)?\\s*.*?(' + moduleNameReqExp + ').*?\\)'; // additional chars when output.pathinfo is true

    // http://stackoverflow.com/a/2593661/130442
    function quoteRegExp (str) {
      return (str + '').replace(/[.?*+^$[\]\\(){}|-]/g, '\\$&')
    }

    function isNumeric(n) {
      return !isNaN(1 * n); // 1 * n converts integers, integers as string ("123"), 1e3 and "1e3" to integers and strings to NaN
    }

    function getModuleDependencies (sources, module, queueName) {
      var retval = {};
      retval[queueName] = [];

      var fnString = module.toString();
      var wrapperSignature = fnString.match(/^function\s?\w*\(\w+,\s*\w+,\s*(\w+)\)/);
      if (!wrapperSignature) return retval
      var webpackRequireName = wrapperSignature[1];

      // main bundle deps
      var re = new RegExp('(\\\\n|\\W)' + quoteRegExp(webpackRequireName) + dependencyRegExp, 'g');
      var match;
      while ((match = re.exec(fnString))) {
        if (match[3] === 'dll-reference') continue
        retval[queueName].push(match[3]);
      }

      // dll deps
      re = new RegExp('\\(' + quoteRegExp(webpackRequireName) + '\\("(dll-reference\\s(' + moduleNameReqExp + '))"\\)\\)' + dependencyRegExp, 'g');
      while ((match = re.exec(fnString))) {
        if (!sources[match[2]]) {
          retval[queueName].push(match[1]);
          sources[match[2]] = __webpack_require__(match[1]).m;
        }
        retval[match[2]] = retval[match[2]] || [];
        retval[match[2]].push(match[4]);
      }

      // convert 1e3 back to 1000 - this can be important after uglify-js converted 1000 to 1e3
      var keys = Object.keys(retval);
      for (var i = 0; i < keys.length; i++) {
        for (var j = 0; j < retval[keys[i]].length; j++) {
          if (isNumeric(retval[keys[i]][j])) {
            retval[keys[i]][j] = 1 * retval[keys[i]][j];
          }
        }
      }

      return retval
    }

    function hasValuesInQueues (queues) {
      var keys = Object.keys(queues);
      return keys.reduce(function (hasValues, key) {
        return hasValues || queues[key].length > 0
      }, false)
    }

    function getRequiredModules (sources, moduleId) {
      var modulesQueue = {
        main: [moduleId]
      };
      var requiredModules = {
        main: []
      };
      var seenModules = {
        main: {}
      };

      while (hasValuesInQueues(modulesQueue)) {
        var queues = Object.keys(modulesQueue);
        for (var i = 0; i < queues.length; i++) {
          var queueName = queues[i];
          var queue = modulesQueue[queueName];
          var moduleToCheck = queue.pop();
          seenModules[queueName] = seenModules[queueName] || {};
          if (seenModules[queueName][moduleToCheck] || !sources[queueName][moduleToCheck]) continue
          seenModules[queueName][moduleToCheck] = true;
          requiredModules[queueName] = requiredModules[queueName] || [];
          requiredModules[queueName].push(moduleToCheck);
          var newModules = getModuleDependencies(sources, sources[queueName][moduleToCheck], queueName);
          var newModulesKeys = Object.keys(newModules);
          for (var j = 0; j < newModulesKeys.length; j++) {
            modulesQueue[newModulesKeys[j]] = modulesQueue[newModulesKeys[j]] || [];
            modulesQueue[newModulesKeys[j]] = modulesQueue[newModulesKeys[j]].concat(newModules[newModulesKeys[j]]);
          }
        }
      }

      return requiredModules
    }

    module.exports = function (moduleId, options) {
      options = options || {};
      var sources = {
        main: __webpack_require__.m
      };

      var requiredModules = options.all ? { main: Object.keys(sources.main) } : getRequiredModules(sources, moduleId);

      var src = '';

      Object.keys(requiredModules).filter(function (m) { return m !== 'main' }).forEach(function (module) {
        var entryModule = 0;
        while (requiredModules[module][entryModule]) {
          entryModule++;
        }
        requiredModules[module].push(entryModule);
        sources[module][entryModule] = '(function(module, exports, __webpack_require__) { module.exports = __webpack_require__; })';
        src = src + 'var ' + module + ' = (' + webpackBootstrapFunc.toString().replace('ENTRY_MODULE', JSON.stringify(entryModule)) + ')({' + requiredModules[module].map(function (id) { return '' + JSON.stringify(id) + ': ' + sources[module][id].toString() }).join(',') + '});\n';
      });

      src = src + 'new ((' + webpackBootstrapFunc.toString().replace('ENTRY_MODULE', JSON.stringify(moduleId)) + ')({' + requiredModules.main.map(function (id) { return '' + JSON.stringify(id) + ': ' + sources.main[id].toString() }).join(',') + '}))(self);';

      var blob = new window.Blob([src], { type: 'text/javascript' });
      if (options.bare) { return blob }

      var URL = window.URL || window.webkitURL || window.mozURL || window.msURL;

      var workerUrl = URL.createObjectURL(blob);
      var worker = new window.Worker(workerUrl);
      worker.objectURL = workerUrl;

      return worker
    };


    /***/ }),

    /***/ "./src/config.ts":
    /*!***********************!*\
      !*** ./src/config.ts ***!
      \***********************/
    /*! exports provided: hlsDefaultConfig, mergeConfig, enableStreamingMode */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "hlsDefaultConfig", function() { return hlsDefaultConfig; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "mergeConfig", function() { return mergeConfig; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "enableStreamingMode", function() { return enableStreamingMode; });
    /* harmony import */ var _controller_abr_controller__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./controller/abr-controller */ "./src/controller/abr-controller.ts");
    /* harmony import */ var _controller_audio_stream_controller__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./controller/audio-stream-controller */ "./src/controller/audio-stream-controller.ts");
    /* harmony import */ var _controller_audio_track_controller__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./controller/audio-track-controller */ "./src/controller/audio-track-controller.ts");
    /* harmony import */ var _controller_subtitle_stream_controller__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./controller/subtitle-stream-controller */ "./src/controller/subtitle-stream-controller.ts");
    /* harmony import */ var _controller_subtitle_track_controller__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./controller/subtitle-track-controller */ "./src/controller/subtitle-track-controller.ts");
    /* harmony import */ var _controller_buffer_controller__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./controller/buffer-controller */ "./src/controller/buffer-controller.ts");
    /* harmony import */ var _controller_timeline_controller__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./controller/timeline-controller */ "./src/controller/timeline-controller.ts");
    /* harmony import */ var _controller_cap_level_controller__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./controller/cap-level-controller */ "./src/controller/cap-level-controller.ts");
    /* harmony import */ var _controller_fps_controller__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./controller/fps-controller */ "./src/controller/fps-controller.ts");
    /* harmony import */ var _controller_eme_controller__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./controller/eme-controller */ "./src/controller/eme-controller.ts");
    /* harmony import */ var _controller_cmcd_controller__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./controller/cmcd-controller */ "./src/controller/cmcd-controller.ts");
    /* harmony import */ var _utils_xhr_loader__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./utils/xhr-loader */ "./src/utils/xhr-loader.ts");
    /* harmony import */ var _utils_fetch_loader__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./utils/fetch-loader */ "./src/utils/fetch-loader.ts");
    /* harmony import */ var _utils_cues__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./utils/cues */ "./src/utils/cues.ts");
    /* harmony import */ var _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./utils/mediakeys-helper */ "./src/utils/mediakeys-helper.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./utils/logger */ "./src/utils/logger.ts");
    function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

    function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) { symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); } keys.push.apply(keys, symbols); } return keys; }

    function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }

    function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

















    // If possible, keep hlsDefaultConfig shallow
    // It is cloned whenever a new Hls instance is created, by keeping the config
    // shallow the properties are cloned, and we don't end up manipulating the default
    var hlsDefaultConfig = _objectSpread(_objectSpread({
      autoStartLoad: true,
      // used by stream-controller
      startPosition: -1,
      // used by stream-controller
      defaultAudioCodec: undefined,
      // used by stream-controller
      debug: false,
      // used by logger
      capLevelOnFPSDrop: false,
      // used by fps-controller
      capLevelToPlayerSize: false,
      // used by cap-level-controller
      initialLiveManifestSize: 1,
      // used by stream-controller
      maxBufferLength: 30,
      // used by stream-controller
      backBufferLength: Infinity,
      // used by buffer-controller
      maxBufferSize: 60 * 1000 * 1000,
      // used by stream-controller
      maxBufferHole: 0.1,
      // used by stream-controller
      highBufferWatchdogPeriod: 2,
      // used by stream-controller
      nudgeOffset: 0.1,
      // used by stream-controller
      nudgeMaxRetry: 3,
      // used by stream-controller
      maxFragLookUpTolerance: 0.25,
      // used by stream-controller
      liveSyncDurationCount: 3,
      // used by latency-controller
      liveMaxLatencyDurationCount: Infinity,
      // used by latency-controller
      liveSyncDuration: undefined,
      // used by latency-controller
      liveMaxLatencyDuration: undefined,
      // used by latency-controller
      maxLiveSyncPlaybackRate: 1,
      // used by latency-controller
      liveDurationInfinity: false,
      // used by buffer-controller
      liveBackBufferLength: null,
      // used by buffer-controller
      maxMaxBufferLength: 600,
      // used by stream-controller
      enableWorker: true,
      // used by demuxer
      enableSoftwareAES: true,
      // used by decrypter
      manifestLoadingTimeOut: 10000,
      // used by playlist-loader
      manifestLoadingMaxRetry: 1,
      // used by playlist-loader
      manifestLoadingRetryDelay: 1000,
      // used by playlist-loader
      manifestLoadingMaxRetryTimeout: 64000,
      // used by playlist-loader
      startLevel: undefined,
      // used by level-controller
      levelLoadingTimeOut: 10000,
      // used by playlist-loader
      levelLoadingMaxRetry: 4,
      // used by playlist-loader
      levelLoadingRetryDelay: 1000,
      // used by playlist-loader
      levelLoadingMaxRetryTimeout: 64000,
      // used by playlist-loader
      fragLoadingTimeOut: 20000,
      // used by fragment-loader
      fragLoadingMaxRetry: 6,
      // used by fragment-loader
      fragLoadingRetryDelay: 1000,
      // used by fragment-loader
      fragLoadingMaxRetryTimeout: 64000,
      // used by fragment-loader
      startFragPrefetch: false,
      // used by stream-controller
      fpsDroppedMonitoringPeriod: 5000,
      // used by fps-controller
      fpsDroppedMonitoringThreshold: 0.2,
      // used by fps-controller
      appendErrorMaxRetry: 3,
      // used by buffer-controller
      loader: _utils_xhr_loader__WEBPACK_IMPORTED_MODULE_11__["default"],
      // loader: FetchLoader,
      fLoader: undefined,
      // used by fragment-loader
      pLoader: undefined,
      // used by playlist-loader
      xhrSetup: undefined,
      // used by xhr-loader
      licenseXhrSetup: undefined,
      // used by eme-controller
      licenseResponseCallback: undefined,
      // used by eme-controller
      abrController: _controller_abr_controller__WEBPACK_IMPORTED_MODULE_0__["default"],
      bufferController: _controller_buffer_controller__WEBPACK_IMPORTED_MODULE_5__["default"],
      capLevelController: _controller_cap_level_controller__WEBPACK_IMPORTED_MODULE_7__["default"],
      fpsController: _controller_fps_controller__WEBPACK_IMPORTED_MODULE_8__["default"],
      stretchShortVideoTrack: false,
      // used by mp4-remuxer
      maxAudioFramesDrift: 1,
      // used by mp4-remuxer
      forceKeyFrameOnDiscontinuity: true,
      // used by ts-demuxer
      abrEwmaFastLive: 3,
      // used by abr-controller
      abrEwmaSlowLive: 9,
      // used by abr-controller
      abrEwmaFastVoD: 3,
      // used by abr-controller
      abrEwmaSlowVoD: 9,
      // used by abr-controller
      abrEwmaDefaultEstimate: 5e5,
      // 500 kbps  // used by abr-controller
      abrBandWidthFactor: 0.95,
      // used by abr-controller
      abrBandWidthUpFactor: 0.7,
      // used by abr-controller
      abrMaxWithRealBitrate: false,
      // used by abr-controller
      maxStarvationDelay: 4,
      // used by abr-controller
      maxLoadingDelay: 4,
      // used by abr-controller
      minAutoBitrate: 0,
      // used by hls
      emeEnabled: false,
      // used by eme-controller
      widevineLicenseUrl: undefined,
      // used by eme-controller
      drmSystemOptions: {},
      // used by eme-controller
      requestMediaKeySystemAccessFunc: _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_14__["requestMediaKeySystemAccess"],
      // used by eme-controller
      testBandwidth: true,
      progressive: false,
      lowLatencyMode: true,
      cmcd: undefined
    }, timelineConfig()), {}, {
      subtitleStreamController:  _controller_subtitle_stream_controller__WEBPACK_IMPORTED_MODULE_3__["SubtitleStreamController"] ,
      subtitleTrackController:  _controller_subtitle_track_controller__WEBPACK_IMPORTED_MODULE_4__["default"] ,
      timelineController:  _controller_timeline_controller__WEBPACK_IMPORTED_MODULE_6__["TimelineController"] ,
      audioStreamController:  _controller_audio_stream_controller__WEBPACK_IMPORTED_MODULE_1__["default"] ,
      audioTrackController:  _controller_audio_track_controller__WEBPACK_IMPORTED_MODULE_2__["default"] ,
      emeController:  _controller_eme_controller__WEBPACK_IMPORTED_MODULE_9__["default"] ,
      cmcdController:  _controller_cmcd_controller__WEBPACK_IMPORTED_MODULE_10__["default"] 
    });

    function timelineConfig() {
      return {
        cueHandler: _utils_cues__WEBPACK_IMPORTED_MODULE_13__["default"],
        // used by timeline-controller
        enableCEA708Captions: true,
        // used by timeline-controller
        enableWebVTT: true,
        // used by timeline-controller
        enableIMSC1: true,
        // used by timeline-controller
        captionsTextTrack1Label: 'English',
        // used by timeline-controller
        captionsTextTrack1LanguageCode: 'en',
        // used by timeline-controller
        captionsTextTrack2Label: 'Spanish',
        // used by timeline-controller
        captionsTextTrack2LanguageCode: 'es',
        // used by timeline-controller
        captionsTextTrack3Label: 'Unknown CC',
        // used by timeline-controller
        captionsTextTrack3LanguageCode: '',
        // used by timeline-controller
        captionsTextTrack4Label: 'Unknown CC',
        // used by timeline-controller
        captionsTextTrack4LanguageCode: '',
        // used by timeline-controller
        renderTextTracksNatively: true
      };
    }

    function mergeConfig(defaultConfig, userConfig) {
      if ((userConfig.liveSyncDurationCount || userConfig.liveMaxLatencyDurationCount) && (userConfig.liveSyncDuration || userConfig.liveMaxLatencyDuration)) {
        throw new Error("Illegal hls.js config: don't mix up liveSyncDurationCount/liveMaxLatencyDurationCount and liveSyncDuration/liveMaxLatencyDuration");
      }

      if (userConfig.liveMaxLatencyDurationCount !== undefined && (userConfig.liveSyncDurationCount === undefined || userConfig.liveMaxLatencyDurationCount <= userConfig.liveSyncDurationCount)) {
        throw new Error('Illegal hls.js config: "liveMaxLatencyDurationCount" must be greater than "liveSyncDurationCount"');
      }

      if (userConfig.liveMaxLatencyDuration !== undefined && (userConfig.liveSyncDuration === undefined || userConfig.liveMaxLatencyDuration <= userConfig.liveSyncDuration)) {
        throw new Error('Illegal hls.js config: "liveMaxLatencyDuration" must be greater than "liveSyncDuration"');
      }

      return _extends({}, defaultConfig, userConfig);
    }
    function enableStreamingMode(config) {
      var currentLoader = config.loader;

      if (currentLoader !== _utils_fetch_loader__WEBPACK_IMPORTED_MODULE_12__["default"] && currentLoader !== _utils_xhr_loader__WEBPACK_IMPORTED_MODULE_11__["default"]) {
        // If a developer has configured their own loader, respect that choice
        _utils_logger__WEBPACK_IMPORTED_MODULE_15__["logger"].log('[config]: Custom loader detected, cannot enable progressive streaming');
        config.progressive = false;
      } else {
        var canStreamProgressively = Object(_utils_fetch_loader__WEBPACK_IMPORTED_MODULE_12__["fetchSupported"])();

        if (canStreamProgressively) {
          config.loader = _utils_fetch_loader__WEBPACK_IMPORTED_MODULE_12__["default"];
          config.progressive = true;
          config.enableSoftwareAES = true;
          _utils_logger__WEBPACK_IMPORTED_MODULE_15__["logger"].log('[config]: Progressive streaming enabled, using FetchLoader');
        }
      }
    }

    /***/ }),

    /***/ "./src/controller/abr-controller.ts":
    /*!******************************************!*\
      !*** ./src/controller/abr-controller.ts ***!
      \******************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _utils_ewma_bandwidth_estimator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/ewma-bandwidth-estimator */ "./src/utils/ewma-bandwidth-estimator.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");



    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }








    var AbrController = /*#__PURE__*/function () {
      function AbrController(hls) {
        this.hls = void 0;
        this.lastLoadedFragLevel = 0;
        this._nextAutoLevel = -1;
        this.timer = void 0;
        this.onCheck = this._abandonRulesCheck.bind(this);
        this.fragCurrent = null;
        this.partCurrent = null;
        this.bitrateTestDelay = 0;
        this.bwEstimator = void 0;
        this.hls = hls;
        var config = hls.config;
        this.bwEstimator = new _utils_ewma_bandwidth_estimator__WEBPACK_IMPORTED_MODULE_1__["default"](config.abrEwmaSlowVoD, config.abrEwmaFastVoD, config.abrEwmaDefaultEstimate);
        this.registerListeners();
      }

      var _proto = AbrController.prototype;

      _proto.registerListeners = function registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_LOADING, this.onFragLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_LOADED, this.onFragLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_BUFFERED, this.onFragBuffered, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].LEVEL_LOADED, this.onLevelLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].ERROR, this.onError, this);
      };

      _proto.unregisterListeners = function unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_LOADING, this.onFragLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_LOADED, this.onFragLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_BUFFERED, this.onFragBuffered, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].LEVEL_LOADED, this.onLevelLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].ERROR, this.onError, this);
      };

      _proto.destroy = function destroy() {
        this.unregisterListeners();
        this.clearTimer(); // @ts-ignore

        this.hls = this.onCheck = null;
        this.fragCurrent = this.partCurrent = null;
      };

      _proto.onFragLoading = function onFragLoading(event, data) {
        var frag = data.frag;

        if (frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_5__["PlaylistLevelType"].MAIN) {
          if (!this.timer) {
            var _data$part;

            this.fragCurrent = frag;
            this.partCurrent = (_data$part = data.part) != null ? _data$part : null;
            this.timer = self.setInterval(this.onCheck, 100);
          }
        }
      };

      _proto.onLevelLoaded = function onLevelLoaded(event, data) {
        var config = this.hls.config;

        if (data.details.live) {
          this.bwEstimator.update(config.abrEwmaSlowLive, config.abrEwmaFastLive);
        } else {
          this.bwEstimator.update(config.abrEwmaSlowVoD, config.abrEwmaFastVoD);
        }
      }
      /*
          This method monitors the download rate of the current fragment, and will downswitch if that fragment will not load
          quickly enough to prevent underbuffering
        */
      ;

      _proto._abandonRulesCheck = function _abandonRulesCheck() {
        var frag = this.fragCurrent,
            part = this.partCurrent,
            hls = this.hls;
        var autoLevelEnabled = hls.autoLevelEnabled,
            config = hls.config,
            media = hls.media;

        if (!frag || !media) {
          return;
        }

        var stats = part ? part.stats : frag.stats;
        var duration = part ? part.duration : frag.duration; // If loading has been aborted and not in lowLatencyMode, stop timer and return

        if (stats.aborted) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_6__["logger"].warn('frag loader destroy or aborted, disarm abandonRules');
          this.clearTimer(); // reset forced auto level value so that next level will be selected

          this._nextAutoLevel = -1;
          return;
        } // This check only runs if we're in ABR mode and actually playing


        if (!autoLevelEnabled || media.paused || !media.playbackRate || !media.readyState) {
          return;
        }

        var requestDelay = performance.now() - stats.loading.start;
        var playbackRate = Math.abs(media.playbackRate); // In order to work with a stable bandwidth, only begin monitoring bandwidth after half of the fragment has been loaded

        if (requestDelay <= 500 * duration / playbackRate) {
          return;
        }

        var levels = hls.levels,
            minAutoLevel = hls.minAutoLevel;
        var level = levels[frag.level];
        var expectedLen = stats.total || Math.max(stats.loaded, Math.round(duration * level.maxBitrate / 8));
        var loadRate = Math.max(1, stats.bwEstimate ? stats.bwEstimate / 8 : stats.loaded * 1000 / requestDelay); // fragLoadDelay is an estimate of the time (in seconds) it will take to buffer the entire fragment

        var fragLoadedDelay = (expectedLen - stats.loaded) / loadRate;
        var pos = media.currentTime; // bufferStarvationDelay is an estimate of the amount time (in seconds) it will take to exhaust the buffer

        var bufferStarvationDelay = (_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__["BufferHelper"].bufferInfo(media, pos, config.maxBufferHole).end - pos) / playbackRate; // Attempt an emergency downswitch only if less than 2 fragment lengths are buffered, and the time to finish loading
        // the current fragment is greater than the amount of buffer we have left

        if (bufferStarvationDelay >= 2 * duration / playbackRate || fragLoadedDelay <= bufferStarvationDelay) {
          return;
        }

        var fragLevelNextLoadedDelay = Number.POSITIVE_INFINITY;
        var nextLoadLevel; // Iterate through lower level and try to find the largest one that avoids rebuffering

        for (nextLoadLevel = frag.level - 1; nextLoadLevel > minAutoLevel; nextLoadLevel--) {
          // compute time to load next fragment at lower level
          // 0.8 : consider only 80% of current bw to be conservative
          // 8 = bits per byte (bps/Bps)
          var levelNextBitrate = levels[nextLoadLevel].maxBitrate;
          fragLevelNextLoadedDelay = duration * levelNextBitrate / (8 * 0.8 * loadRate);

          if (fragLevelNextLoadedDelay < bufferStarvationDelay) {
            break;
          }
        } // Only emergency switch down if it takes less time to load a new fragment at lowest level instead of continuing
        // to load the current one


        if (fragLevelNextLoadedDelay >= fragLoadedDelay) {
          return;
        }

        var bwEstimate = this.bwEstimator.getEstimate();
        _utils_logger__WEBPACK_IMPORTED_MODULE_6__["logger"].warn("Fragment " + frag.sn + (part ? ' part ' + part.index : '') + " of level " + frag.level + " is loading too slowly and will cause an underbuffer; aborting and switching to level " + nextLoadLevel + "\n      Current BW estimate: " + (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(bwEstimate) ? (bwEstimate / 1024).toFixed(3) : 'Unknown') + " Kb/s\n      Estimated load time for current fragment: " + fragLoadedDelay.toFixed(3) + " s\n      Estimated load time for the next fragment: " + fragLevelNextLoadedDelay.toFixed(3) + " s\n      Time to underbuffer: " + bufferStarvationDelay.toFixed(3) + " s");
        hls.nextLoadLevel = nextLoadLevel;
        this.bwEstimator.sample(requestDelay, stats.loaded);
        this.clearTimer();

        if (frag.loader) {
          this.fragCurrent = this.partCurrent = null;
          frag.loader.abort();
        }

        hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_LOAD_EMERGENCY_ABORTED, {
          frag: frag,
          part: part,
          stats: stats
        });
      };

      _proto.onFragLoaded = function onFragLoaded(event, _ref) {
        var frag = _ref.frag,
            part = _ref.part;

        if (frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_5__["PlaylistLevelType"].MAIN && Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(frag.sn)) {
          var stats = part ? part.stats : frag.stats;
          var duration = part ? part.duration : frag.duration; // stop monitoring bw once frag loaded

          this.clearTimer(); // store level id after successful fragment load

          this.lastLoadedFragLevel = frag.level; // reset forced auto level value so that next level will be selected

          this._nextAutoLevel = -1; // compute level average bitrate

          if (this.hls.config.abrMaxWithRealBitrate) {
            var level = this.hls.levels[frag.level];
            var loadedBytes = (level.loaded ? level.loaded.bytes : 0) + stats.loaded;
            var loadedDuration = (level.loaded ? level.loaded.duration : 0) + duration;
            level.loaded = {
              bytes: loadedBytes,
              duration: loadedDuration
            };
            level.realBitrate = Math.round(8 * loadedBytes / loadedDuration);
          }

          if (frag.bitrateTest) {
            var fragBufferedData = {
              stats: stats,
              frag: frag,
              part: part,
              id: frag.type
            };
            this.onFragBuffered(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_BUFFERED, fragBufferedData);
            frag.bitrateTest = false;
          }
        }
      };

      _proto.onFragBuffered = function onFragBuffered(event, data) {
        var frag = data.frag,
            part = data.part;
        var stats = part ? part.stats : frag.stats;

        if (stats.aborted) {
          return;
        } // Only count non-alt-audio frags which were actually buffered in our BW calculations


        if (frag.type !== _types_loader__WEBPACK_IMPORTED_MODULE_5__["PlaylistLevelType"].MAIN || frag.sn === 'initSegment') {
          return;
        } // Use the difference between parsing and request instead of buffering and request to compute fragLoadingProcessing;
        // rationale is that buffer appending only happens once media is attached. This can happen when config.startFragPrefetch
        // is used. If we used buffering in that case, our BW estimate sample will be very large.


        var processingMs = stats.parsing.end - stats.loading.start;
        this.bwEstimator.sample(processingMs, stats.loaded);
        stats.bwEstimate = this.bwEstimator.getEstimate();

        if (frag.bitrateTest) {
          this.bitrateTestDelay = processingMs / 1000;
        } else {
          this.bitrateTestDelay = 0;
        }
      };

      _proto.onError = function onError(event, data) {
        // stop timer in case of frag loading error
        switch (data.details) {
          case _errors__WEBPACK_IMPORTED_MODULE_4__["ErrorDetails"].FRAG_LOAD_ERROR:
          case _errors__WEBPACK_IMPORTED_MODULE_4__["ErrorDetails"].FRAG_LOAD_TIMEOUT:
            this.clearTimer();
            break;
        }
      };

      _proto.clearTimer = function clearTimer() {
        self.clearInterval(this.timer);
        this.timer = undefined;
      } // return next auto level
      ;

      _proto.getNextABRAutoLevel = function getNextABRAutoLevel() {
        var fragCurrent = this.fragCurrent,
            partCurrent = this.partCurrent,
            hls = this.hls;
        var maxAutoLevel = hls.maxAutoLevel,
            config = hls.config,
            minAutoLevel = hls.minAutoLevel,
            media = hls.media;
        var currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;
        var pos = media ? media.currentTime : 0; // playbackRate is the absolute value of the playback rate; if media.playbackRate is 0, we use 1 to load as
        // if we're playing back at the normal rate.

        var playbackRate = media && media.playbackRate !== 0 ? Math.abs(media.playbackRate) : 1.0;
        var avgbw = this.bwEstimator ? this.bwEstimator.getEstimate() : config.abrEwmaDefaultEstimate; // bufferStarvationDelay is the wall-clock time left until the playback buffer is exhausted.

        var bufferStarvationDelay = (_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__["BufferHelper"].bufferInfo(media, pos, config.maxBufferHole).end - pos) / playbackRate; // First, look to see if we can find a level matching with our avg bandwidth AND that could also guarantee no rebuffering at all

        var bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, config.abrBandWidthFactor, config.abrBandWidthUpFactor);

        if (bestLevel >= 0) {
          return bestLevel;
        }

        _utils_logger__WEBPACK_IMPORTED_MODULE_6__["logger"].trace((bufferStarvationDelay ? 'rebuffering expected' : 'buffer is empty') + ", finding optimal quality level"); // not possible to get rid of rebuffering ... let's try to find level that will guarantee less than maxStarvationDelay of rebuffering
        // if no matching level found, logic will return 0

        var maxStarvationDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxStarvationDelay) : config.maxStarvationDelay;
        var bwFactor = config.abrBandWidthFactor;
        var bwUpFactor = config.abrBandWidthUpFactor;

        if (!bufferStarvationDelay) {
          // in case buffer is empty, let's check if previous fragment was loaded to perform a bitrate test
          var bitrateTestDelay = this.bitrateTestDelay;

          if (bitrateTestDelay) {
            // if it is the case, then we need to adjust our max starvation delay using maxLoadingDelay config value
            // max video loading delay used in  automatic start level selection :
            // in that mode ABR controller will ensure that video loading time (ie the time to fetch the first fragment at lowest quality level +
            // the time to fetch the fragment at the appropriate quality level is less than ```maxLoadingDelay``` )
            // cap maxLoadingDelay and ensure it is not bigger 'than bitrate test' frag duration
            var maxLoadingDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxLoadingDelay) : config.maxLoadingDelay;
            maxStarvationDelay = maxLoadingDelay - bitrateTestDelay;
            _utils_logger__WEBPACK_IMPORTED_MODULE_6__["logger"].trace("bitrate test took " + Math.round(1000 * bitrateTestDelay) + "ms, set first fragment max fetchDuration to " + Math.round(1000 * maxStarvationDelay) + " ms"); // don't use conservative factor on bitrate test

            bwFactor = bwUpFactor = 1;
          }
        }

        bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay + maxStarvationDelay, bwFactor, bwUpFactor);
        return Math.max(bestLevel, 0);
      };

      _proto.findBestLevel = function findBestLevel(currentBw, minAutoLevel, maxAutoLevel, maxFetchDuration, bwFactor, bwUpFactor) {
        var _level$details;

        var fragCurrent = this.fragCurrent,
            partCurrent = this.partCurrent,
            currentLevel = this.lastLoadedFragLevel;
        var levels = this.hls.levels;
        var level = levels[currentLevel];
        var live = !!(level !== null && level !== void 0 && (_level$details = level.details) !== null && _level$details !== void 0 && _level$details.live);
        var currentCodecSet = level === null || level === void 0 ? void 0 : level.codecSet;
        var currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;

        for (var i = maxAutoLevel; i >= minAutoLevel; i--) {
          var levelInfo = levels[i];

          if (!levelInfo || currentCodecSet && levelInfo.codecSet !== currentCodecSet) {
            continue;
          }

          var levelDetails = levelInfo.details;
          var avgDuration = (partCurrent ? levelDetails === null || levelDetails === void 0 ? void 0 : levelDetails.partTarget : levelDetails === null || levelDetails === void 0 ? void 0 : levelDetails.averagetargetduration) || currentFragDuration;
          var adjustedbw = void 0; // follow algorithm captured from stagefright :
          // https://android.googlesource.com/platform/frameworks/av/+/master/media/libstagefright/httplive/LiveSession.cpp
          // Pick the highest bandwidth stream below or equal to estimated bandwidth.
          // consider only 80% of the available bandwidth, but if we are switching up,
          // be even more conservative (70%) to avoid overestimating and immediately
          // switching back.

          if (i <= currentLevel) {
            adjustedbw = bwFactor * currentBw;
          } else {
            adjustedbw = bwUpFactor * currentBw;
          }

          var bitrate = levels[i].maxBitrate;
          var fetchDuration = bitrate * avgDuration / adjustedbw;
          _utils_logger__WEBPACK_IMPORTED_MODULE_6__["logger"].trace("level/adjustedbw/bitrate/avgDuration/maxFetchDuration/fetchDuration: " + i + "/" + Math.round(adjustedbw) + "/" + bitrate + "/" + avgDuration + "/" + maxFetchDuration + "/" + fetchDuration); // if adjusted bw is greater than level bitrate AND

          if (adjustedbw > bitrate && ( // fragment fetchDuration unknown OR live stream OR fragment fetchDuration less than max allowed fetch duration, then this level matches
          // we don't account for max Fetch Duration for live streams, this is to avoid switching down when near the edge of live sliding window ...
          // special case to support startLevel = -1 (bitrateTest) on live streams : in that case we should not exit loop so that findBestLevel will return -1
          !fetchDuration || live && !this.bitrateTestDelay || fetchDuration < maxFetchDuration)) {
            // as we are looping from highest to lowest, this will return the best achievable quality level
            return i;
          }
        } // not enough time budget even with quality level 0 ... rebuffering might happen


        return -1;
      };

      _createClass(AbrController, [{
        key: "nextAutoLevel",
        get: function get() {
          var forcedAutoLevel = this._nextAutoLevel;
          var bwEstimator = this.bwEstimator; // in case next auto level has been forced, and bw not available or not reliable, return forced value

          if (forcedAutoLevel !== -1 && (!bwEstimator || !bwEstimator.canEstimate())) {
            return forcedAutoLevel;
          } // compute next level using ABR logic


          var nextABRAutoLevel = this.getNextABRAutoLevel(); // if forced auto level has been defined, use it to cap ABR computed quality level

          if (forcedAutoLevel !== -1) {
            nextABRAutoLevel = Math.min(forcedAutoLevel, nextABRAutoLevel);
          }

          return nextABRAutoLevel;
        },
        set: function set(nextLevel) {
          this._nextAutoLevel = nextLevel;
        }
      }]);

      return AbrController;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (AbrController);

    /***/ }),

    /***/ "./src/controller/audio-stream-controller.ts":
    /*!***************************************************!*\
      !*** ./src/controller/audio-stream-controller.ts ***!
      \***************************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./base-stream-controller */ "./src/controller/base-stream-controller.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
    /* harmony import */ var _fragment_tracker__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./fragment-tracker */ "./src/controller/fragment-tracker.ts");
    /* harmony import */ var _types_level__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../types/level */ "./src/types/level.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
    /* harmony import */ var _loader_fragment__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../loader/fragment */ "./src/loader/fragment.ts");
    /* harmony import */ var _demux_chunk_cache__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../demux/chunk-cache */ "./src/demux/chunk-cache.ts");
    /* harmony import */ var _demux_transmuxer_interface__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../demux/transmuxer-interface */ "./src/demux/transmuxer-interface.ts");
    /* harmony import */ var _types_transmuxer__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../types/transmuxer */ "./src/types/transmuxer.ts");
    /* harmony import */ var _fragment_finders__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./fragment-finders */ "./src/controller/fragment-finders.ts");
    /* harmony import */ var _utils_discontinuities__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../utils/discontinuities */ "./src/utils/discontinuities.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");


    function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }















    var TICK_INTERVAL = 100; // how often to tick in ms

    var AudioStreamController = /*#__PURE__*/function (_BaseStreamController) {
      _inheritsLoose(AudioStreamController, _BaseStreamController);

      function AudioStreamController(hls, fragmentTracker) {
        var _this;

        _this = _BaseStreamController.call(this, hls, fragmentTracker, '[audio-stream-controller]') || this;
        _this.videoBuffer = null;
        _this.videoTrackCC = -1;
        _this.waitingVideoCC = -1;
        _this.audioSwitch = false;
        _this.trackId = -1;
        _this.waitingData = null;
        _this.mainDetails = null;
        _this.bufferFlushed = false;

        _this._registerListeners();

        return _this;
      }

      var _proto = AudioStreamController.prototype;

      _proto.onHandlerDestroying = function onHandlerDestroying() {
        this._unregisterListeners();

        this.mainDetails = null;
      };

      _proto._registerListeners = function _registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].LEVEL_LOADED, this.onLevelLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].ERROR, this.onError, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].BUFFER_RESET, this.onBufferReset, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].BUFFER_CREATED, this.onBufferCreated, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].BUFFER_FLUSHED, this.onBufferFlushed, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].INIT_PTS_FOUND, this.onInitPtsFound, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_BUFFERED, this.onFragBuffered, this);
      };

      _proto._unregisterListeners = function _unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].LEVEL_LOADED, this.onLevelLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].ERROR, this.onError, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].BUFFER_RESET, this.onBufferReset, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].BUFFER_CREATED, this.onBufferCreated, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].BUFFER_FLUSHED, this.onBufferFlushed, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].INIT_PTS_FOUND, this.onInitPtsFound, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_BUFFERED, this.onFragBuffered, this);
      } // INIT_PTS_FOUND is triggered when the video track parsed in the stream-controller has a new PTS value
      ;

      _proto.onInitPtsFound = function onInitPtsFound(event, _ref) {
        var frag = _ref.frag,
            id = _ref.id,
            initPTS = _ref.initPTS;

        // Always update the new INIT PTS
        // Can change due level switch
        if (id === 'main') {
          var cc = frag.cc;
          this.initPTS[frag.cc] = initPTS;
          this.log("InitPTS for cc: " + cc + " found from main: " + initPTS);
          this.videoTrackCC = cc; // If we are waiting, tick immediately to unblock audio fragment transmuxing

          if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_INIT_PTS) {
            this.tick();
          }
        }
      };

      _proto.startLoad = function startLoad(startPosition) {
        if (!this.levels) {
          this.startPosition = startPosition;
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].STOPPED;
          return;
        }

        var lastCurrentTime = this.lastCurrentTime;
        this.stopLoad();
        this.setInterval(TICK_INTERVAL);
        this.fragLoadError = 0;

        if (lastCurrentTime > 0 && startPosition === -1) {
          this.log("Override startPosition with lastCurrentTime @" + lastCurrentTime.toFixed(3));
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
        } else {
          this.loadedmetadata = false;
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_TRACK;
        }

        this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;
        this.tick();
      };

      _proto.doTick = function doTick() {
        switch (this.state) {
          case _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE:
            this.doTickIdle();
            break;

          case _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_TRACK:
            {
              var _levels$trackId;

              var levels = this.levels,
                  trackId = this.trackId;
              var details = levels === null || levels === void 0 ? void 0 : (_levels$trackId = levels[trackId]) === null || _levels$trackId === void 0 ? void 0 : _levels$trackId.details;

              if (details) {
                if (this.waitForCdnTuneIn(details)) {
                  break;
                }

                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_INIT_PTS;
              }

              break;
            }

          case _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].FRAG_LOADING_WAITING_RETRY:
            {
              var _this$media;

              var now = performance.now();
              var retryDate = this.retryDate; // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading

              if (!retryDate || now >= retryDate || (_this$media = this.media) !== null && _this$media !== void 0 && _this$media.seeking) {
                this.log('RetryDate reached, switch back to IDLE state');
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
              }

              break;
            }

          case _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_INIT_PTS:
            {
              // Ensure we don't get stuck in the WAITING_INIT_PTS state if the waiting frag CC doesn't match any initPTS
              var waitingData = this.waitingData;

              if (waitingData) {
                var frag = waitingData.frag,
                    part = waitingData.part,
                    cache = waitingData.cache,
                    complete = waitingData.complete;

                if (this.initPTS[frag.cc] !== undefined) {
                  this.waitingData = null;
                  this.waitingVideoCC = -1;
                  this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].FRAG_LOADING;
                  var payload = cache.flush();
                  var data = {
                    frag: frag,
                    part: part,
                    payload: payload,
                    networkDetails: null
                  };

                  this._handleFragmentLoadProgress(data);

                  if (complete) {
                    _BaseStreamController.prototype._handleFragmentLoadComplete.call(this, data);
                  }
                } else if (this.videoTrackCC !== this.waitingVideoCC) {
                  // Drop waiting fragment if videoTrackCC has changed since waitingFragment was set and initPTS was not found
                  _utils_logger__WEBPACK_IMPORTED_MODULE_14__["logger"].log("Waiting fragment cc (" + frag.cc + ") cancelled because video is at cc " + this.videoTrackCC);
                  this.clearWaitingFragment();
                } else {
                  // Drop waiting fragment if an earlier fragment is needed
                  var pos = this.getLoadPosition();
                  var bufferInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__["BufferHelper"].bufferInfo(this.mediaBuffer, pos, this.config.maxBufferHole);
                  var waitingFragmentAtPosition = Object(_fragment_finders__WEBPACK_IMPORTED_MODULE_11__["fragmentWithinToleranceTest"])(bufferInfo.end, this.config.maxFragLookUpTolerance, frag);

                  if (waitingFragmentAtPosition < 0) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_14__["logger"].log("Waiting fragment cc (" + frag.cc + ") @ " + frag.start + " cancelled because another fragment at " + bufferInfo.end + " is needed");
                    this.clearWaitingFragment();
                  }
                }
              } else {
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
              }
            }
        }

        this.onTickEnd();
      };

      _proto.clearWaitingFragment = function clearWaitingFragment() {
        var waitingData = this.waitingData;

        if (waitingData) {
          this.fragmentTracker.removeFragment(waitingData.frag);
          this.waitingData = null;
          this.waitingVideoCC = -1;
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
        }
      };

      _proto.onTickEnd = function onTickEnd() {
        var media = this.media;

        if (!media || !media.readyState) {
          // Exit early if we don't have media or if the media hasn't buffered anything yet (readyState 0)
          return;
        }

        var mediaBuffer = this.mediaBuffer ? this.mediaBuffer : media;
        var buffered = mediaBuffer.buffered;

        if (!this.loadedmetadata && buffered.length) {
          this.loadedmetadata = true;
        }

        this.lastCurrentTime = media.currentTime;
      };

      _proto.doTickIdle = function doTickIdle() {
        var _frag$decryptdata, _frag$decryptdata2;

        var hls = this.hls,
            levels = this.levels,
            media = this.media,
            trackId = this.trackId;
        var config = hls.config;

        if (!levels || !levels[trackId]) {
          return;
        } // if video not attached AND
        // start fragment already requested OR start frag prefetch not enabled
        // exit loop
        // => if media not attached but start frag prefetch is enabled and start frag not requested yet, we will not exit loop


        if (!media && (this.startFragRequested || !config.startFragPrefetch)) {
          return;
        }

        var levelInfo = levels[trackId];
        var trackDetails = levelInfo.details;

        if (!trackDetails || trackDetails.live && this.levelLastLoaded !== trackId || this.waitForCdnTuneIn(trackDetails)) {
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_TRACK;
          return;
        }

        if (this.bufferFlushed) {
          this.bufferFlushed = false;
          this.afterBufferFlushed(this.mediaBuffer ? this.mediaBuffer : this.media, _loader_fragment__WEBPACK_IMPORTED_MODULE_7__["ElementaryStreamTypes"].AUDIO, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].AUDIO);
        }

        var bufferInfo = this.getFwdBufferInfo(this.mediaBuffer ? this.mediaBuffer : this.media, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].AUDIO);

        if (bufferInfo === null) {
          return;
        }

        var bufferLen = bufferInfo.len;
        var maxBufLen = this.getMaxBufferLength();
        var audioSwitch = this.audioSwitch; // if buffer length is less than maxBufLen try to load a new fragment

        if (bufferLen >= maxBufLen && !audioSwitch) {
          return;
        }

        if (!audioSwitch && this._streamEnded(bufferInfo, trackDetails)) {
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].BUFFER_EOS, {
            type: 'audio'
          });
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].ENDED;
          return;
        }

        var fragments = trackDetails.fragments;
        var start = fragments[0].start;
        var targetBufferTime = bufferInfo.end;

        if (audioSwitch) {
          var pos = this.getLoadPosition();
          targetBufferTime = pos; // if currentTime (pos) is less than alt audio playlist start time, it means that alt audio is ahead of currentTime

          if (trackDetails.PTSKnown && pos < start) {
            // if everything is buffered from pos to start or if audio buffer upfront, let's seek to start
            if (bufferInfo.end > start || bufferInfo.nextStart) {
              this.log('Alt audio track ahead of main track, seek to start of alt audio track');
              media.currentTime = start + 0.05;
            }
          }
        }

        var frag = this.getNextFragment(targetBufferTime, trackDetails);

        if (!frag) {
          this.bufferFlushed = true;
          return;
        }

        if (((_frag$decryptdata = frag.decryptdata) === null || _frag$decryptdata === void 0 ? void 0 : _frag$decryptdata.keyFormat) === 'identity' && !((_frag$decryptdata2 = frag.decryptdata) !== null && _frag$decryptdata2 !== void 0 && _frag$decryptdata2.key)) {
          this.loadKey(frag, trackDetails);
        } else {
          this.loadFragment(frag, trackDetails, targetBufferTime);
        }
      };

      _proto.getMaxBufferLength = function getMaxBufferLength() {
        var maxConfigBuffer = _BaseStreamController.prototype.getMaxBufferLength.call(this);

        var mainBufferInfo = this.getFwdBufferInfo(this.videoBuffer ? this.videoBuffer : this.media, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN);

        if (mainBufferInfo === null) {
          return maxConfigBuffer;
        }

        return Math.max(maxConfigBuffer, mainBufferInfo.len);
      };

      _proto.onMediaDetaching = function onMediaDetaching() {
        this.videoBuffer = null;

        _BaseStreamController.prototype.onMediaDetaching.call(this);
      };

      _proto.onAudioTracksUpdated = function onAudioTracksUpdated(event, _ref2) {
        var audioTracks = _ref2.audioTracks;
        this.resetTransmuxer();
        this.levels = audioTracks.map(function (mediaPlaylist) {
          return new _types_level__WEBPACK_IMPORTED_MODULE_5__["Level"](mediaPlaylist);
        });
      };

      _proto.onAudioTrackSwitching = function onAudioTrackSwitching(event, data) {
        // if any URL found on new audio track, it is an alternate audio track
        var altAudio = !!data.url;
        this.trackId = data.id;
        var fragCurrent = this.fragCurrent;

        if (fragCurrent !== null && fragCurrent !== void 0 && fragCurrent.loader) {
          fragCurrent.loader.abort();
        }

        this.fragCurrent = null;
        this.clearWaitingFragment(); // destroy useless transmuxer when switching audio to main

        if (!altAudio) {
          this.resetTransmuxer();
        } else {
          // switching to audio track, start timer if not already started
          this.setInterval(TICK_INTERVAL);
        } // should we switch tracks ?


        if (altAudio) {
          this.audioSwitch = true; // main audio track are handled by stream-controller, just do something if switching to alt audio track

          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
        } else {
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].STOPPED;
        }

        this.tick();
      };

      _proto.onManifestLoading = function onManifestLoading() {
        this.mainDetails = null;
        this.fragmentTracker.removeAllFragments();
        this.startPosition = this.lastCurrentTime = 0;
        this.bufferFlushed = false;
      };

      _proto.onLevelLoaded = function onLevelLoaded(event, data) {
        this.mainDetails = data.details;
      };

      _proto.onAudioTrackLoaded = function onAudioTrackLoaded(event, data) {
        var _track$details;

        var levels = this.levels;
        var newDetails = data.details,
            trackId = data.id;

        if (!levels) {
          this.warn("Audio tracks were reset while loading level " + trackId);
          return;
        }

        this.log("Track " + trackId + " loaded [" + newDetails.startSN + "," + newDetails.endSN + "],duration:" + newDetails.totalduration);
        var track = levels[trackId];
        var sliding = 0;

        if (newDetails.live || (_track$details = track.details) !== null && _track$details !== void 0 && _track$details.live) {
          var mainDetails = this.mainDetails;

          if (!newDetails.fragments[0]) {
            newDetails.deltaUpdateFailed = true;
          }

          if (newDetails.deltaUpdateFailed || !mainDetails) {
            return;
          }

          if (!track.details && newDetails.hasProgramDateTime && mainDetails.hasProgramDateTime) {
            // Make sure our audio rendition is aligned with the "main" rendition, using
            // pdt as our reference times.
            Object(_utils_discontinuities__WEBPACK_IMPORTED_MODULE_12__["alignMediaPlaylistByPDT"])(newDetails, mainDetails);
            sliding = newDetails.fragments[0].start;
          } else {
            sliding = this.alignPlaylists(newDetails, track.details);
          }
        }

        track.details = newDetails;
        this.levelLastLoaded = trackId; // compute start position if we are aligned with the main playlist

        if (!this.startFragRequested && (this.mainDetails || !newDetails.live)) {
          this.setStartPosition(track.details, sliding);
        } // only switch back to IDLE state if we were waiting for track to start downloading a new fragment


        if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_TRACK && !this.waitForCdnTuneIn(newDetails)) {
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
        } // trigger handler right now


        this.tick();
      };

      _proto._handleFragmentLoadProgress = function _handleFragmentLoadProgress(data) {
        var _frag$initSegment;

        var frag = data.frag,
            part = data.part,
            payload = data.payload;
        var config = this.config,
            trackId = this.trackId,
            levels = this.levels;

        if (!levels) {
          this.warn("Audio tracks were reset while fragment load was in progress. Fragment " + frag.sn + " of level " + frag.level + " will not be buffered");
          return;
        }

        var track = levels[trackId];
        console.assert(track, 'Audio track is defined on fragment load progress');
        var details = track.details;
        console.assert(details, 'Audio track details are defined on fragment load progress');
        var audioCodec = config.defaultAudioCodec || track.audioCodec || 'mp4a.40.2';
        var transmuxer = this.transmuxer;

        if (!transmuxer) {
          transmuxer = this.transmuxer = new _demux_transmuxer_interface__WEBPACK_IMPORTED_MODULE_9__["default"](this.hls, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].AUDIO, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this));
        } // Check if we have video initPTS
        // If not we need to wait for it


        var initPTS = this.initPTS[frag.cc];
        var initSegmentData = (_frag$initSegment = frag.initSegment) === null || _frag$initSegment === void 0 ? void 0 : _frag$initSegment.data;

        if (initPTS !== undefined) {
          // this.log(`Transmuxing ${sn} of [${details.startSN} ,${details.endSN}],track ${trackId}`);
          // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)
          var accurateTimeOffset = false; // details.PTSKnown || !details.live;

          var partIndex = part ? part.index : -1;
          var partial = partIndex !== -1;
          var chunkMeta = new _types_transmuxer__WEBPACK_IMPORTED_MODULE_10__["ChunkMetadata"](frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);
          transmuxer.push(payload, initSegmentData, audioCodec, '', frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);
        } else {
          _utils_logger__WEBPACK_IMPORTED_MODULE_14__["logger"].log("Unknown video PTS for cc " + frag.cc + ", waiting for video PTS before demuxing audio frag " + frag.sn + " of [" + details.startSN + " ," + details.endSN + "],track " + trackId);

          var _this$waitingData = this.waitingData = this.waitingData || {
            frag: frag,
            part: part,
            cache: new _demux_chunk_cache__WEBPACK_IMPORTED_MODULE_8__["default"](),
            complete: false
          },
              cache = _this$waitingData.cache;

          cache.push(new Uint8Array(payload));
          this.waitingVideoCC = this.videoTrackCC;
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_INIT_PTS;
        }
      };

      _proto._handleFragmentLoadComplete = function _handleFragmentLoadComplete(fragLoadedData) {
        if (this.waitingData) {
          this.waitingData.complete = true;
          return;
        }

        _BaseStreamController.prototype._handleFragmentLoadComplete.call(this, fragLoadedData);
      };

      _proto.onBufferReset = function
        /* event: Events.BUFFER_RESET */
      onBufferReset() {
        // reset reference to sourcebuffers
        this.mediaBuffer = this.videoBuffer = null;
        this.loadedmetadata = false;
      };

      _proto.onBufferCreated = function onBufferCreated(event, data) {
        var audioTrack = data.tracks.audio;

        if (audioTrack) {
          this.mediaBuffer = audioTrack.buffer;
        }

        if (data.tracks.video) {
          this.videoBuffer = data.tracks.video.buffer;
        }
      };

      _proto.onFragBuffered = function onFragBuffered(event, data) {
        var frag = data.frag,
            part = data.part;

        if (frag.type !== _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].AUDIO) {
          return;
        }

        if (this.fragContextChanged(frag)) {
          // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion
          // Avoid setting state back to IDLE or concluding the audio switch; otherwise, the switched-to track will not buffer
          this.warn("Fragment " + frag.sn + (part ? ' p: ' + part.index : '') + " of level " + frag.level + " finished buffering, but was aborted. state: " + this.state + ", audioSwitch: " + this.audioSwitch);
          return;
        }

        if (frag.sn !== 'initSegment') {
          this.fragPrevious = frag;

          if (this.audioSwitch) {
            this.audioSwitch = false;
            this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].AUDIO_TRACK_SWITCHED, {
              id: this.trackId
            });
          }
        }

        this.fragBufferedComplete(frag, part);
      };

      _proto.onError = function onError(event, data) {
        switch (data.details) {
          case _errors__WEBPACK_IMPORTED_MODULE_13__["ErrorDetails"].FRAG_LOAD_ERROR:
          case _errors__WEBPACK_IMPORTED_MODULE_13__["ErrorDetails"].FRAG_LOAD_TIMEOUT:
          case _errors__WEBPACK_IMPORTED_MODULE_13__["ErrorDetails"].KEY_LOAD_ERROR:
          case _errors__WEBPACK_IMPORTED_MODULE_13__["ErrorDetails"].KEY_LOAD_TIMEOUT:
            // TODO: Skip fragments that do not belong to this.fragCurrent audio-group id
            this.onFragmentOrKeyLoadError(_types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].AUDIO, data);
            break;

          case _errors__WEBPACK_IMPORTED_MODULE_13__["ErrorDetails"].AUDIO_TRACK_LOAD_ERROR:
          case _errors__WEBPACK_IMPORTED_MODULE_13__["ErrorDetails"].AUDIO_TRACK_LOAD_TIMEOUT:
            //  when in ERROR state, don't switch back to IDLE state in case a non-fatal error is received
            if (this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].ERROR && this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].STOPPED) {
              // if fatal error, stop processing, otherwise move to IDLE to retry loading
              this.state = data.fatal ? _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].ERROR : _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
              this.warn(data.details + " while loading frag, switching to " + this.state + " state");
            }

            break;

          case _errors__WEBPACK_IMPORTED_MODULE_13__["ErrorDetails"].BUFFER_FULL_ERROR:
            // if in appending state
            if (data.parent === 'audio' && (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].PARSING || this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].PARSED)) {
              var flushBuffer = true;
              var bufferedInfo = this.getFwdBufferInfo(this.mediaBuffer, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].AUDIO); // 0.5 : tolerance needed as some browsers stalls playback before reaching buffered end
              // reduce max buf len if current position is buffered

              if (bufferedInfo && bufferedInfo.len > 0.5) {
                flushBuffer = !this.reduceMaxBufferLength(bufferedInfo.len);
              }

              if (flushBuffer) {
                // current position is not buffered, but browser is still complaining about buffer full error
                // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708
                // in that case flush the whole audio buffer to recover
                this.warn('Buffer full error also media.currentTime is not buffered, flush audio buffer');
                this.fragCurrent = null;

                _BaseStreamController.prototype.flushMainBuffer.call(this, 0, Number.POSITIVE_INFINITY, 'audio');
              }

              this.resetLoadingState();
            }

            break;
        }
      };

      _proto.onBufferFlushed = function onBufferFlushed(event, _ref3) {
        var type = _ref3.type;

        if (type === _loader_fragment__WEBPACK_IMPORTED_MODULE_7__["ElementaryStreamTypes"].AUDIO) {
          this.bufferFlushed = true;
        }
      };

      _proto._handleTransmuxComplete = function _handleTransmuxComplete(transmuxResult) {
        var _id3$samples;

        var id = 'audio';
        var hls = this.hls;
        var remuxResult = transmuxResult.remuxResult,
            chunkMeta = transmuxResult.chunkMeta;
        var context = this.getCurrentContext(chunkMeta);

        if (!context) {
          this.warn("The loading context changed while buffering fragment " + chunkMeta.sn + " of level " + chunkMeta.level + ". This chunk will not be buffered.");
          this.resetLiveStartWhenNotLoaded(chunkMeta.level);
          return;
        }

        var frag = context.frag,
            part = context.part;
        var audio = remuxResult.audio,
            text = remuxResult.text,
            id3 = remuxResult.id3,
            initSegment = remuxResult.initSegment; // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.
        // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.

        if (this.fragContextChanged(frag)) {
          return;
        }

        this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].PARSING;

        if (this.audioSwitch && audio) {
          this.completeAudioSwitch();
        }

        if (initSegment !== null && initSegment !== void 0 && initSegment.tracks) {
          this._bufferInitSegment(initSegment.tracks, frag, chunkMeta);

          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_PARSING_INIT_SEGMENT, {
            frag: frag,
            id: id,
            tracks: initSegment.tracks
          }); // Only flush audio from old audio tracks when PTS is known on new audio track
        }

        if (audio) {
          var startPTS = audio.startPTS,
              endPTS = audio.endPTS,
              startDTS = audio.startDTS,
              endDTS = audio.endDTS;

          if (part) {
            part.elementaryStreams[_loader_fragment__WEBPACK_IMPORTED_MODULE_7__["ElementaryStreamTypes"].AUDIO] = {
              startPTS: startPTS,
              endPTS: endPTS,
              startDTS: startDTS,
              endDTS: endDTS
            };
          }

          frag.setElementaryStreamInfo(_loader_fragment__WEBPACK_IMPORTED_MODULE_7__["ElementaryStreamTypes"].AUDIO, startPTS, endPTS, startDTS, endDTS);
          this.bufferFragmentData(audio, frag, part, chunkMeta);
        }

        if (id3 !== null && id3 !== void 0 && (_id3$samples = id3.samples) !== null && _id3$samples !== void 0 && _id3$samples.length) {
          var emittedID3 = _extends({
            frag: frag,
            id: id
          }, id3);

          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_PARSING_METADATA, emittedID3);
        }

        if (text) {
          var emittedText = _extends({
            frag: frag,
            id: id
          }, text);

          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].FRAG_PARSING_USERDATA, emittedText);
        }
      };

      _proto._bufferInitSegment = function _bufferInitSegment(tracks, frag, chunkMeta) {
        if (this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].PARSING) {
          return;
        } // delete any video track found on audio transmuxer


        if (tracks.video) {
          delete tracks.video;
        } // include levelCodec in audio and video tracks


        var track = tracks.audio;

        if (!track) {
          return;
        }

        track.levelCodec = track.codec;
        track.id = 'audio';
        this.log("Init audio buffer, container:" + track.container + ", codecs[parsed]=[" + track.codec + "]");
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].BUFFER_CODECS, tracks);
        var initSegment = track.initSegment;

        if (initSegment !== null && initSegment !== void 0 && initSegment.byteLength) {
          var segment = {
            type: 'audio',
            frag: frag,
            part: null,
            chunkMeta: chunkMeta,
            parent: frag.type,
            data: initSegment
          };
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].BUFFER_APPENDING, segment);
        } // trigger handler right now


        this.tick();
      };

      _proto.loadFragment = function loadFragment(frag, trackDetails, targetBufferTime) {
        // only load if fragment is not loaded or if in audio switch
        var fragState = this.fragmentTracker.getState(frag);
        this.fragCurrent = frag; // we force a frag loading in audio switch as fragment tracker might not have evicted previous frags in case of quick audio switch

        if (this.audioSwitch || fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_4__["FragmentState"].NOT_LOADED || fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_4__["FragmentState"].PARTIAL) {
          if (frag.sn === 'initSegment') {
            this._loadInitSegment(frag);
          } else if (trackDetails.live && !Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(this.initPTS[frag.cc])) {
            this.log("Waiting for video PTS in continuity counter " + frag.cc + " of live stream before loading audio fragment " + frag.sn + " of level " + this.trackId);
            this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_INIT_PTS;
          } else {
            this.startFragRequested = true;

            _BaseStreamController.prototype.loadFragment.call(this, frag, trackDetails, targetBufferTime);
          }
        }
      };

      _proto.completeAudioSwitch = function completeAudioSwitch() {
        var hls = this.hls,
            media = this.media,
            trackId = this.trackId;

        if (media) {
          this.log('Switching audio track : flushing all audio');

          _BaseStreamController.prototype.flushMainBuffer.call(this, 0, Number.POSITIVE_INFINITY, 'audio');
        }

        this.audioSwitch = false;
        hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].AUDIO_TRACK_SWITCHED, {
          id: trackId
        });
      };

      return AudioStreamController;
    }(_base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["default"]);

    /* harmony default export */ __webpack_exports__["default"] = (AudioStreamController);

    /***/ }),

    /***/ "./src/controller/audio-track-controller.ts":
    /*!**************************************************!*\
      !*** ./src/controller/audio-track-controller.ts ***!
      \**************************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _base_playlist_controller__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./base-playlist-controller */ "./src/controller/base-playlist-controller.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }






    var AudioTrackController = /*#__PURE__*/function (_BasePlaylistControll) {
      _inheritsLoose(AudioTrackController, _BasePlaylistControll);

      function AudioTrackController(hls) {
        var _this;

        _this = _BasePlaylistControll.call(this, hls, '[audio-track-controller]') || this;
        _this.tracks = [];
        _this.groupId = null;
        _this.tracksInGroup = [];
        _this.trackId = -1;
        _this.trackName = '';
        _this.selectDefaultTrack = true;

        _this.registerListeners();

        return _this;
      }

      var _proto = AudioTrackController.prototype;

      _proto.registerListeners = function registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].LEVEL_LOADING, this.onLevelLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].LEVEL_SWITCHING, this.onLevelSwitching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, this.onError, this);
      };

      _proto.unregisterListeners = function unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].LEVEL_LOADING, this.onLevelLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].LEVEL_SWITCHING, this.onLevelSwitching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, this.onError, this);
      };

      _proto.destroy = function destroy() {
        this.unregisterListeners();
        this.tracks.length = 0;
        this.tracksInGroup.length = 0;

        _BasePlaylistControll.prototype.destroy.call(this);
      };

      _proto.onManifestLoading = function onManifestLoading() {
        this.tracks = [];
        this.groupId = null;
        this.tracksInGroup = [];
        this.trackId = -1;
        this.trackName = '';
        this.selectDefaultTrack = true;
      };

      _proto.onManifestParsed = function onManifestParsed(event, data) {
        this.tracks = data.audioTracks || [];
      };

      _proto.onAudioTrackLoaded = function onAudioTrackLoaded(event, data) {
        var id = data.id,
            details = data.details;
        var currentTrack = this.tracksInGroup[id];

        if (!currentTrack) {
          this.warn("Invalid audio track id " + id);
          return;
        }

        var curDetails = currentTrack.details;
        currentTrack.details = data.details;
        this.log("audioTrack " + id + " loaded [" + details.startSN + "-" + details.endSN + "]");

        if (id === this.trackId) {
          this.retryCount = 0;
          this.playlistLoaded(id, data, curDetails);
        }
      };

      _proto.onLevelLoading = function onLevelLoading(event, data) {
        this.switchLevel(data.level);
      };

      _proto.onLevelSwitching = function onLevelSwitching(event, data) {
        this.switchLevel(data.level);
      };

      _proto.switchLevel = function switchLevel(levelIndex) {
        var levelInfo = this.hls.levels[levelIndex];

        if (!(levelInfo !== null && levelInfo !== void 0 && levelInfo.audioGroupIds)) {
          return;
        }

        var audioGroupId = levelInfo.audioGroupIds[levelInfo.urlId];

        if (this.groupId !== audioGroupId) {
          this.groupId = audioGroupId;
          var audioTracks = this.tracks.filter(function (track) {
            return !audioGroupId || track.groupId === audioGroupId;
          }); // Disable selectDefaultTrack if there are no default tracks

          if (this.selectDefaultTrack && !audioTracks.some(function (track) {
            return track.default;
          })) {
            this.selectDefaultTrack = false;
          }

          this.tracksInGroup = audioTracks;
          var audioTracksUpdated = {
            audioTracks: audioTracks
          };
          this.log("Updating audio tracks, " + audioTracks.length + " track(s) found in \"" + audioGroupId + "\" group-id");
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].AUDIO_TRACKS_UPDATED, audioTracksUpdated);
          this.selectInitialTrack();
        }
      };

      _proto.onError = function onError(event, data) {
        _BasePlaylistControll.prototype.onError.call(this, event, data);

        if (data.fatal || !data.context) {
          return;
        }

        if (data.context.type === _types_loader__WEBPACK_IMPORTED_MODULE_3__["PlaylistContextType"].AUDIO_TRACK && data.context.id === this.trackId && data.context.groupId === this.groupId) {
          this.retryLoadingOrFail(data);
        }
      };

      _proto.setAudioTrack = function setAudioTrack(newId) {
        var tracks = this.tracksInGroup; // check if level idx is valid

        if (newId < 0 || newId >= tracks.length) {
          this.warn('Invalid id passed to audio-track controller');
          return;
        } // stopping live reloading timer if any


        this.clearTimer();
        var lastTrack = tracks[this.trackId];
        this.log("Now switching to audio-track index " + newId);
        var track = tracks[newId];
        var id = track.id,
            _track$groupId = track.groupId,
            groupId = _track$groupId === void 0 ? '' : _track$groupId,
            name = track.name,
            type = track.type,
            url = track.url;
        this.trackId = newId;
        this.trackName = name;
        this.selectDefaultTrack = false;
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].AUDIO_TRACK_SWITCHING, {
          id: id,
          groupId: groupId,
          name: name,
          type: type,
          url: url
        }); // Do not reload track unless live

        if (track.details && !track.details.live) {
          return;
        }

        var hlsUrlParameters = this.switchParams(track.url, lastTrack === null || lastTrack === void 0 ? void 0 : lastTrack.details);
        this.loadPlaylist(hlsUrlParameters);
      };

      _proto.selectInitialTrack = function selectInitialTrack() {
        var audioTracks = this.tracksInGroup;
        console.assert(audioTracks.length, 'Initial audio track should be selected when tracks are known');
        var currentAudioTrackName = this.trackName;
        var trackId = this.findTrackId(currentAudioTrackName) || this.findTrackId();

        if (trackId !== -1) {
          this.setAudioTrack(trackId);
        } else {
          this.warn("No track found for running audio group-ID: " + this.groupId);
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].MEDIA_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].AUDIO_TRACK_LOAD_ERROR,
            fatal: true
          });
        }
      };

      _proto.findTrackId = function findTrackId(name) {
        var audioTracks = this.tracksInGroup;

        for (var i = 0; i < audioTracks.length; i++) {
          var track = audioTracks[i];

          if (!this.selectDefaultTrack || track.default) {
            if (!name || name === track.name) {
              return track.id;
            }
          }
        }

        return -1;
      };

      _proto.loadPlaylist = function loadPlaylist(hlsUrlParameters) {
        var audioTrack = this.tracksInGroup[this.trackId];

        if (this.shouldLoadTrack(audioTrack)) {
          var id = audioTrack.id;
          var groupId = audioTrack.groupId;
          var url = audioTrack.url;

          if (hlsUrlParameters) {
            try {
              url = hlsUrlParameters.addDirectives(url);
            } catch (error) {
              this.warn("Could not construct new URL with HLS Delivery Directives: " + error);
            }
          } // track not retrieved yet, or live playlist we need to (re)load it


          this.log("loading audio-track playlist for id: " + id);
          this.clearTimer();
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].AUDIO_TRACK_LOADING, {
            url: url,
            id: id,
            groupId: groupId,
            deliveryDirectives: hlsUrlParameters || null
          });
        }
      };

      _createClass(AudioTrackController, [{
        key: "audioTracks",
        get: function get() {
          return this.tracksInGroup;
        }
      }, {
        key: "audioTrack",
        get: function get() {
          return this.trackId;
        },
        set: function set(newId) {
          // If audio track is selected from API then don't choose from the manifest default track
          this.selectDefaultTrack = false;
          this.setAudioTrack(newId);
        }
      }]);

      return AudioTrackController;
    }(_base_playlist_controller__WEBPACK_IMPORTED_MODULE_2__["default"]);

    /* harmony default export */ __webpack_exports__["default"] = (AudioTrackController);

    /***/ }),

    /***/ "./src/controller/base-playlist-controller.ts":
    /*!****************************************************!*\
      !*** ./src/controller/base-playlist-controller.ts ***!
      \****************************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return BasePlaylistController; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _types_level__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../types/level */ "./src/types/level.ts");
    /* harmony import */ var _level_helper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./level-helper */ "./src/controller/level-helper.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");







    var BasePlaylistController = /*#__PURE__*/function () {
      function BasePlaylistController(hls, logPrefix) {
        this.hls = void 0;
        this.timer = -1;
        this.canLoad = false;
        this.retryCount = 0;
        this.log = void 0;
        this.warn = void 0;
        this.log = _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].log.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"], logPrefix + ":");
        this.warn = _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"], logPrefix + ":");
        this.hls = hls;
      }

      var _proto = BasePlaylistController.prototype;

      _proto.destroy = function destroy() {
        this.clearTimer(); // @ts-ignore

        this.hls = this.log = this.warn = null;
      };

      _proto.onError = function onError(event, data) {
        if (data.fatal && data.type === _errors__WEBPACK_IMPORTED_MODULE_4__["ErrorTypes"].NETWORK_ERROR) {
          this.clearTimer();
        }
      };

      _proto.clearTimer = function clearTimer() {
        clearTimeout(this.timer);
        this.timer = -1;
      };

      _proto.startLoad = function startLoad() {
        this.canLoad = true;
        this.retryCount = 0;
        this.loadPlaylist();
      };

      _proto.stopLoad = function stopLoad() {
        this.canLoad = false;
        this.clearTimer();
      };

      _proto.switchParams = function switchParams(playlistUri, previous) {
        var renditionReports = previous === null || previous === void 0 ? void 0 : previous.renditionReports;

        if (renditionReports) {
          for (var i = 0; i < renditionReports.length; i++) {
            var attr = renditionReports[i];
            var uri = '' + attr.URI;

            if (uri === playlistUri.substr(-uri.length)) {
              var msn = parseInt(attr['LAST-MSN']);
              var part = parseInt(attr['LAST-PART']);

              if (previous && this.hls.config.lowLatencyMode) {
                var currentGoal = Math.min(previous.age - previous.partTarget, previous.targetduration);

                if (part !== undefined && currentGoal > previous.partTarget) {
                  part += 1;
                }
              }

              if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(msn)) {
                return new _types_level__WEBPACK_IMPORTED_MODULE_1__["HlsUrlParameters"](msn, Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(part) ? part : undefined, _types_level__WEBPACK_IMPORTED_MODULE_1__["HlsSkip"].No);
              }
            }
          }
        }
      };

      _proto.loadPlaylist = function loadPlaylist(hlsUrlParameters) {};

      _proto.shouldLoadTrack = function shouldLoadTrack(track) {
        return this.canLoad && track && !!track.url && (!track.details || track.details.live);
      };

      _proto.playlistLoaded = function playlistLoaded(index, data, previousDetails) {
        var _this = this;

        var details = data.details,
            stats = data.stats; // Set last updated date-time

        var elapsed = stats.loading.end ? Math.max(0, self.performance.now() - stats.loading.end) : 0;
        details.advancedDateTime = Date.now() - elapsed; // if current playlist is a live playlist, arm a timer to reload it

        if (details.live || previousDetails !== null && previousDetails !== void 0 && previousDetails.live) {
          details.reloaded(previousDetails);

          if (previousDetails) {
            this.log("live playlist " + index + " " + (details.advanced ? 'REFRESHED ' + details.lastPartSn + '-' + details.lastPartIndex : 'MISSED'));
          } // Merge live playlists to adjust fragment starts and fill in delta playlist skipped segments


          if (previousDetails && details.fragments.length > 0) {
            Object(_level_helper__WEBPACK_IMPORTED_MODULE_2__["mergeDetails"])(previousDetails, details);
          }

          if (!this.canLoad || !details.live) {
            return;
          }

          var deliveryDirectives;
          var msn = undefined;
          var part = undefined;

          if (details.canBlockReload && details.endSN && details.advanced) {
            // Load level with LL-HLS delivery directives
            var lowLatencyMode = this.hls.config.lowLatencyMode;
            var lastPartSn = details.lastPartSn;
            var endSn = details.endSN;
            var lastPartIndex = details.lastPartIndex;
            var hasParts = lastPartIndex !== -1;
            var lastPart = lastPartSn === endSn; // When low latency mode is disabled, we'll skip part requests once the last part index is found

            var nextSnStartIndex = lowLatencyMode ? 0 : lastPartIndex;

            if (hasParts) {
              msn = lastPart ? endSn + 1 : lastPartSn;
              part = lastPart ? nextSnStartIndex : lastPartIndex + 1;
            } else {
              msn = endSn + 1;
            } // Low-Latency CDN Tune-in: "age" header and time since load indicates we're behind by more than one part
            // Update directives to obtain the Playlist that has the estimated additional duration of media


            var lastAdvanced = details.age;
            var cdnAge = lastAdvanced + details.ageHeader;
            var currentGoal = Math.min(cdnAge - details.partTarget, details.targetduration * 1.5);

            if (currentGoal > 0) {
              if (previousDetails && currentGoal > previousDetails.tuneInGoal) {
                // If we attempted to get the next or latest playlist update, but currentGoal increased,
                // then we either can't catchup, or the "age" header cannot be trusted.
                this.warn("CDN Tune-in goal increased from: " + previousDetails.tuneInGoal + " to: " + currentGoal + " with playlist age: " + details.age);
                currentGoal = 0;
              } else {
                var segments = Math.floor(currentGoal / details.targetduration);
                msn += segments;

                if (part !== undefined) {
                  var parts = Math.round(currentGoal % details.targetduration / details.partTarget);
                  part += parts;
                }

                this.log("CDN Tune-in age: " + details.ageHeader + "s last advanced " + lastAdvanced.toFixed(2) + "s goal: " + currentGoal + " skip sn " + segments + " to part " + part);
              }

              details.tuneInGoal = currentGoal;
            }

            deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);

            if (lowLatencyMode || !lastPart) {
              this.loadPlaylist(deliveryDirectives);
              return;
            }
          } else {
            deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);
          }

          var reloadInterval = Object(_level_helper__WEBPACK_IMPORTED_MODULE_2__["computeReloadInterval"])(details, stats);

          if (msn !== undefined && details.canBlockReload) {
            reloadInterval -= details.partTarget || 1;
          }

          this.log("reload live playlist " + index + " in " + Math.round(reloadInterval) + " ms");
          this.timer = self.setTimeout(function () {
            return _this.loadPlaylist(deliveryDirectives);
          }, reloadInterval);
        } else {
          this.clearTimer();
        }
      };

      _proto.getDeliveryDirectives = function getDeliveryDirectives(details, previousDeliveryDirectives, msn, part) {
        var skip = Object(_types_level__WEBPACK_IMPORTED_MODULE_1__["getSkipValue"])(details, msn);

        if (previousDeliveryDirectives !== null && previousDeliveryDirectives !== void 0 && previousDeliveryDirectives.skip && details.deltaUpdateFailed) {
          msn = previousDeliveryDirectives.msn;
          part = previousDeliveryDirectives.part;
          skip = _types_level__WEBPACK_IMPORTED_MODULE_1__["HlsSkip"].No;
        }

        return new _types_level__WEBPACK_IMPORTED_MODULE_1__["HlsUrlParameters"](msn, part, skip);
      };

      _proto.retryLoadingOrFail = function retryLoadingOrFail(errorEvent) {
        var _this2 = this;

        var config = this.hls.config;
        var retry = this.retryCount < config.levelLoadingMaxRetry;

        if (retry) {
          var _errorEvent$context;

          this.retryCount++;

          if (errorEvent.details.indexOf('LoadTimeOut') > -1 && (_errorEvent$context = errorEvent.context) !== null && _errorEvent$context !== void 0 && _errorEvent$context.deliveryDirectives) {
            // The LL-HLS request already timed out so retry immediately
            this.warn("retry playlist loading #" + this.retryCount + " after \"" + errorEvent.details + "\"");
            this.loadPlaylist();
          } else {
            // exponential backoff capped to max retry timeout
            var delay = Math.min(Math.pow(2, this.retryCount) * config.levelLoadingRetryDelay, config.levelLoadingMaxRetryTimeout); // Schedule level/track reload

            this.timer = self.setTimeout(function () {
              return _this2.loadPlaylist();
            }, delay);
            this.warn("retry playlist loading #" + this.retryCount + " in " + delay + " ms after \"" + errorEvent.details + "\"");
          }
        } else {
          this.warn("cannot recover from error \"" + errorEvent.details + "\""); // stopping live reloading timer if any

          this.clearTimer(); // switch error to fatal

          errorEvent.fatal = true;
        }

        return retry;
      };

      return BasePlaylistController;
    }();



    /***/ }),

    /***/ "./src/controller/base-stream-controller.ts":
    /*!**************************************************!*\
      !*** ./src/controller/base-stream-controller.ts ***!
      \**************************************************/
    /*! exports provided: State, default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "State", function() { return State; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return BaseStreamController; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _task_loop__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../task-loop */ "./src/task-loop.ts");
    /* harmony import */ var _fragment_tracker__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./fragment-tracker */ "./src/controller/fragment-tracker.ts");
    /* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _types_transmuxer__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../types/transmuxer */ "./src/types/transmuxer.ts");
    /* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
    /* harmony import */ var _utils_discontinuities__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../utils/discontinuities */ "./src/utils/discontinuities.ts");
    /* harmony import */ var _fragment_finders__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./fragment-finders */ "./src/controller/fragment-finders.ts");
    /* harmony import */ var _level_helper__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./level-helper */ "./src/controller/level-helper.ts");
    /* harmony import */ var _loader_fragment_loader__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../loader/fragment-loader */ "./src/loader/fragment-loader.ts");
    /* harmony import */ var _crypt_decrypter__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../crypt/decrypter */ "./src/crypt/decrypter.ts");
    /* harmony import */ var _utils_time_ranges__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../utils/time-ranges */ "./src/utils/time-ranges.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");






    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

    function _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError("this hasn't been initialised - super() hasn't been called"); } return self; }

    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }
















    var State = {
      STOPPED: 'STOPPED',
      IDLE: 'IDLE',
      KEY_LOADING: 'KEY_LOADING',
      FRAG_LOADING: 'FRAG_LOADING',
      FRAG_LOADING_WAITING_RETRY: 'FRAG_LOADING_WAITING_RETRY',
      WAITING_TRACK: 'WAITING_TRACK',
      PARSING: 'PARSING',
      PARSED: 'PARSED',
      BACKTRACKING: 'BACKTRACKING',
      ENDED: 'ENDED',
      ERROR: 'ERROR',
      WAITING_INIT_PTS: 'WAITING_INIT_PTS',
      WAITING_LEVEL: 'WAITING_LEVEL'
    };

    var BaseStreamController = /*#__PURE__*/function (_TaskLoop) {
      _inheritsLoose(BaseStreamController, _TaskLoop);

      function BaseStreamController(hls, fragmentTracker, logPrefix) {
        var _this;

        _this = _TaskLoop.call(this) || this;
        _this.hls = void 0;
        _this.fragPrevious = null;
        _this.fragCurrent = null;
        _this.fragmentTracker = void 0;
        _this.transmuxer = null;
        _this._state = State.STOPPED;
        _this.media = void 0;
        _this.mediaBuffer = void 0;
        _this.config = void 0;
        _this.bitrateTest = false;
        _this.lastCurrentTime = 0;
        _this.nextLoadPosition = 0;
        _this.startPosition = 0;
        _this.loadedmetadata = false;
        _this.fragLoadError = 0;
        _this.retryDate = 0;
        _this.levels = null;
        _this.fragmentLoader = void 0;
        _this.levelLastLoaded = null;
        _this.startFragRequested = false;
        _this.decrypter = void 0;
        _this.initPTS = [];
        _this.onvseeking = null;
        _this.onvended = null;
        _this.logPrefix = '';
        _this.log = void 0;
        _this.warn = void 0;
        _this.logPrefix = logPrefix;
        _this.log = _utils_logger__WEBPACK_IMPORTED_MODULE_4__["logger"].log.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_4__["logger"], logPrefix + ":");
        _this.warn = _utils_logger__WEBPACK_IMPORTED_MODULE_4__["logger"].warn.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_4__["logger"], logPrefix + ":");
        _this.hls = hls;
        _this.fragmentLoader = new _loader_fragment_loader__WEBPACK_IMPORTED_MODULE_12__["default"](hls.config);
        _this.fragmentTracker = fragmentTracker;
        _this.config = hls.config;
        _this.decrypter = new _crypt_decrypter__WEBPACK_IMPORTED_MODULE_13__["default"](hls, hls.config);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].KEY_LOADED, _this.onKeyLoaded, _assertThisInitialized(_this));
        return _this;
      }

      var _proto = BaseStreamController.prototype;

      _proto.doTick = function doTick() {
        this.onTickEnd();
      };

      _proto.onTickEnd = function onTickEnd() {} // eslint-disable-next-line @typescript-eslint/no-unused-vars
      ;

      _proto.startLoad = function startLoad(startPosition) {};

      _proto.stopLoad = function stopLoad() {
        this.fragmentLoader.abort();
        var frag = this.fragCurrent;

        if (frag) {
          this.fragmentTracker.removeFragment(frag);
        }

        this.resetTransmuxer();
        this.fragCurrent = null;
        this.fragPrevious = null;
        this.clearInterval();
        this.clearNextTick();
        this.state = State.STOPPED;
      };

      _proto._streamEnded = function _streamEnded(bufferInfo, levelDetails) {
        var fragCurrent = this.fragCurrent,
            fragmentTracker = this.fragmentTracker; // we just got done loading the final fragment and there is no other buffered range after ...
        // rationale is that in case there are any buffered ranges after, it means that there are unbuffered portion in between
        // so we should not switch to ENDED in that case, to be able to buffer them

        if (!levelDetails.live && fragCurrent && // NOTE: Because of the way parts are currently parsed/represented in the playlist, we can end up
        // in situations where the current fragment is actually greater than levelDetails.endSN. While
        // this feels like the "wrong place" to account for that, this is a narrower/safer change than
        // updating e.g. M3U8Parser::parseLevelPlaylist().
        fragCurrent.sn >= levelDetails.endSN && !bufferInfo.nextStart) {
          var partList = levelDetails.partList; // Since the last part isn't guaranteed to correspond to fragCurrent for ll-hls, check instead if the last part is buffered.

          if (partList !== null && partList !== void 0 && partList.length) {
            var lastPart = partList[partList.length - 1]; // Checking the midpoint of the part for potential margin of error and related issues.
            // NOTE: Technically I believe parts could yield content that is < the computed duration (including potential a duration of 0)
            // and still be spec-compliant, so there may still be edge cases here. Likewise, there could be issues in end of stream
            // part mismatches for independent audio and video playlists/segments.

            var lastPartBuffered = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__["BufferHelper"].isBuffered(this.media, lastPart.start + lastPart.duration / 2);
            return lastPartBuffered;
          }

          var fragState = fragmentTracker.getState(fragCurrent);
          return fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_2__["FragmentState"].PARTIAL || fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_2__["FragmentState"].OK;
        }

        return false;
      };

      _proto.onMediaAttached = function onMediaAttached(event, data) {
        var media = this.media = this.mediaBuffer = data.media;
        this.onvseeking = this.onMediaSeeking.bind(this);
        this.onvended = this.onMediaEnded.bind(this);
        media.addEventListener('seeking', this.onvseeking);
        media.addEventListener('ended', this.onvended);
        var config = this.config;

        if (this.levels && config.autoStartLoad && this.state === State.STOPPED) {
          this.startLoad(config.startPosition);
        }
      };

      _proto.onMediaDetaching = function onMediaDetaching() {
        var media = this.media;

        if (media !== null && media !== void 0 && media.ended) {
          this.log('MSE detaching and video ended, reset startPosition');
          this.startPosition = this.lastCurrentTime = 0;
        } // remove video listeners


        if (media) {
          media.removeEventListener('seeking', this.onvseeking);
          media.removeEventListener('ended', this.onvended);
          this.onvseeking = this.onvended = null;
        }

        this.media = this.mediaBuffer = null;
        this.loadedmetadata = false;
        this.fragmentTracker.removeAllFragments();
        this.stopLoad();
      };

      _proto.onMediaSeeking = function onMediaSeeking() {
        var config = this.config,
            fragCurrent = this.fragCurrent,
            media = this.media,
            mediaBuffer = this.mediaBuffer,
            state = this.state;
        var currentTime = media ? media.currentTime : 0;
        var bufferInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__["BufferHelper"].bufferInfo(mediaBuffer || media, currentTime, config.maxBufferHole);
        this.log("media seeking to " + (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(currentTime) ? currentTime.toFixed(3) : currentTime) + ", state: " + state);

        if (state === State.ENDED) {
          this.resetLoadingState();
        } else if (fragCurrent && !bufferInfo.len) {
          // check if we are seeking to a unbuffered area AND if frag loading is in progress
          var tolerance = config.maxFragLookUpTolerance;
          var fragStartOffset = fragCurrent.start - tolerance;
          var fragEndOffset = fragCurrent.start + fragCurrent.duration + tolerance;
          var pastFragment = currentTime > fragEndOffset; // check if the seek position is past current fragment, and if so abort loading

          if (currentTime < fragStartOffset || pastFragment) {
            if (pastFragment && fragCurrent.loader) {
              this.log('seeking outside of buffer while fragment load in progress, cancel fragment load');
              fragCurrent.loader.abort();
            }

            this.resetLoadingState();
          }
        }

        if (media) {
          this.lastCurrentTime = currentTime;
        } // in case seeking occurs although no media buffered, adjust startPosition and nextLoadPosition to seek target


        if (!this.loadedmetadata && !bufferInfo.len) {
          this.nextLoadPosition = this.startPosition = currentTime;
        } // Async tick to speed up processing


        this.tickImmediate();
      };

      _proto.onMediaEnded = function onMediaEnded() {
        // reset startPosition and lastCurrentTime to restart playback @ stream beginning
        this.startPosition = this.lastCurrentTime = 0;
      };

      _proto.onKeyLoaded = function onKeyLoaded(event, data) {
        if (this.state !== State.KEY_LOADING || data.frag !== this.fragCurrent || !this.levels) {
          return;
        }

        this.state = State.IDLE;
        var levelDetails = this.levels[data.frag.level].details;

        if (levelDetails) {
          this.loadFragment(data.frag, levelDetails, data.frag.start);
        }
      };

      _proto.onHandlerDestroying = function onHandlerDestroying() {
        this.stopLoad();

        _TaskLoop.prototype.onHandlerDestroying.call(this);
      };

      _proto.onHandlerDestroyed = function onHandlerDestroyed() {
        this.state = State.STOPPED;
        this.hls.off(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].KEY_LOADED, this.onKeyLoaded, this);

        if (this.fragmentLoader) {
          this.fragmentLoader.destroy();
        }

        if (this.decrypter) {
          this.decrypter.destroy();
        }

        this.hls = this.log = this.warn = this.decrypter = this.fragmentLoader = this.fragmentTracker = null;

        _TaskLoop.prototype.onHandlerDestroyed.call(this);
      };

      _proto.loadKey = function loadKey(frag, details) {
        this.log("Loading key for " + frag.sn + " of [" + details.startSN + "-" + details.endSN + "], " + (this.logPrefix === '[stream-controller]' ? 'level' : 'track') + " " + frag.level);
        this.state = State.KEY_LOADING;
        this.fragCurrent = frag;
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].KEY_LOADING, {
          frag: frag
        });
      };

      _proto.loadFragment = function loadFragment(frag, levelDetails, targetBufferTime) {
        this._loadFragForPlayback(frag, levelDetails, targetBufferTime);
      };

      _proto._loadFragForPlayback = function _loadFragForPlayback(frag, levelDetails, targetBufferTime) {
        var _this2 = this;

        var progressCallback = function progressCallback(data) {
          if (_this2.fragContextChanged(frag)) {
            _this2.warn("Fragment " + frag.sn + (data.part ? ' p: ' + data.part.index : '') + " of level " + frag.level + " was dropped during download.");

            _this2.fragmentTracker.removeFragment(frag);

            return;
          }

          frag.stats.chunkCount++;

          _this2._handleFragmentLoadProgress(data);
        };

        this._doFragLoad(frag, levelDetails, targetBufferTime, progressCallback).then(function (data) {
          if (!data) {
            // if we're here we probably needed to backtrack or are waiting for more parts
            return;
          }

          _this2.fragLoadError = 0;
          var state = _this2.state;

          if (_this2.fragContextChanged(frag)) {
            if (state === State.FRAG_LOADING || state === State.BACKTRACKING || !_this2.fragCurrent && state === State.PARSING) {
              _this2.fragmentTracker.removeFragment(frag);

              _this2.state = State.IDLE;
            }

            return;
          }

          if ('payload' in data) {
            _this2.log("Loaded fragment " + frag.sn + " of level " + frag.level);

            _this2.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].FRAG_LOADED, data); // Tracker backtrack must be called after onFragLoaded to update the fragment entity state to BACKTRACKED
            // This happens after handleTransmuxComplete when the worker or progressive is disabled


            if (_this2.state === State.BACKTRACKING) {
              _this2.fragmentTracker.backtrack(frag, data);

              _this2.resetFragmentLoading(frag);

              return;
            }
          } // Pass through the whole payload; controllers not implementing progressive loading receive data from this callback


          _this2._handleFragmentLoadComplete(data);
        }).catch(function (reason) {
          _this2.warn(reason);

          _this2.resetFragmentLoading(frag);
        });
      };

      _proto.flushMainBuffer = function flushMainBuffer(startOffset, endOffset, type) {
        if (type === void 0) {
          type = null;
        }

        if (!(startOffset - endOffset)) {
          return;
        } // When alternate audio is playing, the audio-stream-controller is responsible for the audio buffer. Otherwise,
        // passing a null type flushes both buffers


        var flushScope = {
          startOffset: startOffset,
          endOffset: endOffset,
          type: type
        }; // Reset load errors on flush

        this.fragLoadError = 0;
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].BUFFER_FLUSHING, flushScope);
      };

      _proto._loadInitSegment = function _loadInitSegment(frag) {
        var _this3 = this;

        this._doFragLoad(frag).then(function (data) {
          if (!data || _this3.fragContextChanged(frag) || !_this3.levels) {
            throw new Error('init load aborted');
          }

          return data;
        }).then(function (data) {
          var hls = _this3.hls;
          var payload = data.payload;
          var decryptData = frag.decryptdata; // check to see if the payload needs to be decrypted

          if (payload && payload.byteLength > 0 && decryptData && decryptData.key && decryptData.iv && decryptData.method === 'AES-128') {
            var startTime = self.performance.now(); // decrypt the subtitles

            return _this3.decrypter.webCryptoDecrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer).then(function (decryptedData) {
              var endTime = self.performance.now();
              hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].FRAG_DECRYPTED, {
                frag: frag,
                payload: decryptedData,
                stats: {
                  tstart: startTime,
                  tdecrypt: endTime
                }
              });
              data.payload = decryptedData;
              return data;
            });
          }

          return data;
        }).then(function (data) {
          var fragCurrent = _this3.fragCurrent,
              hls = _this3.hls,
              levels = _this3.levels;

          if (!levels) {
            throw new Error('init load aborted, missing levels');
          }

          var details = levels[frag.level].details;
          console.assert(details, 'Level details are defined when init segment is loaded');
          var stats = frag.stats;
          _this3.state = State.IDLE;
          _this3.fragLoadError = 0;
          frag.data = new Uint8Array(data.payload);
          stats.parsing.start = stats.buffering.start = self.performance.now();
          stats.parsing.end = stats.buffering.end = self.performance.now(); // Silence FRAG_BUFFERED event if fragCurrent is null

          if (data.frag === fragCurrent) {
            hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].FRAG_BUFFERED, {
              stats: stats,
              frag: fragCurrent,
              part: null,
              id: frag.type
            });
          }

          _this3.tick();
        }).catch(function (reason) {
          _this3.warn(reason);

          _this3.resetFragmentLoading(frag);
        });
      };

      _proto.fragContextChanged = function fragContextChanged(frag) {
        var fragCurrent = this.fragCurrent;
        return !frag || !fragCurrent || frag.level !== fragCurrent.level || frag.sn !== fragCurrent.sn || frag.urlId !== fragCurrent.urlId;
      };

      _proto.fragBufferedComplete = function fragBufferedComplete(frag, part) {
        var media = this.mediaBuffer ? this.mediaBuffer : this.media;
        this.log("Buffered " + frag.type + " sn: " + frag.sn + (part ? ' part: ' + part.index : '') + " of " + (this.logPrefix === '[stream-controller]' ? 'level' : 'track') + " " + frag.level + " " + _utils_time_ranges__WEBPACK_IMPORTED_MODULE_14__["default"].toString(_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__["BufferHelper"].getBuffered(media)));
        this.state = State.IDLE;
        this.tick();
      };

      _proto._handleFragmentLoadComplete = function _handleFragmentLoadComplete(fragLoadedEndData) {
        var transmuxer = this.transmuxer;

        if (!transmuxer) {
          return;
        }

        var frag = fragLoadedEndData.frag,
            part = fragLoadedEndData.part,
            partsLoaded = fragLoadedEndData.partsLoaded; // If we did not load parts, or loaded all parts, we have complete (not partial) fragment data

        var complete = !partsLoaded || partsLoaded.length === 0 || partsLoaded.some(function (fragLoaded) {
          return !fragLoaded;
        });
        var chunkMeta = new _types_transmuxer__WEBPACK_IMPORTED_MODULE_7__["ChunkMetadata"](frag.level, frag.sn, frag.stats.chunkCount + 1, 0, part ? part.index : -1, !complete);
        transmuxer.flush(chunkMeta);
      } // eslint-disable-next-line @typescript-eslint/no-unused-vars
      ;

      _proto._handleFragmentLoadProgress = function _handleFragmentLoadProgress(frag) {};

      _proto._doFragLoad = function _doFragLoad(frag, details, targetBufferTime, progressCallback) {
        var _this4 = this;

        if (targetBufferTime === void 0) {
          targetBufferTime = null;
        }

        if (!this.levels) {
          throw new Error('frag load aborted, missing levels');
        }

        targetBufferTime = Math.max(frag.start, targetBufferTime || 0);

        if (this.config.lowLatencyMode && details) {
          var partList = details.partList;

          if (partList && progressCallback) {
            if (targetBufferTime > frag.end && details.fragmentHint) {
              frag = details.fragmentHint;
            }

            var partIndex = this.getNextPart(partList, frag, targetBufferTime);

            if (partIndex > -1) {
              var part = partList[partIndex];
              this.log("Loading part sn: " + frag.sn + " p: " + part.index + " cc: " + frag.cc + " of playlist [" + details.startSN + "-" + details.endSN + "] parts [0-" + partIndex + "-" + (partList.length - 1) + "] " + (this.logPrefix === '[stream-controller]' ? 'level' : 'track') + ": " + frag.level + ", target: " + parseFloat(targetBufferTime.toFixed(3)));
              this.nextLoadPosition = part.start + part.duration;
              this.state = State.FRAG_LOADING;
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].FRAG_LOADING, {
                frag: frag,
                part: partList[partIndex],
                targetBufferTime: targetBufferTime
              });
              return this.doFragPartsLoad(frag, partList, partIndex, progressCallback).catch(function (error) {
                return _this4.handleFragLoadError(error);
              });
            } else if (!frag.url || this.loadedEndOfParts(partList, targetBufferTime)) {
              // Fragment hint has no parts
              return Promise.resolve(null);
            }
          }
        }

        this.log("Loading fragment " + frag.sn + " cc: " + frag.cc + " " + (details ? 'of [' + details.startSN + '-' + details.endSN + '] ' : '') + (this.logPrefix === '[stream-controller]' ? 'level' : 'track') + ": " + frag.level + ", target: " + parseFloat(targetBufferTime.toFixed(3))); // Don't update nextLoadPosition for fragments which are not buffered

        if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(frag.sn) && !this.bitrateTest) {
          this.nextLoadPosition = frag.start + frag.duration;
        }

        this.state = State.FRAG_LOADING;
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].FRAG_LOADING, {
          frag: frag,
          targetBufferTime: targetBufferTime
        });
        return this.fragmentLoader.load(frag, progressCallback).catch(function (error) {
          return _this4.handleFragLoadError(error);
        });
      };

      _proto.doFragPartsLoad = function doFragPartsLoad(frag, partList, partIndex, progressCallback) {
        var _this5 = this;

        return new Promise(function (resolve, reject) {
          var partsLoaded = [];

          var loadPartIndex = function loadPartIndex(index) {
            var part = partList[index];

            _this5.fragmentLoader.loadPart(frag, part, progressCallback).then(function (partLoadedData) {
              partsLoaded[part.index] = partLoadedData;
              var loadedPart = partLoadedData.part;

              _this5.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].FRAG_LOADED, partLoadedData);

              var nextPart = partList[index + 1];

              if (nextPart && nextPart.fragment === frag) {
                loadPartIndex(index + 1);
              } else {
                return resolve({
                  frag: frag,
                  part: loadedPart,
                  partsLoaded: partsLoaded
                });
              }
            }).catch(reject);
          };

          loadPartIndex(partIndex);
        });
      };

      _proto.handleFragLoadError = function handleFragLoadError(_ref) {
        var data = _ref.data;

        if (data && data.details === _errors__WEBPACK_IMPORTED_MODULE_6__["ErrorDetails"].INTERNAL_ABORTED) {
          this.handleFragLoadAborted(data.frag, data.part);
        } else {
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].ERROR, data);
        }

        return null;
      };

      _proto._handleTransmuxerFlush = function _handleTransmuxerFlush(chunkMeta) {
        var context = this.getCurrentContext(chunkMeta);

        if (!context || this.state !== State.PARSING) {
          if (!this.fragCurrent) {
            this.state = State.IDLE;
          }

          return;
        }

        var frag = context.frag,
            part = context.part,
            level = context.level;
        var now = self.performance.now();
        frag.stats.parsing.end = now;

        if (part) {
          part.stats.parsing.end = now;
        }

        this.updateLevelTiming(frag, part, level, chunkMeta.partial);
      };

      _proto.getCurrentContext = function getCurrentContext(chunkMeta) {
        var levels = this.levels;
        var levelIndex = chunkMeta.level,
            sn = chunkMeta.sn,
            partIndex = chunkMeta.part;

        if (!levels || !levels[levelIndex]) {
          this.warn("Levels object was unset while buffering fragment " + sn + " of level " + levelIndex + ". The current chunk will not be buffered.");
          return null;
        }

        var level = levels[levelIndex];
        var part = partIndex > -1 ? Object(_level_helper__WEBPACK_IMPORTED_MODULE_11__["getPartWith"])(level, sn, partIndex) : null;
        var frag = part ? part.fragment : Object(_level_helper__WEBPACK_IMPORTED_MODULE_11__["getFragmentWithSN"])(level, sn, this.fragCurrent);

        if (!frag) {
          return null;
        }

        return {
          frag: frag,
          part: part,
          level: level
        };
      };

      _proto.bufferFragmentData = function bufferFragmentData(data, frag, part, chunkMeta) {
        if (!data || this.state !== State.PARSING) {
          return;
        }

        var data1 = data.data1,
            data2 = data.data2;
        var buffer = data1;

        if (data1 && data2) {
          // Combine the moof + mdat so that we buffer with a single append
          buffer = Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_8__["appendUint8Array"])(data1, data2);
        }

        if (!buffer || !buffer.length) {
          return;
        }

        var segment = {
          type: data.type,
          frag: frag,
          part: part,
          chunkMeta: chunkMeta,
          parent: frag.type,
          data: buffer
        };
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].BUFFER_APPENDING, segment);

        if (data.dropped && data.independent && !part) {
          // Clear buffer so that we reload previous segments sequentially if required
          this.flushBufferGap(frag);
        }
      };

      _proto.flushBufferGap = function flushBufferGap(frag) {
        var media = this.media;

        if (!media) {
          return;
        } // If currentTime is not buffered, clear the back buffer so that we can backtrack as much as needed


        if (!_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__["BufferHelper"].isBuffered(media, media.currentTime)) {
          this.flushMainBuffer(0, frag.start);
          return;
        } // Remove back-buffer without interrupting playback to allow back tracking


        var currentTime = media.currentTime;
        var bufferInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__["BufferHelper"].bufferInfo(media, currentTime, 0);
        var fragDuration = frag.duration;
        var segmentFraction = Math.min(this.config.maxFragLookUpTolerance * 2, fragDuration * 0.25);
        var start = Math.max(Math.min(frag.start - segmentFraction, bufferInfo.end - segmentFraction), currentTime + segmentFraction);

        if (frag.start - start > segmentFraction) {
          this.flushMainBuffer(start, frag.start);
        }
      };

      _proto.getFwdBufferInfo = function getFwdBufferInfo(bufferable, type) {
        var config = this.config;
        var pos = this.getLoadPosition();

        if (!Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(pos)) {
          return null;
        }

        var bufferInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__["BufferHelper"].bufferInfo(bufferable, pos, config.maxBufferHole); // Workaround flaw in getting forward buffer when maxBufferHole is smaller than gap at current pos

        if (bufferInfo.len === 0 && bufferInfo.nextStart !== undefined) {
          var bufferedFragAtPos = this.fragmentTracker.getBufferedFrag(pos, type);

          if (bufferedFragAtPos && bufferInfo.nextStart < bufferedFragAtPos.end) {
            return _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__["BufferHelper"].bufferInfo(bufferable, pos, Math.max(bufferInfo.nextStart, config.maxBufferHole));
          }
        }

        return bufferInfo;
      };

      _proto.getMaxBufferLength = function getMaxBufferLength(levelBitrate) {
        var config = this.config;
        var maxBufLen;

        if (levelBitrate) {
          maxBufLen = Math.max(8 * config.maxBufferSize / levelBitrate, config.maxBufferLength);
        } else {
          maxBufLen = config.maxBufferLength;
        }

        return Math.min(maxBufLen, config.maxMaxBufferLength);
      };

      _proto.reduceMaxBufferLength = function reduceMaxBufferLength(threshold) {
        var config = this.config;
        var minLength = threshold || config.maxBufferLength;

        if (config.maxMaxBufferLength >= minLength) {
          // reduce max buffer length as it might be too high. we do this to avoid loop flushing ...
          config.maxMaxBufferLength /= 2;
          this.warn("Reduce max buffer length to " + config.maxMaxBufferLength + "s");
          return true;
        }

        return false;
      };

      _proto.getNextFragment = function getNextFragment(pos, levelDetails) {
        var _frag, _frag2;

        var fragments = levelDetails.fragments;
        var fragLen = fragments.length;

        if (!fragLen) {
          return null;
        } // find fragment index, contiguous with end of buffer position


        var config = this.config;
        var start = fragments[0].start;
        var frag;

        if (levelDetails.live) {
          var initialLiveManifestSize = config.initialLiveManifestSize;

          if (fragLen < initialLiveManifestSize) {
            this.warn("Not enough fragments to start playback (have: " + fragLen + ", need: " + initialLiveManifestSize + ")");
            return null;
          } // The real fragment start times for a live stream are only known after the PTS range for that level is known.
          // In order to discover the range, we load the best matching fragment for that level and demux it.
          // Do not load using live logic if the starting frag is requested - we want to use getFragmentAtPosition() so that
          // we get the fragment matching that start time


          if (!levelDetails.PTSKnown && !this.startFragRequested && this.startPosition === -1) {
            frag = this.getInitialLiveFragment(levelDetails, fragments);
            this.startPosition = frag ? this.hls.liveSyncPosition || frag.start : pos;
          }
        } else if (pos <= start) {
          // VoD playlist: if loadPosition before start of playlist, load first fragment
          frag = fragments[0];
        } // If we haven't run into any special cases already, just load the fragment most closely matching the requested position


        if (!frag) {
          var end = config.lowLatencyMode ? levelDetails.partEnd : levelDetails.fragmentEnd;
          frag = this.getFragmentAtPosition(pos, end, levelDetails);
        } // If an initSegment is present, it must be buffered first


        if ((_frag = frag) !== null && _frag !== void 0 && _frag.initSegment && !((_frag2 = frag) !== null && _frag2 !== void 0 && _frag2.initSegment.data) && !this.bitrateTest) {
          frag = frag.initSegment;
        }

        return frag;
      };

      _proto.getNextPart = function getNextPart(partList, frag, targetBufferTime) {
        var nextPart = -1;
        var contiguous = false;
        var independentAttrOmitted = true;

        for (var i = 0, len = partList.length; i < len; i++) {
          var part = partList[i];
          independentAttrOmitted = independentAttrOmitted && !part.independent;

          if (nextPart > -1 && targetBufferTime < part.start) {
            break;
          }

          var loaded = part.loaded;

          if (!loaded && (contiguous || part.independent || independentAttrOmitted) && part.fragment === frag) {
            nextPart = i;
          }

          contiguous = loaded;
        }

        return nextPart;
      };

      _proto.loadedEndOfParts = function loadedEndOfParts(partList, targetBufferTime) {
        var lastPart = partList[partList.length - 1];
        return lastPart && targetBufferTime > lastPart.start && lastPart.loaded;
      }
      /*
       This method is used find the best matching first fragment for a live playlist. This fragment is used to calculate the
       "sliding" of the playlist, which is its offset from the start of playback. After sliding we can compute the real
       start and end times for each fragment in the playlist (after which this method will not need to be called).
      */
      ;

      _proto.getInitialLiveFragment = function getInitialLiveFragment(levelDetails, fragments) {
        var fragPrevious = this.fragPrevious;
        var frag = null;

        if (fragPrevious) {
          if (levelDetails.hasProgramDateTime) {
            // Prefer using PDT, because it can be accurate enough to choose the correct fragment without knowing the level sliding
            this.log("Live playlist, switching playlist, load frag with same PDT: " + fragPrevious.programDateTime);
            frag = Object(_fragment_finders__WEBPACK_IMPORTED_MODULE_10__["findFragmentByPDT"])(fragments, fragPrevious.endProgramDateTime, this.config.maxFragLookUpTolerance);
          }

          if (!frag) {
            // SN does not need to be accurate between renditions, but depending on the packaging it may be so.
            var targetSN = fragPrevious.sn + 1;

            if (targetSN >= levelDetails.startSN && targetSN <= levelDetails.endSN) {
              var fragNext = fragments[targetSN - levelDetails.startSN]; // Ensure that we're staying within the continuity range, since PTS resets upon a new range

              if (fragPrevious.cc === fragNext.cc) {
                frag = fragNext;
                this.log("Live playlist, switching playlist, load frag with next SN: " + frag.sn);
              }
            } // It's important to stay within the continuity range if available; otherwise the fragments in the playlist
            // will have the wrong start times


            if (!frag) {
              frag = Object(_fragment_finders__WEBPACK_IMPORTED_MODULE_10__["findFragWithCC"])(fragments, fragPrevious.cc);

              if (frag) {
                this.log("Live playlist, switching playlist, load frag with same CC: " + frag.sn);
              }
            }
          }
        } else {
          // Find a new start fragment when fragPrevious is null
          var liveStart = this.hls.liveSyncPosition;

          if (liveStart !== null) {
            frag = this.getFragmentAtPosition(liveStart, this.bitrateTest ? levelDetails.fragmentEnd : levelDetails.edge, levelDetails);
          }
        }

        return frag;
      }
      /*
      This method finds the best matching fragment given the provided position.
       */
      ;

      _proto.getFragmentAtPosition = function getFragmentAtPosition(bufferEnd, end, levelDetails) {
        var config = this.config,
            fragPrevious = this.fragPrevious;
        var fragments = levelDetails.fragments,
            endSN = levelDetails.endSN;
        var fragmentHint = levelDetails.fragmentHint;
        var tolerance = config.maxFragLookUpTolerance;
        var loadingParts = !!(config.lowLatencyMode && levelDetails.partList && fragmentHint);

        if (loadingParts && fragmentHint && !this.bitrateTest) {
          // Include incomplete fragment with parts at end
          fragments = fragments.concat(fragmentHint);
          endSN = fragmentHint.sn;
        }

        var frag;

        if (bufferEnd < end) {
          var lookupTolerance = bufferEnd > end - tolerance ? 0 : tolerance; // Remove the tolerance if it would put the bufferEnd past the actual end of stream
          // Uses buffer and sequence number to calculate switch segment (required if using EXT-X-DISCONTINUITY-SEQUENCE)

          frag = Object(_fragment_finders__WEBPACK_IMPORTED_MODULE_10__["findFragmentByPTS"])(fragPrevious, fragments, bufferEnd, lookupTolerance);
        } else {
          // reach end of playlist
          frag = fragments[fragments.length - 1];
        }

        if (frag) {
          var curSNIdx = frag.sn - levelDetails.startSN;
          var sameLevel = fragPrevious && frag.level === fragPrevious.level;
          var nextFrag = fragments[curSNIdx + 1];
          var fragState = this.fragmentTracker.getState(frag);

          if (fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_2__["FragmentState"].BACKTRACKED) {
            frag = null;
            var i = curSNIdx;

            while (fragments[i] && this.fragmentTracker.getState(fragments[i]) === _fragment_tracker__WEBPACK_IMPORTED_MODULE_2__["FragmentState"].BACKTRACKED) {
              // When fragPrevious is null, backtrack to first the first fragment is not BACKTRACKED for loading
              // When fragPrevious is set, we want the first BACKTRACKED fragment for parsing and buffering
              if (!fragPrevious) {
                frag = fragments[--i];
              } else {
                frag = fragments[i--];
              }
            }

            if (!frag) {
              frag = nextFrag;
            }
          } else if (fragPrevious && frag.sn === fragPrevious.sn && !loadingParts) {
            // Force the next fragment to load if the previous one was already selected. This can occasionally happen with
            // non-uniform fragment durations
            if (sameLevel) {
              if (frag.sn < endSN && this.fragmentTracker.getState(nextFrag) !== _fragment_tracker__WEBPACK_IMPORTED_MODULE_2__["FragmentState"].OK) {
                this.log("SN " + frag.sn + " just loaded, load next one: " + nextFrag.sn);
                frag = nextFrag;
              } else {
                frag = null;
              }
            }
          }
        }

        return frag;
      };

      _proto.synchronizeToLiveEdge = function synchronizeToLiveEdge(levelDetails) {
        var config = this.config,
            media = this.media;

        if (!media) {
          return;
        }

        var liveSyncPosition = this.hls.liveSyncPosition;
        var currentTime = media.currentTime;
        var start = levelDetails.fragments[0].start;
        var end = levelDetails.edge;
        var withinSlidingWindow = currentTime >= start - config.maxFragLookUpTolerance && currentTime <= end; // Continue if we can seek forward to sync position or if current time is outside of sliding window

        if (liveSyncPosition !== null && media.duration > liveSyncPosition && (currentTime < liveSyncPosition || !withinSlidingWindow)) {
          // Continue if buffer is starving or if current time is behind max latency
          var maxLatency = config.liveMaxLatencyDuration !== undefined ? config.liveMaxLatencyDuration : config.liveMaxLatencyDurationCount * levelDetails.targetduration;

          if (!withinSlidingWindow && media.readyState < 4 || currentTime < end - maxLatency) {
            if (!this.loadedmetadata) {
              this.nextLoadPosition = liveSyncPosition;
            } // Only seek if ready and there is not a significant forward buffer available for playback


            if (media.readyState) {
              this.warn("Playback: " + currentTime.toFixed(3) + " is located too far from the end of live sliding playlist: " + end + ", reset currentTime to : " + liveSyncPosition.toFixed(3));
              media.currentTime = liveSyncPosition;
            }
          }
        }
      };

      _proto.alignPlaylists = function alignPlaylists(details, previousDetails) {
        var levels = this.levels,
            levelLastLoaded = this.levelLastLoaded,
            fragPrevious = this.fragPrevious;
        var lastLevel = levelLastLoaded !== null ? levels[levelLastLoaded] : null; // FIXME: If not for `shouldAlignOnDiscontinuities` requiring fragPrevious.cc,
        //  this could all go in level-helper mergeDetails()

        var length = details.fragments.length;

        if (!length) {
          this.warn("No fragments in live playlist");
          return 0;
        }

        var slidingStart = details.fragments[0].start;
        var firstLevelLoad = !previousDetails;

        var aligned = details.alignedSliding && Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(slidingStart);

        if (firstLevelLoad || !aligned && !slidingStart) {
          Object(_utils_discontinuities__WEBPACK_IMPORTED_MODULE_9__["alignStream"])(fragPrevious, lastLevel, details);
          var alignedSlidingStart = details.fragments[0].start;
          this.log("Live playlist sliding: " + alignedSlidingStart.toFixed(2) + " start-sn: " + (previousDetails ? previousDetails.startSN : 'na') + "->" + details.startSN + " prev-sn: " + (fragPrevious ? fragPrevious.sn : 'na') + " fragments: " + length);
          return alignedSlidingStart;
        }

        return slidingStart;
      };

      _proto.waitForCdnTuneIn = function waitForCdnTuneIn(details) {
        // Wait for Low-Latency CDN Tune-in to get an updated playlist
        var advancePartLimit = 3;
        return details.live && details.canBlockReload && details.tuneInGoal > Math.max(details.partHoldBack, details.partTarget * advancePartLimit);
      };

      _proto.setStartPosition = function setStartPosition(details, sliding) {
        // compute start position if set to -1. use it straight away if value is defined
        var startPosition = this.startPosition;

        if (startPosition < sliding) {
          startPosition = -1;
        }

        if (startPosition === -1 || this.lastCurrentTime === -1) {
          // first, check if start time offset has been set in playlist, if yes, use this value
          var startTimeOffset = details.startTimeOffset;

          if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(startTimeOffset)) {
            startPosition = sliding + startTimeOffset;

            if (startTimeOffset < 0) {
              startPosition += details.totalduration;
            }

            startPosition = Math.min(Math.max(sliding, startPosition), sliding + details.totalduration);
            this.log("Start time offset " + startTimeOffset + " found in playlist, adjust startPosition to " + startPosition);
            this.startPosition = startPosition;
          } else if (details.live) {
            // Leave this.startPosition at -1, so that we can use `getInitialLiveFragment` logic when startPosition has
            // not been specified via the config or an as an argument to startLoad (#3736).
            startPosition = this.hls.liveSyncPosition || sliding;
          } else {
            this.startPosition = startPosition = 0;
          }

          this.lastCurrentTime = startPosition;
        }

        this.nextLoadPosition = startPosition;
      };

      _proto.getLoadPosition = function getLoadPosition() {
        var media = this.media; // if we have not yet loaded any fragment, start loading from start position

        var pos = 0;

        if (this.loadedmetadata && media) {
          pos = media.currentTime;
        } else if (this.nextLoadPosition) {
          pos = this.nextLoadPosition;
        }

        return pos;
      };

      _proto.handleFragLoadAborted = function handleFragLoadAborted(frag, part) {
        if (this.transmuxer && frag.sn !== 'initSegment' && frag.stats.aborted) {
          this.warn("Fragment " + frag.sn + (part ? ' part' + part.index : '') + " of level " + frag.level + " was aborted");
          this.resetFragmentLoading(frag);
        }
      };

      _proto.resetFragmentLoading = function resetFragmentLoading(frag) {
        if (!this.fragCurrent || !this.fragContextChanged(frag)) {
          this.state = State.IDLE;
        }
      };

      _proto.onFragmentOrKeyLoadError = function onFragmentOrKeyLoadError(filterType, data) {
        if (data.fatal) {
          return;
        }

        var frag = data.frag; // Handle frag error related to caller's filterType

        if (!frag || frag.type !== filterType) {
          return;
        }

        var fragCurrent = this.fragCurrent;
        console.assert(fragCurrent && frag.sn === fragCurrent.sn && frag.level === fragCurrent.level && frag.urlId === fragCurrent.urlId, 'Frag load error must match current frag to retry');
        var config = this.config; // keep retrying until the limit will be reached

        if (this.fragLoadError + 1 <= config.fragLoadingMaxRetry) {
          if (this.resetLiveStartWhenNotLoaded(frag.level)) {
            return;
          } // exponential backoff capped to config.fragLoadingMaxRetryTimeout


          var delay = Math.min(Math.pow(2, this.fragLoadError) * config.fragLoadingRetryDelay, config.fragLoadingMaxRetryTimeout);
          this.warn("Fragment " + frag.sn + " of " + filterType + " " + frag.level + " failed to load, retrying in " + delay + "ms");
          this.retryDate = self.performance.now() + delay;
          this.fragLoadError++;
          this.state = State.FRAG_LOADING_WAITING_RETRY;
        } else if (data.levelRetry) {
          if (filterType === _types_loader__WEBPACK_IMPORTED_MODULE_15__["PlaylistLevelType"].AUDIO) {
            // Reset current fragment since audio track audio is essential and may not have a fail-over track
            this.fragCurrent = null;
          } // Fragment errors that result in a level switch or redundant fail-over
          // should reset the stream controller state to idle


          this.fragLoadError = 0;
          this.state = State.IDLE;
        } else {
          _utils_logger__WEBPACK_IMPORTED_MODULE_4__["logger"].error(data.details + " reaches max retry, redispatch as fatal ..."); // switch error to fatal

          data.fatal = true;
          this.hls.stopLoad();
          this.state = State.ERROR;
        }
      };

      _proto.afterBufferFlushed = function afterBufferFlushed(media, bufferType, playlistType) {
        if (!media) {
          return;
        } // After successful buffer flushing, filter flushed fragments from bufferedFrags use mediaBuffered instead of media
        // (so that we will check against video.buffered ranges in case of alt audio track)


        var bufferedTimeRanges = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__["BufferHelper"].getBuffered(media);
        this.fragmentTracker.detectEvictedFragments(bufferType, bufferedTimeRanges, playlistType);

        if (this.state === State.ENDED) {
          this.resetLoadingState();
        }
      };

      _proto.resetLoadingState = function resetLoadingState() {
        this.fragCurrent = null;
        this.fragPrevious = null;
        this.state = State.IDLE;
      };

      _proto.resetLiveStartWhenNotLoaded = function resetLiveStartWhenNotLoaded(level) {
        // if loadedmetadata is not set, it means that we are emergency switch down on first frag
        // in that case, reset startFragRequested flag
        if (!this.loadedmetadata) {
          this.startFragRequested = false;
          var details = this.levels ? this.levels[level].details : null;

          if (details !== null && details !== void 0 && details.live) {
            // We can't afford to retry after a delay in a live scenario. Update the start position and return to IDLE.
            this.startPosition = -1;
            this.setStartPosition(details, 0);
            this.resetLoadingState();
            return true;
          }

          this.nextLoadPosition = this.startPosition;
        }

        return false;
      };

      _proto.updateLevelTiming = function updateLevelTiming(frag, part, level, partial) {
        var _this6 = this;

        var details = level.details;
        console.assert(!!details, 'level.details must be defined');
        var parsed = Object.keys(frag.elementaryStreams).reduce(function (result, type) {
          var info = frag.elementaryStreams[type];

          if (info) {
            var parsedDuration = info.endPTS - info.startPTS;

            if (parsedDuration <= 0) {
              // Destroy the transmuxer after it's next time offset failed to advance because duration was <= 0.
              // The new transmuxer will be configured with a time offset matching the next fragment start,
              // preventing the timeline from shifting.
              _this6.warn("Could not parse fragment " + frag.sn + " " + type + " duration reliably (" + parsedDuration + ") resetting transmuxer to fallback to playlist timing");

              _this6.resetTransmuxer();

              return result || false;
            }

            var drift = partial ? 0 : Object(_level_helper__WEBPACK_IMPORTED_MODULE_11__["updateFragPTSDTS"])(details, frag, info.startPTS, info.endPTS, info.startDTS, info.endDTS);

            _this6.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].LEVEL_PTS_UPDATED, {
              details: details,
              level: level,
              drift: drift,
              type: type,
              frag: frag,
              start: info.startPTS,
              end: info.endPTS
            });

            return true;
          }

          return result;
        }, false);

        if (parsed) {
          this.state = State.PARSED;
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].FRAG_PARSED, {
            frag: frag,
            part: part
          });
        } else {
          this.resetLoadingState();
        }
      };

      _proto.resetTransmuxer = function resetTransmuxer() {
        if (this.transmuxer) {
          this.transmuxer.destroy();
          this.transmuxer = null;
        }
      };

      _createClass(BaseStreamController, [{
        key: "state",
        get: function get() {
          return this._state;
        },
        set: function set(nextState) {
          var previousState = this._state;

          if (previousState !== nextState) {
            this._state = nextState;
            this.log(previousState + "->" + nextState);
          }
        }
      }]);

      return BaseStreamController;
    }(_task_loop__WEBPACK_IMPORTED_MODULE_1__["default"]);



    /***/ }),

    /***/ "./src/controller/buffer-controller.ts":
    /*!*********************************************!*\
      !*** ./src/controller/buffer-controller.ts ***!
      \*********************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return BufferController; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
    /* harmony import */ var _utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/mediasource-helper */ "./src/utils/mediasource-helper.ts");
    /* harmony import */ var _loader_fragment__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../loader/fragment */ "./src/loader/fragment.ts");
    /* harmony import */ var _buffer_operation_queue__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./buffer-operation-queue */ "./src/controller/buffer-operation-queue.ts");












    var MediaSource = Object(_utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_5__["getMediaSource"])();
    var VIDEO_CODEC_PROFILE_REPACE = /([ha]vc.)(?:\.[^.,]+)+/;

    var BufferController = /*#__PURE__*/function () {
      // The level details used to determine duration, target-duration and live
      // cache the self generated object url to detect hijack of video tag
      // A queue of buffer operations which require the SourceBuffer to not be updating upon execution
      // References to event listeners for each SourceBuffer, so that they can be referenced for event removal
      // The number of BUFFER_CODEC events received before any sourceBuffers are created
      // The total number of BUFFER_CODEC events received
      // A reference to the attached media element
      // A reference to the active media source
      // counters
      function BufferController(_hls) {
        var _this = this;

        this.details = null;
        this._objectUrl = null;
        this.operationQueue = void 0;
        this.listeners = void 0;
        this.hls = void 0;
        this.bufferCodecEventsExpected = 0;
        this._bufferCodecEventsTotal = 0;
        this.media = null;
        this.mediaSource = null;
        this.appendError = 0;
        this.tracks = {};
        this.pendingTracks = {};
        this.sourceBuffer = void 0;

        this._onMediaSourceOpen = function () {
          var hls = _this.hls,
              media = _this.media,
              mediaSource = _this.mediaSource;
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('[buffer-controller]: Media source opened');

          if (media) {
            _this.updateMediaElementDuration();

            hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_ATTACHED, {
              media: media
            });
          }

          if (mediaSource) {
            // once received, don't listen anymore to sourceopen event
            mediaSource.removeEventListener('sourceopen', _this._onMediaSourceOpen);
          }

          _this.checkPendingTracks();
        };

        this._onMediaSourceClose = function () {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('[buffer-controller]: Media source closed');
        };

        this._onMediaSourceEnded = function () {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('[buffer-controller]: Media source ended');
        };

        this.hls = _hls;

        this._initSourceBuffer();

        this.registerListeners();
      }

      var _proto = BufferController.prototype;

      _proto.hasSourceTypes = function hasSourceTypes() {
        return this.getSourceBufferTypes().length > 0 || Object.keys(this.pendingTracks).length > 0;
      };

      _proto.destroy = function destroy() {
        this.unregisterListeners();
        this.details = null;
      };

      _proto.registerListeners = function registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_ATTACHING, this.onMediaAttaching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_RESET, this.onBufferReset, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_APPENDING, this.onBufferAppending, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_CODECS, this.onBufferCodecs, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_EOS, this.onBufferEos, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_FLUSHING, this.onBufferFlushing, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVEL_UPDATED, this.onLevelUpdated, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_PARSED, this.onFragParsed, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_CHANGED, this.onFragChanged, this);
      };

      _proto.unregisterListeners = function unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_ATTACHING, this.onMediaAttaching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_RESET, this.onBufferReset, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_APPENDING, this.onBufferAppending, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_CODECS, this.onBufferCodecs, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_EOS, this.onBufferEos, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_FLUSHING, this.onBufferFlushing, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVEL_UPDATED, this.onLevelUpdated, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_PARSED, this.onFragParsed, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_CHANGED, this.onFragChanged, this);
      };

      _proto._initSourceBuffer = function _initSourceBuffer() {
        this.sourceBuffer = {};
        this.operationQueue = new _buffer_operation_queue__WEBPACK_IMPORTED_MODULE_7__["default"](this.sourceBuffer);
        this.listeners = {
          audio: [],
          video: [],
          audiovideo: []
        };
      };

      _proto.onManifestParsed = function onManifestParsed(event, data) {
        // in case of alt audio 2 BUFFER_CODECS events will be triggered, one per stream controller
        // sourcebuffers will be created all at once when the expected nb of tracks will be reached
        // in case alt audio is not used, only one BUFFER_CODEC event will be fired from main stream controller
        // it will contain the expected nb of source buffers, no need to compute it
        var codecEvents = 2;

        if (data.audio && !data.video || !data.altAudio) {
          codecEvents = 1;
        }

        this.bufferCodecEventsExpected = this._bufferCodecEventsTotal = codecEvents;
        this.details = null;
        _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log(this.bufferCodecEventsExpected + " bufferCodec event(s) expected");
      };

      _proto.onMediaAttaching = function onMediaAttaching(event, data) {
        var media = this.media = data.media;

        if (media && MediaSource) {
          var ms = this.mediaSource = new MediaSource(); // MediaSource listeners are arrow functions with a lexical scope, and do not need to be bound

          ms.addEventListener('sourceopen', this._onMediaSourceOpen);
          ms.addEventListener('sourceended', this._onMediaSourceEnded);
          ms.addEventListener('sourceclose', this._onMediaSourceClose); // link video and media Source

          media.src = self.URL.createObjectURL(ms); // cache the locally generated object url

          this._objectUrl = media.src;
        }
      };

      _proto.onMediaDetaching = function onMediaDetaching() {
        var media = this.media,
            mediaSource = this.mediaSource,
            _objectUrl = this._objectUrl;

        if (mediaSource) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('[buffer-controller]: media source detaching');

          if (mediaSource.readyState === 'open') {
            try {
              // endOfStream could trigger exception if any sourcebuffer is in updating state
              // we don't really care about checking sourcebuffer state here,
              // as we are anyway detaching the MediaSource
              // let's just avoid this exception to propagate
              mediaSource.endOfStream();
            } catch (err) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn("[buffer-controller]: onMediaDetaching: " + err.message + " while calling endOfStream");
            }
          } // Clean up the SourceBuffers by invoking onBufferReset


          this.onBufferReset();
          mediaSource.removeEventListener('sourceopen', this._onMediaSourceOpen);
          mediaSource.removeEventListener('sourceended', this._onMediaSourceEnded);
          mediaSource.removeEventListener('sourceclose', this._onMediaSourceClose); // Detach properly the MediaSource from the HTMLMediaElement as
          // suggested in https://github.com/w3c/media-source/issues/53.

          if (media) {
            if (_objectUrl) {
              self.URL.revokeObjectURL(_objectUrl);
            } // clean up video tag src only if it's our own url. some external libraries might
            // hijack the video tag and change its 'src' without destroying the Hls instance first


            if (media.src === _objectUrl) {
              media.removeAttribute('src');
              media.load();
            } else {
              _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn('[buffer-controller]: media.src was changed by a third party - skip cleanup');
            }
          }

          this.mediaSource = null;
          this.media = null;
          this._objectUrl = null;
          this.bufferCodecEventsExpected = this._bufferCodecEventsTotal;
          this.pendingTracks = {};
          this.tracks = {};
        }

        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_DETACHED, undefined);
      };

      _proto.onBufferReset = function onBufferReset() {
        var _this2 = this;

        this.getSourceBufferTypes().forEach(function (type) {
          var sb = _this2.sourceBuffer[type];

          try {
            if (sb) {
              _this2.removeBufferListeners(type);

              if (_this2.mediaSource) {
                _this2.mediaSource.removeSourceBuffer(sb);
              } // Synchronously remove the SB from the map before the next call in order to prevent an async function from
              // accessing it


              _this2.sourceBuffer[type] = undefined;
            }
          } catch (err) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn("[buffer-controller]: Failed to reset the " + type + " buffer", err);
          }
        });

        this._initSourceBuffer();
      };

      _proto.onBufferCodecs = function onBufferCodecs(event, data) {
        var _this3 = this;

        var sourceBufferCount = this.getSourceBufferTypes().length;
        Object.keys(data).forEach(function (trackName) {
          if (sourceBufferCount) {
            // check if SourceBuffer codec needs to change
            var track = _this3.tracks[trackName];

            if (track && typeof track.buffer.changeType === 'function') {
              var _data$trackName = data[trackName],
                  codec = _data$trackName.codec,
                  levelCodec = _data$trackName.levelCodec,
                  container = _data$trackName.container;
              var currentCodec = (track.levelCodec || track.codec).replace(VIDEO_CODEC_PROFILE_REPACE, '$1');
              var nextCodec = (levelCodec || codec).replace(VIDEO_CODEC_PROFILE_REPACE, '$1');

              if (currentCodec !== nextCodec) {
                var mimeType = container + ";codecs=" + (levelCodec || codec);

                _this3.appendChangeType(trackName, mimeType);
              }
            }
          } else {
            // if source buffer(s) not created yet, appended buffer tracks in this.pendingTracks
            _this3.pendingTracks[trackName] = data[trackName];
          }
        }); // if sourcebuffers already created, do nothing ...

        if (sourceBufferCount) {
          return;
        }

        this.bufferCodecEventsExpected = Math.max(this.bufferCodecEventsExpected - 1, 0);

        if (this.mediaSource && this.mediaSource.readyState === 'open') {
          this.checkPendingTracks();
        }
      };

      _proto.appendChangeType = function appendChangeType(type, mimeType) {
        var _this4 = this;

        var operationQueue = this.operationQueue;
        var operation = {
          execute: function execute() {
            var sb = _this4.sourceBuffer[type];

            if (sb) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("[buffer-controller]: changing " + type + " sourceBuffer type to " + mimeType);
              sb.changeType(mimeType);
            }

            operationQueue.shiftAndExecuteNext(type);
          },
          onStart: function onStart() {},
          onComplete: function onComplete() {},
          onError: function onError(e) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn("[buffer-controller]: Failed to change " + type + " SourceBuffer type", e);
          }
        };
        operationQueue.append(operation, type);
      };

      _proto.onBufferAppending = function onBufferAppending(event, eventData) {
        var _this5 = this;

        var hls = this.hls,
            operationQueue = this.operationQueue,
            tracks = this.tracks;
        var data = eventData.data,
            type = eventData.type,
            frag = eventData.frag,
            part = eventData.part,
            chunkMeta = eventData.chunkMeta;
        var chunkStats = chunkMeta.buffering[type];
        var bufferAppendingStart = self.performance.now();
        chunkStats.start = bufferAppendingStart;
        var fragBuffering = frag.stats.buffering;
        var partBuffering = part ? part.stats.buffering : null;

        if (fragBuffering.start === 0) {
          fragBuffering.start = bufferAppendingStart;
        }

        if (partBuffering && partBuffering.start === 0) {
          partBuffering.start = bufferAppendingStart;
        } // TODO: Only update timestampOffset when audio/mpeg fragment or part is not contiguous with previously appended
        // Adjusting `SourceBuffer.timestampOffset` (desired point in the timeline where the next frames should be appended)
        // in Chrome browser when we detect MPEG audio container and time delta between level PTS and `SourceBuffer.timestampOffset`
        // is greater than 100ms (this is enough to handle seek for VOD or level change for LIVE videos).
        // More info here: https://github.com/video-dev/hls.js/issues/332#issuecomment-257986486


        var audioTrack = tracks.audio;
        var checkTimestampOffset = type === 'audio' && chunkMeta.id === 1 && (audioTrack === null || audioTrack === void 0 ? void 0 : audioTrack.container) === 'audio/mpeg';
        var operation = {
          execute: function execute() {
            chunkStats.executeStart = self.performance.now();

            if (checkTimestampOffset) {
              var sb = _this5.sourceBuffer[type];

              if (sb) {
                var delta = frag.start - sb.timestampOffset;

                if (Math.abs(delta) >= 0.1) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("[buffer-controller]: Updating audio SourceBuffer timestampOffset to " + frag.start + " (delta: " + delta + ") sn: " + frag.sn + ")");
                  sb.timestampOffset = frag.start;
                }
              }
            }

            _this5.appendExecutor(data, type);
          },
          onStart: function onStart() {// logger.debug(`[buffer-controller]: ${type} SourceBuffer updatestart`);
          },
          onComplete: function onComplete() {
            // logger.debug(`[buffer-controller]: ${type} SourceBuffer updateend`);
            var end = self.performance.now();
            chunkStats.executeEnd = chunkStats.end = end;

            if (fragBuffering.first === 0) {
              fragBuffering.first = end;
            }

            if (partBuffering && partBuffering.first === 0) {
              partBuffering.first = end;
            }

            var sourceBuffer = _this5.sourceBuffer;
            var timeRanges = {};

            for (var _type in sourceBuffer) {
              timeRanges[_type] = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_4__["BufferHelper"].getBuffered(sourceBuffer[_type]);
            }

            _this5.appendError = 0;

            _this5.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_APPENDED, {
              type: type,
              frag: frag,
              part: part,
              chunkMeta: chunkMeta,
              parent: frag.type,
              timeRanges: timeRanges
            });
          },
          onError: function onError(err) {
            // in case any error occured while appending, put back segment in segments table
            _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error("[buffer-controller]: Error encountered while trying to append to the " + type + " SourceBuffer", err);
            var event = {
              type: _errors__WEBPACK_IMPORTED_MODULE_3__["ErrorTypes"].MEDIA_ERROR,
              parent: frag.type,
              details: _errors__WEBPACK_IMPORTED_MODULE_3__["ErrorDetails"].BUFFER_APPEND_ERROR,
              err: err,
              fatal: false
            };

            if (err.code === DOMException.QUOTA_EXCEEDED_ERR) {
              // QuotaExceededError: http://www.w3.org/TR/html5/infrastructure.html#quotaexceedederror
              // let's stop appending any segments, and report BUFFER_FULL_ERROR error
              event.details = _errors__WEBPACK_IMPORTED_MODULE_3__["ErrorDetails"].BUFFER_FULL_ERROR;
            } else {
              _this5.appendError++;
              event.details = _errors__WEBPACK_IMPORTED_MODULE_3__["ErrorDetails"].BUFFER_APPEND_ERROR;
              /* with UHD content, we could get loop of quota exceeded error until
                browser is able to evict some data from sourcebuffer. Retrying can help recover.
              */

              if (_this5.appendError > hls.config.appendErrorMaxRetry) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error("[buffer-controller]: Failed " + hls.config.appendErrorMaxRetry + " times to append segment in sourceBuffer");
                event.fatal = true;
              }
            }

            hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, event);
          }
        };
        operationQueue.append(operation, type);
      };

      _proto.onBufferFlushing = function onBufferFlushing(event, data) {
        var _this6 = this;

        var operationQueue = this.operationQueue;

        var flushOperation = function flushOperation(type) {
          return {
            execute: _this6.removeExecutor.bind(_this6, type, data.startOffset, data.endOffset),
            onStart: function onStart() {// logger.debug(`[buffer-controller]: Started flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);
            },
            onComplete: function onComplete() {
              // logger.debug(`[buffer-controller]: Finished flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);
              _this6.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_FLUSHED, {
                type: type
              });
            },
            onError: function onError(e) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn("[buffer-controller]: Failed to remove from " + type + " SourceBuffer", e);
            }
          };
        };

        if (data.type) {
          operationQueue.append(flushOperation(data.type), data.type);
        } else {
          this.getSourceBufferTypes().forEach(function (type) {
            operationQueue.append(flushOperation(type), type);
          });
        }
      };

      _proto.onFragParsed = function onFragParsed(event, data) {
        var _this7 = this;

        var frag = data.frag,
            part = data.part;
        var buffersAppendedTo = [];
        var elementaryStreams = part ? part.elementaryStreams : frag.elementaryStreams;

        if (elementaryStreams[_loader_fragment__WEBPACK_IMPORTED_MODULE_6__["ElementaryStreamTypes"].AUDIOVIDEO]) {
          buffersAppendedTo.push('audiovideo');
        } else {
          if (elementaryStreams[_loader_fragment__WEBPACK_IMPORTED_MODULE_6__["ElementaryStreamTypes"].AUDIO]) {
            buffersAppendedTo.push('audio');
          }

          if (elementaryStreams[_loader_fragment__WEBPACK_IMPORTED_MODULE_6__["ElementaryStreamTypes"].VIDEO]) {
            buffersAppendedTo.push('video');
          }
        }

        var onUnblocked = function onUnblocked() {
          var now = self.performance.now();
          frag.stats.buffering.end = now;

          if (part) {
            part.stats.buffering.end = now;
          }

          var stats = part ? part.stats : frag.stats;

          _this7.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_BUFFERED, {
            frag: frag,
            part: part,
            stats: stats,
            id: frag.type
          });
        };

        if (buffersAppendedTo.length === 0) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn("Fragments must have at least one ElementaryStreamType set. type: " + frag.type + " level: " + frag.level + " sn: " + frag.sn);
        }

        this.blockBuffers(onUnblocked, buffersAppendedTo);
      };

      _proto.onFragChanged = function onFragChanged(event, data) {
        this.flushBackBuffer();
      } // on BUFFER_EOS mark matching sourcebuffer(s) as ended and trigger checkEos()
      // an undefined data.type will mark all buffers as EOS.
      ;

      _proto.onBufferEos = function onBufferEos(event, data) {
        var _this8 = this;

        var ended = this.getSourceBufferTypes().reduce(function (acc, type) {
          var sb = _this8.sourceBuffer[type];

          if (!data.type || data.type === type) {
            if (sb && !sb.ended) {
              sb.ended = true;
              _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("[buffer-controller]: " + type + " sourceBuffer now EOS");
            }
          }

          return acc && !!(!sb || sb.ended);
        }, true);

        if (ended) {
          this.blockBuffers(function () {
            var mediaSource = _this8.mediaSource;

            if (!mediaSource || mediaSource.readyState !== 'open') {
              return;
            } // Allow this to throw and be caught by the enqueueing function


            mediaSource.endOfStream();
          });
        }
      };

      _proto.onLevelUpdated = function onLevelUpdated(event, _ref) {
        var details = _ref.details;

        if (!details.fragments.length) {
          return;
        }

        this.details = details;

        if (this.getSourceBufferTypes().length) {
          this.blockBuffers(this.updateMediaElementDuration.bind(this));
        } else {
          this.updateMediaElementDuration();
        }
      };

      _proto.flushBackBuffer = function flushBackBuffer() {
        var hls = this.hls,
            details = this.details,
            media = this.media,
            sourceBuffer = this.sourceBuffer;

        if (!media || details === null) {
          return;
        }

        var sourceBufferTypes = this.getSourceBufferTypes();

        if (!sourceBufferTypes.length) {
          return;
        } // Support for deprecated liveBackBufferLength


        var backBufferLength = details.live && hls.config.liveBackBufferLength !== null ? hls.config.liveBackBufferLength : hls.config.backBufferLength;

        if (!Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(backBufferLength) || backBufferLength < 0) {
          return;
        }

        var currentTime = media.currentTime;
        var targetDuration = details.levelTargetDuration;
        var maxBackBufferLength = Math.max(backBufferLength, targetDuration);
        var targetBackBufferPosition = Math.floor(currentTime / targetDuration) * targetDuration - maxBackBufferLength;
        sourceBufferTypes.forEach(function (type) {
          var sb = sourceBuffer[type];

          if (sb) {
            var buffered = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_4__["BufferHelper"].getBuffered(sb); // when target buffer start exceeds actual buffer start

            if (buffered.length > 0 && targetBackBufferPosition > buffered.start(0)) {
              hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BACK_BUFFER_REACHED, {
                bufferEnd: targetBackBufferPosition
              }); // Support for deprecated event:

              if (details.live) {
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LIVE_BACK_BUFFER_REACHED, {
                  bufferEnd: targetBackBufferPosition
                });
              }

              hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_FLUSHING, {
                startOffset: 0,
                endOffset: targetBackBufferPosition,
                type: type
              });
            }
          }
        });
      }
      /**
       * Update Media Source duration to current level duration or override to Infinity if configuration parameter
       * 'liveDurationInfinity` is set to `true`
       * More details: https://github.com/video-dev/hls.js/issues/355
       */
      ;

      _proto.updateMediaElementDuration = function updateMediaElementDuration() {
        if (!this.details || !this.media || !this.mediaSource || this.mediaSource.readyState !== 'open') {
          return;
        }

        var details = this.details,
            hls = this.hls,
            media = this.media,
            mediaSource = this.mediaSource;
        var levelDuration = details.fragments[0].start + details.totalduration;
        var mediaDuration = media.duration;
        var msDuration = Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(mediaSource.duration) ? mediaSource.duration : 0;

        if (details.live && hls.config.liveDurationInfinity) {
          // Override duration to Infinity
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('[buffer-controller]: Media Source duration is set to Infinity');
          mediaSource.duration = Infinity;
          this.updateSeekableRange(details);
        } else if (levelDuration > msDuration && levelDuration > mediaDuration || !Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(mediaDuration)) {
          // levelDuration was the last value we set.
          // not using mediaSource.duration as the browser may tweak this value
          // only update Media Source duration if its value increase, this is to avoid
          // flushing already buffered portion when switching between quality level
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("[buffer-controller]: Updating Media Source duration to " + levelDuration.toFixed(3));
          mediaSource.duration = levelDuration;
        }
      };

      _proto.updateSeekableRange = function updateSeekableRange(levelDetails) {
        var mediaSource = this.mediaSource;
        var fragments = levelDetails.fragments;
        var len = fragments.length;

        if (len && levelDetails.live && mediaSource !== null && mediaSource !== void 0 && mediaSource.setLiveSeekableRange) {
          var start = Math.max(0, fragments[0].start);
          var end = Math.max(start, start + levelDetails.totalduration);
          mediaSource.setLiveSeekableRange(start, end);
        }
      };

      _proto.checkPendingTracks = function checkPendingTracks() {
        var bufferCodecEventsExpected = this.bufferCodecEventsExpected,
            operationQueue = this.operationQueue,
            pendingTracks = this.pendingTracks; // Check if we've received all of the expected bufferCodec events. When none remain, create all the sourceBuffers at once.
        // This is important because the MSE spec allows implementations to throw QuotaExceededErrors if creating new sourceBuffers after
        // data has been appended to existing ones.
        // 2 tracks is the max (one for audio, one for video). If we've reach this max go ahead and create the buffers.

        var pendingTracksCount = Object.keys(pendingTracks).length;

        if (pendingTracksCount && !bufferCodecEventsExpected || pendingTracksCount === 2) {
          // ok, let's create them now !
          this.createSourceBuffers(pendingTracks);
          this.pendingTracks = {}; // append any pending segments now !

          var buffers = this.getSourceBufferTypes();

          if (buffers.length === 0) {
            this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, {
              type: _errors__WEBPACK_IMPORTED_MODULE_3__["ErrorTypes"].MEDIA_ERROR,
              details: _errors__WEBPACK_IMPORTED_MODULE_3__["ErrorDetails"].BUFFER_INCOMPATIBLE_CODECS_ERROR,
              fatal: true,
              reason: 'could not create source buffer for media codec(s)'
            });
            return;
          }

          buffers.forEach(function (type) {
            operationQueue.executeNext(type);
          });
        }
      };

      _proto.createSourceBuffers = function createSourceBuffers(tracks) {
        var sourceBuffer = this.sourceBuffer,
            mediaSource = this.mediaSource;

        if (!mediaSource) {
          throw Error('createSourceBuffers called when mediaSource was null');
        }

        var tracksCreated = 0;

        for (var trackName in tracks) {
          if (!sourceBuffer[trackName]) {
            var track = tracks[trackName];

            if (!track) {
              throw Error("source buffer exists for track " + trackName + ", however track does not");
            } // use levelCodec as first priority


            var codec = track.levelCodec || track.codec;
            var mimeType = track.container + ";codecs=" + codec;
            _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("[buffer-controller]: creating sourceBuffer(" + mimeType + ")");

            try {
              var sb = sourceBuffer[trackName] = mediaSource.addSourceBuffer(mimeType);
              var sbName = trackName;
              this.addBufferListener(sbName, 'updatestart', this._onSBUpdateStart);
              this.addBufferListener(sbName, 'updateend', this._onSBUpdateEnd);
              this.addBufferListener(sbName, 'error', this._onSBUpdateError);
              this.tracks[trackName] = {
                buffer: sb,
                codec: codec,
                container: track.container,
                levelCodec: track.levelCodec,
                id: track.id
              };
              tracksCreated++;
            } catch (err) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error("[buffer-controller]: error while trying to add sourceBuffer: " + err.message);
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, {
                type: _errors__WEBPACK_IMPORTED_MODULE_3__["ErrorTypes"].MEDIA_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_3__["ErrorDetails"].BUFFER_ADD_CODEC_ERROR,
                fatal: false,
                error: err,
                mimeType: mimeType
              });
            }
          }
        }

        if (tracksCreated) {
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_CREATED, {
            tracks: this.tracks
          });
        }
      } // Keep as arrow functions so that we can directly reference these functions directly as event listeners
      ;

      _proto._onSBUpdateStart = function _onSBUpdateStart(type) {
        var operationQueue = this.operationQueue;
        var operation = operationQueue.current(type);
        operation.onStart();
      };

      _proto._onSBUpdateEnd = function _onSBUpdateEnd(type) {
        var operationQueue = this.operationQueue;
        var operation = operationQueue.current(type);
        operation.onComplete();
        operationQueue.shiftAndExecuteNext(type);
      };

      _proto._onSBUpdateError = function _onSBUpdateError(type, event) {
        _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error("[buffer-controller]: " + type + " SourceBuffer error", event); // according to http://www.w3.org/TR/media-source/#sourcebuffer-append-error
        // SourceBuffer errors are not necessarily fatal; if so, the HTMLMediaElement will fire an error event

        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, {
          type: _errors__WEBPACK_IMPORTED_MODULE_3__["ErrorTypes"].MEDIA_ERROR,
          details: _errors__WEBPACK_IMPORTED_MODULE_3__["ErrorDetails"].BUFFER_APPENDING_ERROR,
          fatal: false
        }); // updateend is always fired after error, so we'll allow that to shift the current operation off of the queue

        var operation = this.operationQueue.current(type);

        if (operation) {
          operation.onError(event);
        }
      } // This method must result in an updateend event; if remove is not called, _onSBUpdateEnd must be called manually
      ;

      _proto.removeExecutor = function removeExecutor(type, startOffset, endOffset) {
        var media = this.media,
            mediaSource = this.mediaSource,
            operationQueue = this.operationQueue,
            sourceBuffer = this.sourceBuffer;
        var sb = sourceBuffer[type];

        if (!media || !mediaSource || !sb) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn("[buffer-controller]: Attempting to remove from the " + type + " SourceBuffer, but it does not exist");
          operationQueue.shiftAndExecuteNext(type);
          return;
        }

        var mediaDuration = Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(media.duration) ? media.duration : Infinity;
        var msDuration = Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(mediaSource.duration) ? mediaSource.duration : Infinity;
        var removeStart = Math.max(0, startOffset);
        var removeEnd = Math.min(endOffset, mediaDuration, msDuration);

        if (removeEnd > removeStart) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("[buffer-controller]: Removing [" + removeStart + "," + removeEnd + "] from the " + type + " SourceBuffer");
          console.assert(!sb.updating, type + " sourceBuffer must not be updating");
          sb.remove(removeStart, removeEnd);
        } else {
          // Cycle the queue
          operationQueue.shiftAndExecuteNext(type);
        }
      } // This method must result in an updateend event; if append is not called, _onSBUpdateEnd must be called manually
      ;

      _proto.appendExecutor = function appendExecutor(data, type) {
        var operationQueue = this.operationQueue,
            sourceBuffer = this.sourceBuffer;
        var sb = sourceBuffer[type];

        if (!sb) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn("[buffer-controller]: Attempting to append to the " + type + " SourceBuffer, but it does not exist");
          operationQueue.shiftAndExecuteNext(type);
          return;
        }

        sb.ended = false;
        console.assert(!sb.updating, type + " sourceBuffer must not be updating");
        sb.appendBuffer(data);
      } // Enqueues an operation to each SourceBuffer queue which, upon execution, resolves a promise. When all promises
      // resolve, the onUnblocked function is executed. Functions calling this method do not need to unblock the queue
      // upon completion, since we already do it here
      ;

      _proto.blockBuffers = function blockBuffers(onUnblocked, buffers) {
        var _this9 = this;

        if (buffers === void 0) {
          buffers = this.getSourceBufferTypes();
        }

        if (!buffers.length) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('[buffer-controller]: Blocking operation requested, but no SourceBuffers exist');
          Promise.resolve(onUnblocked);
          return;
        }

        var operationQueue = this.operationQueue; // logger.debug(`[buffer-controller]: Blocking ${buffers} SourceBuffer`);

        var blockingOperations = buffers.map(function (type) {
          return operationQueue.appendBlocker(type);
        });
        Promise.all(blockingOperations).then(function () {
          // logger.debug(`[buffer-controller]: Blocking operation resolved; unblocking ${buffers} SourceBuffer`);
          onUnblocked();
          buffers.forEach(function (type) {
            var sb = _this9.sourceBuffer[type]; // Only cycle the queue if the SB is not updating. There's a bug in Chrome which sets the SB updating flag to
            // true when changing the MediaSource duration (https://bugs.chromium.org/p/chromium/issues/detail?id=959359&can=2&q=mediasource%20duration)
            // While this is a workaround, it's probably useful to have around

            if (!sb || !sb.updating) {
              operationQueue.shiftAndExecuteNext(type);
            }
          });
        });
      };

      _proto.getSourceBufferTypes = function getSourceBufferTypes() {
        return Object.keys(this.sourceBuffer);
      };

      _proto.addBufferListener = function addBufferListener(type, event, fn) {
        var buffer = this.sourceBuffer[type];

        if (!buffer) {
          return;
        }

        var listener = fn.bind(this, type);
        this.listeners[type].push({
          event: event,
          listener: listener
        });
        buffer.addEventListener(event, listener);
      };

      _proto.removeBufferListeners = function removeBufferListeners(type) {
        var buffer = this.sourceBuffer[type];

        if (!buffer) {
          return;
        }

        this.listeners[type].forEach(function (l) {
          buffer.removeEventListener(l.event, l.listener);
        });
      };

      return BufferController;
    }();



    /***/ }),

    /***/ "./src/controller/buffer-operation-queue.ts":
    /*!**************************************************!*\
      !*** ./src/controller/buffer-operation-queue.ts ***!
      \**************************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return BufferOperationQueue; });
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");


    var BufferOperationQueue = /*#__PURE__*/function () {
      function BufferOperationQueue(sourceBufferReference) {
        this.buffers = void 0;
        this.queues = {
          video: [],
          audio: [],
          audiovideo: []
        };
        this.buffers = sourceBufferReference;
      }

      var _proto = BufferOperationQueue.prototype;

      _proto.append = function append(operation, type) {
        var queue = this.queues[type];
        queue.push(operation);

        if (queue.length === 1 && this.buffers[type]) {
          this.executeNext(type);
        }
      };

      _proto.insertAbort = function insertAbort(operation, type) {
        var queue = this.queues[type];
        queue.unshift(operation);
        this.executeNext(type);
      };

      _proto.appendBlocker = function appendBlocker(type) {
        var execute;
        var promise = new Promise(function (resolve) {
          execute = resolve;
        });
        var operation = {
          execute: execute,
          onStart: function onStart() {},
          onComplete: function onComplete() {},
          onError: function onError() {}
        };
        this.append(operation, type);
        return promise;
      };

      _proto.executeNext = function executeNext(type) {
        var buffers = this.buffers,
            queues = this.queues;
        var sb = buffers[type];
        var queue = queues[type];

        if (queue.length) {
          var operation = queue[0];

          try {
            // Operations are expected to result in an 'updateend' event being fired. If not, the queue will lock. Operations
            // which do not end with this event must call _onSBUpdateEnd manually
            operation.execute();
          } catch (e) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_0__["logger"].warn('[buffer-operation-queue]: Unhandled exception executing the current operation');
            operation.onError(e); // Only shift the current operation off, otherwise the updateend handler will do this for us

            if (!sb || !sb.updating) {
              queue.shift();
              this.executeNext(type);
            }
          }
        }
      };

      _proto.shiftAndExecuteNext = function shiftAndExecuteNext(type) {
        this.queues[type].shift();
        this.executeNext(type);
      };

      _proto.current = function current(type) {
        return this.queues[type][0];
      };

      return BufferOperationQueue;
    }();



    /***/ }),

    /***/ "./src/controller/cap-level-controller.ts":
    /*!************************************************!*\
      !*** ./src/controller/cap-level-controller.ts ***!
      \************************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

    /*
     * cap stream level to media size dimension controller
     */


    var CapLevelController = /*#__PURE__*/function () {
      function CapLevelController(hls) {
        this.autoLevelCapping = void 0;
        this.firstLevel = void 0;
        this.media = void 0;
        this.restrictedLevels = void 0;
        this.timer = void 0;
        this.hls = void 0;
        this.streamController = void 0;
        this.clientRect = void 0;
        this.hls = hls;
        this.autoLevelCapping = Number.POSITIVE_INFINITY;
        this.firstLevel = -1;
        this.media = null;
        this.restrictedLevels = [];
        this.timer = undefined;
        this.clientRect = null;
        this.registerListeners();
      }

      var _proto = CapLevelController.prototype;

      _proto.setStreamController = function setStreamController(streamController) {
        this.streamController = streamController;
      };

      _proto.destroy = function destroy() {
        this.unregisterListener();

        if (this.hls.config.capLevelToPlayerSize) {
          this.stopCapping();
        }

        this.media = null;
        this.clientRect = null; // @ts-ignore

        this.hls = this.streamController = null;
      };

      _proto.registerListeners = function registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHING, this.onMediaAttaching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].BUFFER_CODECS, this.onBufferCodecs, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
      };

      _proto.unregisterListener = function unregisterListener() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHING, this.onMediaAttaching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].BUFFER_CODECS, this.onBufferCodecs, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
      };

      _proto.onFpsDropLevelCapping = function onFpsDropLevelCapping(event, data) {
        // Don't add a restricted level more than once
        if (CapLevelController.isLevelAllowed(data.droppedLevel, this.restrictedLevels)) {
          this.restrictedLevels.push(data.droppedLevel);
        }
      };

      _proto.onMediaAttaching = function onMediaAttaching(event, data) {
        this.media = data.media instanceof HTMLVideoElement ? data.media : null;
      };

      _proto.onManifestParsed = function onManifestParsed(event, data) {
        var hls = this.hls;
        this.restrictedLevels = [];
        this.firstLevel = data.firstLevel;

        if (hls.config.capLevelToPlayerSize && data.video) {
          // Start capping immediately if the manifest has signaled video codecs
          this.startCapping();
        }
      } // Only activate capping when playing a video stream; otherwise, multi-bitrate audio-only streams will be restricted
      // to the first level
      ;

      _proto.onBufferCodecs = function onBufferCodecs(event, data) {
        var hls = this.hls;

        if (hls.config.capLevelToPlayerSize && data.video) {
          // If the manifest did not signal a video codec capping has been deferred until we're certain video is present
          this.startCapping();
        }
      };

      _proto.onMediaDetaching = function onMediaDetaching() {
        this.stopCapping();
      };

      _proto.detectPlayerSize = function detectPlayerSize() {
        if (this.media && this.mediaHeight > 0 && this.mediaWidth > 0) {
          var levels = this.hls.levels;

          if (levels.length) {
            var hls = this.hls;
            hls.autoLevelCapping = this.getMaxLevel(levels.length - 1);

            if (hls.autoLevelCapping > this.autoLevelCapping && this.streamController) {
              // if auto level capping has a higher value for the previous one, flush the buffer using nextLevelSwitch
              // usually happen when the user go to the fullscreen mode.
              this.streamController.nextLevelSwitch();
            }

            this.autoLevelCapping = hls.autoLevelCapping;
          }
        }
      }
      /*
       * returns level should be the one with the dimensions equal or greater than the media (player) dimensions (so the video will be downscaled)
       */
      ;

      _proto.getMaxLevel = function getMaxLevel(capLevelIndex) {
        var _this = this;

        var levels = this.hls.levels;

        if (!levels.length) {
          return -1;
        }

        var validLevels = levels.filter(function (level, index) {
          return CapLevelController.isLevelAllowed(index, _this.restrictedLevels) && index <= capLevelIndex;
        });
        this.clientRect = null;
        return CapLevelController.getMaxLevelByMediaSize(validLevels, this.mediaWidth, this.mediaHeight);
      };

      _proto.startCapping = function startCapping() {
        if (this.timer) {
          // Don't reset capping if started twice; this can happen if the manifest signals a video codec
          return;
        }

        this.autoLevelCapping = Number.POSITIVE_INFINITY;
        this.hls.firstLevel = this.getMaxLevel(this.firstLevel);
        self.clearInterval(this.timer);
        this.timer = self.setInterval(this.detectPlayerSize.bind(this), 1000);
        this.detectPlayerSize();
      };

      _proto.stopCapping = function stopCapping() {
        this.restrictedLevels = [];
        this.firstLevel = -1;
        this.autoLevelCapping = Number.POSITIVE_INFINITY;

        if (this.timer) {
          self.clearInterval(this.timer);
          this.timer = undefined;
        }
      };

      _proto.getDimensions = function getDimensions() {
        if (this.clientRect) {
          return this.clientRect;
        }

        var media = this.media;
        var boundsRect = {
          width: 0,
          height: 0
        };

        if (media) {
          var clientRect = media.getBoundingClientRect();
          boundsRect.width = clientRect.width;
          boundsRect.height = clientRect.height;

          if (!boundsRect.width && !boundsRect.height) {
            // When the media element has no width or height (equivalent to not being in the DOM),
            // then use its width and height attributes (media.width, media.height)
            boundsRect.width = clientRect.right - clientRect.left || media.width || 0;
            boundsRect.height = clientRect.bottom - clientRect.top || media.height || 0;
          }
        }

        this.clientRect = boundsRect;
        return boundsRect;
      };

      CapLevelController.isLevelAllowed = function isLevelAllowed(level, restrictedLevels) {
        if (restrictedLevels === void 0) {
          restrictedLevels = [];
        }

        return restrictedLevels.indexOf(level) === -1;
      };

      CapLevelController.getMaxLevelByMediaSize = function getMaxLevelByMediaSize(levels, width, height) {
        if (!levels || !levels.length) {
          return -1;
        } // Levels can have the same dimensions but differing bandwidths - since levels are ordered, we can look to the next
        // to determine whether we've chosen the greatest bandwidth for the media's dimensions


        var atGreatestBandiwdth = function atGreatestBandiwdth(curLevel, nextLevel) {
          if (!nextLevel) {
            return true;
          }

          return curLevel.width !== nextLevel.width || curLevel.height !== nextLevel.height;
        }; // If we run through the loop without breaking, the media's dimensions are greater than every level, so default to
        // the max level


        var maxLevelIndex = levels.length - 1;

        for (var i = 0; i < levels.length; i += 1) {
          var level = levels[i];

          if ((level.width >= width || level.height >= height) && atGreatestBandiwdth(level, levels[i + 1])) {
            maxLevelIndex = i;
            break;
          }
        }

        return maxLevelIndex;
      };

      _createClass(CapLevelController, [{
        key: "mediaWidth",
        get: function get() {
          return this.getDimensions().width * CapLevelController.contentScaleFactor;
        }
      }, {
        key: "mediaHeight",
        get: function get() {
          return this.getDimensions().height * CapLevelController.contentScaleFactor;
        }
      }], [{
        key: "contentScaleFactor",
        get: function get() {
          var pixelRatio = 1;

          try {
            pixelRatio = self.devicePixelRatio;
          } catch (e) {
            /* no-op */
          }

          return pixelRatio;
        }
      }]);

      return CapLevelController;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (CapLevelController);

    /***/ }),

    /***/ "./src/controller/cmcd-controller.ts":
    /*!*******************************************!*\
      !*** ./src/controller/cmcd-controller.ts ***!
      \*******************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return CMCDController; });
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _types_cmcd__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../types/cmcd */ "./src/types/cmcd.ts");
    /* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

    function _createForOfIteratorHelperLoose(o, allowArrayLike) { var it = typeof Symbol !== "undefined" && o[Symbol.iterator] || o["@@iterator"]; if (it) return (it = it.call(o)).next.bind(it); if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === "number") { if (it) o = it; var i = 0; return function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }; } throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); }

    function _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === "string") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === "Object" && o.constructor) n = o.constructor.name; if (n === "Map" || n === "Set") return Array.from(o); if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }

    function _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }

    function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }





    /**
     * Controller to deal with Common Media Client Data (CMCD)
     * @see https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf
     */

    var CMCDController = /*#__PURE__*/function () {
      // eslint-disable-line no-restricted-globals
      // eslint-disable-line no-restricted-globals
      function CMCDController(hls) {
        var _this = this;

        this.hls = void 0;
        this.config = void 0;
        this.media = void 0;
        this.sid = void 0;
        this.cid = void 0;
        this.useHeaders = false;
        this.initialized = false;
        this.starved = false;
        this.buffering = true;
        this.audioBuffer = void 0;
        this.videoBuffer = void 0;

        this.onWaiting = function () {
          if (_this.initialized) {
            _this.starved = true;
          }

          _this.buffering = true;
        };

        this.onPlaying = function () {
          if (!_this.initialized) {
            _this.initialized = true;
          }

          _this.buffering = false;
        };

        this.applyPlaylistData = function (context) {
          try {
            _this.apply(context, {
              ot: _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].MANIFEST,
              su: !_this.initialized
            });
          } catch (error) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn('Could not generate manifest CMCD data.', error);
          }
        };

        this.applyFragmentData = function (context) {
          try {
            var fragment = context.frag;
            var level = _this.hls.levels[fragment.level];

            var ot = _this.getObjectType(fragment);

            var data = {
              d: fragment.duration * 1000,
              ot: ot
            };

            if (ot === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].VIDEO || ot === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].AUDIO || ot == _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].MUXED) {
              data.br = level.bitrate / 1000;
              data.tb = _this.getTopBandwidth(ot) / 1000;
              data.bl = _this.getBufferLength(ot);
            }

            _this.apply(context, data);
          } catch (error) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn('Could not generate segment CMCD data.', error);
          }
        };

        this.hls = hls;
        var config = this.config = hls.config;
        var cmcd = config.cmcd;

        if (cmcd != null) {
          config.pLoader = this.createPlaylistLoader();
          config.fLoader = this.createFragmentLoader();
          this.sid = cmcd.sessionId || CMCDController.uuid();
          this.cid = cmcd.contentId;
          this.useHeaders = cmcd.useHeaders === true;
          this.registerListeners();
        }
      }

      var _proto = CMCDController.prototype;

      _proto.registerListeners = function registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHED, this.onMediaDetached, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].BUFFER_CREATED, this.onBufferCreated, this);
      };

      _proto.unregisterListeners = function unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHED, this.onMediaDetached, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].BUFFER_CREATED, this.onBufferCreated, this);
        this.onMediaDetached();
      };

      _proto.destroy = function destroy() {
        this.unregisterListeners(); // @ts-ignore

        this.hls = this.config = this.audioBuffer = this.videoBuffer = null;
      };

      _proto.onMediaAttached = function onMediaAttached(event, data) {
        this.media = data.media;
        this.media.addEventListener('waiting', this.onWaiting);
        this.media.addEventListener('playing', this.onPlaying);
      };

      _proto.onMediaDetached = function onMediaDetached() {
        if (!this.media) {
          return;
        }

        this.media.removeEventListener('waiting', this.onWaiting);
        this.media.removeEventListener('playing', this.onPlaying); // @ts-ignore

        this.media = null;
      };

      _proto.onBufferCreated = function onBufferCreated(event, data) {
        var _data$tracks$audio, _data$tracks$video;

        this.audioBuffer = (_data$tracks$audio = data.tracks.audio) === null || _data$tracks$audio === void 0 ? void 0 : _data$tracks$audio.buffer;
        this.videoBuffer = (_data$tracks$video = data.tracks.video) === null || _data$tracks$video === void 0 ? void 0 : _data$tracks$video.buffer;
      };

      /**
       * Create baseline CMCD data
       */
      _proto.createData = function createData() {
        var _this$media;

        return {
          v: _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDVersion"],
          sf: _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDStreamingFormat"].HLS,
          sid: this.sid,
          cid: this.cid,
          pr: (_this$media = this.media) === null || _this$media === void 0 ? void 0 : _this$media.playbackRate,
          mtp: this.hls.bandwidthEstimate / 1000
        };
      }
      /**
       * Apply CMCD data to a request.
       */
      ;

      _proto.apply = function apply(context, data) {
        if (data === void 0) {
          data = {};
        }

        // apply baseline data
        _extends(data, this.createData());

        var isVideo = data.ot === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].INIT || data.ot === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].VIDEO || data.ot === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].MUXED;

        if (this.starved && isVideo) {
          data.bs = true;
          data.su = true;
          this.starved = false;
        }

        if (data.su == null) {
          data.su = this.buffering;
        } // TODO: Implement rtp, nrr, nor, dl


        if (this.useHeaders) {
          var headers = CMCDController.toHeaders(data);

          if (!Object.keys(headers).length) {
            return;
          }

          if (!context.headers) {
            context.headers = {};
          }

          _extends(context.headers, headers);
        } else {
          var query = CMCDController.toQuery(data);

          if (!query) {
            return;
          }

          context.url = CMCDController.appendQueryToUri(context.url, query);
        }
      }
      /**
       * Apply CMCD data to a manifest request.
       */
      ;

      /**
       * The CMCD object type.
       */
      _proto.getObjectType = function getObjectType(fragment) {
        var type = fragment.type;

        if (type === 'subtitle') {
          return _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].TIMED_TEXT;
        }

        if (fragment.sn === 'initSegment') {
          return _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].INIT;
        }

        if (type === 'audio') {
          return _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].AUDIO;
        }

        if (type === 'main') {
          if (!this.hls.audioTracks.length) {
            return _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].MUXED;
          }

          return _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].VIDEO;
        }

        return undefined;
      }
      /**
       * Get the highest bitrate.
       */
      ;

      _proto.getTopBandwidth = function getTopBandwidth(type) {
        var bitrate = 0;
        var levels;
        var hls = this.hls;

        if (type === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].AUDIO) {
          levels = hls.audioTracks;
        } else {
          var max = hls.maxAutoLevel;
          var len = max > -1 ? max + 1 : hls.levels.length;
          levels = hls.levels.slice(0, len);
        }

        for (var _iterator = _createForOfIteratorHelperLoose(levels), _step; !(_step = _iterator()).done;) {
          var level = _step.value;

          if (level.bitrate > bitrate) {
            bitrate = level.bitrate;
          }
        }

        return bitrate > 0 ? bitrate : NaN;
      }
      /**
       * Get the buffer length for a media type in milliseconds
       */
      ;

      _proto.getBufferLength = function getBufferLength(type) {
        var media = this.hls.media;
        var buffer = type === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__["CMCDObjectType"].AUDIO ? this.audioBuffer : this.videoBuffer;

        if (!buffer || !media) {
          return NaN;
        }

        var info = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__["BufferHelper"].bufferInfo(buffer, media.currentTime, this.config.maxBufferHole);
        return info.len * 1000;
      }
      /**
       * Create a playlist loader
       */
      ;

      _proto.createPlaylistLoader = function createPlaylistLoader() {
        var pLoader = this.config.pLoader;
        var apply = this.applyPlaylistData;
        var Ctor = pLoader || this.config.loader;
        return /*#__PURE__*/function () {
          function CmcdPlaylistLoader(config) {
            this.loader = void 0;
            this.loader = new Ctor(config);
          }

          var _proto2 = CmcdPlaylistLoader.prototype;

          _proto2.destroy = function destroy() {
            this.loader.destroy();
          };

          _proto2.abort = function abort() {
            this.loader.abort();
          };

          _proto2.load = function load(context, config, callbacks) {
            apply(context);
            this.loader.load(context, config, callbacks);
          };

          _createClass(CmcdPlaylistLoader, [{
            key: "stats",
            get: function get() {
              return this.loader.stats;
            }
          }, {
            key: "context",
            get: function get() {
              return this.loader.context;
            }
          }]);

          return CmcdPlaylistLoader;
        }();
      }
      /**
       * Create a playlist loader
       */
      ;

      _proto.createFragmentLoader = function createFragmentLoader() {
        var fLoader = this.config.fLoader;
        var apply = this.applyFragmentData;
        var Ctor = fLoader || this.config.loader;
        return /*#__PURE__*/function () {
          function CmcdFragmentLoader(config) {
            this.loader = void 0;
            this.loader = new Ctor(config);
          }

          var _proto3 = CmcdFragmentLoader.prototype;

          _proto3.destroy = function destroy() {
            this.loader.destroy();
          };

          _proto3.abort = function abort() {
            this.loader.abort();
          };

          _proto3.load = function load(context, config, callbacks) {
            apply(context);
            this.loader.load(context, config, callbacks);
          };

          _createClass(CmcdFragmentLoader, [{
            key: "stats",
            get: function get() {
              return this.loader.stats;
            }
          }, {
            key: "context",
            get: function get() {
              return this.loader.context;
            }
          }]);

          return CmcdFragmentLoader;
        }();
      }
      /**
       * Generate a random v4 UUI
       *
       * @returns {string}
       */
      ;

      CMCDController.uuid = function uuid() {
        var url = URL.createObjectURL(new Blob());
        var uuid = url.toString();
        URL.revokeObjectURL(url);
        return uuid.substr(uuid.lastIndexOf('/') + 1);
      }
      /**
       * Serialize a CMCD data object according to the rules defined in the
       * section 3.2 of
       * [CTA-5004](https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf).
       */
      ;

      CMCDController.serialize = function serialize(data) {
        var results = [];

        var isValid = function isValid(value) {
          return !Number.isNaN(value) && value != null && value !== '' && value !== false;
        };

        var toRounded = function toRounded(value) {
          return Math.round(value);
        };

        var toHundred = function toHundred(value) {
          return toRounded(value / 100) * 100;
        };

        var toUrlSafe = function toUrlSafe(value) {
          return encodeURIComponent(value);
        };

        var formatters = {
          br: toRounded,
          d: toRounded,
          bl: toHundred,
          dl: toHundred,
          mtp: toHundred,
          nor: toUrlSafe,
          rtp: toHundred,
          tb: toRounded
        };
        var keys = Object.keys(data || {}).sort();

        for (var _iterator2 = _createForOfIteratorHelperLoose(keys), _step2; !(_step2 = _iterator2()).done;) {
          var key = _step2.value;
          var value = data[key]; // ignore invalid values

          if (!isValid(value)) {
            continue;
          } // Version should only be reported if not equal to 1.


          if (key === 'v' && value === 1) {
            continue;
          } // Playback rate should only be sent if not equal to 1.


          if (key == 'pr' && value === 1) {
            continue;
          } // Certain values require special formatting


          var formatter = formatters[key];

          if (formatter) {
            value = formatter(value);
          } // Serialize the key/value pair


          var type = typeof value;
          var result = void 0;

          if (key === 'ot' || key === 'sf' || key === 'st') {
            result = key + "=" + value;
          } else if (type === 'boolean') {
            result = key;
          } else if (type === 'number') {
            result = key + "=" + value;
          } else {
            result = key + "=" + JSON.stringify(value);
          }

          results.push(result);
        }

        return results.join(',');
      }
      /**
       * Convert a CMCD data object to request headers according to the rules
       * defined in the section 2.1 and 3.2 of
       * [CTA-5004](https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf).
       */
      ;

      CMCDController.toHeaders = function toHeaders(data) {
        var keys = Object.keys(data);
        var headers = {};
        var headerNames = ['Object', 'Request', 'Session', 'Status'];
        var headerGroups = [{}, {}, {}, {}];
        var headerMap = {
          br: 0,
          d: 0,
          ot: 0,
          tb: 0,
          bl: 1,
          dl: 1,
          mtp: 1,
          nor: 1,
          nrr: 1,
          su: 1,
          cid: 2,
          pr: 2,
          sf: 2,
          sid: 2,
          st: 2,
          v: 2,
          bs: 3,
          rtp: 3
        };

        for (var _i = 0, _keys = keys; _i < _keys.length; _i++) {
          var key = _keys[_i];
          // Unmapped fields are mapped to the Request header
          var index = headerMap[key] != null ? headerMap[key] : 1;
          headerGroups[index][key] = data[key];
        }

        for (var i = 0; i < headerGroups.length; i++) {
          var value = CMCDController.serialize(headerGroups[i]);

          if (value) {
            headers["CMCD-" + headerNames[i]] = value;
          }
        }

        return headers;
      }
      /**
       * Convert a CMCD data object to query args according to the rules
       * defined in the section 2.2 and 3.2 of
       * [CTA-5004](https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf).
       */
      ;

      CMCDController.toQuery = function toQuery(data) {
        return "CMCD=" + encodeURIComponent(CMCDController.serialize(data));
      }
      /**
       * Append query args to a uri.
       */
      ;

      CMCDController.appendQueryToUri = function appendQueryToUri(uri, query) {
        if (!query) {
          return uri;
        }

        var separator = uri.includes('?') ? '&' : '?';
        return "" + uri + separator + query;
      };

      return CMCDController;
    }();



    /***/ }),

    /***/ "./src/controller/eme-controller.ts":
    /*!******************************************!*\
      !*** ./src/controller/eme-controller.ts ***!
      \******************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/mediakeys-helper */ "./src/utils/mediakeys-helper.ts");
    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

    /**
     * @author Stephan Hesse <disparat@gmail.com> | <tchakabam@gmail.com>
     *
     * DRM support for Hls.js
     */




    var MAX_LICENSE_REQUEST_FAILURES = 3;
    /**
     * @see https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemConfiguration
     * @param {Array<string>} audioCodecs List of required audio codecs to support
     * @param {Array<string>} videoCodecs List of required video codecs to support
     * @param {object} drmSystemOptions Optional parameters/requirements for the key-system
     * @returns {Array<MediaSystemConfiguration>} An array of supported configurations
     */

    var createWidevineMediaKeySystemConfigurations = function createWidevineMediaKeySystemConfigurations(audioCodecs, videoCodecs, drmSystemOptions) {
      /* jshint ignore:line */
      var baseConfig = {
        // initDataTypes: ['keyids', 'mp4'],
        // label: "",
        // persistentState: "not-allowed", // or "required" ?
        // distinctiveIdentifier: "not-allowed", // or "required" ?
        // sessionTypes: ['temporary'],
        audioCapabilities: [],
        // { contentType: 'audio/mp4; codecs="mp4a.40.2"' }
        videoCapabilities: [] // { contentType: 'video/mp4; codecs="avc1.42E01E"' }

      };
      audioCodecs.forEach(function (codec) {
        baseConfig.audioCapabilities.push({
          contentType: "audio/mp4; codecs=\"" + codec + "\"",
          robustness: drmSystemOptions.audioRobustness || ''
        });
      });
      videoCodecs.forEach(function (codec) {
        baseConfig.videoCapabilities.push({
          contentType: "video/mp4; codecs=\"" + codec + "\"",
          robustness: drmSystemOptions.videoRobustness || ''
        });
      });
      return [baseConfig];
    };
    /**
     * The idea here is to handle key-system (and their respective platforms) specific configuration differences
     * in order to work with the local requestMediaKeySystemAccess method.
     *
     * We can also rule-out platform-related key-system support at this point by throwing an error.
     *
     * @param {string} keySystem Identifier for the key-system, see `KeySystems` enum
     * @param {Array<string>} audioCodecs List of required audio codecs to support
     * @param {Array<string>} videoCodecs List of required video codecs to support
     * @throws will throw an error if a unknown key system is passed
     * @returns {Array<MediaSystemConfiguration>} A non-empty Array of MediaKeySystemConfiguration objects
     */


    var getSupportedMediaKeySystemConfigurations = function getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, drmSystemOptions) {
      switch (keySystem) {
        case _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__["KeySystems"].WIDEVINE:
          return createWidevineMediaKeySystemConfigurations(audioCodecs, videoCodecs, drmSystemOptions);

        default:
          throw new Error("Unknown key-system: " + keySystem);
      }
    };

    /**
     * Controller to deal with encrypted media extensions (EME)
     * @see https://developer.mozilla.org/en-US/docs/Web/API/Encrypted_Media_Extensions_API
     *
     * @class
     * @constructor
     */
    var EMEController = /*#__PURE__*/function () {
      /**
       * @constructs
       * @param {Hls} hls Our Hls.js instance
       */
      function EMEController(hls) {
        this.hls = void 0;
        this._widevineLicenseUrl = void 0;
        this._licenseXhrSetup = void 0;
        this._licenseResponseCallback = void 0;
        this._emeEnabled = void 0;
        this._requestMediaKeySystemAccess = void 0;
        this._drmSystemOptions = void 0;
        this._config = void 0;
        this._mediaKeysList = [];
        this._media = null;
        this._hasSetMediaKeys = false;
        this._requestLicenseFailureCount = 0;
        this.mediaKeysPromise = null;
        this._onMediaEncrypted = this.onMediaEncrypted.bind(this);
        this.hls = hls;
        this._config = hls.config;
        this._widevineLicenseUrl = this._config.widevineLicenseUrl;
        this._licenseXhrSetup = this._config.licenseXhrSetup;
        this._licenseResponseCallback = this._config.licenseResponseCallback;
        this._emeEnabled = this._config.emeEnabled;
        this._requestMediaKeySystemAccess = this._config.requestMediaKeySystemAccessFunc;
        this._drmSystemOptions = this._config.drmSystemOptions;

        this._registerListeners();
      }

      var _proto = EMEController.prototype;

      _proto.destroy = function destroy() {
        this._unregisterListeners(); // @ts-ignore


        this.hls = this._onMediaEncrypted = null;
        this._requestMediaKeySystemAccess = null;
      };

      _proto._registerListeners = function _registerListeners() {
        this.hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        this.hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHED, this.onMediaDetached, this);
        this.hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
      };

      _proto._unregisterListeners = function _unregisterListeners() {
        this.hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        this.hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHED, this.onMediaDetached, this);
        this.hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
      }
      /**
       * @param {string} keySystem Identifier for the key-system, see `KeySystems` enum
       * @returns {string} License server URL for key-system (if any configured, otherwise causes error)
       * @throws if a unsupported keysystem is passed
       */
      ;

      _proto.getLicenseServerUrl = function getLicenseServerUrl(keySystem) {
        switch (keySystem) {
          case _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__["KeySystems"].WIDEVINE:
            if (!this._widevineLicenseUrl) {
              break;
            }

            return this._widevineLicenseUrl;
        }

        throw new Error("no license server URL configured for key-system \"" + keySystem + "\"");
      }
      /**
       * Requests access object and adds it to our list upon success
       * @private
       * @param {string} keySystem System ID (see `KeySystems`)
       * @param {Array<string>} audioCodecs List of required audio codecs to support
       * @param {Array<string>} videoCodecs List of required video codecs to support
       * @throws When a unsupported KeySystem is passed
       */
      ;

      _proto._attemptKeySystemAccess = function _attemptKeySystemAccess(keySystem, audioCodecs, videoCodecs) {
        var _this = this;

        // This can throw, but is caught in event handler callpath
        var mediaKeySystemConfigs = getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, this._drmSystemOptions);
        _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('Requesting encrypted media key-system access'); // expecting interface like window.navigator.requestMediaKeySystemAccess

        var keySystemAccessPromise = this.requestMediaKeySystemAccess(keySystem, mediaKeySystemConfigs);
        this.mediaKeysPromise = keySystemAccessPromise.then(function (mediaKeySystemAccess) {
          return _this._onMediaKeySystemAccessObtained(keySystem, mediaKeySystemAccess);
        });
        keySystemAccessPromise.catch(function (err) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error("Failed to obtain key-system \"" + keySystem + "\" access:", err);
        });
      };

      /**
       * Handles obtaining access to a key-system
       * @private
       * @param {string} keySystem
       * @param {MediaKeySystemAccess} mediaKeySystemAccess https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemAccess
       */
      _proto._onMediaKeySystemAccessObtained = function _onMediaKeySystemAccessObtained(keySystem, mediaKeySystemAccess) {
        var _this2 = this;

        _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("Access for key-system \"" + keySystem + "\" obtained");
        var mediaKeysListItem = {
          mediaKeysSessionInitialized: false,
          mediaKeySystemAccess: mediaKeySystemAccess,
          mediaKeySystemDomain: keySystem
        };

        this._mediaKeysList.push(mediaKeysListItem);

        var mediaKeysPromise = Promise.resolve().then(function () {
          return mediaKeySystemAccess.createMediaKeys();
        }).then(function (mediaKeys) {
          mediaKeysListItem.mediaKeys = mediaKeys;
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("Media-keys created for key-system \"" + keySystem + "\"");

          _this2._onMediaKeysCreated();

          return mediaKeys;
        });
        mediaKeysPromise.catch(function (err) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error('Failed to create media-keys:', err);
        });
        return mediaKeysPromise;
      }
      /**
       * Handles key-creation (represents access to CDM). We are going to create key-sessions upon this
       * for all existing keys where no session exists yet.
       *
       * @private
       */
      ;

      _proto._onMediaKeysCreated = function _onMediaKeysCreated() {
        var _this3 = this;

        // check for all key-list items if a session exists, otherwise, create one
        this._mediaKeysList.forEach(function (mediaKeysListItem) {
          if (!mediaKeysListItem.mediaKeysSession) {
            // mediaKeys is definitely initialized here
            mediaKeysListItem.mediaKeysSession = mediaKeysListItem.mediaKeys.createSession();

            _this3._onNewMediaKeySession(mediaKeysListItem.mediaKeysSession);
          }
        });
      }
      /**
       * @private
       * @param {*} keySession
       */
      ;

      _proto._onNewMediaKeySession = function _onNewMediaKeySession(keySession) {
        var _this4 = this;

        _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("New key-system session " + keySession.sessionId);
        keySession.addEventListener('message', function (event) {
          _this4._onKeySessionMessage(keySession, event.message);
        }, false);
      }
      /**
       * @private
       * @param {MediaKeySession} keySession
       * @param {ArrayBuffer} message
       */
      ;

      _proto._onKeySessionMessage = function _onKeySessionMessage(keySession, message) {
        _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('Got EME message event, creating license request');

        this._requestLicense(message, function (data) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("Received license data (length: " + (data ? data.byteLength : data) + "), updating key-session");
          keySession.update(data);
        });
      }
      /**
       * @private
       * @param e {MediaEncryptedEvent}
       */
      ;

      _proto.onMediaEncrypted = function onMediaEncrypted(e) {
        var _this5 = this;

        _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("Media is encrypted using \"" + e.initDataType + "\" init data type");

        if (!this.mediaKeysPromise) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error('Fatal: Media is encrypted but no CDM access or no keys have been requested');
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].KEY_SYSTEM_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].KEY_SYSTEM_NO_KEYS,
            fatal: true
          });
          return;
        }

        var finallySetKeyAndStartSession = function finallySetKeyAndStartSession(mediaKeys) {
          if (!_this5._media) {
            return;
          }

          _this5._attemptSetMediaKeys(mediaKeys);

          _this5._generateRequestWithPreferredKeySession(e.initDataType, e.initData);
        }; // Could use `Promise.finally` but some Promise polyfills are missing it


        this.mediaKeysPromise.then(finallySetKeyAndStartSession).catch(finallySetKeyAndStartSession);
      }
      /**
       * @private
       */
      ;

      _proto._attemptSetMediaKeys = function _attemptSetMediaKeys(mediaKeys) {
        if (!this._media) {
          throw new Error('Attempted to set mediaKeys without first attaching a media element');
        }

        if (!this._hasSetMediaKeys) {
          // FIXME: see if we can/want/need-to really to deal with several potential key-sessions?
          var keysListItem = this._mediaKeysList[0];

          if (!keysListItem || !keysListItem.mediaKeys) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error('Fatal: Media is encrypted but no CDM access or no keys have been obtained yet');
            this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
              type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].KEY_SYSTEM_ERROR,
              details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].KEY_SYSTEM_NO_KEYS,
              fatal: true
            });
            return;
          }

          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('Setting keys for encrypted media');

          this._media.setMediaKeys(keysListItem.mediaKeys);

          this._hasSetMediaKeys = true;
        }
      }
      /**
       * @private
       */
      ;

      _proto._generateRequestWithPreferredKeySession = function _generateRequestWithPreferredKeySession(initDataType, initData) {
        var _this6 = this;

        // FIXME: see if we can/want/need-to really to deal with several potential key-sessions?
        var keysListItem = this._mediaKeysList[0];

        if (!keysListItem) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error('Fatal: Media is encrypted but not any key-system access has been obtained yet');
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].KEY_SYSTEM_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].KEY_SYSTEM_NO_ACCESS,
            fatal: true
          });
          return;
        }

        if (keysListItem.mediaKeysSessionInitialized) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn('Key-Session already initialized but requested again');
          return;
        }

        var keySession = keysListItem.mediaKeysSession;

        if (!keySession) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error('Fatal: Media is encrypted but no key-session existing');
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].KEY_SYSTEM_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].KEY_SYSTEM_NO_SESSION,
            fatal: true
          });
          return;
        } // initData is null if the media is not CORS-same-origin


        if (!initData) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn('Fatal: initData required for generating a key session is null');
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].KEY_SYSTEM_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].KEY_SYSTEM_NO_INIT_DATA,
            fatal: true
          });
          return;
        }

        _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("Generating key-session request for \"" + initDataType + "\" init data type");
        keysListItem.mediaKeysSessionInitialized = true;
        keySession.generateRequest(initDataType, initData).then(function () {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].debug('Key-session generation succeeded');
        }).catch(function (err) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error('Error generating key-session request:', err);

          _this6.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].KEY_SYSTEM_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].KEY_SYSTEM_NO_SESSION,
            fatal: false
          });
        });
      }
      /**
       * @private
       * @param {string} url License server URL
       * @param {ArrayBuffer} keyMessage Message data issued by key-system
       * @param {function} callback Called when XHR has succeeded
       * @returns {XMLHttpRequest} Unsent (but opened state) XHR object
       * @throws if XMLHttpRequest construction failed
       */
      ;

      _proto._createLicenseXhr = function _createLicenseXhr(url, keyMessage, callback) {
        var xhr = new XMLHttpRequest();
        xhr.responseType = 'arraybuffer';
        xhr.onreadystatechange = this._onLicenseRequestReadyStageChange.bind(this, xhr, url, keyMessage, callback);
        var licenseXhrSetup = this._licenseXhrSetup;

        if (licenseXhrSetup) {
          try {
            licenseXhrSetup.call(this.hls, xhr, url);
            licenseXhrSetup = undefined;
          } catch (e) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error(e);
          }
        }

        try {
          // if licenseXhrSetup did not yet call open, let's do it now
          if (!xhr.readyState) {
            xhr.open('POST', url, true);
          }

          if (licenseXhrSetup) {
            licenseXhrSetup.call(this.hls, xhr, url);
          }
        } catch (e) {
          // IE11 throws an exception on xhr.open if attempting to access an HTTP resource over HTTPS
          throw new Error("issue setting up KeySystem license XHR " + e);
        }

        return xhr;
      }
      /**
       * @private
       * @param {XMLHttpRequest} xhr
       * @param {string} url License server URL
       * @param {ArrayBuffer} keyMessage Message data issued by key-system
       * @param {function} callback Called when XHR has succeeded
       */
      ;

      _proto._onLicenseRequestReadyStageChange = function _onLicenseRequestReadyStageChange(xhr, url, keyMessage, callback) {
        switch (xhr.readyState) {
          case 4:
            if (xhr.status === 200) {
              this._requestLicenseFailureCount = 0;
              _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('License request succeeded');
              var _data = xhr.response;
              var licenseResponseCallback = this._licenseResponseCallback;

              if (licenseResponseCallback) {
                try {
                  _data = licenseResponseCallback.call(this.hls, xhr, url);
                } catch (e) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error(e);
                }
              }

              callback(_data);
            } else {
              _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error("License Request XHR failed (" + url + "). Status: " + xhr.status + " (" + xhr.statusText + ")");
              this._requestLicenseFailureCount++;

              if (this._requestLicenseFailureCount > MAX_LICENSE_REQUEST_FAILURES) {
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].KEY_SYSTEM_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].KEY_SYSTEM_LICENSE_REQUEST_FAILED,
                  fatal: true
                });
                return;
              }

              var attemptsLeft = MAX_LICENSE_REQUEST_FAILURES - this._requestLicenseFailureCount + 1;
              _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn("Retrying license request, " + attemptsLeft + " attempts left");

              this._requestLicense(keyMessage, callback);
            }

            break;
        }
      }
      /**
       * @private
       * @param {MediaKeysListItem} keysListItem
       * @param {ArrayBuffer} keyMessage
       * @returns {ArrayBuffer} Challenge data posted to license server
       * @throws if KeySystem is unsupported
       */
      ;

      _proto._generateLicenseRequestChallenge = function _generateLicenseRequestChallenge(keysListItem, keyMessage) {
        switch (keysListItem.mediaKeySystemDomain) {
          // case KeySystems.PLAYREADY:
          // from https://github.com/MicrosoftEdge/Demos/blob/master/eme/scripts/demo.js

          /*
          if (this.licenseType !== this.LICENSE_TYPE_WIDEVINE) {
            // For PlayReady CDMs, we need to dig the Challenge out of the XML.
            var keyMessageXml = new DOMParser().parseFromString(String.fromCharCode.apply(null, new Uint16Array(keyMessage)), 'application/xml');
            if (keyMessageXml.getElementsByTagName('Challenge')[0]) {
                challenge = atob(keyMessageXml.getElementsByTagName('Challenge')[0].childNodes[0].nodeValue);
            } else {
                throw 'Cannot find <Challenge> in key message';
            }
            var headerNames = keyMessageXml.getElementsByTagName('name');
            var headerValues = keyMessageXml.getElementsByTagName('value');
            if (headerNames.length !== headerValues.length) {
                throw 'Mismatched header <name>/<value> pair in key message';
            }
            for (var i = 0; i < headerNames.length; i++) {
                xhr.setRequestHeader(headerNames[i].childNodes[0].nodeValue, headerValues[i].childNodes[0].nodeValue);
            }
          }
          break;
          */
          case _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__["KeySystems"].WIDEVINE:
            // For Widevine CDMs, the challenge is the keyMessage.
            return keyMessage;
        }

        throw new Error("unsupported key-system: " + keysListItem.mediaKeySystemDomain);
      }
      /**
       * @private
       * @param keyMessage
       * @param callback
       */
      ;

      _proto._requestLicense = function _requestLicense(keyMessage, callback) {
        _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('Requesting content license for key-system');
        var keysListItem = this._mediaKeysList[0];

        if (!keysListItem) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error('Fatal error: Media is encrypted but no key-system access has been obtained yet');
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].KEY_SYSTEM_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].KEY_SYSTEM_NO_ACCESS,
            fatal: true
          });
          return;
        }

        try {
          var _url = this.getLicenseServerUrl(keysListItem.mediaKeySystemDomain);

          var _xhr = this._createLicenseXhr(_url, keyMessage, callback);

          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log("Sending license request to URL: " + _url);

          var challenge = this._generateLicenseRequestChallenge(keysListItem, keyMessage);

          _xhr.send(challenge);
        } catch (e) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error("Failure requesting DRM license: " + e);
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].KEY_SYSTEM_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].KEY_SYSTEM_LICENSE_REQUEST_FAILED,
            fatal: true
          });
        }
      };

      _proto.onMediaAttached = function onMediaAttached(event, data) {
        if (!this._emeEnabled) {
          return;
        }

        var media = data.media; // keep reference of media

        this._media = media;
        media.addEventListener('encrypted', this._onMediaEncrypted);
      };

      _proto.onMediaDetached = function onMediaDetached() {
        var media = this._media;
        var mediaKeysList = this._mediaKeysList;

        if (!media) {
          return;
        }

        media.removeEventListener('encrypted', this._onMediaEncrypted);
        this._media = null;
        this._mediaKeysList = []; // Close all sessions and remove media keys from the video element.

        Promise.all(mediaKeysList.map(function (mediaKeysListItem) {
          if (mediaKeysListItem.mediaKeysSession) {
            return mediaKeysListItem.mediaKeysSession.close().catch(function () {// Ignore errors when closing the sessions. Closing a session that
              // generated no key requests will throw an error.
            });
          }
        })).then(function () {
          return media.setMediaKeys(null);
        }).catch(function () {// Ignore any failures while removing media keys from the video element.
        });
      };

      _proto.onManifestParsed = function onManifestParsed(event, data) {
        if (!this._emeEnabled) {
          return;
        }

        var audioCodecs = data.levels.map(function (level) {
          return level.audioCodec;
        }).filter(function (audioCodec) {
          return !!audioCodec;
        });
        var videoCodecs = data.levels.map(function (level) {
          return level.videoCodec;
        }).filter(function (videoCodec) {
          return !!videoCodec;
        });

        this._attemptKeySystemAccess(_utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__["KeySystems"].WIDEVINE, audioCodecs, videoCodecs);
      };

      _createClass(EMEController, [{
        key: "requestMediaKeySystemAccess",
        get: function get() {
          if (!this._requestMediaKeySystemAccess) {
            throw new Error('No requestMediaKeySystemAccess function configured');
          }

          return this._requestMediaKeySystemAccess;
        }
      }]);

      return EMEController;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (EMEController);

    /***/ }),

    /***/ "./src/controller/fps-controller.ts":
    /*!******************************************!*\
      !*** ./src/controller/fps-controller.ts ***!
      \******************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");



    var FPSController = /*#__PURE__*/function () {
      // stream controller must be provided as a dependency!
      function FPSController(hls) {
        this.hls = void 0;
        this.isVideoPlaybackQualityAvailable = false;
        this.timer = void 0;
        this.media = null;
        this.lastTime = void 0;
        this.lastDroppedFrames = 0;
        this.lastDecodedFrames = 0;
        this.streamController = void 0;
        this.hls = hls;
        this.registerListeners();
      }

      var _proto = FPSController.prototype;

      _proto.setStreamController = function setStreamController(streamController) {
        this.streamController = streamController;
      };

      _proto.registerListeners = function registerListeners() {
        this.hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHING, this.onMediaAttaching, this);
      };

      _proto.unregisterListeners = function unregisterListeners() {
        this.hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHING, this.onMediaAttaching);
      };

      _proto.destroy = function destroy() {
        if (this.timer) {
          clearInterval(this.timer);
        }

        this.unregisterListeners();
        this.isVideoPlaybackQualityAvailable = false;
        this.media = null;
      };

      _proto.onMediaAttaching = function onMediaAttaching(event, data) {
        var config = this.hls.config;

        if (config.capLevelOnFPSDrop) {
          var media = data.media instanceof self.HTMLVideoElement ? data.media : null;
          this.media = media;

          if (media && typeof media.getVideoPlaybackQuality === 'function') {
            this.isVideoPlaybackQualityAvailable = true;
          }

          self.clearInterval(this.timer);
          this.timer = self.setInterval(this.checkFPSInterval.bind(this), config.fpsDroppedMonitoringPeriod);
        }
      };

      _proto.checkFPS = function checkFPS(video, decodedFrames, droppedFrames) {
        var currentTime = performance.now();

        if (decodedFrames) {
          if (this.lastTime) {
            var currentPeriod = currentTime - this.lastTime;
            var currentDropped = droppedFrames - this.lastDroppedFrames;
            var currentDecoded = decodedFrames - this.lastDecodedFrames;
            var droppedFPS = 1000 * currentDropped / currentPeriod;
            var hls = this.hls;
            hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].FPS_DROP, {
              currentDropped: currentDropped,
              currentDecoded: currentDecoded,
              totalDroppedFrames: droppedFrames
            });

            if (droppedFPS > 0) {
              // logger.log('checkFPS : droppedFPS/decodedFPS:' + droppedFPS/(1000 * currentDecoded / currentPeriod));
              if (currentDropped > hls.config.fpsDroppedMonitoringThreshold * currentDecoded) {
                var currentLevel = hls.currentLevel;
                _utils_logger__WEBPACK_IMPORTED_MODULE_1__["logger"].warn('drop FPS ratio greater than max allowed value for currentLevel: ' + currentLevel);

                if (currentLevel > 0 && (hls.autoLevelCapping === -1 || hls.autoLevelCapping >= currentLevel)) {
                  currentLevel = currentLevel - 1;
                  hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].FPS_DROP_LEVEL_CAPPING, {
                    level: currentLevel,
                    droppedLevel: hls.currentLevel
                  });
                  hls.autoLevelCapping = currentLevel;
                  this.streamController.nextLevelSwitch();
                }
              }
            }
          }

          this.lastTime = currentTime;
          this.lastDroppedFrames = droppedFrames;
          this.lastDecodedFrames = decodedFrames;
        }
      };

      _proto.checkFPSInterval = function checkFPSInterval() {
        var video = this.media;

        if (video) {
          if (this.isVideoPlaybackQualityAvailable) {
            var videoPlaybackQuality = video.getVideoPlaybackQuality();
            this.checkFPS(video, videoPlaybackQuality.totalVideoFrames, videoPlaybackQuality.droppedVideoFrames);
          } else {
            // HTMLVideoElement doesn't include the webkit types
            this.checkFPS(video, video.webkitDecodedFrameCount, video.webkitDroppedFrameCount);
          }
        }
      };

      return FPSController;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (FPSController);

    /***/ }),

    /***/ "./src/controller/fragment-finders.ts":
    /*!********************************************!*\
      !*** ./src/controller/fragment-finders.ts ***!
      \********************************************/
    /*! exports provided: findFragmentByPDT, findFragmentByPTS, fragmentWithinToleranceTest, pdtWithinToleranceTest, findFragWithCC */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "findFragmentByPDT", function() { return findFragmentByPDT; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "findFragmentByPTS", function() { return findFragmentByPTS; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "fragmentWithinToleranceTest", function() { return fragmentWithinToleranceTest; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "pdtWithinToleranceTest", function() { return pdtWithinToleranceTest; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "findFragWithCC", function() { return findFragWithCC; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _utils_binary_search__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/binary-search */ "./src/utils/binary-search.ts");



    /**
     * Returns first fragment whose endPdt value exceeds the given PDT.
     * @param {Array<Fragment>} fragments - The array of candidate fragments
     * @param {number|null} [PDTValue = null] - The PDT value which must be exceeded
     * @param {number} [maxFragLookUpTolerance = 0] - The amount of time that a fragment's start/end can be within in order to be considered contiguous
     * @returns {*|null} fragment - The best matching fragment
     */
    function findFragmentByPDT(fragments, PDTValue, maxFragLookUpTolerance) {
      if (PDTValue === null || !Array.isArray(fragments) || !fragments.length || !Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(PDTValue)) {
        return null;
      } // if less than start


      var startPDT = fragments[0].programDateTime;

      if (PDTValue < (startPDT || 0)) {
        return null;
      }

      var endPDT = fragments[fragments.length - 1].endProgramDateTime;

      if (PDTValue >= (endPDT || 0)) {
        return null;
      }

      maxFragLookUpTolerance = maxFragLookUpTolerance || 0;

      for (var seg = 0; seg < fragments.length; ++seg) {
        var frag = fragments[seg];

        if (pdtWithinToleranceTest(PDTValue, maxFragLookUpTolerance, frag)) {
          return frag;
        }
      }

      return null;
    }
    /**
     * Finds a fragment based on the SN of the previous fragment; or based on the needs of the current buffer.
     * This method compensates for small buffer gaps by applying a tolerance to the start of any candidate fragment, thus
     * breaking any traps which would cause the same fragment to be continuously selected within a small range.
     * @param {*} fragPrevious - The last frag successfully appended
     * @param {Array} fragments - The array of candidate fragments
     * @param {number} [bufferEnd = 0] - The end of the contiguous buffered range the playhead is currently within
     * @param {number} maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous
     * @returns {*} foundFrag - The best matching fragment
     */

    function findFragmentByPTS(fragPrevious, fragments, bufferEnd, maxFragLookUpTolerance) {
      if (bufferEnd === void 0) {
        bufferEnd = 0;
      }

      if (maxFragLookUpTolerance === void 0) {
        maxFragLookUpTolerance = 0;
      }

      var fragNext = null;

      if (fragPrevious) {
        fragNext = fragments[fragPrevious.sn - fragments[0].sn + 1] || null;
      } else if (bufferEnd === 0 && fragments[0].start === 0) {
        fragNext = fragments[0];
      } // Prefer the next fragment if it's within tolerance


      if (fragNext && fragmentWithinToleranceTest(bufferEnd, maxFragLookUpTolerance, fragNext) === 0) {
        return fragNext;
      } // We might be seeking past the tolerance so find the best match


      var foundFragment = _utils_binary_search__WEBPACK_IMPORTED_MODULE_1__["default"].search(fragments, fragmentWithinToleranceTest.bind(null, bufferEnd, maxFragLookUpTolerance));

      if (foundFragment) {
        return foundFragment;
      } // If no match was found return the next fragment after fragPrevious, or null


      return fragNext;
    }
    /**
     * The test function used by the findFragmentBySn's BinarySearch to look for the best match to the current buffer conditions.
     * @param {*} candidate - The fragment to test
     * @param {number} [bufferEnd = 0] - The end of the current buffered range the playhead is currently within
     * @param {number} [maxFragLookUpTolerance = 0] - The amount of time that a fragment's start can be within in order to be considered contiguous
     * @returns {number} - 0 if it matches, 1 if too low, -1 if too high
     */

    function fragmentWithinToleranceTest(bufferEnd, maxFragLookUpTolerance, candidate) {
      if (bufferEnd === void 0) {
        bufferEnd = 0;
      }

      if (maxFragLookUpTolerance === void 0) {
        maxFragLookUpTolerance = 0;
      }

      // offset should be within fragment boundary - config.maxFragLookUpTolerance
      // this is to cope with situations like
      // bufferEnd = 9.991
      // frag[Ø] : [0,10]
      // frag[1] : [10,20]
      // bufferEnd is within frag[0] range ... although what we are expecting is to return frag[1] here
      //              frag start               frag start+duration
      //                  |-----------------------------|
      //              <--->                         <--->
      //  ...--------><-----------------------------><---------....
      // previous frag         matching fragment         next frag
      //  return -1             return 0                 return 1
      // logger.log(`level/sn/start/end/bufEnd:${level}/${candidate.sn}/${candidate.start}/${(candidate.start+candidate.duration)}/${bufferEnd}`);
      // Set the lookup tolerance to be small enough to detect the current segment - ensures we don't skip over very small segments
      var candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0));

      if (candidate.start + candidate.duration - candidateLookupTolerance <= bufferEnd) {
        return 1;
      } else if (candidate.start - candidateLookupTolerance > bufferEnd && candidate.start) {
        // if maxFragLookUpTolerance will have negative value then don't return -1 for first element
        return -1;
      }

      return 0;
    }
    /**
     * The test function used by the findFragmentByPdt's BinarySearch to look for the best match to the current buffer conditions.
     * This function tests the candidate's program date time values, as represented in Unix time
     * @param {*} candidate - The fragment to test
     * @param {number} [pdtBufferEnd = 0] - The Unix time representing the end of the current buffered range
     * @param {number} [maxFragLookUpTolerance = 0] - The amount of time that a fragment's start can be within in order to be considered contiguous
     * @returns {boolean} True if contiguous, false otherwise
     */

    function pdtWithinToleranceTest(pdtBufferEnd, maxFragLookUpTolerance, candidate) {
      var candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0)) * 1000; // endProgramDateTime can be null, default to zero

      var endProgramDateTime = candidate.endProgramDateTime || 0;
      return endProgramDateTime - candidateLookupTolerance > pdtBufferEnd;
    }
    function findFragWithCC(fragments, cc) {
      return _utils_binary_search__WEBPACK_IMPORTED_MODULE_1__["default"].search(fragments, function (candidate) {
        if (candidate.cc < cc) {
          return 1;
        } else if (candidate.cc > cc) {
          return -1;
        } else {
          return 0;
        }
      });
    }

    /***/ }),

    /***/ "./src/controller/fragment-tracker.ts":
    /*!********************************************!*\
      !*** ./src/controller/fragment-tracker.ts ***!
      \********************************************/
    /*! exports provided: FragmentState, FragmentTracker */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "FragmentState", function() { return FragmentState; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "FragmentTracker", function() { return FragmentTracker; });
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");


    var FragmentState;

    (function (FragmentState) {
      FragmentState["NOT_LOADED"] = "NOT_LOADED";
      FragmentState["BACKTRACKED"] = "BACKTRACKED";
      FragmentState["APPENDING"] = "APPENDING";
      FragmentState["PARTIAL"] = "PARTIAL";
      FragmentState["OK"] = "OK";
    })(FragmentState || (FragmentState = {}));

    var FragmentTracker = /*#__PURE__*/function () {
      function FragmentTracker(hls) {
        this.activeFragment = null;
        this.activeParts = null;
        this.fragments = Object.create(null);
        this.timeRanges = Object.create(null);
        this.bufferPadding = 0.2;
        this.hls = void 0;
        this.hls = hls;

        this._registerListeners();
      }

      var _proto = FragmentTracker.prototype;

      _proto._registerListeners = function _registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].BUFFER_APPENDED, this.onBufferAppended, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].FRAG_BUFFERED, this.onFragBuffered, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].FRAG_LOADED, this.onFragLoaded, this);
      };

      _proto._unregisterListeners = function _unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].BUFFER_APPENDED, this.onBufferAppended, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].FRAG_BUFFERED, this.onFragBuffered, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].FRAG_LOADED, this.onFragLoaded, this);
      };

      _proto.destroy = function destroy() {
        this._unregisterListeners(); // @ts-ignore


        this.fragments = this.timeRanges = null;
      }
      /**
       * Return a Fragment with an appended range that matches the position and levelType.
       * If not found any Fragment, return null
       */
      ;

      _proto.getAppendedFrag = function getAppendedFrag(position, levelType) {
        if (levelType === _types_loader__WEBPACK_IMPORTED_MODULE_1__["PlaylistLevelType"].MAIN) {
          var activeFragment = this.activeFragment,
              activeParts = this.activeParts;

          if (!activeFragment) {
            return null;
          }

          if (activeParts) {
            for (var i = activeParts.length; i--;) {
              var activePart = activeParts[i];
              var appendedPTS = activePart ? activePart.end : activeFragment.appendedPTS;

              if (activePart.start <= position && appendedPTS !== undefined && position <= appendedPTS) {
                // 9 is a magic number. remove parts from lookup after a match but keep some short seeks back.
                if (i > 9) {
                  this.activeParts = activeParts.slice(i - 9);
                }

                return activePart;
              }
            }
          } else if (activeFragment.start <= position && activeFragment.appendedPTS !== undefined && position <= activeFragment.appendedPTS) {
            return activeFragment;
          }
        }

        return this.getBufferedFrag(position, levelType);
      }
      /**
       * Return a buffered Fragment that matches the position and levelType.
       * A buffered Fragment is one whose loading, parsing and appending is done (completed or "partial" meaning aborted).
       * If not found any Fragment, return null
       */
      ;

      _proto.getBufferedFrag = function getBufferedFrag(position, levelType) {
        var fragments = this.fragments;
        var keys = Object.keys(fragments);

        for (var i = keys.length; i--;) {
          var fragmentEntity = fragments[keys[i]];

          if ((fragmentEntity === null || fragmentEntity === void 0 ? void 0 : fragmentEntity.body.type) === levelType && fragmentEntity.buffered) {
            var frag = fragmentEntity.body;

            if (frag.start <= position && position <= frag.end) {
              return frag;
            }
          }
        }

        return null;
      }
      /**
       * Partial fragments effected by coded frame eviction will be removed
       * The browser will unload parts of the buffer to free up memory for new buffer data
       * Fragments will need to be reloaded when the buffer is freed up, removing partial fragments will allow them to reload(since there might be parts that are still playable)
       */
      ;

      _proto.detectEvictedFragments = function detectEvictedFragments(elementaryStream, timeRange, playlistType) {
        var _this = this;

        // Check if any flagged fragments have been unloaded
        Object.keys(this.fragments).forEach(function (key) {
          var fragmentEntity = _this.fragments[key];

          if (!fragmentEntity) {
            return;
          }

          if (!fragmentEntity.buffered) {
            if (fragmentEntity.body.type === playlistType) {
              _this.removeFragment(fragmentEntity.body);
            }

            return;
          }

          var esData = fragmentEntity.range[elementaryStream];

          if (!esData) {
            return;
          }

          esData.time.some(function (time) {
            var isNotBuffered = !_this.isTimeBuffered(time.startPTS, time.endPTS, timeRange);

            if (isNotBuffered) {
              // Unregister partial fragment as it needs to load again to be reused
              _this.removeFragment(fragmentEntity.body);
            }

            return isNotBuffered;
          });
        });
      }
      /**
       * Checks if the fragment passed in is loaded in the buffer properly
       * Partially loaded fragments will be registered as a partial fragment
       */
      ;

      _proto.detectPartialFragments = function detectPartialFragments(data) {
        var _this2 = this;

        var timeRanges = this.timeRanges;
        var frag = data.frag,
            part = data.part;

        if (!timeRanges || frag.sn === 'initSegment') {
          return;
        }

        var fragKey = getFragmentKey(frag);
        var fragmentEntity = this.fragments[fragKey];

        if (!fragmentEntity) {
          return;
        }

        Object.keys(timeRanges).forEach(function (elementaryStream) {
          var streamInfo = frag.elementaryStreams[elementaryStream];

          if (!streamInfo) {
            return;
          }

          var timeRange = timeRanges[elementaryStream];
          var partial = part !== null || streamInfo.partial === true;
          fragmentEntity.range[elementaryStream] = _this2.getBufferedTimes(frag, part, partial, timeRange);
        });
        fragmentEntity.backtrack = fragmentEntity.loaded = null;

        if (Object.keys(fragmentEntity.range).length) {
          fragmentEntity.buffered = true;
        } else {
          // remove fragment if nothing was appended
          this.removeFragment(fragmentEntity.body);
        }
      };

      _proto.fragBuffered = function fragBuffered(frag) {
        var fragKey = getFragmentKey(frag);
        var fragmentEntity = this.fragments[fragKey];

        if (fragmentEntity) {
          fragmentEntity.backtrack = fragmentEntity.loaded = null;
          fragmentEntity.buffered = true;
        }
      };

      _proto.getBufferedTimes = function getBufferedTimes(fragment, part, partial, timeRange) {
        var buffered = {
          time: [],
          partial: partial
        };
        var startPTS = part ? part.start : fragment.start;
        var endPTS = part ? part.end : fragment.end;
        var minEndPTS = fragment.minEndPTS || endPTS;
        var maxStartPTS = fragment.maxStartPTS || startPTS;

        for (var i = 0; i < timeRange.length; i++) {
          var startTime = timeRange.start(i) - this.bufferPadding;
          var endTime = timeRange.end(i) + this.bufferPadding;

          if (maxStartPTS >= startTime && minEndPTS <= endTime) {
            // Fragment is entirely contained in buffer
            // No need to check the other timeRange times since it's completely playable
            buffered.time.push({
              startPTS: Math.max(startPTS, timeRange.start(i)),
              endPTS: Math.min(endPTS, timeRange.end(i))
            });
            break;
          } else if (startPTS < endTime && endPTS > startTime) {
            buffered.partial = true; // Check for intersection with buffer
            // Get playable sections of the fragment

            buffered.time.push({
              startPTS: Math.max(startPTS, timeRange.start(i)),
              endPTS: Math.min(endPTS, timeRange.end(i))
            });
          } else if (endPTS <= startTime) {
            // No need to check the rest of the timeRange as it is in order
            break;
          }
        }

        return buffered;
      }
      /**
       * Gets the partial fragment for a certain time
       */
      ;

      _proto.getPartialFragment = function getPartialFragment(time) {
        var bestFragment = null;
        var timePadding;
        var startTime;
        var endTime;
        var bestOverlap = 0;
        var bufferPadding = this.bufferPadding,
            fragments = this.fragments;
        Object.keys(fragments).forEach(function (key) {
          var fragmentEntity = fragments[key];

          if (!fragmentEntity) {
            return;
          }

          if (isPartial(fragmentEntity)) {
            startTime = fragmentEntity.body.start - bufferPadding;
            endTime = fragmentEntity.body.end + bufferPadding;

            if (time >= startTime && time <= endTime) {
              // Use the fragment that has the most padding from start and end time
              timePadding = Math.min(time - startTime, endTime - time);

              if (bestOverlap <= timePadding) {
                bestFragment = fragmentEntity.body;
                bestOverlap = timePadding;
              }
            }
          }
        });
        return bestFragment;
      };

      _proto.getState = function getState(fragment) {
        var fragKey = getFragmentKey(fragment);
        var fragmentEntity = this.fragments[fragKey];

        if (fragmentEntity) {
          if (!fragmentEntity.buffered) {
            if (fragmentEntity.backtrack) {
              return FragmentState.BACKTRACKED;
            }

            return FragmentState.APPENDING;
          } else if (isPartial(fragmentEntity)) {
            return FragmentState.PARTIAL;
          } else {
            return FragmentState.OK;
          }
        }

        return FragmentState.NOT_LOADED;
      };

      _proto.backtrack = function backtrack(frag, data) {
        var fragKey = getFragmentKey(frag);
        var fragmentEntity = this.fragments[fragKey];

        if (!fragmentEntity || fragmentEntity.backtrack) {
          return null;
        }

        var backtrack = fragmentEntity.backtrack = data ? data : fragmentEntity.loaded;
        fragmentEntity.loaded = null;
        return backtrack;
      };

      _proto.getBacktrackData = function getBacktrackData(fragment) {
        var fragKey = getFragmentKey(fragment);
        var fragmentEntity = this.fragments[fragKey];

        if (fragmentEntity) {
          var _backtrack$payload;

          var backtrack = fragmentEntity.backtrack; // If data was already sent to Worker it is detached no longer available

          if (backtrack !== null && backtrack !== void 0 && (_backtrack$payload = backtrack.payload) !== null && _backtrack$payload !== void 0 && _backtrack$payload.byteLength) {
            return backtrack;
          } else {
            this.removeFragment(fragment);
          }
        }

        return null;
      };

      _proto.isTimeBuffered = function isTimeBuffered(startPTS, endPTS, timeRange) {
        var startTime;
        var endTime;

        for (var i = 0; i < timeRange.length; i++) {
          startTime = timeRange.start(i) - this.bufferPadding;
          endTime = timeRange.end(i) + this.bufferPadding;

          if (startPTS >= startTime && endPTS <= endTime) {
            return true;
          }

          if (endPTS <= startTime) {
            // No need to check the rest of the timeRange as it is in order
            return false;
          }
        }

        return false;
      };

      _proto.onFragLoaded = function onFragLoaded(event, data) {
        var frag = data.frag,
            part = data.part; // don't track initsegment (for which sn is not a number)
        // don't track frags used for bitrateTest, they're irrelevant.
        // don't track parts for memory efficiency

        if (frag.sn === 'initSegment' || frag.bitrateTest || part) {
          return;
        }

        var fragKey = getFragmentKey(frag);
        this.fragments[fragKey] = {
          body: frag,
          loaded: data,
          backtrack: null,
          buffered: false,
          range: Object.create(null)
        };
      };

      _proto.onBufferAppended = function onBufferAppended(event, data) {
        var _this3 = this;

        var frag = data.frag,
            part = data.part,
            timeRanges = data.timeRanges;

        if (frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_1__["PlaylistLevelType"].MAIN) {
          this.activeFragment = frag;

          if (part) {
            var activeParts = this.activeParts;

            if (!activeParts) {
              this.activeParts = activeParts = [];
            }

            activeParts.push(part);
          } else {
            this.activeParts = null;
          }
        } // Store the latest timeRanges loaded in the buffer


        this.timeRanges = timeRanges;
        Object.keys(timeRanges).forEach(function (elementaryStream) {
          var timeRange = timeRanges[elementaryStream];

          _this3.detectEvictedFragments(elementaryStream, timeRange);

          if (!part) {
            for (var i = 0; i < timeRange.length; i++) {
              frag.appendedPTS = Math.max(timeRange.end(i), frag.appendedPTS || 0);
            }
          }
        });
      };

      _proto.onFragBuffered = function onFragBuffered(event, data) {
        this.detectPartialFragments(data);
      };

      _proto.hasFragment = function hasFragment(fragment) {
        var fragKey = getFragmentKey(fragment);
        return !!this.fragments[fragKey];
      };

      _proto.removeFragmentsInRange = function removeFragmentsInRange(start, end, playlistType) {
        var _this4 = this;

        Object.keys(this.fragments).forEach(function (key) {
          var fragmentEntity = _this4.fragments[key];

          if (!fragmentEntity) {
            return;
          }

          if (fragmentEntity.buffered) {
            var frag = fragmentEntity.body;

            if (frag.type === playlistType && frag.start < end && frag.end > start) {
              _this4.removeFragment(frag);
            }
          }
        });
      };

      _proto.removeFragment = function removeFragment(fragment) {
        var fragKey = getFragmentKey(fragment);
        fragment.stats.loaded = 0;
        fragment.clearElementaryStreamInfo();
        delete this.fragments[fragKey];
      };

      _proto.removeAllFragments = function removeAllFragments() {
        this.fragments = Object.create(null);
        this.activeFragment = null;
        this.activeParts = null;
      };

      return FragmentTracker;
    }();

    function isPartial(fragmentEntity) {
      var _fragmentEntity$range, _fragmentEntity$range2;

      return fragmentEntity.buffered && (((_fragmentEntity$range = fragmentEntity.range.video) === null || _fragmentEntity$range === void 0 ? void 0 : _fragmentEntity$range.partial) || ((_fragmentEntity$range2 = fragmentEntity.range.audio) === null || _fragmentEntity$range2 === void 0 ? void 0 : _fragmentEntity$range2.partial));
    }

    function getFragmentKey(fragment) {
      return fragment.type + "_" + fragment.level + "_" + fragment.urlId + "_" + fragment.sn;
    }

    /***/ }),

    /***/ "./src/controller/gap-controller.ts":
    /*!******************************************!*\
      !*** ./src/controller/gap-controller.ts ***!
      \******************************************/
    /*! exports provided: STALL_MINIMUM_DURATION_MS, MAX_START_GAP_JUMP, SKIP_BUFFER_HOLE_STEP_SECONDS, SKIP_BUFFER_RANGE_START, default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "STALL_MINIMUM_DURATION_MS", function() { return STALL_MINIMUM_DURATION_MS; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "MAX_START_GAP_JUMP", function() { return MAX_START_GAP_JUMP; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SKIP_BUFFER_HOLE_STEP_SECONDS", function() { return SKIP_BUFFER_HOLE_STEP_SECONDS; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SKIP_BUFFER_RANGE_START", function() { return SKIP_BUFFER_RANGE_START; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return GapController; });
    /* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");




    var STALL_MINIMUM_DURATION_MS = 250;
    var MAX_START_GAP_JUMP = 2.0;
    var SKIP_BUFFER_HOLE_STEP_SECONDS = 0.1;
    var SKIP_BUFFER_RANGE_START = 0.05;

    var GapController = /*#__PURE__*/function () {
      function GapController(config, media, fragmentTracker, hls) {
        this.config = void 0;
        this.media = void 0;
        this.fragmentTracker = void 0;
        this.hls = void 0;
        this.nudgeRetry = 0;
        this.stallReported = false;
        this.stalled = null;
        this.moved = false;
        this.seeking = false;
        this.config = config;
        this.media = media;
        this.fragmentTracker = fragmentTracker;
        this.hls = hls;
      }

      var _proto = GapController.prototype;

      _proto.destroy = function destroy() {
        // @ts-ignore
        this.hls = this.fragmentTracker = this.media = null;
      }
      /**
       * Checks if the playhead is stuck within a gap, and if so, attempts to free it.
       * A gap is an unbuffered range between two buffered ranges (or the start and the first buffered range).
       *
       * @param {number} lastCurrentTime Previously read playhead position
       */
      ;

      _proto.poll = function poll(lastCurrentTime) {
        var config = this.config,
            media = this.media,
            stalled = this.stalled;
        var currentTime = media.currentTime,
            seeking = media.seeking;
        var seeked = this.seeking && !seeking;
        var beginSeek = !this.seeking && seeking;
        this.seeking = seeking; // The playhead is moving, no-op

        if (currentTime !== lastCurrentTime) {
          this.moved = true;

          if (stalled !== null) {
            // The playhead is now moving, but was previously stalled
            if (this.stallReported) {
              var _stalledDuration = self.performance.now() - stalled;

              _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn("playback not stuck anymore @" + currentTime + ", after " + Math.round(_stalledDuration) + "ms");
              this.stallReported = false;
            }

            this.stalled = null;
            this.nudgeRetry = 0;
          }

          return;
        } // Clear stalled state when beginning or finishing seeking so that we don't report stalls coming out of a seek


        if (beginSeek || seeked) {
          this.stalled = null;
        } // The playhead should not be moving


        if (media.paused || media.ended || media.playbackRate === 0 || !_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_0__["BufferHelper"].getBuffered(media).length) {
          return;
        }

        var bufferInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_0__["BufferHelper"].bufferInfo(media, currentTime, 0);
        var isBuffered = bufferInfo.len > 0;
        var nextStart = bufferInfo.nextStart || 0; // There is no playable buffer (seeked, waiting for buffer)

        if (!isBuffered && !nextStart) {
          return;
        }

        if (seeking) {
          // Waiting for seeking in a buffered range to complete
          var hasEnoughBuffer = bufferInfo.len > MAX_START_GAP_JUMP; // Next buffered range is too far ahead to jump to while still seeking

          var noBufferGap = !nextStart || nextStart - currentTime > MAX_START_GAP_JUMP && !this.fragmentTracker.getPartialFragment(currentTime);

          if (hasEnoughBuffer || noBufferGap) {
            return;
          } // Reset moved state when seeking to a point in or before a gap


          this.moved = false;
        } // Skip start gaps if we haven't played, but the last poll detected the start of a stall
        // The addition poll gives the browser a chance to jump the gap for us


        if (!this.moved && this.stalled !== null) {
          var _level$details;

          // Jump start gaps within jump threshold
          var startJump = Math.max(nextStart, bufferInfo.start || 0) - currentTime; // When joining a live stream with audio tracks, account for live playlist window sliding by allowing
          // a larger jump over start gaps caused by the audio-stream-controller buffering a start fragment
          // that begins over 1 target duration after the video start position.

          var level = this.hls.levels ? this.hls.levels[this.hls.currentLevel] : null;
          var isLive = level === null || level === void 0 ? void 0 : (_level$details = level.details) === null || _level$details === void 0 ? void 0 : _level$details.live;
          var maxStartGapJump = isLive ? level.details.targetduration * 2 : MAX_START_GAP_JUMP;

          if (startJump > 0 && startJump <= maxStartGapJump) {
            this._trySkipBufferHole(null);

            return;
          }
        } // Start tracking stall time


        var tnow = self.performance.now();

        if (stalled === null) {
          this.stalled = tnow;
          return;
        }

        var stalledDuration = tnow - stalled;

        if (!seeking && stalledDuration >= STALL_MINIMUM_DURATION_MS) {
          // Report stalling after trying to fix
          this._reportStall(bufferInfo.len);
        }

        var bufferedWithHoles = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_0__["BufferHelper"].bufferInfo(media, currentTime, config.maxBufferHole);

        this._tryFixBufferStall(bufferedWithHoles, stalledDuration);
      }
      /**
       * Detects and attempts to fix known buffer stalling issues.
       * @param bufferInfo - The properties of the current buffer.
       * @param stalledDurationMs - The amount of time Hls.js has been stalling for.
       * @private
       */
      ;

      _proto._tryFixBufferStall = function _tryFixBufferStall(bufferInfo, stalledDurationMs) {
        var config = this.config,
            fragmentTracker = this.fragmentTracker,
            media = this.media;
        var currentTime = media.currentTime;
        var partial = fragmentTracker.getPartialFragment(currentTime);

        if (partial) {
          // Try to skip over the buffer hole caused by a partial fragment
          // This method isn't limited by the size of the gap between buffered ranges
          var targetTime = this._trySkipBufferHole(partial); // we return here in this case, meaning
          // the branch below only executes when we don't handle a partial fragment


          if (targetTime) {
            return;
          }
        } // if we haven't had to skip over a buffer hole of a partial fragment
        // we may just have to "nudge" the playlist as the browser decoding/rendering engine
        // needs to cross some sort of threshold covering all source-buffers content
        // to start playing properly.


        if (bufferInfo.len > config.maxBufferHole && stalledDurationMs > config.highBufferWatchdogPeriod * 1000) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn('Trying to nudge playhead over buffer-hole'); // Try to nudge currentTime over a buffer hole if we've been stalling for the configured amount of seconds
          // We only try to jump the hole if it's under the configured size
          // Reset stalled so to rearm watchdog timer

          this.stalled = null;

          this._tryNudgeBuffer();
        }
      }
      /**
       * Triggers a BUFFER_STALLED_ERROR event, but only once per stall period.
       * @param bufferLen - The playhead distance from the end of the current buffer segment.
       * @private
       */
      ;

      _proto._reportStall = function _reportStall(bufferLen) {
        var hls = this.hls,
            media = this.media,
            stallReported = this.stallReported;

        if (!stallReported) {
          // Report stalled error once
          this.stallReported = true;
          _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn("Playback stalling at @" + media.currentTime + " due to low buffer (buffer=" + bufferLen + ")");
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].MEDIA_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].BUFFER_STALLED_ERROR,
            fatal: false,
            buffer: bufferLen
          });
        }
      }
      /**
       * Attempts to fix buffer stalls by jumping over known gaps caused by partial fragments
       * @param partial - The partial fragment found at the current time (where playback is stalling).
       * @private
       */
      ;

      _proto._trySkipBufferHole = function _trySkipBufferHole(partial) {
        var config = this.config,
            hls = this.hls,
            media = this.media;
        var currentTime = media.currentTime;
        var lastEndTime = 0; // Check if currentTime is between unbuffered regions of partial fragments

        var buffered = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_0__["BufferHelper"].getBuffered(media);

        for (var i = 0; i < buffered.length; i++) {
          var startTime = buffered.start(i);

          if (currentTime + config.maxBufferHole >= lastEndTime && currentTime < startTime) {
            var targetTime = Math.max(startTime + SKIP_BUFFER_RANGE_START, media.currentTime + SKIP_BUFFER_HOLE_STEP_SECONDS);
            _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn("skipping hole, adjusting currentTime from " + currentTime + " to " + targetTime);
            this.moved = true;
            this.stalled = null;
            media.currentTime = targetTime;

            if (partial) {
              hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].ERROR, {
                type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].MEDIA_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].BUFFER_SEEK_OVER_HOLE,
                fatal: false,
                reason: "fragment loaded with buffer holes, seeking from " + currentTime + " to " + targetTime,
                frag: partial
              });
            }

            return targetTime;
          }

          lastEndTime = buffered.end(i);
        }

        return 0;
      }
      /**
       * Attempts to fix buffer stalls by advancing the mediaElement's current time by a small amount.
       * @private
       */
      ;

      _proto._tryNudgeBuffer = function _tryNudgeBuffer() {
        var config = this.config,
            hls = this.hls,
            media = this.media;
        var currentTime = media.currentTime;
        var nudgeRetry = (this.nudgeRetry || 0) + 1;
        this.nudgeRetry = nudgeRetry;

        if (nudgeRetry < config.nudgeMaxRetry) {
          var targetTime = currentTime + nudgeRetry * config.nudgeOffset; // playback stalled in buffered area ... let's nudge currentTime to try to overcome this

          _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn("Nudging 'currentTime' from " + currentTime + " to " + targetTime);
          media.currentTime = targetTime;
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].MEDIA_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].BUFFER_NUDGE_ON_STALL,
            fatal: false
          });
        } else {
          _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].error("Playhead still not moving while enough data buffered @" + currentTime + " after " + config.nudgeMaxRetry + " nudges");
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].MEDIA_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].BUFFER_STALLED_ERROR,
            fatal: true
          });
        }
      };

      return GapController;
    }();



    /***/ }),

    /***/ "./src/controller/id3-track-controller.ts":
    /*!************************************************!*\
      !*** ./src/controller/id3-track-controller.ts ***!
      \************************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/texttrack-utils */ "./src/utils/texttrack-utils.ts");
    /* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");



    var MIN_CUE_DURATION = 0.25;

    var ID3TrackController = /*#__PURE__*/function () {
      function ID3TrackController(hls) {
        this.hls = void 0;
        this.id3Track = null;
        this.media = null;
        this.hls = hls;

        this._registerListeners();
      }

      var _proto = ID3TrackController.prototype;

      _proto.destroy = function destroy() {
        this._unregisterListeners();
      };

      _proto._registerListeners = function _registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].BUFFER_FLUSHING, this.onBufferFlushing, this);
      };

      _proto._unregisterListeners = function _unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].BUFFER_FLUSHING, this.onBufferFlushing, this);
      } // Add ID3 metatadata text track.
      ;

      _proto.onMediaAttached = function onMediaAttached(event, data) {
        this.media = data.media;
      };

      _proto.onMediaDetaching = function onMediaDetaching() {
        if (!this.id3Track) {
          return;
        }

        Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__["clearCurrentCues"])(this.id3Track);
        this.id3Track = null;
        this.media = null;
      };

      _proto.getID3Track = function getID3Track(textTracks) {
        if (!this.media) {
          return;
        }

        for (var i = 0; i < textTracks.length; i++) {
          var textTrack = textTracks[i];

          if (textTrack.kind === 'metadata' && textTrack.label === 'id3') {
            // send 'addtrack' when reusing the textTrack for metadata,
            // same as what we do for captions
            Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__["sendAddTrackEvent"])(textTrack, this.media);
            return textTrack;
          }
        }

        return this.media.addTextTrack('metadata', 'id3');
      };

      _proto.onFragParsingMetadata = function onFragParsingMetadata(event, data) {
        if (!this.media) {
          return;
        }

        var fragment = data.frag;
        var samples = data.samples; // create track dynamically

        if (!this.id3Track) {
          this.id3Track = this.getID3Track(this.media.textTracks);
          this.id3Track.mode = 'hidden';
        } // Attempt to recreate Safari functionality by creating
        // WebKitDataCue objects when available and store the decoded
        // ID3 data in the value property of the cue


        var Cue = self.WebKitDataCue || self.VTTCue || self.TextTrackCue;

        for (var i = 0; i < samples.length; i++) {
          var frames = _demux_id3__WEBPACK_IMPORTED_MODULE_2__["getID3Frames"](samples[i].data);

          if (frames) {
            var startTime = samples[i].pts;
            var endTime = i < samples.length - 1 ? samples[i + 1].pts : fragment.end;
            var timeDiff = endTime - startTime;

            if (timeDiff <= 0) {
              endTime = startTime + MIN_CUE_DURATION;
            }

            for (var j = 0; j < frames.length; j++) {
              var frame = frames[j]; // Safari doesn't put the timestamp frame in the TextTrack

              if (!_demux_id3__WEBPACK_IMPORTED_MODULE_2__["isTimeStampFrame"](frame)) {
                var cue = new Cue(startTime, endTime, '');
                cue.value = frame;
                this.id3Track.addCue(cue);
              }
            }
          }
        }
      };

      _proto.onBufferFlushing = function onBufferFlushing(event, _ref) {
        var startOffset = _ref.startOffset,
            endOffset = _ref.endOffset,
            type = _ref.type;

        if (!type || type === 'audio') {
          // id3 cues come from parsed audio only remove cues when audio buffer is cleared
          var id3Track = this.id3Track;

          if (id3Track) {
            Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__["removeCuesInRange"])(id3Track, startOffset, endOffset);
          }
        }
      };

      return ID3TrackController;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (ID3TrackController);

    /***/ }),

    /***/ "./src/controller/latency-controller.ts":
    /*!**********************************************!*\
      !*** ./src/controller/latency-controller.ts ***!
      \**********************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return LatencyController; });
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }





    var LatencyController = /*#__PURE__*/function () {
      function LatencyController(hls) {
        var _this = this;

        this.hls = void 0;
        this.config = void 0;
        this.media = null;
        this.levelDetails = null;
        this.currentTime = 0;
        this.stallCount = 0;
        this._latency = null;

        this.timeupdateHandler = function () {
          return _this.timeupdate();
        };

        this.hls = hls;
        this.config = hls.config;
        this.registerListeners();
      }

      var _proto = LatencyController.prototype;

      _proto.destroy = function destroy() {
        this.unregisterListeners();
        this.onMediaDetaching();
        this.levelDetails = null; // @ts-ignore

        this.hls = this.timeupdateHandler = null;
      };

      _proto.registerListeners = function registerListeners() {
        this.hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        this.hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        this.hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        this.hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVEL_UPDATED, this.onLevelUpdated, this);
        this.hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, this.onError, this);
      };

      _proto.unregisterListeners = function unregisterListeners() {
        this.hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_ATTACHED, this.onMediaAttached);
        this.hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_DETACHING, this.onMediaDetaching);
        this.hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADING, this.onManifestLoading);
        this.hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVEL_UPDATED, this.onLevelUpdated);
        this.hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, this.onError);
      };

      _proto.onMediaAttached = function onMediaAttached(event, data) {
        this.media = data.media;
        this.media.addEventListener('timeupdate', this.timeupdateHandler);
      };

      _proto.onMediaDetaching = function onMediaDetaching() {
        if (this.media) {
          this.media.removeEventListener('timeupdate', this.timeupdateHandler);
          this.media = null;
        }
      };

      _proto.onManifestLoading = function onManifestLoading() {
        this.levelDetails = null;
        this._latency = null;
        this.stallCount = 0;
      };

      _proto.onLevelUpdated = function onLevelUpdated(event, _ref) {
        var details = _ref.details;
        this.levelDetails = details;

        if (details.advanced) {
          this.timeupdate();
        }

        if (!details.live && this.media) {
          this.media.removeEventListener('timeupdate', this.timeupdateHandler);
        }
      };

      _proto.onError = function onError(event, data) {
        if (data.details !== _errors__WEBPACK_IMPORTED_MODULE_0__["ErrorDetails"].BUFFER_STALLED_ERROR) {
          return;
        }

        this.stallCount++;
        _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn('[playback-rate-controller]: Stall detected, adjusting target latency');
      };

      _proto.timeupdate = function timeupdate() {
        var media = this.media,
            levelDetails = this.levelDetails;

        if (!media || !levelDetails) {
          return;
        }

        this.currentTime = media.currentTime;
        var latency = this.computeLatency();

        if (latency === null) {
          return;
        }

        this._latency = latency; // Adapt playbackRate to meet target latency in low-latency mode

        var _this$config = this.config,
            lowLatencyMode = _this$config.lowLatencyMode,
            maxLiveSyncPlaybackRate = _this$config.maxLiveSyncPlaybackRate;

        if (!lowLatencyMode || maxLiveSyncPlaybackRate === 1) {
          return;
        }

        var targetLatency = this.targetLatency;

        if (targetLatency === null) {
          return;
        }

        var distanceFromTarget = latency - targetLatency; // Only adjust playbackRate when within one target duration of targetLatency
        // and more than one second from under-buffering.
        // Playback further than one target duration from target can be considered DVR playback.

        var liveMinLatencyDuration = Math.min(this.maxLatency, targetLatency + levelDetails.targetduration);
        var inLiveRange = distanceFromTarget < liveMinLatencyDuration;

        if (levelDetails.live && inLiveRange && distanceFromTarget > 0.05 && this.forwardBufferLength > 1) {
          var max = Math.min(2, Math.max(1.0, maxLiveSyncPlaybackRate));
          var rate = Math.round(2 / (1 + Math.exp(-0.75 * distanceFromTarget - this.edgeStalled)) * 20) / 20;
          media.playbackRate = Math.min(max, Math.max(1, rate));
        } else if (media.playbackRate !== 1 && media.playbackRate !== 0) {
          media.playbackRate = 1;
        }
      };

      _proto.estimateLiveEdge = function estimateLiveEdge() {
        var levelDetails = this.levelDetails;

        if (levelDetails === null) {
          return null;
        }

        return levelDetails.edge + levelDetails.age;
      };

      _proto.computeLatency = function computeLatency() {
        var liveEdge = this.estimateLiveEdge();

        if (liveEdge === null) {
          return null;
        }

        return liveEdge - this.currentTime;
      };

      _createClass(LatencyController, [{
        key: "latency",
        get: function get() {
          return this._latency || 0;
        }
      }, {
        key: "maxLatency",
        get: function get() {
          var config = this.config,
              levelDetails = this.levelDetails;

          if (config.liveMaxLatencyDuration !== undefined) {
            return config.liveMaxLatencyDuration;
          }

          return levelDetails ? config.liveMaxLatencyDurationCount * levelDetails.targetduration : 0;
        }
      }, {
        key: "targetLatency",
        get: function get() {
          var levelDetails = this.levelDetails;

          if (levelDetails === null) {
            return null;
          }

          var holdBack = levelDetails.holdBack,
              partHoldBack = levelDetails.partHoldBack,
              targetduration = levelDetails.targetduration;
          var _this$config2 = this.config,
              liveSyncDuration = _this$config2.liveSyncDuration,
              liveSyncDurationCount = _this$config2.liveSyncDurationCount,
              lowLatencyMode = _this$config2.lowLatencyMode;
          var userConfig = this.hls.userConfig;
          var targetLatency = lowLatencyMode ? partHoldBack || holdBack : holdBack;

          if (userConfig.liveSyncDuration || userConfig.liveSyncDurationCount || targetLatency === 0) {
            targetLatency = liveSyncDuration !== undefined ? liveSyncDuration : liveSyncDurationCount * targetduration;
          }

          var maxLiveSyncOnStallIncrease = targetduration;
          var liveSyncOnStallIncrease = 1.0;
          return targetLatency + Math.min(this.stallCount * liveSyncOnStallIncrease, maxLiveSyncOnStallIncrease);
        }
      }, {
        key: "liveSyncPosition",
        get: function get() {
          var liveEdge = this.estimateLiveEdge();
          var targetLatency = this.targetLatency;
          var levelDetails = this.levelDetails;

          if (liveEdge === null || targetLatency === null || levelDetails === null) {
            return null;
          }

          var edge = levelDetails.edge;
          var syncPosition = liveEdge - targetLatency - this.edgeStalled;
          var min = edge - levelDetails.totalduration;
          var max = edge - (this.config.lowLatencyMode && levelDetails.partTarget || levelDetails.targetduration);
          return Math.min(Math.max(min, syncPosition), max);
        }
      }, {
        key: "drift",
        get: function get() {
          var levelDetails = this.levelDetails;

          if (levelDetails === null) {
            return 1;
          }

          return levelDetails.drift;
        }
      }, {
        key: "edgeStalled",
        get: function get() {
          var levelDetails = this.levelDetails;

          if (levelDetails === null) {
            return 0;
          }

          var maxLevelUpdateAge = (this.config.lowLatencyMode && levelDetails.partTarget || levelDetails.targetduration) * 3;
          return Math.max(levelDetails.age - maxLevelUpdateAge, 0);
        }
      }, {
        key: "forwardBufferLength",
        get: function get() {
          var media = this.media,
              levelDetails = this.levelDetails;

          if (!media || !levelDetails) {
            return 0;
          }

          var bufferedRanges = media.buffered.length;
          return bufferedRanges ? media.buffered.end(bufferedRanges - 1) : levelDetails.edge - this.currentTime;
        }
      }]);

      return LatencyController;
    }();



    /***/ }),

    /***/ "./src/controller/level-controller.ts":
    /*!********************************************!*\
      !*** ./src/controller/level-controller.ts ***!
      \********************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return LevelController; });
    /* harmony import */ var _types_level__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../types/level */ "./src/types/level.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _utils_codecs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/codecs */ "./src/utils/codecs.ts");
    /* harmony import */ var _level_helper__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./level-helper */ "./src/controller/level-helper.ts");
    /* harmony import */ var _base_playlist_controller__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./base-playlist-controller */ "./src/controller/base-playlist-controller.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
    function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }

    /*
     * Level Controller
     */







    var chromeOrFirefox = /chrome|firefox/.test(navigator.userAgent.toLowerCase());

    var LevelController = /*#__PURE__*/function (_BasePlaylistControll) {
      _inheritsLoose(LevelController, _BasePlaylistControll);

      function LevelController(hls) {
        var _this;

        _this = _BasePlaylistControll.call(this, hls, '[level-controller]') || this;
        _this._levels = [];
        _this._firstLevel = -1;
        _this._startLevel = void 0;
        _this.currentLevelIndex = -1;
        _this.manualLevelIndex = -1;
        _this.onParsedComplete = void 0;

        _this._registerListeners();

        return _this;
      }

      var _proto = LevelController.prototype;

      _proto._registerListeners = function _registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADED, this.onManifestLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVEL_LOADED, this.onLevelLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_LOADED, this.onFragLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, this.onError, this);
      };

      _proto._unregisterListeners = function _unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADED, this.onManifestLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVEL_LOADED, this.onLevelLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_LOADED, this.onFragLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, this.onError, this);
      };

      _proto.destroy = function destroy() {
        this._unregisterListeners();

        this.manualLevelIndex = -1;
        this._levels.length = 0;

        _BasePlaylistControll.prototype.destroy.call(this);
      };

      _proto.startLoad = function startLoad() {
        var levels = this._levels; // clean up live level details to force reload them, and reset load errors

        levels.forEach(function (level) {
          level.loadError = 0;
        });

        _BasePlaylistControll.prototype.startLoad.call(this);
      };

      _proto.onManifestLoaded = function onManifestLoaded(event, data) {
        var levels = [];
        var audioTracks = [];
        var subtitleTracks = [];
        var bitrateStart;
        var levelSet = {};
        var levelFromSet;
        var resolutionFound = false;
        var videoCodecFound = false;
        var audioCodecFound = false; // regroup redundant levels together

        data.levels.forEach(function (levelParsed) {
          var attributes = levelParsed.attrs;
          resolutionFound = resolutionFound || !!(levelParsed.width && levelParsed.height);
          videoCodecFound = videoCodecFound || !!levelParsed.videoCodec;
          audioCodecFound = audioCodecFound || !!levelParsed.audioCodec; // erase audio codec info if browser does not support mp4a.40.34.
          // demuxer will autodetect codec and fallback to mpeg/audio

          if (chromeOrFirefox && levelParsed.audioCodec && levelParsed.audioCodec.indexOf('mp4a.40.34') !== -1) {
            levelParsed.audioCodec = undefined;
          }

          var levelKey = levelParsed.bitrate + "-" + levelParsed.attrs.RESOLUTION + "-" + levelParsed.attrs.CODECS;
          levelFromSet = levelSet[levelKey];

          if (!levelFromSet) {
            levelFromSet = new _types_level__WEBPACK_IMPORTED_MODULE_0__["Level"](levelParsed);
            levelSet[levelKey] = levelFromSet;
            levels.push(levelFromSet);
          } else {
            levelFromSet.url.push(levelParsed.url);
          }

          if (attributes) {
            if (attributes.AUDIO) {
              Object(_level_helper__WEBPACK_IMPORTED_MODULE_4__["addGroupId"])(levelFromSet, 'audio', attributes.AUDIO);
            }

            if (attributes.SUBTITLES) {
              Object(_level_helper__WEBPACK_IMPORTED_MODULE_4__["addGroupId"])(levelFromSet, 'text', attributes.SUBTITLES);
            }
          }
        }); // remove audio-only level if we also have levels with video codecs or RESOLUTION signalled

        if ((resolutionFound || videoCodecFound) && audioCodecFound) {
          levels = levels.filter(function (_ref) {
            var videoCodec = _ref.videoCodec,
                width = _ref.width,
                height = _ref.height;
            return !!videoCodec || !!(width && height);
          });
        } // only keep levels with supported audio/video codecs


        levels = levels.filter(function (_ref2) {
          var audioCodec = _ref2.audioCodec,
              videoCodec = _ref2.videoCodec;
          return (!audioCodec || Object(_utils_codecs__WEBPACK_IMPORTED_MODULE_3__["isCodecSupportedInMp4"])(audioCodec, 'audio')) && (!videoCodec || Object(_utils_codecs__WEBPACK_IMPORTED_MODULE_3__["isCodecSupportedInMp4"])(videoCodec, 'video'));
        });

        if (data.audioTracks) {
          audioTracks = data.audioTracks.filter(function (track) {
            return !track.audioCodec || Object(_utils_codecs__WEBPACK_IMPORTED_MODULE_3__["isCodecSupportedInMp4"])(track.audioCodec, 'audio');
          }); // Assign ids after filtering as array indices by group-id

          Object(_level_helper__WEBPACK_IMPORTED_MODULE_4__["assignTrackIdsByGroup"])(audioTracks);
        }

        if (data.subtitles) {
          subtitleTracks = data.subtitles;
          Object(_level_helper__WEBPACK_IMPORTED_MODULE_4__["assignTrackIdsByGroup"])(subtitleTracks);
        }

        if (levels.length > 0) {
          // start bitrate is the first bitrate of the manifest
          bitrateStart = levels[0].bitrate; // sort level on bitrate

          levels.sort(function (a, b) {
            return a.bitrate - b.bitrate;
          });
          this._levels = levels; // find index of first level in sorted levels

          for (var i = 0; i < levels.length; i++) {
            if (levels[i].bitrate === bitrateStart) {
              this._firstLevel = i;
              this.log("manifest loaded, " + levels.length + " level(s) found, first bitrate: " + bitrateStart);
              break;
            }
          } // Audio is only alternate if manifest include a URI along with the audio group tag,
          // and this is not an audio-only stream where levels contain audio-only


          var audioOnly = audioCodecFound && !videoCodecFound;
          var edata = {
            levels: levels,
            audioTracks: audioTracks,
            subtitleTracks: subtitleTracks,
            firstLevel: this._firstLevel,
            stats: data.stats,
            audio: audioCodecFound,
            video: videoCodecFound,
            altAudio: !audioOnly && audioTracks.some(function (t) {
              return !!t.url;
            })
          };
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_PARSED, edata); // Initiate loading after all controllers have received MANIFEST_PARSED

          if (this.hls.config.autoStartLoad || this.hls.forceStartLoad) {
            this.hls.startLoad(this.hls.config.startPosition);
          }
        } else {
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorTypes"].MEDIA_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].MANIFEST_INCOMPATIBLE_CODECS_ERROR,
            fatal: true,
            url: data.url,
            reason: 'no level with compatible codecs found in manifest'
          });
        }
      };

      _proto.onError = function onError(event, data) {
        _BasePlaylistControll.prototype.onError.call(this, event, data);

        if (data.fatal) {
          return;
        } // Switch to redundant level when track fails to load


        var context = data.context;
        var level = this._levels[this.currentLevelIndex];

        if (context && (context.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].AUDIO_TRACK && level.audioGroupIds && context.groupId === level.audioGroupIds[level.urlId] || context.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].SUBTITLE_TRACK && level.textGroupIds && context.groupId === level.textGroupIds[level.urlId])) {
          this.redundantFailover(this.currentLevelIndex);
          return;
        }

        var levelError = false;
        var levelSwitch = true;
        var levelIndex; // try to recover not fatal errors

        switch (data.details) {
          case _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].FRAG_LOAD_ERROR:
          case _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].FRAG_LOAD_TIMEOUT:
          case _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].KEY_LOAD_ERROR:
          case _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].KEY_LOAD_TIMEOUT:
            if (data.frag) {
              var _level = this._levels[data.frag.level]; // Set levelIndex when we're out of fragment retries

              if (_level) {
                _level.fragmentError++;

                if (_level.fragmentError > this.hls.config.fragLoadingMaxRetry) {
                  levelIndex = data.frag.level;
                }
              } else {
                levelIndex = data.frag.level;
              }
            }

            break;

          case _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].LEVEL_LOAD_ERROR:
          case _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].LEVEL_LOAD_TIMEOUT:
            // Do not perform level switch if an error occurred using delivery directives
            // Attempt to reload level without directives first
            if (context) {
              if (context.deliveryDirectives) {
                levelSwitch = false;
              }

              levelIndex = context.level;
            }

            levelError = true;
            break;

          case _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].REMUX_ALLOC_ERROR:
            levelIndex = data.level;
            levelError = true;
            break;
        }

        if (levelIndex !== undefined) {
          this.recoverLevel(data, levelIndex, levelError, levelSwitch);
        }
      }
      /**
       * Switch to a redundant stream if any available.
       * If redundant stream is not available, emergency switch down if ABR mode is enabled.
       */
      ;

      _proto.recoverLevel = function recoverLevel(errorEvent, levelIndex, levelError, levelSwitch) {
        var errorDetails = errorEvent.details;
        var level = this._levels[levelIndex];
        level.loadError++;

        if (levelError) {
          var retrying = this.retryLoadingOrFail(errorEvent);

          if (retrying) {
            // boolean used to inform stream controller not to switch back to IDLE on non fatal error
            errorEvent.levelRetry = true;
          } else {
            this.currentLevelIndex = -1;
            return;
          }
        }

        if (levelSwitch) {
          var redundantLevels = level.url.length; // Try redundant fail-over until level.loadError reaches redundantLevels

          if (redundantLevels > 1 && level.loadError < redundantLevels) {
            errorEvent.levelRetry = true;
            this.redundantFailover(levelIndex);
          } else if (this.manualLevelIndex === -1) {
            // Search for available level in auto level selection mode, cycling from highest to lowest bitrate
            var nextLevel = levelIndex === 0 ? this._levels.length - 1 : levelIndex - 1;

            if (this.currentLevelIndex !== nextLevel && this._levels[nextLevel].loadError === 0) {
              this.warn(errorDetails + ": switch to " + nextLevel);
              errorEvent.levelRetry = true;
              this.hls.nextAutoLevel = nextLevel;
            }
          }
        }
      };

      _proto.redundantFailover = function redundantFailover(levelIndex) {
        var level = this._levels[levelIndex];
        var redundantLevels = level.url.length;

        if (redundantLevels > 1) {
          // Update the url id of all levels so that we stay on the same set of variants when level switching
          var newUrlId = (level.urlId + 1) % redundantLevels;
          this.warn("Switching to redundant URL-id " + newUrlId);

          this._levels.forEach(function (level) {
            level.urlId = newUrlId;
          });

          this.level = levelIndex;
        }
      } // reset errors on the successful load of a fragment
      ;

      _proto.onFragLoaded = function onFragLoaded(event, _ref3) {
        var frag = _ref3.frag;

        if (frag !== undefined && frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN) {
          var level = this._levels[frag.level];

          if (level !== undefined) {
            level.fragmentError = 0;
            level.loadError = 0;
          }
        }
      };

      _proto.onLevelLoaded = function onLevelLoaded(event, data) {
        var _data$deliveryDirecti2;

        var level = data.level,
            details = data.details;
        var curLevel = this._levels[level];

        if (!curLevel) {
          var _data$deliveryDirecti;

          this.warn("Invalid level index " + level);

          if ((_data$deliveryDirecti = data.deliveryDirectives) !== null && _data$deliveryDirecti !== void 0 && _data$deliveryDirecti.skip) {
            details.deltaUpdateFailed = true;
          }

          return;
        } // only process level loaded events matching with expected level


        if (level === this.currentLevelIndex) {
          // reset level load error counter on successful level loaded only if there is no issues with fragments
          if (curLevel.fragmentError === 0) {
            curLevel.loadError = 0;
            this.retryCount = 0;
          }

          this.playlistLoaded(level, data, curLevel.details);
        } else if ((_data$deliveryDirecti2 = data.deliveryDirectives) !== null && _data$deliveryDirecti2 !== void 0 && _data$deliveryDirecti2.skip) {
          // received a delta playlist update that cannot be merged
          details.deltaUpdateFailed = true;
        }
      };

      _proto.onAudioTrackSwitched = function onAudioTrackSwitched(event, data) {
        var currentLevel = this.hls.levels[this.currentLevelIndex];

        if (!currentLevel) {
          return;
        }

        if (currentLevel.audioGroupIds) {
          var urlId = -1;
          var audioGroupId = this.hls.audioTracks[data.id].groupId;

          for (var i = 0; i < currentLevel.audioGroupIds.length; i++) {
            if (currentLevel.audioGroupIds[i] === audioGroupId) {
              urlId = i;
              break;
            }
          }

          if (urlId !== currentLevel.urlId) {
            currentLevel.urlId = urlId;
            this.startLoad();
          }
        }
      };

      _proto.loadPlaylist = function loadPlaylist(hlsUrlParameters) {
        var level = this.currentLevelIndex;
        var currentLevel = this._levels[level];

        if (this.canLoad && currentLevel && currentLevel.url.length > 0) {
          var id = currentLevel.urlId;
          var url = currentLevel.url[id];

          if (hlsUrlParameters) {
            try {
              url = hlsUrlParameters.addDirectives(url);
            } catch (error) {
              this.warn("Could not construct new URL with HLS Delivery Directives: " + error);
            }
          }

          this.log("Attempt loading level index " + level + (hlsUrlParameters ? ' at sn ' + hlsUrlParameters.msn + ' part ' + hlsUrlParameters.part : '') + " with URL-id " + id + " " + url); // console.log('Current audio track group ID:', this.hls.audioTracks[this.hls.audioTrack].groupId);
          // console.log('New video quality level audio group id:', levelObject.attrs.AUDIO, level);

          this.clearTimer();
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVEL_LOADING, {
            url: url,
            level: level,
            id: id,
            deliveryDirectives: hlsUrlParameters || null
          });
        }
      };

      _proto.removeLevel = function removeLevel(levelIndex, urlId) {
        var filterLevelAndGroupByIdIndex = function filterLevelAndGroupByIdIndex(url, id) {
          return id !== urlId;
        };

        var levels = this._levels.filter(function (level, index) {
          if (index !== levelIndex) {
            return true;
          }

          if (level.url.length > 1 && urlId !== undefined) {
            level.url = level.url.filter(filterLevelAndGroupByIdIndex);

            if (level.audioGroupIds) {
              level.audioGroupIds = level.audioGroupIds.filter(filterLevelAndGroupByIdIndex);
            }

            if (level.textGroupIds) {
              level.textGroupIds = level.textGroupIds.filter(filterLevelAndGroupByIdIndex);
            }

            level.urlId = 0;
            return true;
          }

          return false;
        }).map(function (level, index) {
          var details = level.details;

          if (details !== null && details !== void 0 && details.fragments) {
            details.fragments.forEach(function (fragment) {
              fragment.level = index;
            });
          }

          return level;
        });

        this._levels = levels;
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVELS_UPDATED, {
          levels: levels
        });
      };

      _createClass(LevelController, [{
        key: "levels",
        get: function get() {
          if (this._levels.length === 0) {
            return null;
          }

          return this._levels;
        }
      }, {
        key: "level",
        get: function get() {
          return this.currentLevelIndex;
        },
        set: function set(newLevel) {
          var _levels$newLevel;

          var levels = this._levels;

          if (levels.length === 0) {
            return;
          }

          if (this.currentLevelIndex === newLevel && (_levels$newLevel = levels[newLevel]) !== null && _levels$newLevel !== void 0 && _levels$newLevel.details) {
            return;
          } // check if level idx is valid


          if (newLevel < 0 || newLevel >= levels.length) {
            // invalid level id given, trigger error
            var fatal = newLevel < 0;
            this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, {
              type: _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorTypes"].OTHER_ERROR,
              details: _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].LEVEL_SWITCH_ERROR,
              level: newLevel,
              fatal: fatal,
              reason: 'invalid level idx'
            });

            if (fatal) {
              return;
            }

            newLevel = Math.min(newLevel, levels.length - 1);
          } // stopping live reloading timer if any


          this.clearTimer();
          var lastLevelIndex = this.currentLevelIndex;
          var lastLevel = levels[lastLevelIndex];
          var level = levels[newLevel];
          this.log("switching to level " + newLevel + " from " + lastLevelIndex);
          this.currentLevelIndex = newLevel;

          var levelSwitchingData = _extends({}, level, {
            level: newLevel,
            maxBitrate: level.maxBitrate,
            uri: level.uri,
            urlId: level.urlId
          }); // @ts-ignore


          delete levelSwitchingData._urlId;
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVEL_SWITCHING, levelSwitchingData); // check if we need to load playlist for this level

          var levelDetails = level.details;

          if (!levelDetails || levelDetails.live) {
            // level not retrieved yet, or live playlist we need to (re)load it
            var hlsUrlParameters = this.switchParams(level.uri, lastLevel === null || lastLevel === void 0 ? void 0 : lastLevel.details);
            this.loadPlaylist(hlsUrlParameters);
          }
        }
      }, {
        key: "manualLevel",
        get: function get() {
          return this.manualLevelIndex;
        },
        set: function set(newLevel) {
          this.manualLevelIndex = newLevel;

          if (this._startLevel === undefined) {
            this._startLevel = newLevel;
          }

          if (newLevel !== -1) {
            this.level = newLevel;
          }
        }
      }, {
        key: "firstLevel",
        get: function get() {
          return this._firstLevel;
        },
        set: function set(newLevel) {
          this._firstLevel = newLevel;
        }
      }, {
        key: "startLevel",
        get: function get() {
          // hls.startLevel takes precedence over config.startLevel
          // if none of these values are defined, fallback on this._firstLevel (first quality level appearing in variant manifest)
          if (this._startLevel === undefined) {
            var configStartLevel = this.hls.config.startLevel;

            if (configStartLevel !== undefined) {
              return configStartLevel;
            } else {
              return this._firstLevel;
            }
          } else {
            return this._startLevel;
          }
        },
        set: function set(newLevel) {
          this._startLevel = newLevel;
        }
      }, {
        key: "nextLoadLevel",
        get: function get() {
          if (this.manualLevelIndex !== -1) {
            return this.manualLevelIndex;
          } else {
            return this.hls.nextAutoLevel;
          }
        },
        set: function set(nextLevel) {
          this.level = nextLevel;

          if (this.manualLevelIndex === -1) {
            this.hls.nextAutoLevel = nextLevel;
          }
        }
      }]);

      return LevelController;
    }(_base_playlist_controller__WEBPACK_IMPORTED_MODULE_5__["default"]);



    /***/ }),

    /***/ "./src/controller/level-helper.ts":
    /*!****************************************!*\
      !*** ./src/controller/level-helper.ts ***!
      \****************************************/
    /*! exports provided: addGroupId, assignTrackIdsByGroup, updatePTS, updateFragPTSDTS, mergeDetails, mapPartIntersection, mapFragmentIntersection, adjustSliding, addSliding, computeReloadInterval, getFragmentWithSN, getPartWith */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "addGroupId", function() { return addGroupId; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "assignTrackIdsByGroup", function() { return assignTrackIdsByGroup; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "updatePTS", function() { return updatePTS; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "updateFragPTSDTS", function() { return updateFragPTSDTS; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "mergeDetails", function() { return mergeDetails; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "mapPartIntersection", function() { return mapPartIntersection; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "mapFragmentIntersection", function() { return mapFragmentIntersection; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "adjustSliding", function() { return adjustSliding; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "addSliding", function() { return addSliding; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "computeReloadInterval", function() { return computeReloadInterval; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getFragmentWithSN", function() { return getFragmentWithSN; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getPartWith", function() { return getPartWith; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");






    /**
     * @module LevelHelper
     * Providing methods dealing with playlist sliding and drift
     * */

    function addGroupId(level, type, id) {
      switch (type) {
        case 'audio':
          if (!level.audioGroupIds) {
            level.audioGroupIds = [];
          }

          level.audioGroupIds.push(id);
          break;

        case 'text':
          if (!level.textGroupIds) {
            level.textGroupIds = [];
          }

          level.textGroupIds.push(id);
          break;
      }
    }
    function assignTrackIdsByGroup(tracks) {
      var groups = {};
      tracks.forEach(function (track) {
        var groupId = track.groupId || '';
        track.id = groups[groupId] = groups[groupId] || 0;
        groups[groupId]++;
      });
    }
    function updatePTS(fragments, fromIdx, toIdx) {
      var fragFrom = fragments[fromIdx];
      var fragTo = fragments[toIdx];
      updateFromToPTS(fragFrom, fragTo);
    }

    function updateFromToPTS(fragFrom, fragTo) {
      var fragToPTS = fragTo.startPTS; // if we know startPTS[toIdx]

      if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(fragToPTS)) {
        // update fragment duration.
        // it helps to fix drifts between playlist reported duration and fragment real duration
        var duration = 0;
        var frag;

        if (fragTo.sn > fragFrom.sn) {
          duration = fragToPTS - fragFrom.start;
          frag = fragFrom;
        } else {
          duration = fragFrom.start - fragToPTS;
          frag = fragTo;
        } // TODO? Drift can go either way, or the playlist could be completely accurate
        // console.assert(duration > 0,
        //   `duration of ${duration} computed for frag ${frag.sn}, level ${frag.level}, there should be some duration drift between playlist and fragment!`);


        if (frag.duration !== duration) {
          frag.duration = duration;
        } // we dont know startPTS[toIdx]

      } else if (fragTo.sn > fragFrom.sn) {
        var contiguous = fragFrom.cc === fragTo.cc; // TODO: With part-loading end/durations we need to confirm the whole fragment is loaded before using (or setting) minEndPTS

        if (contiguous && fragFrom.minEndPTS) {
          fragTo.start = fragFrom.start + (fragFrom.minEndPTS - fragFrom.start);
        } else {
          fragTo.start = fragFrom.start + fragFrom.duration;
        }
      } else {
        fragTo.start = Math.max(fragFrom.start - fragTo.duration, 0);
      }
    }

    function updateFragPTSDTS(details, frag, startPTS, endPTS, startDTS, endDTS) {
      var parsedMediaDuration = endPTS - startPTS;

      if (parsedMediaDuration <= 0) {
        _utils_logger__WEBPACK_IMPORTED_MODULE_1__["logger"].warn('Fragment should have a positive duration', frag);
        endPTS = startPTS + frag.duration;
        endDTS = startDTS + frag.duration;
      }

      var maxStartPTS = startPTS;
      var minEndPTS = endPTS;
      var fragStartPts = frag.startPTS;
      var fragEndPts = frag.endPTS;

      if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(fragStartPts)) {
        // delta PTS between audio and video
        var deltaPTS = Math.abs(fragStartPts - startPTS);

        if (!Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(frag.deltaPTS)) {
          frag.deltaPTS = deltaPTS;
        } else {
          frag.deltaPTS = Math.max(deltaPTS, frag.deltaPTS);
        }

        maxStartPTS = Math.max(startPTS, fragStartPts);
        startPTS = Math.min(startPTS, fragStartPts);
        startDTS = Math.min(startDTS, frag.startDTS);
        minEndPTS = Math.min(endPTS, fragEndPts);
        endPTS = Math.max(endPTS, fragEndPts);
        endDTS = Math.max(endDTS, frag.endDTS);
      }

      frag.duration = endPTS - startPTS;
      var drift = startPTS - frag.start;
      frag.appendedPTS = endPTS;
      frag.start = frag.startPTS = startPTS;
      frag.maxStartPTS = maxStartPTS;
      frag.startDTS = startDTS;
      frag.endPTS = endPTS;
      frag.minEndPTS = minEndPTS;
      frag.endDTS = endDTS;
      var sn = frag.sn; // 'initSegment'
      // exit if sn out of range

      if (!details || sn < details.startSN || sn > details.endSN) {
        return 0;
      }

      var i;
      var fragIdx = sn - details.startSN;
      var fragments = details.fragments; // update frag reference in fragments array
      // rationale is that fragments array might not contain this frag object.
      // this will happen if playlist has been refreshed between frag loading and call to updateFragPTSDTS()
      // if we don't update frag, we won't be able to propagate PTS info on the playlist
      // resulting in invalid sliding computation

      fragments[fragIdx] = frag; // adjust fragment PTS/duration from seqnum-1 to frag 0

      for (i = fragIdx; i > 0; i--) {
        updateFromToPTS(fragments[i], fragments[i - 1]);
      } // adjust fragment PTS/duration from seqnum to last frag


      for (i = fragIdx; i < fragments.length - 1; i++) {
        updateFromToPTS(fragments[i], fragments[i + 1]);
      }

      if (details.fragmentHint) {
        updateFromToPTS(fragments[fragments.length - 1], details.fragmentHint);
      }

      details.PTSKnown = details.alignedSliding = true;
      return drift;
    }
    function mergeDetails(oldDetails, newDetails) {
      // Track the last initSegment processed. Initialize it to the last one on the timeline.
      var currentInitSegment = null;
      var oldFragments = oldDetails.fragments;

      for (var i = oldFragments.length - 1; i >= 0; i--) {
        var oldInit = oldFragments[i].initSegment;

        if (oldInit) {
          currentInitSegment = oldInit;
          break;
        }
      }

      if (oldDetails.fragmentHint) {
        // prevent PTS and duration from being adjusted on the next hint
        delete oldDetails.fragmentHint.endPTS;
      } // check if old/new playlists have fragments in common
      // loop through overlapping SN and update startPTS , cc, and duration if any found


      var ccOffset = 0;
      var PTSFrag;
      mapFragmentIntersection(oldDetails, newDetails, function (oldFrag, newFrag) {
        if (oldFrag.relurl) {
          // Do not compare CC if the old fragment has no url. This is a level.fragmentHint used by LL-HLS parts.
          // It maybe be off by 1 if it was created before any parts or discontinuity tags were appended to the end
          // of the playlist.
          ccOffset = oldFrag.cc - newFrag.cc;
        }

        if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(oldFrag.startPTS) && Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(oldFrag.endPTS)) {
          newFrag.start = newFrag.startPTS = oldFrag.startPTS;
          newFrag.startDTS = oldFrag.startDTS;
          newFrag.appendedPTS = oldFrag.appendedPTS;
          newFrag.maxStartPTS = oldFrag.maxStartPTS;
          newFrag.endPTS = oldFrag.endPTS;
          newFrag.endDTS = oldFrag.endDTS;
          newFrag.minEndPTS = oldFrag.minEndPTS;
          newFrag.duration = oldFrag.endPTS - oldFrag.startPTS;

          if (newFrag.duration) {
            PTSFrag = newFrag;
          } // PTS is known when any segment has startPTS and endPTS


          newDetails.PTSKnown = newDetails.alignedSliding = true;
        }

        newFrag.elementaryStreams = oldFrag.elementaryStreams;
        newFrag.loader = oldFrag.loader;
        newFrag.stats = oldFrag.stats;
        newFrag.urlId = oldFrag.urlId;

        if (oldFrag.initSegment) {
          newFrag.initSegment = oldFrag.initSegment;
          currentInitSegment = oldFrag.initSegment;
        }
      });

      if (currentInitSegment) {
        var fragmentsToCheck = newDetails.fragmentHint ? newDetails.fragments.concat(newDetails.fragmentHint) : newDetails.fragments;
        fragmentsToCheck.forEach(function (frag) {
          var _currentInitSegment;

          if (!frag.initSegment || frag.initSegment.relurl === ((_currentInitSegment = currentInitSegment) === null || _currentInitSegment === void 0 ? void 0 : _currentInitSegment.relurl)) {
            frag.initSegment = currentInitSegment;
          }
        });
      }

      if (newDetails.skippedSegments) {
        newDetails.deltaUpdateFailed = newDetails.fragments.some(function (frag) {
          return !frag;
        });

        if (newDetails.deltaUpdateFailed) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_1__["logger"].warn('[level-helper] Previous playlist missing segments skipped in delta playlist');

          for (var _i = newDetails.skippedSegments; _i--;) {
            newDetails.fragments.shift();
          }

          newDetails.startSN = newDetails.fragments[0].sn;
          newDetails.startCC = newDetails.fragments[0].cc;
        }
      }

      var newFragments = newDetails.fragments;

      if (ccOffset) {
        _utils_logger__WEBPACK_IMPORTED_MODULE_1__["logger"].warn('discontinuity sliding from playlist, take drift into account');

        for (var _i2 = 0; _i2 < newFragments.length; _i2++) {
          newFragments[_i2].cc += ccOffset;
        }
      }

      if (newDetails.skippedSegments) {
        newDetails.startCC = newDetails.fragments[0].cc;
      } // Merge parts


      mapPartIntersection(oldDetails.partList, newDetails.partList, function (oldPart, newPart) {
        newPart.elementaryStreams = oldPart.elementaryStreams;
        newPart.stats = oldPart.stats;
      }); // if at least one fragment contains PTS info, recompute PTS information for all fragments

      if (PTSFrag) {
        updateFragPTSDTS(newDetails, PTSFrag, PTSFrag.startPTS, PTSFrag.endPTS, PTSFrag.startDTS, PTSFrag.endDTS);
      } else {
        // ensure that delta is within oldFragments range
        // also adjust sliding in case delta is 0 (we could have old=[50-60] and new=old=[50-61])
        // in that case we also need to adjust start offset of all fragments
        adjustSliding(oldDetails, newDetails);
      }

      if (newFragments.length) {
        newDetails.totalduration = newDetails.edge - newFragments[0].start;
      }

      newDetails.driftStartTime = oldDetails.driftStartTime;
      newDetails.driftStart = oldDetails.driftStart;
      var advancedDateTime = newDetails.advancedDateTime;

      if (newDetails.advanced && advancedDateTime) {
        var edge = newDetails.edge;

        if (!newDetails.driftStart) {
          newDetails.driftStartTime = advancedDateTime;
          newDetails.driftStart = edge;
        }

        newDetails.driftEndTime = advancedDateTime;
        newDetails.driftEnd = edge;
      } else {
        newDetails.driftEndTime = oldDetails.driftEndTime;
        newDetails.driftEnd = oldDetails.driftEnd;
        newDetails.advancedDateTime = oldDetails.advancedDateTime;
      }
    }
    function mapPartIntersection(oldParts, newParts, intersectionFn) {
      if (oldParts && newParts) {
        var delta = 0;

        for (var i = 0, len = oldParts.length; i <= len; i++) {
          var _oldPart = oldParts[i];
          var _newPart = newParts[i + delta];

          if (_oldPart && _newPart && _oldPart.index === _newPart.index && _oldPart.fragment.sn === _newPart.fragment.sn) {
            intersectionFn(_oldPart, _newPart);
          } else {
            delta--;
          }
        }
      }
    }
    function mapFragmentIntersection(oldDetails, newDetails, intersectionFn) {
      var skippedSegments = newDetails.skippedSegments;
      var start = Math.max(oldDetails.startSN, newDetails.startSN) - newDetails.startSN;
      var end = (oldDetails.fragmentHint ? 1 : 0) + (skippedSegments ? newDetails.endSN : Math.min(oldDetails.endSN, newDetails.endSN)) - newDetails.startSN;
      var delta = newDetails.startSN - oldDetails.startSN;
      var newFrags = newDetails.fragmentHint ? newDetails.fragments.concat(newDetails.fragmentHint) : newDetails.fragments;
      var oldFrags = oldDetails.fragmentHint ? oldDetails.fragments.concat(oldDetails.fragmentHint) : oldDetails.fragments;

      for (var i = start; i <= end; i++) {
        var _oldFrag = oldFrags[delta + i];
        var _newFrag = newFrags[i];

        if (skippedSegments && !_newFrag && i < skippedSegments) {
          // Fill in skipped segments in delta playlist
          _newFrag = newDetails.fragments[i] = _oldFrag;
        }

        if (_oldFrag && _newFrag) {
          intersectionFn(_oldFrag, _newFrag);
        }
      }
    }
    function adjustSliding(oldDetails, newDetails) {
      var delta = newDetails.startSN + newDetails.skippedSegments - oldDetails.startSN;
      var oldFragments = oldDetails.fragments;

      if (delta < 0 || delta >= oldFragments.length) {
        return;
      }

      addSliding(newDetails, oldFragments[delta].start);
    }
    function addSliding(details, start) {
      if (start) {
        var fragments = details.fragments;

        for (var i = details.skippedSegments; i < fragments.length; i++) {
          fragments[i].start += start;
        }

        if (details.fragmentHint) {
          details.fragmentHint.start += start;
        }
      }
    }
    function computeReloadInterval(newDetails, stats) {
      var reloadInterval = 1000 * newDetails.levelTargetDuration;
      var reloadIntervalAfterMiss = reloadInterval / 2;
      var timeSinceLastModified = newDetails.age;
      var useLastModified = timeSinceLastModified > 0 && timeSinceLastModified < reloadInterval * 3;
      var roundTrip = stats.loading.end - stats.loading.start;
      var estimatedTimeUntilUpdate;
      var availabilityDelay = newDetails.availabilityDelay; // let estimate = 'average';

      if (newDetails.updated === false) {
        if (useLastModified) {
          // estimate = 'miss round trip';
          // We should have had a hit so try again in the time it takes to get a response,
          // but no less than 1/3 second.
          var minRetry = 333 * newDetails.misses;
          estimatedTimeUntilUpdate = Math.max(Math.min(reloadIntervalAfterMiss, roundTrip * 2), minRetry);
          newDetails.availabilityDelay = (newDetails.availabilityDelay || 0) + estimatedTimeUntilUpdate;
        } else {
          // estimate = 'miss half average';
          // follow HLS Spec, If the client reloads a Playlist file and finds that it has not
          // changed then it MUST wait for a period of one-half the target
          // duration before retrying.
          estimatedTimeUntilUpdate = reloadIntervalAfterMiss;
        }
      } else if (useLastModified) {
        // estimate = 'next modified date';
        // Get the closest we've been to timeSinceLastModified on update
        availabilityDelay = Math.min(availabilityDelay || reloadInterval / 2, timeSinceLastModified);
        newDetails.availabilityDelay = availabilityDelay;
        estimatedTimeUntilUpdate = availabilityDelay + reloadInterval - timeSinceLastModified;
      } else {
        estimatedTimeUntilUpdate = reloadInterval - roundTrip;
      } // console.log(`[computeReloadInterval] live reload ${newDetails.updated ? 'REFRESHED' : 'MISSED'}`,
      //   '\n  method', estimate,
      //   '\n  estimated time until update =>', estimatedTimeUntilUpdate,
      //   '\n  average target duration', reloadInterval,
      //   '\n  time since modified', timeSinceLastModified,
      //   '\n  time round trip', roundTrip,
      //   '\n  availability delay', availabilityDelay);


      return Math.round(estimatedTimeUntilUpdate);
    }
    function getFragmentWithSN(level, sn, fragCurrent) {
      if (!level || !level.details) {
        return null;
      }

      var levelDetails = level.details;
      var fragment = levelDetails.fragments[sn - levelDetails.startSN];

      if (fragment) {
        return fragment;
      }

      fragment = levelDetails.fragmentHint;

      if (fragment && fragment.sn === sn) {
        return fragment;
      }

      if (sn < levelDetails.startSN && fragCurrent && fragCurrent.sn === sn) {
        return fragCurrent;
      }

      return null;
    }
    function getPartWith(level, sn, partIndex) {
      if (!level || !level.details) {
        return null;
      }

      var partList = level.details.partList;

      if (partList) {
        for (var i = partList.length; i--;) {
          var part = partList[i];

          if (part.index === partIndex && part.fragment.sn === sn) {
            return part;
          }
        }
      }

      return null;
    }

    /***/ }),

    /***/ "./src/controller/stream-controller.ts":
    /*!*********************************************!*\
      !*** ./src/controller/stream-controller.ts ***!
      \*********************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return StreamController; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./base-stream-controller */ "./src/controller/base-stream-controller.ts");
    /* harmony import */ var _is_supported__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../is-supported */ "./src/is-supported.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
    /* harmony import */ var _fragment_tracker__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./fragment-tracker */ "./src/controller/fragment-tracker.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
    /* harmony import */ var _loader_fragment__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../loader/fragment */ "./src/loader/fragment.ts");
    /* harmony import */ var _demux_transmuxer_interface__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../demux/transmuxer-interface */ "./src/demux/transmuxer-interface.ts");
    /* harmony import */ var _types_transmuxer__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../types/transmuxer */ "./src/types/transmuxer.ts");
    /* harmony import */ var _gap_controller__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./gap-controller */ "./src/controller/gap-controller.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");



    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }













    var TICK_INTERVAL = 100; // how often to tick in ms

    var StreamController = /*#__PURE__*/function (_BaseStreamController) {
      _inheritsLoose(StreamController, _BaseStreamController);

      function StreamController(hls, fragmentTracker) {
        var _this;

        _this = _BaseStreamController.call(this, hls, fragmentTracker, '[stream-controller]') || this;
        _this.audioCodecSwap = false;
        _this.gapController = null;
        _this.level = -1;
        _this._forceStartLoad = false;
        _this.altAudio = false;
        _this.audioOnly = false;
        _this.fragPlaying = null;
        _this.onvplaying = null;
        _this.onvseeked = null;
        _this.fragLastKbps = 0;
        _this.stalled = false;
        _this.couldBacktrack = false;
        _this.audioCodecSwitch = false;
        _this.videoBuffer = null;

        _this._registerListeners();

        return _this;
      }

      var _proto = StreamController.prototype;

      _proto._registerListeners = function _registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].LEVEL_LOADING, this.onLevelLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].LEVEL_LOADED, this.onLevelLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].ERROR, this.onError, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].BUFFER_CREATED, this.onBufferCreated, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].BUFFER_FLUSHED, this.onBufferFlushed, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].LEVELS_UPDATED, this.onLevelsUpdated, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].FRAG_BUFFERED, this.onFragBuffered, this);
      };

      _proto._unregisterListeners = function _unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].LEVEL_LOADED, this.onLevelLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].ERROR, this.onError, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].BUFFER_CREATED, this.onBufferCreated, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].BUFFER_FLUSHED, this.onBufferFlushed, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].LEVELS_UPDATED, this.onLevelsUpdated, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].FRAG_BUFFERED, this.onFragBuffered, this);
      };

      _proto.onHandlerDestroying = function onHandlerDestroying() {
        this._unregisterListeners();

        this.onMediaDetaching();
      };

      _proto.startLoad = function startLoad(startPosition) {
        if (this.levels) {
          var lastCurrentTime = this.lastCurrentTime,
              hls = this.hls;
          this.stopLoad();
          this.setInterval(TICK_INTERVAL);
          this.level = -1;
          this.fragLoadError = 0;

          if (!this.startFragRequested) {
            // determine load level
            var startLevel = hls.startLevel;

            if (startLevel === -1) {
              if (hls.config.testBandwidth) {
                // -1 : guess start Level by doing a bitrate test by loading first fragment of lowest quality level
                startLevel = 0;
                this.bitrateTest = true;
              } else {
                startLevel = hls.nextAutoLevel;
              }
            } // set new level to playlist loader : this will trigger start level load
            // hls.nextLoadLevel remains until it is set to a new value or until a new frag is successfully loaded


            this.level = hls.nextLoadLevel = startLevel;
            this.loadedmetadata = false;
          } // if startPosition undefined but lastCurrentTime set, set startPosition to last currentTime


          if (lastCurrentTime > 0 && startPosition === -1) {
            this.log("Override startPosition with lastCurrentTime @" + lastCurrentTime.toFixed(3));
            startPosition = lastCurrentTime;
          }

          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
          this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;
          this.tick();
        } else {
          this._forceStartLoad = true;
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].STOPPED;
        }
      };

      _proto.stopLoad = function stopLoad() {
        this._forceStartLoad = false;

        _BaseStreamController.prototype.stopLoad.call(this);
      };

      _proto.doTick = function doTick() {
        switch (this.state) {
          case _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE:
            this.doTickIdle();
            break;

          case _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_LEVEL:
            {
              var _levels$level;

              var levels = this.levels,
                  level = this.level;
              var details = levels === null || levels === void 0 ? void 0 : (_levels$level = levels[level]) === null || _levels$level === void 0 ? void 0 : _levels$level.details;

              if (details && (!details.live || this.levelLastLoaded === this.level)) {
                if (this.waitForCdnTuneIn(details)) {
                  break;
                }

                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
                break;
              }

              break;
            }

          case _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].FRAG_LOADING_WAITING_RETRY:
            {
              var _this$media;

              var now = self.performance.now();
              var retryDate = this.retryDate; // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading

              if (!retryDate || now >= retryDate || (_this$media = this.media) !== null && _this$media !== void 0 && _this$media.seeking) {
                this.log('retryDate reached, switch back to IDLE state');
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
              }
            }
            break;
        } // check buffer
        // check/update current fragment


        this.onTickEnd();
      };

      _proto.onTickEnd = function onTickEnd() {
        _BaseStreamController.prototype.onTickEnd.call(this);

        this.checkBuffer();
        this.checkFragmentChanged();
      };

      _proto.doTickIdle = function doTickIdle() {
        var _frag$decryptdata, _frag$decryptdata2;

        var hls = this.hls,
            levelLastLoaded = this.levelLastLoaded,
            levels = this.levels,
            media = this.media;
        var config = hls.config,
            level = hls.nextLoadLevel; // if start level not parsed yet OR
        // if video not attached AND start fragment already requested OR start frag prefetch not enabled
        // exit loop, as we either need more info (level not parsed) or we need media to be attached to load new fragment

        if (levelLastLoaded === null || !media && (this.startFragRequested || !config.startFragPrefetch)) {
          return;
        } // If the "main" level is audio-only but we are loading an alternate track in the same group, do not load anything


        if (this.altAudio && this.audioOnly) {
          return;
        }

        if (!levels || !levels[level]) {
          return;
        }

        var levelInfo = levels[level]; // if buffer length is less than maxBufLen try to load a new fragment
        // set next load level : this will trigger a playlist load if needed

        this.level = hls.nextLoadLevel = level;
        var levelDetails = levelInfo.details; // if level info not retrieved yet, switch state and wait for level retrieval
        // if live playlist, ensure that new playlist has been refreshed to avoid loading/try to load
        // a useless and outdated fragment (that might even introduce load error if it is already out of the live playlist)

        if (!levelDetails || this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_LEVEL || levelDetails.live && this.levelLastLoaded !== level) {
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_LEVEL;
          return;
        }

        var bufferInfo = this.getFwdBufferInfo(this.mediaBuffer ? this.mediaBuffer : media, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN);

        if (bufferInfo === null) {
          return;
        }

        var bufferLen = bufferInfo.len; // compute max Buffer Length that we could get from this load level, based on level bitrate. don't buffer more than 60 MB and more than 30s

        var maxBufLen = this.getMaxBufferLength(levelInfo.maxBitrate); // Stay idle if we are still with buffer margins

        if (bufferLen >= maxBufLen) {
          return;
        }

        if (this._streamEnded(bufferInfo, levelDetails)) {
          var data = {};

          if (this.altAudio) {
            data.type = 'video';
          }

          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].BUFFER_EOS, data);
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].ENDED;
          return;
        }

        var targetBufferTime = bufferInfo.end;
        var frag = this.getNextFragment(targetBufferTime, levelDetails); // Avoid backtracking after seeking or switching by loading an earlier segment in streams that could backtrack

        if (this.couldBacktrack && !this.fragPrevious && frag && frag.sn !== 'initSegment') {
          var fragIdx = frag.sn - levelDetails.startSN;

          if (fragIdx > 1) {
            frag = levelDetails.fragments[fragIdx - 1];
            this.fragmentTracker.removeFragment(frag);
          }
        } // Avoid loop loading by using nextLoadPosition set for backtracking


        if (frag && this.fragmentTracker.getState(frag) === _fragment_tracker__WEBPACK_IMPORTED_MODULE_5__["FragmentState"].OK && this.nextLoadPosition > targetBufferTime) {
          // Cleanup the fragment tracker before trying to find the next unbuffered fragment
          var type = this.audioOnly && !this.altAudio ? _loader_fragment__WEBPACK_IMPORTED_MODULE_7__["ElementaryStreamTypes"].AUDIO : _loader_fragment__WEBPACK_IMPORTED_MODULE_7__["ElementaryStreamTypes"].VIDEO;
          this.afterBufferFlushed(media, type, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN);
          frag = this.getNextFragment(this.nextLoadPosition, levelDetails);
        }

        if (!frag) {
          return;
        }

        if (frag.initSegment && !frag.initSegment.data && !this.bitrateTest) {
          frag = frag.initSegment;
        } // We want to load the key if we're dealing with an identity key, because we will decrypt
        // this content using the key we fetch. Other keys will be handled by the DRM CDM via EME.


        if (((_frag$decryptdata = frag.decryptdata) === null || _frag$decryptdata === void 0 ? void 0 : _frag$decryptdata.keyFormat) === 'identity' && !((_frag$decryptdata2 = frag.decryptdata) !== null && _frag$decryptdata2 !== void 0 && _frag$decryptdata2.key)) {
          this.loadKey(frag, levelDetails);
        } else {
          this.loadFragment(frag, levelDetails, targetBufferTime);
        }
      };

      _proto.loadFragment = function loadFragment(frag, levelDetails, targetBufferTime) {
        var _this$media2;

        // Check if fragment is not loaded
        var fragState = this.fragmentTracker.getState(frag);
        this.fragCurrent = frag; // Use data from loaded backtracked fragment if available

        if (fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_5__["FragmentState"].BACKTRACKED) {
          var data = this.fragmentTracker.getBacktrackData(frag);

          if (data) {
            this._handleFragmentLoadProgress(data);

            this._handleFragmentLoadComplete(data);

            return;
          } else {
            fragState = _fragment_tracker__WEBPACK_IMPORTED_MODULE_5__["FragmentState"].NOT_LOADED;
          }
        }

        if (fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_5__["FragmentState"].NOT_LOADED || fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_5__["FragmentState"].PARTIAL) {
          if (frag.sn === 'initSegment') {
            this._loadInitSegment(frag);
          } else if (this.bitrateTest) {
            frag.bitrateTest = true;
            this.log("Fragment " + frag.sn + " of level " + frag.level + " is being downloaded to test bitrate and will not be buffered");

            this._loadBitrateTestFrag(frag);
          } else {
            this.startFragRequested = true;

            _BaseStreamController.prototype.loadFragment.call(this, frag, levelDetails, targetBufferTime);
          }
        } else if (fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_5__["FragmentState"].APPENDING) {
          // Lower the buffer size and try again
          if (this.reduceMaxBufferLength(frag.duration)) {
            this.fragmentTracker.removeFragment(frag);
          }
        } else if (((_this$media2 = this.media) === null || _this$media2 === void 0 ? void 0 : _this$media2.buffered.length) === 0) {
          // Stop gap for bad tracker / buffer flush behavior
          this.fragmentTracker.removeAllFragments();
        }
      };

      _proto.getAppendedFrag = function getAppendedFrag(position) {
        var fragOrPart = this.fragmentTracker.getAppendedFrag(position, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN);

        if (fragOrPart && 'fragment' in fragOrPart) {
          return fragOrPart.fragment;
        }

        return fragOrPart;
      };

      _proto.getBufferedFrag = function getBufferedFrag(position) {
        return this.fragmentTracker.getBufferedFrag(position, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN);
      };

      _proto.followingBufferedFrag = function followingBufferedFrag(frag) {
        if (frag) {
          // try to get range of next fragment (500ms after this range)
          return this.getBufferedFrag(frag.end + 0.5);
        }

        return null;
      }
      /*
        on immediate level switch :
         - pause playback if playing
         - cancel any pending load request
         - and trigger a buffer flush
      */
      ;

      _proto.immediateLevelSwitch = function immediateLevelSwitch() {
        this.abortCurrentFrag();
        this.flushMainBuffer(0, Number.POSITIVE_INFINITY);
      }
      /**
       * try to switch ASAP without breaking video playback:
       * in order to ensure smooth but quick level switching,
       * we need to find the next flushable buffer range
       * we should take into account new segment fetch time
       */
      ;

      _proto.nextLevelSwitch = function nextLevelSwitch() {
        var levels = this.levels,
            media = this.media; // ensure that media is defined and that metadata are available (to retrieve currentTime)

        if (media !== null && media !== void 0 && media.readyState) {
          var fetchdelay;
          var fragPlayingCurrent = this.getAppendedFrag(media.currentTime);

          if (fragPlayingCurrent && fragPlayingCurrent.start > 1) {
            // flush buffer preceding current fragment (flush until current fragment start offset)
            // minus 1s to avoid video freezing, that could happen if we flush keyframe of current video ...
            this.flushMainBuffer(0, fragPlayingCurrent.start - 1);
          }

          if (!media.paused && levels) {
            // add a safety delay of 1s
            var nextLevelId = this.hls.nextLoadLevel;
            var nextLevel = levels[nextLevelId];
            var fragLastKbps = this.fragLastKbps;

            if (fragLastKbps && this.fragCurrent) {
              fetchdelay = this.fragCurrent.duration * nextLevel.maxBitrate / (1000 * fragLastKbps) + 1;
            } else {
              fetchdelay = 0;
            }
          } else {
            fetchdelay = 0;
          } // this.log('fetchdelay:'+fetchdelay);
          // find buffer range that will be reached once new fragment will be fetched


          var bufferedFrag = this.getBufferedFrag(media.currentTime + fetchdelay);

          if (bufferedFrag) {
            // we can flush buffer range following this one without stalling playback
            var nextBufferedFrag = this.followingBufferedFrag(bufferedFrag);

            if (nextBufferedFrag) {
              // if we are here, we can also cancel any loading/demuxing in progress, as they are useless
              this.abortCurrentFrag(); // start flush position is in next buffered frag. Leave some padding for non-independent segments and smoother playback.

              var maxStart = nextBufferedFrag.maxStartPTS ? nextBufferedFrag.maxStartPTS : nextBufferedFrag.start;
              var fragDuration = nextBufferedFrag.duration;
              var startPts = Math.max(bufferedFrag.end, maxStart + Math.min(Math.max(fragDuration - this.config.maxFragLookUpTolerance, fragDuration * 0.5), fragDuration * 0.75));
              this.flushMainBuffer(startPts, Number.POSITIVE_INFINITY);
            }
          }
        }
      };

      _proto.abortCurrentFrag = function abortCurrentFrag() {
        var fragCurrent = this.fragCurrent;
        this.fragCurrent = null;

        if (fragCurrent !== null && fragCurrent !== void 0 && fragCurrent.loader) {
          fragCurrent.loader.abort();
        }

        if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].KEY_LOADING) {
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
        }

        this.nextLoadPosition = this.getLoadPosition();
      };

      _proto.flushMainBuffer = function flushMainBuffer(startOffset, endOffset) {
        _BaseStreamController.prototype.flushMainBuffer.call(this, startOffset, endOffset, this.altAudio ? 'video' : null);
      };

      _proto.onMediaAttached = function onMediaAttached(event, data) {
        _BaseStreamController.prototype.onMediaAttached.call(this, event, data);

        var media = data.media;
        this.onvplaying = this.onMediaPlaying.bind(this);
        this.onvseeked = this.onMediaSeeked.bind(this);
        media.addEventListener('playing', this.onvplaying);
        media.addEventListener('seeked', this.onvseeked);
        this.gapController = new _gap_controller__WEBPACK_IMPORTED_MODULE_10__["default"](this.config, media, this.fragmentTracker, this.hls);
      };

      _proto.onMediaDetaching = function onMediaDetaching() {
        var media = this.media;

        if (media) {
          media.removeEventListener('playing', this.onvplaying);
          media.removeEventListener('seeked', this.onvseeked);
          this.onvplaying = this.onvseeked = null;
          this.videoBuffer = null;
        }

        this.fragPlaying = null;

        if (this.gapController) {
          this.gapController.destroy();
          this.gapController = null;
        }

        _BaseStreamController.prototype.onMediaDetaching.call(this);
      };

      _proto.onMediaPlaying = function onMediaPlaying() {
        // tick to speed up FRAG_CHANGED triggering
        this.tick();
      };

      _proto.onMediaSeeked = function onMediaSeeked() {
        var media = this.media;
        var currentTime = media ? media.currentTime : null;

        if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(currentTime)) {
          this.log("Media seeked to " + currentTime.toFixed(3));
        } // tick to speed up FRAG_CHANGED triggering


        this.tick();
      };

      _proto.onManifestLoading = function onManifestLoading() {
        // reset buffer on manifest loading
        this.log('Trigger BUFFER_RESET');
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].BUFFER_RESET, undefined);
        this.fragmentTracker.removeAllFragments();
        this.couldBacktrack = this.stalled = false;
        this.startPosition = this.lastCurrentTime = 0;
        this.fragPlaying = null;
      };

      _proto.onManifestParsed = function onManifestParsed(event, data) {
        var aac = false;
        var heaac = false;
        var codec;
        data.levels.forEach(function (level) {
          // detect if we have different kind of audio codecs used amongst playlists
          codec = level.audioCodec;

          if (codec) {
            if (codec.indexOf('mp4a.40.2') !== -1) {
              aac = true;
            }

            if (codec.indexOf('mp4a.40.5') !== -1) {
              heaac = true;
            }
          }
        });
        this.audioCodecSwitch = aac && heaac && !Object(_is_supported__WEBPACK_IMPORTED_MODULE_2__["changeTypeSupported"])();

        if (this.audioCodecSwitch) {
          this.log('Both AAC/HE-AAC audio found in levels; declaring level codec as HE-AAC');
        }

        this.levels = data.levels;
        this.startFragRequested = false;
      };

      _proto.onLevelLoading = function onLevelLoading(event, data) {
        var levels = this.levels;

        if (!levels || this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE) {
          return;
        }

        var level = levels[data.level];

        if (!level.details || level.details.live && this.levelLastLoaded !== data.level || this.waitForCdnTuneIn(level.details)) {
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_LEVEL;
        }
      };

      _proto.onLevelLoaded = function onLevelLoaded(event, data) {
        var _curLevel$details;

        var levels = this.levels;
        var newLevelId = data.level;
        var newDetails = data.details;
        var duration = newDetails.totalduration;

        if (!levels) {
          this.warn("Levels were reset while loading level " + newLevelId);
          return;
        }

        this.log("Level " + newLevelId + " loaded [" + newDetails.startSN + "," + newDetails.endSN + "], cc [" + newDetails.startCC + ", " + newDetails.endCC + "] duration:" + duration);
        var fragCurrent = this.fragCurrent;

        if (fragCurrent && (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].FRAG_LOADING || this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].FRAG_LOADING_WAITING_RETRY)) {
          if (fragCurrent.level !== data.level && fragCurrent.loader) {
            this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
            fragCurrent.loader.abort();
          }
        }

        var curLevel = levels[newLevelId];
        var sliding = 0;

        if (newDetails.live || (_curLevel$details = curLevel.details) !== null && _curLevel$details !== void 0 && _curLevel$details.live) {
          if (!newDetails.fragments[0]) {
            newDetails.deltaUpdateFailed = true;
          }

          if (newDetails.deltaUpdateFailed) {
            return;
          }

          sliding = this.alignPlaylists(newDetails, curLevel.details);
        } // override level info


        curLevel.details = newDetails;
        this.levelLastLoaded = newLevelId;
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].LEVEL_UPDATED, {
          details: newDetails,
          level: newLevelId
        }); // only switch back to IDLE state if we were waiting for level to start downloading a new fragment

        if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_LEVEL) {
          if (this.waitForCdnTuneIn(newDetails)) {
            // Wait for Low-Latency CDN Tune-in
            return;
          }

          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
        }

        if (!this.startFragRequested) {
          this.setStartPosition(newDetails, sliding);
        } else if (newDetails.live) {
          this.synchronizeToLiveEdge(newDetails);
        } // trigger handler right now


        this.tick();
      };

      _proto._handleFragmentLoadProgress = function _handleFragmentLoadProgress(data) {
        var _frag$initSegment;

        var frag = data.frag,
            part = data.part,
            payload = data.payload;
        var levels = this.levels;

        if (!levels) {
          this.warn("Levels were reset while fragment load was in progress. Fragment " + frag.sn + " of level " + frag.level + " will not be buffered");
          return;
        }

        var currentLevel = levels[frag.level];
        var details = currentLevel.details;

        if (!details) {
          this.warn("Dropping fragment " + frag.sn + " of level " + frag.level + " after level details were reset");
          return;
        }

        var videoCodec = currentLevel.videoCodec; // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)

        var accurateTimeOffset = details.PTSKnown || !details.live;
        var initSegmentData = (_frag$initSegment = frag.initSegment) === null || _frag$initSegment === void 0 ? void 0 : _frag$initSegment.data;

        var audioCodec = this._getAudioCodec(currentLevel); // transmux the MPEG-TS data to ISO-BMFF segments
        // this.log(`Transmuxing ${frag.sn} of [${details.startSN} ,${details.endSN}],level ${frag.level}, cc ${frag.cc}`);


        var transmuxer = this.transmuxer = this.transmuxer || new _demux_transmuxer_interface__WEBPACK_IMPORTED_MODULE_8__["default"](this.hls, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this));
        var partIndex = part ? part.index : -1;
        var partial = partIndex !== -1;
        var chunkMeta = new _types_transmuxer__WEBPACK_IMPORTED_MODULE_9__["ChunkMetadata"](frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);
        var initPTS = this.initPTS[frag.cc];
        transmuxer.push(payload, initSegmentData, audioCodec, videoCodec, frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);
      };

      _proto.onAudioTrackSwitching = function onAudioTrackSwitching(event, data) {
        // if any URL found on new audio track, it is an alternate audio track
        var fromAltAudio = this.altAudio;
        var altAudio = !!data.url;
        var trackId = data.id; // if we switch on main audio, ensure that main fragment scheduling is synced with media.buffered
        // don't do anything if we switch to alt audio: audio stream controller is handling it.
        // we will just have to change buffer scheduling on audioTrackSwitched

        if (!altAudio) {
          if (this.mediaBuffer !== this.media) {
            this.log('Switching on main audio, use media.buffered to schedule main fragment loading');
            this.mediaBuffer = this.media;
            var fragCurrent = this.fragCurrent; // we need to refill audio buffer from main: cancel any frag loading to speed up audio switch

            if (fragCurrent !== null && fragCurrent !== void 0 && fragCurrent.loader) {
              this.log('Switching to main audio track, cancel main fragment load');
              fragCurrent.loader.abort();
            } // destroy transmuxer to force init segment generation (following audio switch)


            this.resetTransmuxer(); // switch to IDLE state to load new fragment

            this.resetLoadingState();
          } else if (this.audioOnly) {
            // Reset audio transmuxer so when switching back to main audio we're not still appending where we left off
            this.resetTransmuxer();
          }

          var hls = this.hls; // If switching from alt to main audio, flush all audio and trigger track switched

          if (fromAltAudio) {
            hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].BUFFER_FLUSHING, {
              startOffset: 0,
              endOffset: Number.POSITIVE_INFINITY,
              type: 'audio'
            });
          }

          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].AUDIO_TRACK_SWITCHED, {
            id: trackId
          });
        }
      };

      _proto.onAudioTrackSwitched = function onAudioTrackSwitched(event, data) {
        var trackId = data.id;
        var altAudio = !!this.hls.audioTracks[trackId].url;

        if (altAudio) {
          var videoBuffer = this.videoBuffer; // if we switched on alternate audio, ensure that main fragment scheduling is synced with video sourcebuffer buffered

          if (videoBuffer && this.mediaBuffer !== videoBuffer) {
            this.log('Switching on alternate audio, use video.buffered to schedule main fragment loading');
            this.mediaBuffer = videoBuffer;
          }
        }

        this.altAudio = altAudio;
        this.tick();
      };

      _proto.onBufferCreated = function onBufferCreated(event, data) {
        var tracks = data.tracks;
        var mediaTrack;
        var name;
        var alternate = false;

        for (var type in tracks) {
          var track = tracks[type];

          if (track.id === 'main') {
            name = type;
            mediaTrack = track; // keep video source buffer reference

            if (type === 'video') {
              var videoTrack = tracks[type];

              if (videoTrack) {
                this.videoBuffer = videoTrack.buffer;
              }
            }
          } else {
            alternate = true;
          }
        }

        if (alternate && mediaTrack) {
          this.log("Alternate track found, use " + name + ".buffered to schedule main fragment loading");
          this.mediaBuffer = mediaTrack.buffer;
        } else {
          this.mediaBuffer = this.media;
        }
      };

      _proto.onFragBuffered = function onFragBuffered(event, data) {
        var frag = data.frag,
            part = data.part;

        if (frag && frag.type !== _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN) {
          return;
        }

        if (this.fragContextChanged(frag)) {
          // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion
          // Avoid setting state back to IDLE, since that will interfere with a level switch
          this.warn("Fragment " + frag.sn + (part ? ' p: ' + part.index : '') + " of level " + frag.level + " finished buffering, but was aborted. state: " + this.state);

          if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].PARSED) {
            this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
          }

          return;
        }

        var stats = part ? part.stats : frag.stats;
        this.fragLastKbps = Math.round(8 * stats.total / (stats.buffering.end - stats.loading.first));

        if (frag.sn !== 'initSegment') {
          this.fragPrevious = frag;
        }

        this.fragBufferedComplete(frag, part);
      };

      _proto.onError = function onError(event, data) {
        switch (data.details) {
          case _errors__WEBPACK_IMPORTED_MODULE_11__["ErrorDetails"].FRAG_LOAD_ERROR:
          case _errors__WEBPACK_IMPORTED_MODULE_11__["ErrorDetails"].FRAG_LOAD_TIMEOUT:
          case _errors__WEBPACK_IMPORTED_MODULE_11__["ErrorDetails"].KEY_LOAD_ERROR:
          case _errors__WEBPACK_IMPORTED_MODULE_11__["ErrorDetails"].KEY_LOAD_TIMEOUT:
            this.onFragmentOrKeyLoadError(_types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN, data);
            break;

          case _errors__WEBPACK_IMPORTED_MODULE_11__["ErrorDetails"].LEVEL_LOAD_ERROR:
          case _errors__WEBPACK_IMPORTED_MODULE_11__["ErrorDetails"].LEVEL_LOAD_TIMEOUT:
            if (this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].ERROR) {
              if (data.fatal) {
                // if fatal error, stop processing
                this.warn("" + data.details);
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].ERROR;
              } else {
                // in case of non fatal error while loading level, if level controller is not retrying to load level , switch back to IDLE
                if (!data.levelRetry && this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].WAITING_LEVEL) {
                  this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
                }
              }
            }

            break;

          case _errors__WEBPACK_IMPORTED_MODULE_11__["ErrorDetails"].BUFFER_FULL_ERROR:
            // if in appending state
            if (data.parent === 'main' && (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].PARSING || this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].PARSED)) {
              var flushBuffer = true;
              var bufferedInfo = this.getFwdBufferInfo(this.media, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN); // 0.5 : tolerance needed as some browsers stalls playback before reaching buffered end
              // reduce max buf len if current position is buffered

              if (bufferedInfo && bufferedInfo.len > 0.5) {
                flushBuffer = !this.reduceMaxBufferLength(bufferedInfo.len);
              }

              if (flushBuffer) {
                // current position is not buffered, but browser is still complaining about buffer full error
                // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708
                // in that case flush the whole buffer to recover
                this.warn('buffer full error also media.currentTime is not buffered, flush main'); // flush main buffer

                this.immediateLevelSwitch();
              }

              this.resetLoadingState();
            }

            break;
        }
      } // Checks the health of the buffer and attempts to resolve playback stalls.
      ;

      _proto.checkBuffer = function checkBuffer() {
        var media = this.media,
            gapController = this.gapController;

        if (!media || !gapController || !media.readyState) {
          // Exit early if we don't have media or if the media hasn't buffered anything yet (readyState 0)
          return;
        } // Check combined buffer


        var buffered = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_4__["BufferHelper"].getBuffered(media);

        if (!this.loadedmetadata && buffered.length) {
          this.loadedmetadata = true;
          this.seekToStartPos();
        } else {
          // Resolve gaps using the main buffer, whose ranges are the intersections of the A/V sourcebuffers
          gapController.poll(this.lastCurrentTime);
        }

        this.lastCurrentTime = media.currentTime;
      };

      _proto.onFragLoadEmergencyAborted = function onFragLoadEmergencyAborted() {
        this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE; // if loadedmetadata is not set, it means that we are emergency switch down on first frag
        // in that case, reset startFragRequested flag

        if (!this.loadedmetadata) {
          this.startFragRequested = false;
          this.nextLoadPosition = this.startPosition;
        }

        this.tickImmediate();
      };

      _proto.onBufferFlushed = function onBufferFlushed(event, _ref) {
        var type = _ref.type;

        if (type !== _loader_fragment__WEBPACK_IMPORTED_MODULE_7__["ElementaryStreamTypes"].AUDIO || this.audioOnly && !this.altAudio) {
          var media = (type === _loader_fragment__WEBPACK_IMPORTED_MODULE_7__["ElementaryStreamTypes"].VIDEO ? this.videoBuffer : this.mediaBuffer) || this.media;
          this.afterBufferFlushed(media, type, _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN);
        }
      };

      _proto.onLevelsUpdated = function onLevelsUpdated(event, data) {
        this.levels = data.levels;
      };

      _proto.swapAudioCodec = function swapAudioCodec() {
        this.audioCodecSwap = !this.audioCodecSwap;
      }
      /**
       * Seeks to the set startPosition if not equal to the mediaElement's current time.
       * @private
       */
      ;

      _proto.seekToStartPos = function seekToStartPos() {
        var media = this.media;
        var currentTime = media.currentTime;
        var startPosition = this.startPosition; // only adjust currentTime if different from startPosition or if startPosition not buffered
        // at that stage, there should be only one buffered range, as we reach that code after first fragment has been buffered

        if (startPosition >= 0 && currentTime < startPosition) {
          if (media.seeking) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_12__["logger"].log("could not seek to " + startPosition + ", already seeking at " + currentTime);
            return;
          }

          var buffered = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_4__["BufferHelper"].getBuffered(media);
          var bufferStart = buffered.length ? buffered.start(0) : 0;
          var delta = bufferStart - startPosition;

          if (delta > 0 && (delta < this.config.maxBufferHole || delta < this.config.maxFragLookUpTolerance)) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_12__["logger"].log("adjusting start position by " + delta + " to match buffer start");
            startPosition += delta;
            this.startPosition = startPosition;
          }

          this.log("seek to target start position " + startPosition + " from current time " + currentTime);
          media.currentTime = startPosition;
        }
      };

      _proto._getAudioCodec = function _getAudioCodec(currentLevel) {
        var audioCodec = this.config.defaultAudioCodec || currentLevel.audioCodec;

        if (this.audioCodecSwap && audioCodec) {
          this.log('Swapping audio codec');

          if (audioCodec.indexOf('mp4a.40.5') !== -1) {
            audioCodec = 'mp4a.40.2';
          } else {
            audioCodec = 'mp4a.40.5';
          }
        }

        return audioCodec;
      };

      _proto._loadBitrateTestFrag = function _loadBitrateTestFrag(frag) {
        var _this2 = this;

        this._doFragLoad(frag).then(function (data) {
          var hls = _this2.hls;

          if (!data || hls.nextLoadLevel || _this2.fragContextChanged(frag)) {
            return;
          }

          _this2.fragLoadError = 0;
          _this2.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].IDLE;
          _this2.startFragRequested = false;
          _this2.bitrateTest = false;
          var stats = frag.stats; // Bitrate tests fragments are neither parsed nor buffered

          stats.parsing.start = stats.parsing.end = stats.buffering.start = stats.buffering.end = self.performance.now();
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].FRAG_LOADED, data);
        });
      };

      _proto._handleTransmuxComplete = function _handleTransmuxComplete(transmuxResult) {
        var _id3$samples;

        var id = 'main';
        var hls = this.hls;
        var remuxResult = transmuxResult.remuxResult,
            chunkMeta = transmuxResult.chunkMeta;
        var context = this.getCurrentContext(chunkMeta);

        if (!context) {
          this.warn("The loading context changed while buffering fragment " + chunkMeta.sn + " of level " + chunkMeta.level + ". This chunk will not be buffered.");
          this.resetLiveStartWhenNotLoaded(chunkMeta.level);
          return;
        }

        var frag = context.frag,
            part = context.part,
            level = context.level;
        var video = remuxResult.video,
            text = remuxResult.text,
            id3 = remuxResult.id3,
            initSegment = remuxResult.initSegment; // The audio-stream-controller handles audio buffering if Hls.js is playing an alternate audio track

        var audio = this.altAudio ? undefined : remuxResult.audio; // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.
        // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.

        if (this.fragContextChanged(frag)) {
          return;
        }

        this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].PARSING;

        if (initSegment) {
          if (initSegment.tracks) {
            this._bufferInitSegment(level, initSegment.tracks, frag, chunkMeta);

            hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].FRAG_PARSING_INIT_SEGMENT, {
              frag: frag,
              id: id,
              tracks: initSegment.tracks
            });
          } // This would be nice if Number.isFinite acted as a typeguard, but it doesn't. See: https://github.com/Microsoft/TypeScript/issues/10038


          var initPTS = initSegment.initPTS;
          var timescale = initSegment.timescale;

          if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(initPTS)) {
            this.initPTS[frag.cc] = initPTS;
            hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].INIT_PTS_FOUND, {
              frag: frag,
              id: id,
              initPTS: initPTS,
              timescale: timescale
            });
          }
        } // Avoid buffering if backtracking this fragment


        if (video && remuxResult.independent !== false) {
          if (level.details) {
            var startPTS = video.startPTS,
                endPTS = video.endPTS,
                startDTS = video.startDTS,
                endDTS = video.endDTS;

            if (part) {
              part.elementaryStreams[video.type] = {
                startPTS: startPTS,
                endPTS: endPTS,
                startDTS: startDTS,
                endDTS: endDTS
              };
            } else {
              if (video.firstKeyFrame && video.independent) {
                this.couldBacktrack = true;
              }

              if (video.dropped && video.independent) {
                // Backtrack if dropped frames create a gap after currentTime
                var pos = this.getLoadPosition() + this.config.maxBufferHole;

                if (pos < startPTS) {
                  this.backtrack(frag);
                  return;
                } // Set video stream start to fragment start so that truncated samples do not distort the timeline, and mark it partial


                frag.setElementaryStreamInfo(video.type, frag.start, endPTS, frag.start, endDTS, true);
              }
            }

            frag.setElementaryStreamInfo(video.type, startPTS, endPTS, startDTS, endDTS);
            this.bufferFragmentData(video, frag, part, chunkMeta);
          }
        } else if (remuxResult.independent === false) {
          this.backtrack(frag);
          return;
        }

        if (audio) {
          var _startPTS = audio.startPTS,
              _endPTS = audio.endPTS,
              _startDTS = audio.startDTS,
              _endDTS = audio.endDTS;

          if (part) {
            part.elementaryStreams[_loader_fragment__WEBPACK_IMPORTED_MODULE_7__["ElementaryStreamTypes"].AUDIO] = {
              startPTS: _startPTS,
              endPTS: _endPTS,
              startDTS: _startDTS,
              endDTS: _endDTS
            };
          }

          frag.setElementaryStreamInfo(_loader_fragment__WEBPACK_IMPORTED_MODULE_7__["ElementaryStreamTypes"].AUDIO, _startPTS, _endPTS, _startDTS, _endDTS);
          this.bufferFragmentData(audio, frag, part, chunkMeta);
        }

        if (id3 !== null && id3 !== void 0 && (_id3$samples = id3.samples) !== null && _id3$samples !== void 0 && _id3$samples.length) {
          var emittedID3 = {
            frag: frag,
            id: id,
            samples: id3.samples
          };
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].FRAG_PARSING_METADATA, emittedID3);
        }

        if (text) {
          var emittedText = {
            frag: frag,
            id: id,
            samples: text.samples
          };
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].FRAG_PARSING_USERDATA, emittedText);
        }
      };

      _proto._bufferInitSegment = function _bufferInitSegment(currentLevel, tracks, frag, chunkMeta) {
        var _this3 = this;

        if (this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].PARSING) {
          return;
        }

        this.audioOnly = !!tracks.audio && !tracks.video; // if audio track is expected to come from audio stream controller, discard any coming from main

        if (this.altAudio && !this.audioOnly) {
          delete tracks.audio;
        } // include levelCodec in audio and video tracks


        var audio = tracks.audio,
            video = tracks.video,
            audiovideo = tracks.audiovideo;

        if (audio) {
          var audioCodec = currentLevel.audioCodec;
          var ua = navigator.userAgent.toLowerCase();

          if (this.audioCodecSwitch) {
            if (audioCodec) {
              if (audioCodec.indexOf('mp4a.40.5') !== -1) {
                audioCodec = 'mp4a.40.2';
              } else {
                audioCodec = 'mp4a.40.5';
              }
            } // In the case that AAC and HE-AAC audio codecs are signalled in manifest,
            // force HE-AAC, as it seems that most browsers prefers it.
            // don't force HE-AAC if mono stream, or in Firefox


            if (audio.metadata.channelCount !== 1 && ua.indexOf('firefox') === -1) {
              audioCodec = 'mp4a.40.5';
            }
          } // HE-AAC is broken on Android, always signal audio codec as AAC even if variant manifest states otherwise


          if (ua.indexOf('android') !== -1 && audio.container !== 'audio/mpeg') {
            // Exclude mpeg audio
            audioCodec = 'mp4a.40.2';
            this.log("Android: force audio codec to " + audioCodec);
          }

          if (currentLevel.audioCodec && currentLevel.audioCodec !== audioCodec) {
            this.log("Swapping manifest audio codec \"" + currentLevel.audioCodec + "\" for \"" + audioCodec + "\"");
          }

          audio.levelCodec = audioCodec;
          audio.id = 'main';
          this.log("Init audio buffer, container:" + audio.container + ", codecs[selected/level/parsed]=[" + (audioCodec || '') + "/" + (currentLevel.audioCodec || '') + "/" + audio.codec + "]");
        }

        if (video) {
          video.levelCodec = currentLevel.videoCodec;
          video.id = 'main';
          this.log("Init video buffer, container:" + video.container + ", codecs[level/parsed]=[" + (currentLevel.videoCodec || '') + "/" + video.codec + "]");
        }

        if (audiovideo) {
          this.log("Init audiovideo buffer, container:" + audiovideo.container + ", codecs[level/parsed]=[" + (currentLevel.attrs.CODECS || '') + "/" + audiovideo.codec + "]");
        }

        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].BUFFER_CODECS, tracks); // loop through tracks that are going to be provided to bufferController

        Object.keys(tracks).forEach(function (trackName) {
          var track = tracks[trackName];
          var initSegment = track.initSegment;

          if (initSegment !== null && initSegment !== void 0 && initSegment.byteLength) {
            _this3.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].BUFFER_APPENDING, {
              type: trackName,
              data: initSegment,
              frag: frag,
              part: null,
              chunkMeta: chunkMeta,
              parent: frag.type
            });
          }
        }); // trigger handler right now

        this.tick();
      };

      _proto.backtrack = function backtrack(frag) {
        this.couldBacktrack = true; // Causes findFragments to backtrack through fragments to find the keyframe

        this.resetTransmuxer();
        this.flushBufferGap(frag);
        var data = this.fragmentTracker.backtrack(frag);
        this.fragPrevious = null;
        this.nextLoadPosition = frag.start;

        if (data) {
          this.resetFragmentLoading(frag);
        } else {
          // Change state to BACKTRACKING so that fragmentEntity.backtrack data can be added after _doFragLoad
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["State"].BACKTRACKING;
        }
      };

      _proto.checkFragmentChanged = function checkFragmentChanged() {
        var video = this.media;
        var fragPlayingCurrent = null;

        if (video && video.readyState > 1 && video.seeking === false) {
          var currentTime = video.currentTime;
          /* if video element is in seeked state, currentTime can only increase.
            (assuming that playback rate is positive ...)
            As sometimes currentTime jumps back to zero after a
            media decode error, check this, to avoid seeking back to
            wrong position after a media decode error
          */

          if (_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_4__["BufferHelper"].isBuffered(video, currentTime)) {
            fragPlayingCurrent = this.getAppendedFrag(currentTime);
          } else if (_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_4__["BufferHelper"].isBuffered(video, currentTime + 0.1)) {
            /* ensure that FRAG_CHANGED event is triggered at startup,
              when first video frame is displayed and playback is paused.
              add a tolerance of 100ms, in case current position is not buffered,
              check if current pos+100ms is buffered and use that buffer range
              for FRAG_CHANGED event reporting */
            fragPlayingCurrent = this.getAppendedFrag(currentTime + 0.1);
          }

          if (fragPlayingCurrent) {
            var fragPlaying = this.fragPlaying;
            var fragCurrentLevel = fragPlayingCurrent.level;

            if (!fragPlaying || fragPlayingCurrent.sn !== fragPlaying.sn || fragPlaying.level !== fragCurrentLevel || fragPlayingCurrent.urlId !== fragPlaying.urlId) {
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].FRAG_CHANGED, {
                frag: fragPlayingCurrent
              });

              if (!fragPlaying || fragPlaying.level !== fragCurrentLevel) {
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].LEVEL_SWITCHED, {
                  level: fragCurrentLevel
                });
              }

              this.fragPlaying = fragPlayingCurrent;
            }
          }
        }
      };

      _createClass(StreamController, [{
        key: "nextLevel",
        get: function get() {
          var frag = this.nextBufferedFrag;

          if (frag) {
            return frag.level;
          } else {
            return -1;
          }
        }
      }, {
        key: "currentLevel",
        get: function get() {
          var media = this.media;

          if (media) {
            var fragPlayingCurrent = this.getAppendedFrag(media.currentTime);

            if (fragPlayingCurrent) {
              return fragPlayingCurrent.level;
            }
          }

          return -1;
        }
      }, {
        key: "nextBufferedFrag",
        get: function get() {
          var media = this.media;

          if (media) {
            // first get end range of current fragment
            var fragPlayingCurrent = this.getAppendedFrag(media.currentTime);
            return this.followingBufferedFrag(fragPlayingCurrent);
          } else {
            return null;
          }
        }
      }, {
        key: "forceStartLoad",
        get: function get() {
          return this._forceStartLoad;
        }
      }]);

      return StreamController;
    }(_base_stream_controller__WEBPACK_IMPORTED_MODULE_1__["default"]);



    /***/ }),

    /***/ "./src/controller/subtitle-stream-controller.ts":
    /*!******************************************************!*\
      !*** ./src/controller/subtitle-stream-controller.ts ***!
      \******************************************************/
    /*! exports provided: SubtitleStreamController */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SubtitleStreamController", function() { return SubtitleStreamController; });
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
    /* harmony import */ var _fragment_finders__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./fragment-finders */ "./src/controller/fragment-finders.ts");
    /* harmony import */ var _utils_discontinuities__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/discontinuities */ "./src/utils/discontinuities.ts");
    /* harmony import */ var _level_helper__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./level-helper */ "./src/controller/level-helper.ts");
    /* harmony import */ var _fragment_tracker__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./fragment-tracker */ "./src/controller/fragment-tracker.ts");
    /* harmony import */ var _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./base-stream-controller */ "./src/controller/base-stream-controller.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
    /* harmony import */ var _types_level__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../types/level */ "./src/types/level.ts");
    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }










    var TICK_INTERVAL = 500; // how often to tick in ms

    var SubtitleStreamController = /*#__PURE__*/function (_BaseStreamController) {
      _inheritsLoose(SubtitleStreamController, _BaseStreamController);

      function SubtitleStreamController(hls, fragmentTracker) {
        var _this;

        _this = _BaseStreamController.call(this, hls, fragmentTracker, '[subtitle-stream-controller]') || this;
        _this.levels = [];
        _this.currentTrackId = -1;
        _this.tracksBuffered = [];
        _this.mainDetails = null;

        _this._registerListeners();

        return _this;
      }

      var _proto = SubtitleStreamController.prototype;

      _proto.onHandlerDestroying = function onHandlerDestroying() {
        this._unregisterListeners();

        this.mainDetails = null;
      };

      _proto._registerListeners = function _registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].LEVEL_LOADED, this.onLevelLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, this.onError, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].BUFFER_FLUSHING, this.onBufferFlushing, this);
      };

      _proto._unregisterListeners = function _unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].LEVEL_LOADED, this.onLevelLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, this.onError, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].BUFFER_FLUSHING, this.onBufferFlushing, this);
      };

      _proto.startLoad = function startLoad() {
        this.stopLoad();
        this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__["State"].IDLE;
        this.setInterval(TICK_INTERVAL);
        this.tick();
      };

      _proto.onManifestLoading = function onManifestLoading() {
        this.mainDetails = null;
        this.fragmentTracker.removeAllFragments();
      };

      _proto.onLevelLoaded = function onLevelLoaded(event, data) {
        this.mainDetails = data.details;
      };

      _proto.onSubtitleFragProcessed = function onSubtitleFragProcessed(event, data) {
        var frag = data.frag,
            success = data.success;
        this.fragPrevious = frag;
        this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__["State"].IDLE;

        if (!success) {
          return;
        }

        var buffered = this.tracksBuffered[this.currentTrackId];

        if (!buffered) {
          return;
        } // Create/update a buffered array matching the interface used by BufferHelper.bufferedInfo
        // so we can re-use the logic used to detect how much has been buffered


        var timeRange;
        var fragStart = frag.start;

        for (var i = 0; i < buffered.length; i++) {
          if (fragStart >= buffered[i].start && fragStart <= buffered[i].end) {
            timeRange = buffered[i];
            break;
          }
        }

        var fragEnd = frag.start + frag.duration;

        if (timeRange) {
          timeRange.end = fragEnd;
        } else {
          timeRange = {
            start: fragStart,
            end: fragEnd
          };
          buffered.push(timeRange);
        }

        this.fragmentTracker.fragBuffered(frag);
      };

      _proto.onBufferFlushing = function onBufferFlushing(event, data) {
        var startOffset = data.startOffset,
            endOffset = data.endOffset;

        if (startOffset === 0 && endOffset !== Number.POSITIVE_INFINITY) {
          var currentTrackId = this.currentTrackId,
              levels = this.levels;

          if (!levels.length || !levels[currentTrackId] || !levels[currentTrackId].details) {
            return;
          }

          var trackDetails = levels[currentTrackId].details;
          var targetDuration = trackDetails.targetduration;
          var endOffsetSubtitles = endOffset - targetDuration;

          if (endOffsetSubtitles <= 0) {
            return;
          }

          data.endOffsetSubtitles = Math.max(0, endOffsetSubtitles);
          this.tracksBuffered.forEach(function (buffered) {
            for (var i = 0; i < buffered.length;) {
              if (buffered[i].end <= endOffsetSubtitles) {
                buffered.shift();
                continue;
              } else if (buffered[i].start < endOffsetSubtitles) {
                buffered[i].start = endOffsetSubtitles;
              } else {
                break;
              }

              i++;
            }
          });
          this.fragmentTracker.removeFragmentsInRange(startOffset, endOffsetSubtitles, _types_loader__WEBPACK_IMPORTED_MODULE_7__["PlaylistLevelType"].SUBTITLE);
        }
      } // If something goes wrong, proceed to next frag, if we were processing one.
      ;

      _proto.onError = function onError(event, data) {
        var _this$fragCurrent;

        var frag = data.frag; // don't handle error not related to subtitle fragment

        if (!frag || frag.type !== _types_loader__WEBPACK_IMPORTED_MODULE_7__["PlaylistLevelType"].SUBTITLE) {
          return;
        }

        if ((_this$fragCurrent = this.fragCurrent) !== null && _this$fragCurrent !== void 0 && _this$fragCurrent.loader) {
          this.fragCurrent.loader.abort();
        }

        this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__["State"].IDLE;
      } // Got all new subtitle levels.
      ;

      _proto.onSubtitleTracksUpdated = function onSubtitleTracksUpdated(event, _ref) {
        var _this2 = this;

        var subtitleTracks = _ref.subtitleTracks;
        this.tracksBuffered = [];
        this.levels = subtitleTracks.map(function (mediaPlaylist) {
          return new _types_level__WEBPACK_IMPORTED_MODULE_8__["Level"](mediaPlaylist);
        });
        this.fragmentTracker.removeAllFragments();
        this.fragPrevious = null;
        this.levels.forEach(function (level) {
          _this2.tracksBuffered[level.id] = [];
        });
        this.mediaBuffer = null;
      };

      _proto.onSubtitleTrackSwitch = function onSubtitleTrackSwitch(event, data) {
        this.currentTrackId = data.id;

        if (!this.levels.length || this.currentTrackId === -1) {
          this.clearInterval();
          return;
        } // Check if track has the necessary details to load fragments


        var currentTrack = this.levels[this.currentTrackId];

        if (currentTrack !== null && currentTrack !== void 0 && currentTrack.details) {
          this.mediaBuffer = this.mediaBufferTimeRanges;
        } else {
          this.mediaBuffer = null;
        }

        if (currentTrack) {
          this.setInterval(TICK_INTERVAL);
        }
      } // Got a new set of subtitle fragments.
      ;

      _proto.onSubtitleTrackLoaded = function onSubtitleTrackLoaded(event, data) {
        var _track$details;

        var newDetails = data.details,
            trackId = data.id;
        var currentTrackId = this.currentTrackId,
            levels = this.levels;

        if (!levels.length) {
          return;
        }

        var track = levels[currentTrackId];

        if (trackId >= levels.length || trackId !== currentTrackId || !track) {
          return;
        }

        this.mediaBuffer = this.mediaBufferTimeRanges;

        if (newDetails.live || (_track$details = track.details) !== null && _track$details !== void 0 && _track$details.live) {
          var mainDetails = this.mainDetails;

          if (newDetails.deltaUpdateFailed || !mainDetails) {
            return;
          }

          var mainSlidingStartFragment = mainDetails.fragments[0];

          if (!track.details) {
            if (newDetails.hasProgramDateTime && mainDetails.hasProgramDateTime) {
              Object(_utils_discontinuities__WEBPACK_IMPORTED_MODULE_3__["alignMediaPlaylistByPDT"])(newDetails, mainDetails);
            } else if (mainSlidingStartFragment) {
              // line up live playlist with main so that fragments in range are loaded
              Object(_level_helper__WEBPACK_IMPORTED_MODULE_4__["addSliding"])(newDetails, mainSlidingStartFragment.start);
            }
          } else {
            var sliding = this.alignPlaylists(newDetails, track.details);

            if (sliding === 0 && mainSlidingStartFragment) {
              // realign with main when there is no overlap with last refresh
              Object(_level_helper__WEBPACK_IMPORTED_MODULE_4__["addSliding"])(newDetails, mainSlidingStartFragment.start);
            }
          }
        }

        track.details = newDetails;
        this.levelLastLoaded = trackId; // trigger handler right now

        this.tick(); // If playlist is misaligned because of bad PDT or drift, delete details to resync with main on reload

        if (newDetails.live && !this.fragCurrent && this.media && this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__["State"].IDLE) {
          var foundFrag = Object(_fragment_finders__WEBPACK_IMPORTED_MODULE_2__["findFragmentByPTS"])(null, newDetails.fragments, this.media.currentTime, 0);

          if (!foundFrag) {
            this.warn('Subtitle playlist not aligned with playback');
            track.details = undefined;
          }
        }
      };

      _proto._handleFragmentLoadComplete = function _handleFragmentLoadComplete(fragLoadedData) {
        var frag = fragLoadedData.frag,
            payload = fragLoadedData.payload;
        var decryptData = frag.decryptdata;
        var hls = this.hls;

        if (this.fragContextChanged(frag)) {
          return;
        } // check to see if the payload needs to be decrypted


        if (payload && payload.byteLength > 0 && decryptData && decryptData.key && decryptData.iv && decryptData.method === 'AES-128') {
          var startTime = performance.now(); // decrypt the subtitles

          this.decrypter.webCryptoDecrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer).then(function (decryptedData) {
            var endTime = performance.now();
            hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].FRAG_DECRYPTED, {
              frag: frag,
              payload: decryptedData,
              stats: {
                tstart: startTime,
                tdecrypt: endTime
              }
            });
          });
        }
      };

      _proto.doTick = function doTick() {
        if (!this.media) {
          this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__["State"].IDLE;
          return;
        }

        if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__["State"].IDLE) {
          var _foundFrag;

          var currentTrackId = this.currentTrackId,
              levels = this.levels;

          if (!levels.length || !levels[currentTrackId] || !levels[currentTrackId].details) {
            return;
          } // Expand range of subs loaded by one target-duration in either direction to make up for misaligned playlists


          var trackDetails = levels[currentTrackId].details;
          var targetDuration = trackDetails.targetduration;
          var config = this.config,
              media = this.media;
          var bufferedInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_1__["BufferHelper"].bufferedInfo(this.mediaBufferTimeRanges, media.currentTime - targetDuration, config.maxBufferHole);
          var targetBufferTime = bufferedInfo.end,
              bufferLen = bufferedInfo.len;
          var maxBufLen = this.getMaxBufferLength() + targetDuration;

          if (bufferLen > maxBufLen) {
            return;
          }

          console.assert(trackDetails, 'Subtitle track details are defined on idle subtitle stream controller tick');
          var fragments = trackDetails.fragments;
          var fragLen = fragments.length;
          var end = trackDetails.edge;
          var foundFrag;
          var fragPrevious = this.fragPrevious;

          if (targetBufferTime < end) {
            var maxFragLookUpTolerance = config.maxFragLookUpTolerance;
            foundFrag = Object(_fragment_finders__WEBPACK_IMPORTED_MODULE_2__["findFragmentByPTS"])(fragPrevious, fragments, targetBufferTime, maxFragLookUpTolerance);

            if (!foundFrag && fragPrevious && fragPrevious.start < fragments[0].start) {
              foundFrag = fragments[0];
            }
          } else {
            foundFrag = fragments[fragLen - 1];
          }

          if ((_foundFrag = foundFrag) !== null && _foundFrag !== void 0 && _foundFrag.encrypted) {
            this.loadKey(foundFrag, trackDetails);
          } else if (foundFrag && this.fragmentTracker.getState(foundFrag) === _fragment_tracker__WEBPACK_IMPORTED_MODULE_5__["FragmentState"].NOT_LOADED) {
            // only load if fragment is not loaded
            this.loadFragment(foundFrag, trackDetails, targetBufferTime);
          }
        }
      };

      _proto.loadFragment = function loadFragment(frag, levelDetails, targetBufferTime) {
        this.fragCurrent = frag;

        _BaseStreamController.prototype.loadFragment.call(this, frag, levelDetails, targetBufferTime);
      };

      _createClass(SubtitleStreamController, [{
        key: "mediaBufferTimeRanges",
        get: function get() {
          return this.tracksBuffered[this.currentTrackId] || [];
        }
      }]);

      return SubtitleStreamController;
    }(_base_stream_controller__WEBPACK_IMPORTED_MODULE_6__["default"]);

    /***/ }),

    /***/ "./src/controller/subtitle-track-controller.ts":
    /*!*****************************************************!*\
      !*** ./src/controller/subtitle-track-controller.ts ***!
      \*****************************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/texttrack-utils */ "./src/utils/texttrack-utils.ts");
    /* harmony import */ var _base_playlist_controller__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./base-playlist-controller */ "./src/controller/base-playlist-controller.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }






    var SubtitleTrackController = /*#__PURE__*/function (_BasePlaylistControll) {
      _inheritsLoose(SubtitleTrackController, _BasePlaylistControll);

      // Enable/disable subtitle display rendering
      function SubtitleTrackController(hls) {
        var _this;

        _this = _BasePlaylistControll.call(this, hls, '[subtitle-track-controller]') || this;
        _this.media = null;
        _this.tracks = [];
        _this.groupId = null;
        _this.tracksInGroup = [];
        _this.trackId = -1;
        _this.selectDefaultTrack = true;
        _this.queuedDefaultTrack = -1;

        _this.trackChangeListener = function () {
          return _this.onTextTracksChanged();
        };

        _this.asyncPollTrackChange = function () {
          return _this.pollTrackChange(0);
        };

        _this.useTextTrackPolling = false;
        _this.subtitlePollingInterval = -1;
        _this.subtitleDisplay = true;

        _this.registerListeners();

        return _this;
      }

      var _proto = SubtitleTrackController.prototype;

      _proto.destroy = function destroy() {
        this.unregisterListeners();
        this.tracks.length = 0;
        this.tracksInGroup.length = 0;
        this.trackChangeListener = this.asyncPollTrackChange = null;

        _BasePlaylistControll.prototype.destroy.call(this);
      };

      _proto.registerListeners = function registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].LEVEL_LOADING, this.onLevelLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].LEVEL_SWITCHING, this.onLevelSwitching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, this.onError, this);
      };

      _proto.unregisterListeners = function unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_ATTACHED, this.onMediaAttached, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].MANIFEST_PARSED, this.onManifestParsed, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].LEVEL_LOADING, this.onLevelLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].LEVEL_SWITCHING, this.onLevelSwitching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, this.onError, this);
      } // Listen for subtitle track change, then extract the current track ID.
      ;

      _proto.onMediaAttached = function onMediaAttached(event, data) {
        this.media = data.media;

        if (!this.media) {
          return;
        }

        if (this.queuedDefaultTrack > -1) {
          this.subtitleTrack = this.queuedDefaultTrack;
          this.queuedDefaultTrack = -1;
        }

        this.useTextTrackPolling = !(this.media.textTracks && 'onchange' in this.media.textTracks);

        if (this.useTextTrackPolling) {
          this.pollTrackChange(500);
        } else {
          this.media.textTracks.addEventListener('change', this.asyncPollTrackChange);
        }
      };

      _proto.pollTrackChange = function pollTrackChange(timeout) {
        self.clearInterval(this.subtitlePollingInterval);
        this.subtitlePollingInterval = self.setInterval(this.trackChangeListener, timeout);
      };

      _proto.onMediaDetaching = function onMediaDetaching() {
        if (!this.media) {
          return;
        }

        self.clearInterval(this.subtitlePollingInterval);

        if (!this.useTextTrackPolling) {
          this.media.textTracks.removeEventListener('change', this.asyncPollTrackChange);
        }

        if (this.trackId > -1) {
          this.queuedDefaultTrack = this.trackId;
        }

        var textTracks = filterSubtitleTracks(this.media.textTracks); // Clear loaded cues on media detachment from tracks

        textTracks.forEach(function (track) {
          Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__["clearCurrentCues"])(track);
        }); // Disable all subtitle tracks before detachment so when reattached only tracks in that content are enabled.

        this.subtitleTrack = -1;
        this.media = null;
      };

      _proto.onManifestLoading = function onManifestLoading() {
        this.tracks = [];
        this.groupId = null;
        this.tracksInGroup = [];
        this.trackId = -1;
        this.selectDefaultTrack = true;
      } // Fired whenever a new manifest is loaded.
      ;

      _proto.onManifestParsed = function onManifestParsed(event, data) {
        this.tracks = data.subtitleTracks;
      };

      _proto.onSubtitleTrackLoaded = function onSubtitleTrackLoaded(event, data) {
        var id = data.id,
            details = data.details;
        var trackId = this.trackId;
        var currentTrack = this.tracksInGroup[trackId];

        if (!currentTrack) {
          this.warn("Invalid subtitle track id " + id);
          return;
        }

        var curDetails = currentTrack.details;
        currentTrack.details = data.details;
        this.log("subtitle track " + id + " loaded [" + details.startSN + "-" + details.endSN + "]");

        if (id === this.trackId) {
          this.retryCount = 0;
          this.playlistLoaded(id, data, curDetails);
        }
      };

      _proto.onLevelLoading = function onLevelLoading(event, data) {
        this.switchLevel(data.level);
      };

      _proto.onLevelSwitching = function onLevelSwitching(event, data) {
        this.switchLevel(data.level);
      };

      _proto.switchLevel = function switchLevel(levelIndex) {
        var levelInfo = this.hls.levels[levelIndex];

        if (!(levelInfo !== null && levelInfo !== void 0 && levelInfo.textGroupIds)) {
          return;
        }

        var textGroupId = levelInfo.textGroupIds[levelInfo.urlId];

        if (this.groupId !== textGroupId) {
          var lastTrack = this.tracksInGroup ? this.tracksInGroup[this.trackId] : undefined;
          var subtitleTracks = this.tracks.filter(function (track) {
            return !textGroupId || track.groupId === textGroupId;
          });
          this.tracksInGroup = subtitleTracks;
          var initialTrackId = this.findTrackId(lastTrack === null || lastTrack === void 0 ? void 0 : lastTrack.name) || this.findTrackId();
          this.groupId = textGroupId;
          var subtitleTracksUpdated = {
            subtitleTracks: subtitleTracks
          };
          this.log("Updating subtitle tracks, " + subtitleTracks.length + " track(s) found in \"" + textGroupId + "\" group-id");
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACKS_UPDATED, subtitleTracksUpdated);

          if (initialTrackId !== -1) {
            this.setSubtitleTrack(initialTrackId, lastTrack);
          }
        }
      };

      _proto.findTrackId = function findTrackId(name) {
        var textTracks = this.tracksInGroup;

        for (var i = 0; i < textTracks.length; i++) {
          var track = textTracks[i];

          if (!this.selectDefaultTrack || track.default) {
            if (!name || name === track.name) {
              return track.id;
            }
          }
        }

        return -1;
      };

      _proto.onError = function onError(event, data) {
        _BasePlaylistControll.prototype.onError.call(this, event, data);

        if (data.fatal || !data.context) {
          return;
        }

        if (data.context.type === _types_loader__WEBPACK_IMPORTED_MODULE_3__["PlaylistContextType"].SUBTITLE_TRACK && data.context.id === this.trackId && data.context.groupId === this.groupId) {
          this.retryLoadingOrFail(data);
        }
      }
      /** get alternate subtitle tracks list from playlist **/
      ;

      _proto.loadPlaylist = function loadPlaylist(hlsUrlParameters) {
        var currentTrack = this.tracksInGroup[this.trackId];

        if (this.shouldLoadTrack(currentTrack)) {
          var id = currentTrack.id;
          var groupId = currentTrack.groupId;
          var url = currentTrack.url;

          if (hlsUrlParameters) {
            try {
              url = hlsUrlParameters.addDirectives(url);
            } catch (error) {
              this.warn("Could not construct new URL with HLS Delivery Directives: " + error);
            }
          }

          this.log("Loading subtitle playlist for id " + id);
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACK_LOADING, {
            url: url,
            id: id,
            groupId: groupId,
            deliveryDirectives: hlsUrlParameters || null
          });
        }
      }
      /**
       * Disables the old subtitleTrack and sets current mode on the next subtitleTrack.
       * This operates on the DOM textTracks.
       * A value of -1 will disable all subtitle tracks.
       */
      ;

      _proto.toggleTrackModes = function toggleTrackModes(newId) {
        var _this2 = this;

        var media = this.media,
            subtitleDisplay = this.subtitleDisplay,
            trackId = this.trackId;

        if (!media) {
          return;
        }

        var textTracks = filterSubtitleTracks(media.textTracks);
        var groupTracks = textTracks.filter(function (track) {
          return track.groupId === _this2.groupId;
        });

        if (newId === -1) {
          [].slice.call(textTracks).forEach(function (track) {
            track.mode = 'disabled';
          });
        } else {
          var oldTrack = groupTracks[trackId];

          if (oldTrack) {
            oldTrack.mode = 'disabled';
          }
        }

        var nextTrack = groupTracks[newId];

        if (nextTrack) {
          nextTrack.mode = subtitleDisplay ? 'showing' : 'hidden';
        }
      }
      /**
       * This method is responsible for validating the subtitle index and periodically reloading if live.
       * Dispatches the SUBTITLE_TRACK_SWITCH event, which instructs the subtitle-stream-controller to load the selected track.
       */
      ;

      _proto.setSubtitleTrack = function setSubtitleTrack(newId, lastTrack) {
        var _tracks$newId;

        var tracks = this.tracksInGroup; // setting this.subtitleTrack will trigger internal logic
        // if media has not been attached yet, it will fail
        // we keep a reference to the default track id
        // and we'll set subtitleTrack when onMediaAttached is triggered

        if (!this.media) {
          this.queuedDefaultTrack = newId;
          return;
        }

        if (this.trackId !== newId) {
          this.toggleTrackModes(newId);
        } // exit if track id as already set or invalid


        if (this.trackId === newId && (newId === -1 || (_tracks$newId = tracks[newId]) !== null && _tracks$newId !== void 0 && _tracks$newId.details) || newId < -1 || newId >= tracks.length) {
          return;
        } // stopping live reloading timer if any


        this.clearTimer();
        var track = tracks[newId];
        this.log("Switching to subtitle track " + newId);
        this.trackId = newId;

        if (track) {
          var id = track.id,
              _track$groupId = track.groupId,
              groupId = _track$groupId === void 0 ? '' : _track$groupId,
              name = track.name,
              type = track.type,
              url = track.url;
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACK_SWITCH, {
            id: id,
            groupId: groupId,
            name: name,
            type: type,
            url: url
          });
          var hlsUrlParameters = this.switchParams(track.url, lastTrack === null || lastTrack === void 0 ? void 0 : lastTrack.details);
          this.loadPlaylist(hlsUrlParameters);
        } else {
          // switch to -1
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].SUBTITLE_TRACK_SWITCH, {
            id: newId
          });
        }
      };

      _proto.onTextTracksChanged = function onTextTracksChanged() {
        if (!this.useTextTrackPolling) {
          self.clearInterval(this.subtitlePollingInterval);
        } // Media is undefined when switching streams via loadSource()


        if (!this.media || !this.hls.config.renderTextTracksNatively) {
          return;
        }

        var trackId = -1;
        var tracks = filterSubtitleTracks(this.media.textTracks);

        for (var id = 0; id < tracks.length; id++) {
          if (tracks[id].mode === 'hidden') {
            // Do not break in case there is a following track with showing.
            trackId = id;
          } else if (tracks[id].mode === 'showing') {
            trackId = id;
            break;
          }
        } // Setting current subtitleTrack will invoke code.


        if (this.subtitleTrack !== trackId) {
          this.subtitleTrack = trackId;
        }
      };

      _createClass(SubtitleTrackController, [{
        key: "subtitleTracks",
        get: function get() {
          return this.tracksInGroup;
        }
        /** get/set index of the selected subtitle track (based on index in subtitle track lists) **/

      }, {
        key: "subtitleTrack",
        get: function get() {
          return this.trackId;
        },
        set: function set(newId) {
          this.selectDefaultTrack = false;
          var lastTrack = this.tracksInGroup ? this.tracksInGroup[this.trackId] : undefined;
          this.setSubtitleTrack(newId, lastTrack);
        }
      }]);

      return SubtitleTrackController;
    }(_base_playlist_controller__WEBPACK_IMPORTED_MODULE_2__["default"]);

    function filterSubtitleTracks(textTrackList) {
      var tracks = [];

      for (var i = 0; i < textTrackList.length; i++) {
        var track = textTrackList[i]; // Edge adds a track without a label; we don't want to use it

        if (track.kind === 'subtitles' && track.label) {
          tracks.push(textTrackList[i]);
        }
      }

      return tracks;
    }

    /* harmony default export */ __webpack_exports__["default"] = (SubtitleTrackController);

    /***/ }),

    /***/ "./src/controller/timeline-controller.ts":
    /*!***********************************************!*\
      !*** ./src/controller/timeline-controller.ts ***!
      \***********************************************/
    /*! exports provided: TimelineController */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TimelineController", function() { return TimelineController; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_cea_608_parser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/cea-608-parser */ "./src/utils/cea-608-parser.ts");
    /* harmony import */ var _utils_output_filter__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/output-filter */ "./src/utils/output-filter.ts");
    /* harmony import */ var _utils_webvtt_parser__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/webvtt-parser */ "./src/utils/webvtt-parser.ts");
    /* harmony import */ var _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/texttrack-utils */ "./src/utils/texttrack-utils.ts");
    /* harmony import */ var _utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../utils/imsc1-ttml-parser */ "./src/utils/imsc1-ttml-parser.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");










    var TimelineController = /*#__PURE__*/function () {
      function TimelineController(hls) {
        this.hls = void 0;
        this.media = null;
        this.config = void 0;
        this.enabled = true;
        this.Cues = void 0;
        this.textTracks = [];
        this.tracks = [];
        this.initPTS = [];
        this.timescale = [];
        this.unparsedVttFrags = [];
        this.captionsTracks = {};
        this.nonNativeCaptionsTracks = {};
        this.cea608Parser1 = void 0;
        this.cea608Parser2 = void 0;
        this.lastSn = -1;
        this.lastPartIndex = -1;
        this.prevCC = -1;
        this.vttCCs = newVTTCCs();
        this.captionsProperties = void 0;
        this.hls = hls;
        this.config = hls.config;
        this.Cues = hls.config.cueHandler;
        this.captionsProperties = {
          textTrack1: {
            label: this.config.captionsTextTrack1Label,
            languageCode: this.config.captionsTextTrack1LanguageCode
          },
          textTrack2: {
            label: this.config.captionsTextTrack2Label,
            languageCode: this.config.captionsTextTrack2LanguageCode
          },
          textTrack3: {
            label: this.config.captionsTextTrack3Label,
            languageCode: this.config.captionsTextTrack3LanguageCode
          },
          textTrack4: {
            label: this.config.captionsTextTrack4Label,
            languageCode: this.config.captionsTextTrack4LanguageCode
          }
        };

        if (this.config.enableCEA708Captions) {
          var channel1 = new _utils_output_filter__WEBPACK_IMPORTED_MODULE_3__["default"](this, 'textTrack1');
          var channel2 = new _utils_output_filter__WEBPACK_IMPORTED_MODULE_3__["default"](this, 'textTrack2');
          var channel3 = new _utils_output_filter__WEBPACK_IMPORTED_MODULE_3__["default"](this, 'textTrack3');
          var channel4 = new _utils_output_filter__WEBPACK_IMPORTED_MODULE_3__["default"](this, 'textTrack4');
          this.cea608Parser1 = new _utils_cea_608_parser__WEBPACK_IMPORTED_MODULE_2__["default"](1, channel1, channel2);
          this.cea608Parser2 = new _utils_cea_608_parser__WEBPACK_IMPORTED_MODULE_2__["default"](3, channel3, channel4);
        }

        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_ATTACHING, this.onMediaAttaching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADED, this.onManifestLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_LOADING, this.onFragLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_LOADED, this.onFragLoaded, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_DECRYPTED, this.onFragDecrypted, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].INIT_PTS_FOUND, this.onInitPtsFound, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_FLUSHING, this.onBufferFlushing, this);
      }

      var _proto = TimelineController.prototype;

      _proto.destroy = function destroy() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_ATTACHING, this.onMediaAttaching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MEDIA_DETACHING, this.onMediaDetaching, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADED, this.onManifestLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_LOADING, this.onFragLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_LOADED, this.onFragLoaded, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_DECRYPTED, this.onFragDecrypted, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].INIT_PTS_FOUND, this.onInitPtsFound, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].BUFFER_FLUSHING, this.onBufferFlushing, this); // @ts-ignore

        this.hls = this.config = this.cea608Parser1 = this.cea608Parser2 = null;
      };

      _proto.addCues = function addCues(trackName, startTime, endTime, screen, cueRanges) {
        // skip cues which overlap more than 50% with previously parsed time ranges
        var merged = false;

        for (var i = cueRanges.length; i--;) {
          var cueRange = cueRanges[i];
          var overlap = intersection(cueRange[0], cueRange[1], startTime, endTime);

          if (overlap >= 0) {
            cueRange[0] = Math.min(cueRange[0], startTime);
            cueRange[1] = Math.max(cueRange[1], endTime);
            merged = true;

            if (overlap / (endTime - startTime) > 0.5) {
              return;
            }
          }
        }

        if (!merged) {
          cueRanges.push([startTime, endTime]);
        }

        if (this.config.renderTextTracksNatively) {
          var track = this.captionsTracks[trackName];
          this.Cues.newCue(track, startTime, endTime, screen);
        } else {
          var cues = this.Cues.newCue(null, startTime, endTime, screen);
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].CUES_PARSED, {
            type: 'captions',
            cues: cues,
            track: trackName
          });
        }
      } // Triggered when an initial PTS is found; used for synchronisation of WebVTT.
      ;

      _proto.onInitPtsFound = function onInitPtsFound(event, _ref) {
        var _this = this;

        var frag = _ref.frag,
            id = _ref.id,
            initPTS = _ref.initPTS,
            timescale = _ref.timescale;
        var unparsedVttFrags = this.unparsedVttFrags;

        if (id === 'main') {
          this.initPTS[frag.cc] = initPTS;
          this.timescale[frag.cc] = timescale;
        } // Due to asynchronous processing, initial PTS may arrive later than the first VTT fragments are loaded.
        // Parse any unparsed fragments upon receiving the initial PTS.


        if (unparsedVttFrags.length) {
          this.unparsedVttFrags = [];
          unparsedVttFrags.forEach(function (frag) {
            _this.onFragLoaded(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_LOADED, frag);
          });
        }
      };

      _proto.getExistingTrack = function getExistingTrack(trackName) {
        var media = this.media;

        if (media) {
          for (var i = 0; i < media.textTracks.length; i++) {
            var textTrack = media.textTracks[i];

            if (textTrack[trackName]) {
              return textTrack;
            }
          }
        }

        return null;
      };

      _proto.createCaptionsTrack = function createCaptionsTrack(trackName) {
        if (this.config.renderTextTracksNatively) {
          this.createNativeTrack(trackName);
        } else {
          this.createNonNativeTrack(trackName);
        }
      };

      _proto.createNativeTrack = function createNativeTrack(trackName) {
        if (this.captionsTracks[trackName]) {
          return;
        }

        var captionsProperties = this.captionsProperties,
            captionsTracks = this.captionsTracks,
            media = this.media;
        var _captionsProperties$t = captionsProperties[trackName],
            label = _captionsProperties$t.label,
            languageCode = _captionsProperties$t.languageCode; // Enable reuse of existing text track.

        var existingTrack = this.getExistingTrack(trackName);

        if (!existingTrack) {
          var textTrack = this.createTextTrack('captions', label, languageCode);

          if (textTrack) {
            // Set a special property on the track so we know it's managed by Hls.js
            textTrack[trackName] = true;
            captionsTracks[trackName] = textTrack;
          }
        } else {
          captionsTracks[trackName] = existingTrack;
          Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_5__["clearCurrentCues"])(captionsTracks[trackName]);
          Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_5__["sendAddTrackEvent"])(captionsTracks[trackName], media);
        }
      };

      _proto.createNonNativeTrack = function createNonNativeTrack(trackName) {
        if (this.nonNativeCaptionsTracks[trackName]) {
          return;
        } // Create a list of a single track for the provider to consume


        var trackProperties = this.captionsProperties[trackName];

        if (!trackProperties) {
          return;
        }

        var label = trackProperties.label;
        var track = {
          _id: trackName,
          label: label,
          kind: 'captions',
          default: trackProperties.media ? !!trackProperties.media.default : false,
          closedCaptions: trackProperties.media
        };
        this.nonNativeCaptionsTracks[trackName] = track;
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].NON_NATIVE_TEXT_TRACKS_FOUND, {
          tracks: [track]
        });
      };

      _proto.createTextTrack = function createTextTrack(kind, label, lang) {
        var media = this.media;

        if (!media) {
          return;
        }

        return media.addTextTrack(kind, label, lang);
      };

      _proto.onMediaAttaching = function onMediaAttaching(event, data) {
        this.media = data.media;

        this._cleanTracks();
      };

      _proto.onMediaDetaching = function onMediaDetaching() {
        var captionsTracks = this.captionsTracks;
        Object.keys(captionsTracks).forEach(function (trackName) {
          Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_5__["clearCurrentCues"])(captionsTracks[trackName]);
          delete captionsTracks[trackName];
        });
        this.nonNativeCaptionsTracks = {};
      };

      _proto.onManifestLoading = function onManifestLoading() {
        this.lastSn = -1; // Detect discontinuity in fragment parsing

        this.lastPartIndex = -1;
        this.prevCC = -1;
        this.vttCCs = newVTTCCs(); // Detect discontinuity in subtitle manifests

        this._cleanTracks();

        this.tracks = [];
        this.captionsTracks = {};
        this.nonNativeCaptionsTracks = {};
        this.textTracks = [];
        this.unparsedVttFrags = this.unparsedVttFrags || [];
        this.initPTS = [];
        this.timescale = [];

        if (this.cea608Parser1 && this.cea608Parser2) {
          this.cea608Parser1.reset();
          this.cea608Parser2.reset();
        }
      };

      _proto._cleanTracks = function _cleanTracks() {
        // clear outdated subtitles
        var media = this.media;

        if (!media) {
          return;
        }

        var textTracks = media.textTracks;

        if (textTracks) {
          for (var i = 0; i < textTracks.length; i++) {
            Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_5__["clearCurrentCues"])(textTracks[i]);
          }
        }
      };

      _proto.onSubtitleTracksUpdated = function onSubtitleTracksUpdated(event, data) {
        var _this2 = this;

        this.textTracks = [];
        var tracks = data.subtitleTracks || [];
        var hasIMSC1 = tracks.some(function (track) {
          return track.textCodec === _utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_6__["IMSC1_CODEC"];
        });

        if (this.config.enableWebVTT || hasIMSC1 && this.config.enableIMSC1) {
          var sameTracks = this.tracks && tracks && this.tracks.length === tracks.length;
          this.tracks = tracks || [];

          if (this.config.renderTextTracksNatively) {
            var inUseTracks = this.media ? this.media.textTracks : [];
            this.tracks.forEach(function (track, index) {
              var textTrack;

              if (index < inUseTracks.length) {
                var inUseTrack = null;

                for (var i = 0; i < inUseTracks.length; i++) {
                  if (canReuseVttTextTrack(inUseTracks[i], track)) {
                    inUseTrack = inUseTracks[i];
                    break;
                  }
                } // Reuse tracks with the same label, but do not reuse 608/708 tracks


                if (inUseTrack) {
                  textTrack = inUseTrack;
                }
              }

              if (textTrack) {
                Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_5__["clearCurrentCues"])(textTrack);
              } else {
                textTrack = _this2.createTextTrack('subtitles', track.name, track.lang);

                if (textTrack) {
                  textTrack.mode = 'disabled';
                }
              }

              if (textTrack) {
                textTrack.groupId = track.groupId;

                _this2.textTracks.push(textTrack);
              }
            });
          } else if (!sameTracks && this.tracks && this.tracks.length) {
            // Create a list of tracks for the provider to consume
            var tracksList = this.tracks.map(function (track) {
              return {
                label: track.name,
                kind: track.type.toLowerCase(),
                default: track.default,
                subtitleTrack: track
              };
            });
            this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].NON_NATIVE_TEXT_TRACKS_FOUND, {
              tracks: tracksList
            });
          }
        }
      };

      _proto.onManifestLoaded = function onManifestLoaded(event, data) {
        var _this3 = this;

        if (this.config.enableCEA708Captions && data.captions) {
          data.captions.forEach(function (captionsTrack) {
            var instreamIdMatch = /(?:CC|SERVICE)([1-4])/.exec(captionsTrack.instreamId);

            if (!instreamIdMatch) {
              return;
            }

            var trackName = "textTrack" + instreamIdMatch[1];
            var trackProperties = _this3.captionsProperties[trackName];

            if (!trackProperties) {
              return;
            }

            trackProperties.label = captionsTrack.name;

            if (captionsTrack.lang) {
              // optional attribute
              trackProperties.languageCode = captionsTrack.lang;
            }

            trackProperties.media = captionsTrack;
          });
        }
      };

      _proto.onFragLoading = function onFragLoading(event, data) {
        var cea608Parser1 = this.cea608Parser1,
            cea608Parser2 = this.cea608Parser2,
            lastSn = this.lastSn,
            lastPartIndex = this.lastPartIndex;

        if (!this.enabled || !(cea608Parser1 && cea608Parser2)) {
          return;
        } // if this frag isn't contiguous, clear the parser so cues with bad start/end times aren't added to the textTrack


        if (data.frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_7__["PlaylistLevelType"].MAIN) {
          var _data$part$index, _data$part;

          var sn = data.frag.sn;
          var partIndex = (_data$part$index = data === null || data === void 0 ? void 0 : (_data$part = data.part) === null || _data$part === void 0 ? void 0 : _data$part.index) != null ? _data$part$index : -1;

          if (!(sn === lastSn + 1 || sn === lastSn && partIndex === lastPartIndex + 1)) {
            cea608Parser1.reset();
            cea608Parser2.reset();
          }

          this.lastSn = sn;
          this.lastPartIndex = partIndex;
        }
      };

      _proto.onFragLoaded = function onFragLoaded(event, data) {
        var frag = data.frag,
            payload = data.payload;
        var initPTS = this.initPTS,
            unparsedVttFrags = this.unparsedVttFrags;

        if (frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_7__["PlaylistLevelType"].SUBTITLE) {
          // If fragment is subtitle type, parse as WebVTT.
          if (payload.byteLength) {
            // We need an initial synchronisation PTS. Store fragments as long as none has arrived.
            if (!Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(initPTS[frag.cc])) {
              unparsedVttFrags.push(data);

              if (initPTS.length) {
                // finish unsuccessfully, otherwise the subtitle-stream-controller could be blocked from loading new frags.
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_FRAG_PROCESSED, {
                  success: false,
                  frag: frag,
                  error: new Error('Missing initial subtitle PTS')
                });
              }

              return;
            }

            var decryptData = frag.decryptdata; // fragment after decryption has a stats object

            var decrypted = ('stats' in data); // If the subtitles are not encrypted, parse VTTs now. Otherwise, we need to wait.

            if (decryptData == null || decryptData.key == null || decryptData.method !== 'AES-128' || decrypted) {
              var trackPlaylistMedia = this.tracks[frag.level];
              var vttCCs = this.vttCCs;

              if (!vttCCs[frag.cc]) {
                vttCCs[frag.cc] = {
                  start: frag.start,
                  prevCC: this.prevCC,
                  new: true
                };
                this.prevCC = frag.cc;
              }

              if (trackPlaylistMedia && trackPlaylistMedia.textCodec === _utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_6__["IMSC1_CODEC"]) {
                this._parseIMSC1(frag, payload);
              } else {
                this._parseVTTs(frag, payload, vttCCs);
              }
            }
          } else {
            // In case there is no payload, finish unsuccessfully.
            this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_FRAG_PROCESSED, {
              success: false,
              frag: frag,
              error: new Error('Empty subtitle payload')
            });
          }
        }
      };

      _proto._parseIMSC1 = function _parseIMSC1(frag, payload) {
        var _this4 = this;

        var hls = this.hls;
        Object(_utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_6__["parseIMSC1"])(payload, this.initPTS[frag.cc], this.timescale[frag.cc], function (cues) {
          _this4._appendCues(cues, frag.level);

          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_FRAG_PROCESSED, {
            success: true,
            frag: frag
          });
        }, function (error) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_8__["logger"].log("Failed to parse IMSC1: " + error);
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_FRAG_PROCESSED, {
            success: false,
            frag: frag,
            error: error
          });
        });
      };

      _proto._parseVTTs = function _parseVTTs(frag, payload, vttCCs) {
        var _this5 = this;

        var hls = this.hls; // Parse the WebVTT file contents.

        Object(_utils_webvtt_parser__WEBPACK_IMPORTED_MODULE_4__["parseWebVTT"])(payload, this.initPTS[frag.cc], this.timescale[frag.cc], vttCCs, frag.cc, frag.start, function (cues) {
          _this5._appendCues(cues, frag.level);

          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_FRAG_PROCESSED, {
            success: true,
            frag: frag
          });
        }, function (error) {
          _this5._fallbackToIMSC1(frag, payload); // Something went wrong while parsing. Trigger event with success false.


          _utils_logger__WEBPACK_IMPORTED_MODULE_8__["logger"].log("Failed to parse VTT cue: " + error);
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_FRAG_PROCESSED, {
            success: false,
            frag: frag,
            error: error
          });
        });
      };

      _proto._fallbackToIMSC1 = function _fallbackToIMSC1(frag, payload) {
        var _this6 = this;

        // If textCodec is unknown, try parsing as IMSC1. Set textCodec based on the result
        var trackPlaylistMedia = this.tracks[frag.level];

        if (!trackPlaylistMedia.textCodec) {
          Object(_utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_6__["parseIMSC1"])(payload, this.initPTS[frag.cc], this.timescale[frag.cc], function () {
            trackPlaylistMedia.textCodec = _utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_6__["IMSC1_CODEC"];

            _this6._parseIMSC1(frag, payload);
          }, function () {
            trackPlaylistMedia.textCodec = 'wvtt';
          });
        }
      };

      _proto._appendCues = function _appendCues(cues, fragLevel) {
        var hls = this.hls;

        if (this.config.renderTextTracksNatively) {
          var textTrack = this.textTracks[fragLevel]; // WebVTTParser.parse is an async method and if the currently selected text track mode is set to "disabled"
          // before parsing is done then don't try to access currentTrack.cues.getCueById as cues will be null
          // and trying to access getCueById method of cues will throw an exception
          // Because we check if the mode is disabled, we can force check `cues` below. They can't be null.

          if (textTrack.mode === 'disabled') {
            return;
          }

          cues.forEach(function (cue) {
            return Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_5__["addCueToTrack"])(textTrack, cue);
          });
        } else {
          var currentTrack = this.tracks[fragLevel];
          var track = currentTrack.default ? 'default' : 'subtitles' + fragLevel;
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].CUES_PARSED, {
            type: 'subtitles',
            cues: cues,
            track: track
          });
        }
      };

      _proto.onFragDecrypted = function onFragDecrypted(event, data) {
        var frag = data.frag;

        if (frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_7__["PlaylistLevelType"].SUBTITLE) {
          if (!Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(this.initPTS[frag.cc])) {
            this.unparsedVttFrags.push(data);
            return;
          }

          this.onFragLoaded(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_LOADED, data);
        }
      };

      _proto.onSubtitleTracksCleared = function onSubtitleTracksCleared() {
        this.tracks = [];
        this.captionsTracks = {};
      };

      _proto.onFragParsingUserdata = function onFragParsingUserdata(event, data) {
        var cea608Parser1 = this.cea608Parser1,
            cea608Parser2 = this.cea608Parser2;

        if (!this.enabled || !(cea608Parser1 && cea608Parser2)) {
          return;
        } // If the event contains captions (found in the bytes property), push all bytes into the parser immediately
        // It will create the proper timestamps based on the PTS value


        for (var i = 0; i < data.samples.length; i++) {
          var ccBytes = data.samples[i].bytes;

          if (ccBytes) {
            var ccdatas = this.extractCea608Data(ccBytes);
            cea608Parser1.addData(data.samples[i].pts, ccdatas[0]);
            cea608Parser2.addData(data.samples[i].pts, ccdatas[1]);
          }
        }
      };

      _proto.onBufferFlushing = function onBufferFlushing(event, _ref2) {
        var startOffset = _ref2.startOffset,
            endOffset = _ref2.endOffset,
            endOffsetSubtitles = _ref2.endOffsetSubtitles,
            type = _ref2.type;
        var media = this.media;

        if (!media || media.currentTime < endOffset) {
          return;
        } // Clear 608 caption cues from the captions TextTracks when the video back buffer is flushed
        // Forward cues are never removed because we can loose streamed 608 content from recent fragments


        if (!type || type === 'video') {
          var captionsTracks = this.captionsTracks;
          Object.keys(captionsTracks).forEach(function (trackName) {
            return Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_5__["removeCuesInRange"])(captionsTracks[trackName], startOffset, endOffset);
          });
        }

        if (this.config.renderTextTracksNatively) {
          // Clear VTT/IMSC1 subtitle cues from the subtitle TextTracks when the back buffer is flushed
          if (startOffset === 0 && endOffsetSubtitles !== undefined) {
            var textTracks = this.textTracks;
            Object.keys(textTracks).forEach(function (trackName) {
              return Object(_utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_5__["removeCuesInRange"])(textTracks[trackName], startOffset, endOffsetSubtitles);
            });
          }
        }
      };

      _proto.extractCea608Data = function extractCea608Data(byteArray) {
        var count = byteArray[0] & 31;
        var position = 2;
        var actualCCBytes = [[], []];

        for (var j = 0; j < count; j++) {
          var tmpByte = byteArray[position++];
          var ccbyte1 = 0x7f & byteArray[position++];
          var ccbyte2 = 0x7f & byteArray[position++];
          var ccValid = (4 & tmpByte) !== 0;
          var ccType = 3 & tmpByte;

          if (ccbyte1 === 0 && ccbyte2 === 0) {
            continue;
          }

          if (ccValid) {
            if (ccType === 0 || ccType === 1) {
              actualCCBytes[ccType].push(ccbyte1);
              actualCCBytes[ccType].push(ccbyte2);
            }
          }
        }

        return actualCCBytes;
      };

      return TimelineController;
    }();

    function canReuseVttTextTrack(inUseTrack, manifestTrack) {
      return inUseTrack && inUseTrack.label === manifestTrack.name && !(inUseTrack.textTrack1 || inUseTrack.textTrack2);
    }

    function intersection(x1, x2, y1, y2) {
      return Math.min(x2, y2) - Math.max(x1, y1);
    }

    function newVTTCCs() {
      return {
        ccOffset: 0,
        presentationOffset: 0,
        0: {
          start: 0,
          prevCC: -1,
          new: false
        }
      };
    }

    /***/ }),

    /***/ "./src/crypt/aes-crypto.ts":
    /*!*********************************!*\
      !*** ./src/crypt/aes-crypto.ts ***!
      \*********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return AESCrypto; });
    var AESCrypto = /*#__PURE__*/function () {
      function AESCrypto(subtle, iv) {
        this.subtle = void 0;
        this.aesIV = void 0;
        this.subtle = subtle;
        this.aesIV = iv;
      }

      var _proto = AESCrypto.prototype;

      _proto.decrypt = function decrypt(data, key) {
        return this.subtle.decrypt({
          name: 'AES-CBC',
          iv: this.aesIV
        }, key, data);
      };

      return AESCrypto;
    }();



    /***/ }),

    /***/ "./src/crypt/aes-decryptor.ts":
    /*!************************************!*\
      !*** ./src/crypt/aes-decryptor.ts ***!
      \************************************/
    /*! exports provided: removePadding, default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "removePadding", function() { return removePadding; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return AESDecryptor; });
    /* harmony import */ var _utils_typed_array__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/typed-array */ "./src/utils/typed-array.ts");
     // PKCS7

    function removePadding(array) {
      var outputBytes = array.byteLength;
      var paddingBytes = outputBytes && new DataView(array.buffer).getUint8(outputBytes - 1);

      if (paddingBytes) {
        return Object(_utils_typed_array__WEBPACK_IMPORTED_MODULE_0__["sliceUint8"])(array, 0, outputBytes - paddingBytes);
      }

      return array;
    }

    var AESDecryptor = /*#__PURE__*/function () {
      function AESDecryptor() {
        this.rcon = [0x0, 0x1, 0x2, 0x4, 0x8, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36];
        this.subMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];
        this.invSubMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];
        this.sBox = new Uint32Array(256);
        this.invSBox = new Uint32Array(256);
        this.key = new Uint32Array(0);
        this.ksRows = 0;
        this.keySize = 0;
        this.keySchedule = void 0;
        this.invKeySchedule = void 0;
        this.initTable();
      } // Using view.getUint32() also swaps the byte order.


      var _proto = AESDecryptor.prototype;

      _proto.uint8ArrayToUint32Array_ = function uint8ArrayToUint32Array_(arrayBuffer) {
        var view = new DataView(arrayBuffer);
        var newArray = new Uint32Array(4);

        for (var i = 0; i < 4; i++) {
          newArray[i] = view.getUint32(i * 4);
        }

        return newArray;
      };

      _proto.initTable = function initTable() {
        var sBox = this.sBox;
        var invSBox = this.invSBox;
        var subMix = this.subMix;
        var subMix0 = subMix[0];
        var subMix1 = subMix[1];
        var subMix2 = subMix[2];
        var subMix3 = subMix[3];
        var invSubMix = this.invSubMix;
        var invSubMix0 = invSubMix[0];
        var invSubMix1 = invSubMix[1];
        var invSubMix2 = invSubMix[2];
        var invSubMix3 = invSubMix[3];
        var d = new Uint32Array(256);
        var x = 0;
        var xi = 0;
        var i = 0;

        for (i = 0; i < 256; i++) {
          if (i < 128) {
            d[i] = i << 1;
          } else {
            d[i] = i << 1 ^ 0x11b;
          }
        }

        for (i = 0; i < 256; i++) {
          var sx = xi ^ xi << 1 ^ xi << 2 ^ xi << 3 ^ xi << 4;
          sx = sx >>> 8 ^ sx & 0xff ^ 0x63;
          sBox[x] = sx;
          invSBox[sx] = x; // Compute multiplication

          var x2 = d[x];
          var x4 = d[x2];
          var x8 = d[x4]; // Compute sub/invSub bytes, mix columns tables

          var t = d[sx] * 0x101 ^ sx * 0x1010100;
          subMix0[x] = t << 24 | t >>> 8;
          subMix1[x] = t << 16 | t >>> 16;
          subMix2[x] = t << 8 | t >>> 24;
          subMix3[x] = t; // Compute inv sub bytes, inv mix columns tables

          t = x8 * 0x1010101 ^ x4 * 0x10001 ^ x2 * 0x101 ^ x * 0x1010100;
          invSubMix0[sx] = t << 24 | t >>> 8;
          invSubMix1[sx] = t << 16 | t >>> 16;
          invSubMix2[sx] = t << 8 | t >>> 24;
          invSubMix3[sx] = t; // Compute next counter

          if (!x) {
            x = xi = 1;
          } else {
            x = x2 ^ d[d[d[x8 ^ x2]]];
            xi ^= d[d[xi]];
          }
        }
      };

      _proto.expandKey = function expandKey(keyBuffer) {
        // convert keyBuffer to Uint32Array
        var key = this.uint8ArrayToUint32Array_(keyBuffer);
        var sameKey = true;
        var offset = 0;

        while (offset < key.length && sameKey) {
          sameKey = key[offset] === this.key[offset];
          offset++;
        }

        if (sameKey) {
          return;
        }

        this.key = key;
        var keySize = this.keySize = key.length;

        if (keySize !== 4 && keySize !== 6 && keySize !== 8) {
          throw new Error('Invalid aes key size=' + keySize);
        }

        var ksRows = this.ksRows = (keySize + 6 + 1) * 4;
        var ksRow;
        var invKsRow;
        var keySchedule = this.keySchedule = new Uint32Array(ksRows);
        var invKeySchedule = this.invKeySchedule = new Uint32Array(ksRows);
        var sbox = this.sBox;
        var rcon = this.rcon;
        var invSubMix = this.invSubMix;
        var invSubMix0 = invSubMix[0];
        var invSubMix1 = invSubMix[1];
        var invSubMix2 = invSubMix[2];
        var invSubMix3 = invSubMix[3];
        var prev;
        var t;

        for (ksRow = 0; ksRow < ksRows; ksRow++) {
          if (ksRow < keySize) {
            prev = keySchedule[ksRow] = key[ksRow];
            continue;
          }

          t = prev;

          if (ksRow % keySize === 0) {
            // Rot word
            t = t << 8 | t >>> 24; // Sub word

            t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff]; // Mix Rcon

            t ^= rcon[ksRow / keySize | 0] << 24;
          } else if (keySize > 6 && ksRow % keySize === 4) {
            // Sub word
            t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];
          }

          keySchedule[ksRow] = prev = (keySchedule[ksRow - keySize] ^ t) >>> 0;
        }

        for (invKsRow = 0; invKsRow < ksRows; invKsRow++) {
          ksRow = ksRows - invKsRow;

          if (invKsRow & 3) {
            t = keySchedule[ksRow];
          } else {
            t = keySchedule[ksRow - 4];
          }

          if (invKsRow < 4 || ksRow <= 4) {
            invKeySchedule[invKsRow] = t;
          } else {
            invKeySchedule[invKsRow] = invSubMix0[sbox[t >>> 24]] ^ invSubMix1[sbox[t >>> 16 & 0xff]] ^ invSubMix2[sbox[t >>> 8 & 0xff]] ^ invSubMix3[sbox[t & 0xff]];
          }

          invKeySchedule[invKsRow] = invKeySchedule[invKsRow] >>> 0;
        }
      } // Adding this as a method greatly improves performance.
      ;

      _proto.networkToHostOrderSwap = function networkToHostOrderSwap(word) {
        return word << 24 | (word & 0xff00) << 8 | (word & 0xff0000) >> 8 | word >>> 24;
      };

      _proto.decrypt = function decrypt(inputArrayBuffer, offset, aesIV) {
        var nRounds = this.keySize + 6;
        var invKeySchedule = this.invKeySchedule;
        var invSBOX = this.invSBox;
        var invSubMix = this.invSubMix;
        var invSubMix0 = invSubMix[0];
        var invSubMix1 = invSubMix[1];
        var invSubMix2 = invSubMix[2];
        var invSubMix3 = invSubMix[3];
        var initVector = this.uint8ArrayToUint32Array_(aesIV);
        var initVector0 = initVector[0];
        var initVector1 = initVector[1];
        var initVector2 = initVector[2];
        var initVector3 = initVector[3];
        var inputInt32 = new Int32Array(inputArrayBuffer);
        var outputInt32 = new Int32Array(inputInt32.length);
        var t0, t1, t2, t3;
        var s0, s1, s2, s3;
        var inputWords0, inputWords1, inputWords2, inputWords3;
        var ksRow, i;
        var swapWord = this.networkToHostOrderSwap;

        while (offset < inputInt32.length) {
          inputWords0 = swapWord(inputInt32[offset]);
          inputWords1 = swapWord(inputInt32[offset + 1]);
          inputWords2 = swapWord(inputInt32[offset + 2]);
          inputWords3 = swapWord(inputInt32[offset + 3]);
          s0 = inputWords0 ^ invKeySchedule[0];
          s1 = inputWords3 ^ invKeySchedule[1];
          s2 = inputWords2 ^ invKeySchedule[2];
          s3 = inputWords1 ^ invKeySchedule[3];
          ksRow = 4; // Iterate through the rounds of decryption

          for (i = 1; i < nRounds; i++) {
            t0 = invSubMix0[s0 >>> 24] ^ invSubMix1[s1 >> 16 & 0xff] ^ invSubMix2[s2 >> 8 & 0xff] ^ invSubMix3[s3 & 0xff] ^ invKeySchedule[ksRow];
            t1 = invSubMix0[s1 >>> 24] ^ invSubMix1[s2 >> 16 & 0xff] ^ invSubMix2[s3 >> 8 & 0xff] ^ invSubMix3[s0 & 0xff] ^ invKeySchedule[ksRow + 1];
            t2 = invSubMix0[s2 >>> 24] ^ invSubMix1[s3 >> 16 & 0xff] ^ invSubMix2[s0 >> 8 & 0xff] ^ invSubMix3[s1 & 0xff] ^ invKeySchedule[ksRow + 2];
            t3 = invSubMix0[s3 >>> 24] ^ invSubMix1[s0 >> 16 & 0xff] ^ invSubMix2[s1 >> 8 & 0xff] ^ invSubMix3[s2 & 0xff] ^ invKeySchedule[ksRow + 3]; // Update state

            s0 = t0;
            s1 = t1;
            s2 = t2;
            s3 = t3;
            ksRow = ksRow + 4;
          } // Shift rows, sub bytes, add round key


          t0 = invSBOX[s0 >>> 24] << 24 ^ invSBOX[s1 >> 16 & 0xff] << 16 ^ invSBOX[s2 >> 8 & 0xff] << 8 ^ invSBOX[s3 & 0xff] ^ invKeySchedule[ksRow];
          t1 = invSBOX[s1 >>> 24] << 24 ^ invSBOX[s2 >> 16 & 0xff] << 16 ^ invSBOX[s3 >> 8 & 0xff] << 8 ^ invSBOX[s0 & 0xff] ^ invKeySchedule[ksRow + 1];
          t2 = invSBOX[s2 >>> 24] << 24 ^ invSBOX[s3 >> 16 & 0xff] << 16 ^ invSBOX[s0 >> 8 & 0xff] << 8 ^ invSBOX[s1 & 0xff] ^ invKeySchedule[ksRow + 2];
          t3 = invSBOX[s3 >>> 24] << 24 ^ invSBOX[s0 >> 16 & 0xff] << 16 ^ invSBOX[s1 >> 8 & 0xff] << 8 ^ invSBOX[s2 & 0xff] ^ invKeySchedule[ksRow + 3]; // Write

          outputInt32[offset] = swapWord(t0 ^ initVector0);
          outputInt32[offset + 1] = swapWord(t3 ^ initVector1);
          outputInt32[offset + 2] = swapWord(t2 ^ initVector2);
          outputInt32[offset + 3] = swapWord(t1 ^ initVector3); // reset initVector to last 4 unsigned int

          initVector0 = inputWords0;
          initVector1 = inputWords1;
          initVector2 = inputWords2;
          initVector3 = inputWords3;
          offset = offset + 4;
        }

        return outputInt32.buffer;
      };

      return AESDecryptor;
    }();



    /***/ }),

    /***/ "./src/crypt/decrypter.ts":
    /*!********************************!*\
      !*** ./src/crypt/decrypter.ts ***!
      \********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return Decrypter; });
    /* harmony import */ var _aes_crypto__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./aes-crypto */ "./src/crypt/aes-crypto.ts");
    /* harmony import */ var _fast_aes_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./fast-aes-key */ "./src/crypt/fast-aes-key.ts");
    /* harmony import */ var _aes_decryptor__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./aes-decryptor */ "./src/crypt/aes-decryptor.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
    /* harmony import */ var _utils_typed_array__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/typed-array */ "./src/utils/typed-array.ts");






    var CHUNK_SIZE = 16; // 16 bytes, 128 bits

    var Decrypter = /*#__PURE__*/function () {
      function Decrypter(observer, config, _temp) {
        var _ref = _temp === void 0 ? {} : _temp,
            _ref$removePKCS7Paddi = _ref.removePKCS7Padding,
            removePKCS7Padding = _ref$removePKCS7Paddi === void 0 ? true : _ref$removePKCS7Paddi;

        this.logEnabled = true;
        this.observer = void 0;
        this.config = void 0;
        this.removePKCS7Padding = void 0;
        this.subtle = null;
        this.softwareDecrypter = null;
        this.key = null;
        this.fastAesKey = null;
        this.remainderData = null;
        this.currentIV = null;
        this.currentResult = null;
        this.observer = observer;
        this.config = config;
        this.removePKCS7Padding = removePKCS7Padding; // built in decryptor expects PKCS7 padding

        if (removePKCS7Padding) {
          try {
            var browserCrypto = self.crypto;

            if (browserCrypto) {
              this.subtle = browserCrypto.subtle || browserCrypto.webkitSubtle;
            }
          } catch (e) {
            /* no-op */
          }
        }

        if (this.subtle === null) {
          this.config.enableSoftwareAES = true;
        }
      }

      var _proto = Decrypter.prototype;

      _proto.destroy = function destroy() {
        // @ts-ignore
        this.observer = null;
      };

      _proto.isSync = function isSync() {
        return this.config.enableSoftwareAES;
      };

      _proto.flush = function flush() {
        var currentResult = this.currentResult;

        if (!currentResult) {
          this.reset();
          return;
        }

        var data = new Uint8Array(currentResult);
        this.reset();

        if (this.removePKCS7Padding) {
          return Object(_aes_decryptor__WEBPACK_IMPORTED_MODULE_2__["removePadding"])(data);
        }

        return data;
      };

      _proto.reset = function reset() {
        this.currentResult = null;
        this.currentIV = null;
        this.remainderData = null;

        if (this.softwareDecrypter) {
          this.softwareDecrypter = null;
        }
      };

      _proto.decrypt = function decrypt(data, key, iv, callback) {
        if (this.config.enableSoftwareAES) {
          this.softwareDecrypt(new Uint8Array(data), key, iv);
          var decryptResult = this.flush();

          if (decryptResult) {
            callback(decryptResult.buffer);
          }
        } else {
          this.webCryptoDecrypt(new Uint8Array(data), key, iv).then(callback);
        }
      };

      _proto.softwareDecrypt = function softwareDecrypt(data, key, iv) {
        var currentIV = this.currentIV,
            currentResult = this.currentResult,
            remainderData = this.remainderData;
        this.logOnce('JS AES decrypt'); // The output is staggered during progressive parsing - the current result is cached, and emitted on the next call
        // This is done in order to strip PKCS7 padding, which is found at the end of each segment. We only know we've reached
        // the end on flush(), but by that time we have already received all bytes for the segment.
        // Progressive decryption does not work with WebCrypto

        if (remainderData) {
          data = Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_4__["appendUint8Array"])(remainderData, data);
          this.remainderData = null;
        } // Byte length must be a multiple of 16 (AES-128 = 128 bit blocks = 16 bytes)


        var currentChunk = this.getValidChunk(data);

        if (!currentChunk.length) {
          return null;
        }

        if (currentIV) {
          iv = currentIV;
        }

        var softwareDecrypter = this.softwareDecrypter;

        if (!softwareDecrypter) {
          softwareDecrypter = this.softwareDecrypter = new _aes_decryptor__WEBPACK_IMPORTED_MODULE_2__["default"]();
        }

        softwareDecrypter.expandKey(key);
        var result = currentResult;
        this.currentResult = softwareDecrypter.decrypt(currentChunk.buffer, 0, iv);
        this.currentIV = Object(_utils_typed_array__WEBPACK_IMPORTED_MODULE_5__["sliceUint8"])(currentChunk, -16).buffer;

        if (!result) {
          return null;
        }

        return result;
      };

      _proto.webCryptoDecrypt = function webCryptoDecrypt(data, key, iv) {
        var _this = this;

        var subtle = this.subtle;

        if (this.key !== key || !this.fastAesKey) {
          this.key = key;
          this.fastAesKey = new _fast_aes_key__WEBPACK_IMPORTED_MODULE_1__["default"](subtle, key);
        }

        return this.fastAesKey.expandKey().then(function (aesKey) {
          // decrypt using web crypto
          if (!subtle) {
            return Promise.reject(new Error('web crypto not initialized'));
          }

          var crypto = new _aes_crypto__WEBPACK_IMPORTED_MODULE_0__["default"](subtle, iv);
          return crypto.decrypt(data.buffer, aesKey);
        }).catch(function (err) {
          return _this.onWebCryptoError(err, data, key, iv);
        });
      };

      _proto.onWebCryptoError = function onWebCryptoError(err, data, key, iv) {
        _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn('[decrypter.ts]: WebCrypto Error, disable WebCrypto API:', err);
        this.config.enableSoftwareAES = true;
        this.logEnabled = true;
        return this.softwareDecrypt(data, key, iv);
      };

      _proto.getValidChunk = function getValidChunk(data) {
        var currentChunk = data;
        var splitPoint = data.length - data.length % CHUNK_SIZE;

        if (splitPoint !== data.length) {
          currentChunk = Object(_utils_typed_array__WEBPACK_IMPORTED_MODULE_5__["sliceUint8"])(data, 0, splitPoint);
          this.remainderData = Object(_utils_typed_array__WEBPACK_IMPORTED_MODULE_5__["sliceUint8"])(data, splitPoint);
        }

        return currentChunk;
      };

      _proto.logOnce = function logOnce(msg) {
        if (!this.logEnabled) {
          return;
        }

        _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].log("[decrypter.ts]: " + msg);
        this.logEnabled = false;
      };

      return Decrypter;
    }();



    /***/ }),

    /***/ "./src/crypt/fast-aes-key.ts":
    /*!***********************************!*\
      !*** ./src/crypt/fast-aes-key.ts ***!
      \***********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return FastAESKey; });
    var FastAESKey = /*#__PURE__*/function () {
      function FastAESKey(subtle, key) {
        this.subtle = void 0;
        this.key = void 0;
        this.subtle = subtle;
        this.key = key;
      }

      var _proto = FastAESKey.prototype;

      _proto.expandKey = function expandKey() {
        return this.subtle.importKey('raw', this.key, {
          name: 'AES-CBC'
        }, false, ['encrypt', 'decrypt']);
      };

      return FastAESKey;
    }();



    /***/ }),

    /***/ "./src/demux/aacdemuxer.ts":
    /*!*********************************!*\
      !*** ./src/demux/aacdemuxer.ts ***!
      \*********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _base_audio_demuxer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base-audio-demuxer */ "./src/demux/base-audio-demuxer.ts");
    /* harmony import */ var _adts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./adts */ "./src/demux/adts.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }

    /**
     * AAC demuxer
     */





    var AACDemuxer = /*#__PURE__*/function (_BaseAudioDemuxer) {
      _inheritsLoose(AACDemuxer, _BaseAudioDemuxer);

      function AACDemuxer(observer, config) {
        var _this;

        _this = _BaseAudioDemuxer.call(this) || this;
        _this.observer = void 0;
        _this.config = void 0;
        _this.observer = observer;
        _this.config = config;
        return _this;
      }

      var _proto = AACDemuxer.prototype;

      _proto.resetInitSegment = function resetInitSegment(audioCodec, videoCodec, duration) {
        _BaseAudioDemuxer.prototype.resetInitSegment.call(this, audioCodec, videoCodec, duration);

        this._audioTrack = {
          container: 'audio/adts',
          type: 'audio',
          id: 2,
          pid: -1,
          sequenceNumber: 0,
          isAAC: true,
          samples: [],
          manifestCodec: audioCodec,
          duration: duration,
          inputTimeScale: 90000,
          dropped: 0
        };
      } // Source for probe info - https://wiki.multimedia.cx/index.php?title=ADTS
      ;

      AACDemuxer.probe = function probe(data) {
        if (!data) {
          return false;
        } // Check for the ADTS sync word
        // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1
        // Layer bits (position 14 and 15) in header should be always 0 for ADTS
        // More info https://wiki.multimedia.cx/index.php?title=ADTS


        var id3Data = _demux_id3__WEBPACK_IMPORTED_MODULE_3__["getID3Data"](data, 0) || [];
        var offset = id3Data.length;

        for (var length = data.length; offset < length; offset++) {
          if (_adts__WEBPACK_IMPORTED_MODULE_1__["probe"](data, offset)) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('ADTS sync word found !');
            return true;
          }
        }

        return false;
      };

      _proto.canParse = function canParse(data, offset) {
        return _adts__WEBPACK_IMPORTED_MODULE_1__["canParse"](data, offset);
      };

      _proto.appendFrame = function appendFrame(track, data, offset) {
        _adts__WEBPACK_IMPORTED_MODULE_1__["initTrackConfig"](track, this.observer, data, offset, track.manifestCodec);
        var frame = _adts__WEBPACK_IMPORTED_MODULE_1__["appendFrame"](track, data, offset, this.initPTS, this.frameIndex);

        if (frame && frame.missing === 0) {
          return frame;
        }
      };

      return AACDemuxer;
    }(_base_audio_demuxer__WEBPACK_IMPORTED_MODULE_0__["default"]);

    AACDemuxer.minProbeByteLength = 9;
    /* harmony default export */ __webpack_exports__["default"] = (AACDemuxer);

    /***/ }),

    /***/ "./src/demux/adts.ts":
    /*!***************************!*\
      !*** ./src/demux/adts.ts ***!
      \***************************/
    /*! exports provided: getAudioConfig, isHeaderPattern, getHeaderLength, getFullFrameLength, canGetFrameLength, isHeader, canParse, probe, initTrackConfig, getFrameDuration, parseFrameHeader, appendFrame */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getAudioConfig", function() { return getAudioConfig; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isHeaderPattern", function() { return isHeaderPattern; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getHeaderLength", function() { return getHeaderLength; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getFullFrameLength", function() { return getFullFrameLength; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "canGetFrameLength", function() { return canGetFrameLength; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isHeader", function() { return isHeader; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "canParse", function() { return canParse; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "probe", function() { return probe; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "initTrackConfig", function() { return initTrackConfig; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getFrameDuration", function() { return getFrameDuration; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parseFrameHeader", function() { return parseFrameHeader; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "appendFrame", function() { return appendFrame; });
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /**
     * ADTS parser helper
     * @link https://wiki.multimedia.cx/index.php?title=ADTS
     */



    function getAudioConfig(observer, data, offset, audioCodec) {
      var adtsObjectType;
      var adtsExtensionSamplingIndex;
      var adtsChanelConfig;
      var config;
      var userAgent = navigator.userAgent.toLowerCase();
      var manifestCodec = audioCodec;
      var adtsSampleingRates = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350]; // byte 2

      adtsObjectType = ((data[offset + 2] & 0xc0) >>> 6) + 1;
      var adtsSamplingIndex = (data[offset + 2] & 0x3c) >>> 2;

      if (adtsSamplingIndex > adtsSampleingRates.length - 1) {
        observer.trigger(_events__WEBPACK_IMPORTED_MODULE_2__["Events"].ERROR, {
          type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].MEDIA_ERROR,
          details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].FRAG_PARSING_ERROR,
          fatal: true,
          reason: "invalid ADTS sampling index:" + adtsSamplingIndex
        });
        return;
      }

      adtsChanelConfig = (data[offset + 2] & 0x01) << 2; // byte 3

      adtsChanelConfig |= (data[offset + 3] & 0xc0) >>> 6;
      _utils_logger__WEBPACK_IMPORTED_MODULE_0__["logger"].log("manifest codec:" + audioCodec + ", ADTS type:" + adtsObjectType + ", samplingIndex:" + adtsSamplingIndex); // firefox: freq less than 24kHz = AAC SBR (HE-AAC)

      if (/firefox/i.test(userAgent)) {
        if (adtsSamplingIndex >= 6) {
          adtsObjectType = 5;
          config = new Array(4); // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies
          // there is a factor 2 between frame sample rate and output sample rate
          // multiply frequency by 2 (see table below, equivalent to substract 3)

          adtsExtensionSamplingIndex = adtsSamplingIndex - 3;
        } else {
          adtsObjectType = 2;
          config = new Array(2);
          adtsExtensionSamplingIndex = adtsSamplingIndex;
        } // Android : always use AAC

      } else if (userAgent.indexOf('android') !== -1) {
        adtsObjectType = 2;
        config = new Array(2);
        adtsExtensionSamplingIndex = adtsSamplingIndex;
      } else {
        /*  for other browsers (Chrome/Vivaldi/Opera ...)
            always force audio type to be HE-AAC SBR, as some browsers do not support audio codec switch properly (like Chrome ...)
        */
        adtsObjectType = 5;
        config = new Array(4); // if (manifest codec is HE-AAC or HE-AACv2) OR (manifest codec not specified AND frequency less than 24kHz)

        if (audioCodec && (audioCodec.indexOf('mp4a.40.29') !== -1 || audioCodec.indexOf('mp4a.40.5') !== -1) || !audioCodec && adtsSamplingIndex >= 6) {
          // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies
          // there is a factor 2 between frame sample rate and output sample rate
          // multiply frequency by 2 (see table below, equivalent to substract 3)
          adtsExtensionSamplingIndex = adtsSamplingIndex - 3;
        } else {
          // if (manifest codec is AAC) AND (frequency less than 24kHz AND nb channel is 1) OR (manifest codec not specified and mono audio)
          // Chrome fails to play back with low frequency AAC LC mono when initialized with HE-AAC.  This is not a problem with stereo.
          if (audioCodec && audioCodec.indexOf('mp4a.40.2') !== -1 && (adtsSamplingIndex >= 6 && adtsChanelConfig === 1 || /vivaldi/i.test(userAgent)) || !audioCodec && adtsChanelConfig === 1) {
            adtsObjectType = 2;
            config = new Array(2);
          }

          adtsExtensionSamplingIndex = adtsSamplingIndex;
        }
      }
      /* refer to http://wiki.multimedia.cx/index.php?title=MPEG-4_Audio#Audio_Specific_Config
          ISO 14496-3 (AAC).pdf - Table 1.13 — Syntax of AudioSpecificConfig()
        Audio Profile / Audio Object Type
        0: Null
        1: AAC Main
        2: AAC LC (Low Complexity)
        3: AAC SSR (Scalable Sample Rate)
        4: AAC LTP (Long Term Prediction)
        5: SBR (Spectral Band Replication)
        6: AAC Scalable
       sampling freq
        0: 96000 Hz
        1: 88200 Hz
        2: 64000 Hz
        3: 48000 Hz
        4: 44100 Hz
        5: 32000 Hz
        6: 24000 Hz
        7: 22050 Hz
        8: 16000 Hz
        9: 12000 Hz
        10: 11025 Hz
        11: 8000 Hz
        12: 7350 Hz
        13: Reserved
        14: Reserved
        15: frequency is written explictly
        Channel Configurations
        These are the channel configurations:
        0: Defined in AOT Specifc Config
        1: 1 channel: front-center
        2: 2 channels: front-left, front-right
      */
      // audioObjectType = profile => profile, the MPEG-4 Audio Object Type minus 1


      config[0] = adtsObjectType << 3; // samplingFrequencyIndex

      config[0] |= (adtsSamplingIndex & 0x0e) >> 1;
      config[1] |= (adtsSamplingIndex & 0x01) << 7; // channelConfiguration

      config[1] |= adtsChanelConfig << 3;

      if (adtsObjectType === 5) {
        // adtsExtensionSampleingIndex
        config[1] |= (adtsExtensionSamplingIndex & 0x0e) >> 1;
        config[2] = (adtsExtensionSamplingIndex & 0x01) << 7; // adtsObjectType (force to 2, chrome is checking that object type is less than 5 ???
        //    https://chromium.googlesource.com/chromium/src.git/+/master/media/formats/mp4/aac.cc

        config[2] |= 2 << 2;
        config[3] = 0;
      }

      return {
        config: config,
        samplerate: adtsSampleingRates[adtsSamplingIndex],
        channelCount: adtsChanelConfig,
        codec: 'mp4a.40.' + adtsObjectType,
        manifestCodec: manifestCodec
      };
    }
    function isHeaderPattern(data, offset) {
      return data[offset] === 0xff && (data[offset + 1] & 0xf6) === 0xf0;
    }
    function getHeaderLength(data, offset) {
      return data[offset + 1] & 0x01 ? 7 : 9;
    }
    function getFullFrameLength(data, offset) {
      return (data[offset + 3] & 0x03) << 11 | data[offset + 4] << 3 | (data[offset + 5] & 0xe0) >>> 5;
    }
    function canGetFrameLength(data, offset) {
      return offset + 5 < data.length;
    }
    function isHeader(data, offset) {
      // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1
      // Layer bits (position 14 and 15) in header should be always 0 for ADTS
      // More info https://wiki.multimedia.cx/index.php?title=ADTS
      return offset + 1 < data.length && isHeaderPattern(data, offset);
    }
    function canParse(data, offset) {
      return canGetFrameLength(data, offset) && isHeaderPattern(data, offset) && getFullFrameLength(data, offset) <= data.length - offset;
    }
    function probe(data, offset) {
      // same as isHeader but we also check that ADTS frame follows last ADTS frame
      // or end of data is reached
      if (isHeader(data, offset)) {
        // ADTS header Length
        var headerLength = getHeaderLength(data, offset);

        if (offset + headerLength >= data.length) {
          return false;
        } // ADTS frame Length


        var frameLength = getFullFrameLength(data, offset);

        if (frameLength <= headerLength) {
          return false;
        }

        var newOffset = offset + frameLength;
        return newOffset === data.length || isHeader(data, newOffset);
      }

      return false;
    }
    function initTrackConfig(track, observer, data, offset, audioCodec) {
      if (!track.samplerate) {
        var config = getAudioConfig(observer, data, offset, audioCodec);

        if (!config) {
          return;
        }

        track.config = config.config;
        track.samplerate = config.samplerate;
        track.channelCount = config.channelCount;
        track.codec = config.codec;
        track.manifestCodec = config.manifestCodec;
        _utils_logger__WEBPACK_IMPORTED_MODULE_0__["logger"].log("parsed codec:" + track.codec + ", rate:" + config.samplerate + ", channels:" + config.channelCount);
      }
    }
    function getFrameDuration(samplerate) {
      return 1024 * 90000 / samplerate;
    }
    function parseFrameHeader(data, offset, pts, frameIndex, frameDuration) {
      // The protection skip bit tells us if we have 2 bytes of CRC data at the end of the ADTS header
      var headerLength = getHeaderLength(data, offset); // retrieve frame size

      var frameLength = getFullFrameLength(data, offset);
      frameLength -= headerLength;

      if (frameLength > 0) {
        var stamp = pts + frameIndex * frameDuration; // logger.log(`AAC frame, offset/length/total/pts:${offset+headerLength}/${frameLength}/${data.byteLength}/${(stamp/90).toFixed(0)}`);

        return {
          headerLength: headerLength,
          frameLength: frameLength,
          stamp: stamp
        };
      }
    }
    function appendFrame(track, data, offset, pts, frameIndex) {
      var frameDuration = getFrameDuration(track.samplerate);
      var header = parseFrameHeader(data, offset, pts, frameIndex, frameDuration);

      if (header) {
        var frameLength = header.frameLength,
            headerLength = header.headerLength,
            stamp = header.stamp;
        var length = headerLength + frameLength;
        var missing = Math.max(0, offset + length - data.length); // logger.log(`AAC frame ${frameIndex}, pts:${stamp} length@offset/total: ${frameLength}@${offset+headerLength}/${data.byteLength} missing: ${missing}`);

        var unit;

        if (missing) {
          unit = new Uint8Array(length - headerLength);
          unit.set(data.subarray(offset + headerLength, data.length), 0);
        } else {
          unit = data.subarray(offset + headerLength, offset + length);
        }

        var sample = {
          unit: unit,
          pts: stamp
        };

        if (!missing) {
          track.samples.push(sample);
        }

        return {
          sample: sample,
          length: length,
          missing: missing
        };
      }
    }

    /***/ }),

    /***/ "./src/demux/base-audio-demuxer.ts":
    /*!*****************************************!*\
      !*** ./src/demux/base-audio-demuxer.ts ***!
      \*****************************************/
    /*! exports provided: initPTSFn, default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "initPTSFn", function() { return initPTSFn; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
    /* harmony import */ var _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./dummy-demuxed-track */ "./src/demux/dummy-demuxed-track.ts");
    /* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
    /* harmony import */ var _utils_typed_array__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/typed-array */ "./src/utils/typed-array.ts");






    var BaseAudioDemuxer = /*#__PURE__*/function () {
      function BaseAudioDemuxer() {
        this._audioTrack = void 0;
        this._id3Track = void 0;
        this.frameIndex = 0;
        this.cachedData = null;
        this.initPTS = null;
      }

      var _proto = BaseAudioDemuxer.prototype;

      _proto.resetInitSegment = function resetInitSegment(audioCodec, videoCodec, duration) {
        this._id3Track = {
          type: 'id3',
          id: 3,
          pid: -1,
          inputTimeScale: 90000,
          sequenceNumber: 0,
          samples: [],
          dropped: 0
        };
      };

      _proto.resetTimeStamp = function resetTimeStamp() {};

      _proto.resetContiguity = function resetContiguity() {};

      _proto.canParse = function canParse(data, offset) {
        return false;
      };

      _proto.appendFrame = function appendFrame(track, data, offset) {} // feed incoming data to the front of the parsing pipeline
      ;

      _proto.demux = function demux(data, timeOffset) {
        if (this.cachedData) {
          data = Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_3__["appendUint8Array"])(this.cachedData, data);
          this.cachedData = null;
        }

        var id3Data = _demux_id3__WEBPACK_IMPORTED_MODULE_1__["getID3Data"](data, 0);
        var offset = id3Data ? id3Data.length : 0;
        var lastDataIndex;
        var pts;
        var track = this._audioTrack;
        var id3Track = this._id3Track;
        var timestamp = id3Data ? _demux_id3__WEBPACK_IMPORTED_MODULE_1__["getTimeStamp"](id3Data) : undefined;
        var length = data.length;

        if (this.frameIndex === 0 || this.initPTS === null) {
          this.initPTS = initPTSFn(timestamp, timeOffset);
        } // more expressive than alternative: id3Data?.length


        if (id3Data && id3Data.length > 0) {
          id3Track.samples.push({
            pts: this.initPTS,
            dts: this.initPTS,
            data: id3Data
          });
        }

        pts = this.initPTS;

        while (offset < length) {
          if (this.canParse(data, offset)) {
            var frame = this.appendFrame(track, data, offset);

            if (frame) {
              this.frameIndex++;
              pts = frame.sample.pts;
              offset += frame.length;
              lastDataIndex = offset;
            } else {
              offset = length;
            }
          } else if (_demux_id3__WEBPACK_IMPORTED_MODULE_1__["canParse"](data, offset)) {
            // after a ID3.canParse, a call to ID3.getID3Data *should* always returns some data
            id3Data = _demux_id3__WEBPACK_IMPORTED_MODULE_1__["getID3Data"](data, offset);
            id3Track.samples.push({
              pts: pts,
              dts: pts,
              data: id3Data
            });
            offset += id3Data.length;
            lastDataIndex = offset;
          } else {
            offset++;
          }

          if (offset === length && lastDataIndex !== length) {
            var partialData = Object(_utils_typed_array__WEBPACK_IMPORTED_MODULE_4__["sliceUint8"])(data, lastDataIndex);

            if (this.cachedData) {
              this.cachedData = Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_3__["appendUint8Array"])(this.cachedData, partialData);
            } else {
              this.cachedData = partialData;
            }
          }
        }

        return {
          audioTrack: track,
          avcTrack: Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__["dummyTrack"])(),
          id3Track: id3Track,
          textTrack: Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__["dummyTrack"])()
        };
      };

      _proto.demuxSampleAes = function demuxSampleAes(data, keyData, timeOffset) {
        return Promise.reject(new Error("[" + this + "] This demuxer does not support Sample-AES decryption"));
      };

      _proto.flush = function flush(timeOffset) {
        // Parse cache in case of remaining frames.
        var cachedData = this.cachedData;

        if (cachedData) {
          this.cachedData = null;
          this.demux(cachedData, 0);
        }

        this.frameIndex = 0;
        return {
          audioTrack: this._audioTrack,
          avcTrack: Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__["dummyTrack"])(),
          id3Track: this._id3Track,
          textTrack: Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__["dummyTrack"])()
        };
      };

      _proto.destroy = function destroy() {};

      return BaseAudioDemuxer;
    }();
    /**
     * Initialize PTS
     * <p>
     *    use timestamp unless it is undefined, NaN or Infinity
     * </p>
     */


    var initPTSFn = function initPTSFn(timestamp, timeOffset) {
      return Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(timestamp) ? timestamp * 90 : timeOffset * 90000;
    };
    /* harmony default export */ __webpack_exports__["default"] = (BaseAudioDemuxer);

    /***/ }),

    /***/ "./src/demux/chunk-cache.ts":
    /*!**********************************!*\
      !*** ./src/demux/chunk-cache.ts ***!
      \**********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return ChunkCache; });
    var ChunkCache = /*#__PURE__*/function () {
      function ChunkCache() {
        this.chunks = [];
        this.dataLength = 0;
      }

      var _proto = ChunkCache.prototype;

      _proto.push = function push(chunk) {
        this.chunks.push(chunk);
        this.dataLength += chunk.length;
      };

      _proto.flush = function flush() {
        var chunks = this.chunks,
            dataLength = this.dataLength;
        var result;

        if (!chunks.length) {
          return new Uint8Array(0);
        } else if (chunks.length === 1) {
          result = chunks[0];
        } else {
          result = concatUint8Arrays(chunks, dataLength);
        }

        this.reset();
        return result;
      };

      _proto.reset = function reset() {
        this.chunks.length = 0;
        this.dataLength = 0;
      };

      return ChunkCache;
    }();



    function concatUint8Arrays(chunks, dataLength) {
      var result = new Uint8Array(dataLength);
      var offset = 0;

      for (var i = 0; i < chunks.length; i++) {
        var chunk = chunks[i];
        result.set(chunk, offset);
        offset += chunk.length;
      }

      return result;
    }

    /***/ }),

    /***/ "./src/demux/dummy-demuxed-track.ts":
    /*!******************************************!*\
      !*** ./src/demux/dummy-demuxed-track.ts ***!
      \******************************************/
    /*! exports provided: dummyTrack */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "dummyTrack", function() { return dummyTrack; });
    function dummyTrack() {
      return {
        type: '',
        id: -1,
        pid: -1,
        inputTimeScale: 90000,
        sequenceNumber: -1,
        samples: [],
        dropped: 0
      };
    }

    /***/ }),

    /***/ "./src/demux/exp-golomb.ts":
    /*!*********************************!*\
      !*** ./src/demux/exp-golomb.ts ***!
      \*********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /**
     * Parser for exponential Golomb codes, a variable-bitwidth number encoding scheme used by h264.
     */


    var ExpGolomb = /*#__PURE__*/function () {
      function ExpGolomb(data) {
        this.data = void 0;
        this.bytesAvailable = void 0;
        this.word = void 0;
        this.bitsAvailable = void 0;
        this.data = data; // the number of bytes left to examine in this.data

        this.bytesAvailable = data.byteLength; // the current word being examined

        this.word = 0; // :uint
        // the number of bits left to examine in the current word

        this.bitsAvailable = 0; // :uint
      } // ():void


      var _proto = ExpGolomb.prototype;

      _proto.loadWord = function loadWord() {
        var data = this.data;
        var bytesAvailable = this.bytesAvailable;
        var position = data.byteLength - bytesAvailable;
        var workingBytes = new Uint8Array(4);
        var availableBytes = Math.min(4, bytesAvailable);

        if (availableBytes === 0) {
          throw new Error('no bytes available');
        }

        workingBytes.set(data.subarray(position, position + availableBytes));
        this.word = new DataView(workingBytes.buffer).getUint32(0); // track the amount of this.data that has been processed

        this.bitsAvailable = availableBytes * 8;
        this.bytesAvailable -= availableBytes;
      } // (count:int):void
      ;

      _proto.skipBits = function skipBits(count) {
        var skipBytes; // :int

        if (this.bitsAvailable > count) {
          this.word <<= count;
          this.bitsAvailable -= count;
        } else {
          count -= this.bitsAvailable;
          skipBytes = count >> 3;
          count -= skipBytes >> 3;
          this.bytesAvailable -= skipBytes;
          this.loadWord();
          this.word <<= count;
          this.bitsAvailable -= count;
        }
      } // (size:int):uint
      ;

      _proto.readBits = function readBits(size) {
        var bits = Math.min(this.bitsAvailable, size); // :uint

        var valu = this.word >>> 32 - bits; // :uint

        if (size > 32) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_0__["logger"].error('Cannot read more than 32 bits at a time');
        }

        this.bitsAvailable -= bits;

        if (this.bitsAvailable > 0) {
          this.word <<= bits;
        } else if (this.bytesAvailable > 0) {
          this.loadWord();
        }

        bits = size - bits;

        if (bits > 0 && this.bitsAvailable) {
          return valu << bits | this.readBits(bits);
        } else {
          return valu;
        }
      } // ():uint
      ;

      _proto.skipLZ = function skipLZ() {
        var leadingZeroCount; // :uint

        for (leadingZeroCount = 0; leadingZeroCount < this.bitsAvailable; ++leadingZeroCount) {
          if ((this.word & 0x80000000 >>> leadingZeroCount) !== 0) {
            // the first bit of working word is 1
            this.word <<= leadingZeroCount;
            this.bitsAvailable -= leadingZeroCount;
            return leadingZeroCount;
          }
        } // we exhausted word and still have not found a 1


        this.loadWord();
        return leadingZeroCount + this.skipLZ();
      } // ():void
      ;

      _proto.skipUEG = function skipUEG() {
        this.skipBits(1 + this.skipLZ());
      } // ():void
      ;

      _proto.skipEG = function skipEG() {
        this.skipBits(1 + this.skipLZ());
      } // ():uint
      ;

      _proto.readUEG = function readUEG() {
        var clz = this.skipLZ(); // :uint

        return this.readBits(clz + 1) - 1;
      } // ():int
      ;

      _proto.readEG = function readEG() {
        var valu = this.readUEG(); // :int

        if (0x01 & valu) {
          // the number is odd if the low order bit is set
          return 1 + valu >>> 1; // add 1 to make it even, and divide by 2
        } else {
          return -1 * (valu >>> 1); // divide by two then make it negative
        }
      } // Some convenience functions
      // :Boolean
      ;

      _proto.readBoolean = function readBoolean() {
        return this.readBits(1) === 1;
      } // ():int
      ;

      _proto.readUByte = function readUByte() {
        return this.readBits(8);
      } // ():int
      ;

      _proto.readUShort = function readUShort() {
        return this.readBits(16);
      } // ():int
      ;

      _proto.readUInt = function readUInt() {
        return this.readBits(32);
      }
      /**
       * Advance the ExpGolomb decoder past a scaling list. The scaling
       * list is optionally transmitted as part of a sequence parameter
       * set and is not relevant to transmuxing.
       * @param count the number of entries in this scaling list
       * @see Recommendation ITU-T H.264, Section 7.3.2.1.1.1
       */
      ;

      _proto.skipScalingList = function skipScalingList(count) {
        var lastScale = 8;
        var nextScale = 8;
        var deltaScale;

        for (var j = 0; j < count; j++) {
          if (nextScale !== 0) {
            deltaScale = this.readEG();
            nextScale = (lastScale + deltaScale + 256) % 256;
          }

          lastScale = nextScale === 0 ? lastScale : nextScale;
        }
      }
      /**
       * Read a sequence parameter set and return some interesting video
       * properties. A sequence parameter set is the H264 metadata that
       * describes the properties of upcoming video frames.
       * @param data {Uint8Array} the bytes of a sequence parameter set
       * @return {object} an object with configuration parsed from the
       * sequence parameter set, including the dimensions of the
       * associated video frames.
       */
      ;

      _proto.readSPS = function readSPS() {
        var frameCropLeftOffset = 0;
        var frameCropRightOffset = 0;
        var frameCropTopOffset = 0;
        var frameCropBottomOffset = 0;
        var numRefFramesInPicOrderCntCycle;
        var scalingListCount;
        var i;
        var readUByte = this.readUByte.bind(this);
        var readBits = this.readBits.bind(this);
        var readUEG = this.readUEG.bind(this);
        var readBoolean = this.readBoolean.bind(this);
        var skipBits = this.skipBits.bind(this);
        var skipEG = this.skipEG.bind(this);
        var skipUEG = this.skipUEG.bind(this);
        var skipScalingList = this.skipScalingList.bind(this);
        readUByte();
        var profileIdc = readUByte(); // profile_idc

        readBits(5); // profileCompat constraint_set[0-4]_flag, u(5)

        skipBits(3); // reserved_zero_3bits u(3),

        readUByte(); // level_idc u(8)

        skipUEG(); // seq_parameter_set_id
        // some profiles have more optional data we don't need

        if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128) {
          var chromaFormatIdc = readUEG();

          if (chromaFormatIdc === 3) {
            skipBits(1);
          } // separate_colour_plane_flag


          skipUEG(); // bit_depth_luma_minus8

          skipUEG(); // bit_depth_chroma_minus8

          skipBits(1); // qpprime_y_zero_transform_bypass_flag

          if (readBoolean()) {
            // seq_scaling_matrix_present_flag
            scalingListCount = chromaFormatIdc !== 3 ? 8 : 12;

            for (i = 0; i < scalingListCount; i++) {
              if (readBoolean()) {
                // seq_scaling_list_present_flag[ i ]
                if (i < 6) {
                  skipScalingList(16);
                } else {
                  skipScalingList(64);
                }
              }
            }
          }
        }

        skipUEG(); // log2_max_frame_num_minus4

        var picOrderCntType = readUEG();

        if (picOrderCntType === 0) {
          readUEG(); // log2_max_pic_order_cnt_lsb_minus4
        } else if (picOrderCntType === 1) {
          skipBits(1); // delta_pic_order_always_zero_flag

          skipEG(); // offset_for_non_ref_pic

          skipEG(); // offset_for_top_to_bottom_field

          numRefFramesInPicOrderCntCycle = readUEG();

          for (i = 0; i < numRefFramesInPicOrderCntCycle; i++) {
            skipEG();
          } // offset_for_ref_frame[ i ]

        }

        skipUEG(); // max_num_ref_frames

        skipBits(1); // gaps_in_frame_num_value_allowed_flag

        var picWidthInMbsMinus1 = readUEG();
        var picHeightInMapUnitsMinus1 = readUEG();
        var frameMbsOnlyFlag = readBits(1);

        if (frameMbsOnlyFlag === 0) {
          skipBits(1);
        } // mb_adaptive_frame_field_flag


        skipBits(1); // direct_8x8_inference_flag

        if (readBoolean()) {
          // frame_cropping_flag
          frameCropLeftOffset = readUEG();
          frameCropRightOffset = readUEG();
          frameCropTopOffset = readUEG();
          frameCropBottomOffset = readUEG();
        }

        var pixelRatio = [1, 1];

        if (readBoolean()) {
          // vui_parameters_present_flag
          if (readBoolean()) {
            // aspect_ratio_info_present_flag
            var aspectRatioIdc = readUByte();

            switch (aspectRatioIdc) {
              case 1:
                pixelRatio = [1, 1];
                break;

              case 2:
                pixelRatio = [12, 11];
                break;

              case 3:
                pixelRatio = [10, 11];
                break;

              case 4:
                pixelRatio = [16, 11];
                break;

              case 5:
                pixelRatio = [40, 33];
                break;

              case 6:
                pixelRatio = [24, 11];
                break;

              case 7:
                pixelRatio = [20, 11];
                break;

              case 8:
                pixelRatio = [32, 11];
                break;

              case 9:
                pixelRatio = [80, 33];
                break;

              case 10:
                pixelRatio = [18, 11];
                break;

              case 11:
                pixelRatio = [15, 11];
                break;

              case 12:
                pixelRatio = [64, 33];
                break;

              case 13:
                pixelRatio = [160, 99];
                break;

              case 14:
                pixelRatio = [4, 3];
                break;

              case 15:
                pixelRatio = [3, 2];
                break;

              case 16:
                pixelRatio = [2, 1];
                break;

              case 255:
                {
                  pixelRatio = [readUByte() << 8 | readUByte(), readUByte() << 8 | readUByte()];
                  break;
                }
            }
          }
        }

        return {
          width: Math.ceil((picWidthInMbsMinus1 + 1) * 16 - frameCropLeftOffset * 2 - frameCropRightOffset * 2),
          height: (2 - frameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16 - (frameMbsOnlyFlag ? 2 : 4) * (frameCropTopOffset + frameCropBottomOffset),
          pixelRatio: pixelRatio
        };
      };

      _proto.readSliceType = function readSliceType() {
        // skip NALu type
        this.readUByte(); // discard first_mb_in_slice

        this.readUEG(); // return slice_type

        return this.readUEG();
      };

      return ExpGolomb;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (ExpGolomb);

    /***/ }),

    /***/ "./src/demux/id3.ts":
    /*!**************************!*\
      !*** ./src/demux/id3.ts ***!
      \**************************/
    /*! exports provided: isHeader, isFooter, getID3Data, canParse, getTimeStamp, isTimeStampFrame, getID3Frames, decodeFrame, utf8ArrayToStr, testables */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isHeader", function() { return isHeader; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isFooter", function() { return isFooter; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getID3Data", function() { return getID3Data; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "canParse", function() { return canParse; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getTimeStamp", function() { return getTimeStamp; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isTimeStampFrame", function() { return isTimeStampFrame; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getID3Frames", function() { return getID3Frames; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "decodeFrame", function() { return decodeFrame; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "utf8ArrayToStr", function() { return utf8ArrayToStr; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "testables", function() { return testables; });
    // breaking up those two types in order to clarify what is happening in the decoding path.

    /**
     * Returns true if an ID3 header can be found at offset in data
     * @param {Uint8Array} data - The data to search in
     * @param {number} offset - The offset at which to start searching
     * @return {boolean} - True if an ID3 header is found
     */
    var isHeader = function isHeader(data, offset) {
      /*
       * http://id3.org/id3v2.3.0
       * [0]     = 'I'
       * [1]     = 'D'
       * [2]     = '3'
       * [3,4]   = {Version}
       * [5]     = {Flags}
       * [6-9]   = {ID3 Size}
       *
       * An ID3v2 tag can be detected with the following pattern:
       *  $49 44 33 yy yy xx zz zz zz zz
       * Where yy is less than $FF, xx is the 'flags' byte and zz is less than $80
       */
      if (offset + 10 <= data.length) {
        // look for 'ID3' identifier
        if (data[offset] === 0x49 && data[offset + 1] === 0x44 && data[offset + 2] === 0x33) {
          // check version is within range
          if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {
            // check size is within range
            if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {
              return true;
            }
          }
        }
      }

      return false;
    };
    /**
     * Returns true if an ID3 footer can be found at offset in data
     * @param {Uint8Array} data - The data to search in
     * @param {number} offset - The offset at which to start searching
     * @return {boolean} - True if an ID3 footer is found
     */

    var isFooter = function isFooter(data, offset) {
      /*
       * The footer is a copy of the header, but with a different identifier
       */
      if (offset + 10 <= data.length) {
        // look for '3DI' identifier
        if (data[offset] === 0x33 && data[offset + 1] === 0x44 && data[offset + 2] === 0x49) {
          // check version is within range
          if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {
            // check size is within range
            if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {
              return true;
            }
          }
        }
      }

      return false;
    };
    /**
     * Returns any adjacent ID3 tags found in data starting at offset, as one block of data
     * @param {Uint8Array} data - The data to search in
     * @param {number} offset - The offset at which to start searching
     * @return {Uint8Array | undefined} - The block of data containing any ID3 tags found
     * or *undefined* if no header is found at the starting offset
     */

    var getID3Data = function getID3Data(data, offset) {
      var front = offset;
      var length = 0;

      while (isHeader(data, offset)) {
        // ID3 header is 10 bytes
        length += 10;
        var size = readSize(data, offset + 6);
        length += size;

        if (isFooter(data, offset + 10)) {
          // ID3 footer is 10 bytes
          length += 10;
        }

        offset += length;
      }

      if (length > 0) {
        return data.subarray(front, front + length);
      }

      return undefined;
    };

    var readSize = function readSize(data, offset) {
      var size = 0;
      size = (data[offset] & 0x7f) << 21;
      size |= (data[offset + 1] & 0x7f) << 14;
      size |= (data[offset + 2] & 0x7f) << 7;
      size |= data[offset + 3] & 0x7f;
      return size;
    };

    var canParse = function canParse(data, offset) {
      return isHeader(data, offset) && readSize(data, offset + 6) + 10 <= data.length - offset;
    };
    /**
     * Searches for the Elementary Stream timestamp found in the ID3 data chunk
     * @param {Uint8Array} data - Block of data containing one or more ID3 tags
     * @return {number | undefined} - The timestamp
     */

    var getTimeStamp = function getTimeStamp(data) {
      var frames = getID3Frames(data);

      for (var i = 0; i < frames.length; i++) {
        var frame = frames[i];

        if (isTimeStampFrame(frame)) {
          return readTimeStamp(frame);
        }
      }

      return undefined;
    };
    /**
     * Returns true if the ID3 frame is an Elementary Stream timestamp frame
     * @param {ID3 frame} frame
     */

    var isTimeStampFrame = function isTimeStampFrame(frame) {
      return frame && frame.key === 'PRIV' && frame.info === 'com.apple.streaming.transportStreamTimestamp';
    };

    var getFrameData = function getFrameData(data) {
      /*
      Frame ID       $xx xx xx xx (four characters)
      Size           $xx xx xx xx
      Flags          $xx xx
      */
      var type = String.fromCharCode(data[0], data[1], data[2], data[3]);
      var size = readSize(data, 4); // skip frame id, size, and flags

      var offset = 10;
      return {
        type: type,
        size: size,
        data: data.subarray(offset, offset + size)
      };
    };
    /**
     * Returns an array of ID3 frames found in all the ID3 tags in the id3Data
     * @param {Uint8Array} id3Data - The ID3 data containing one or more ID3 tags
     * @return {ID3.Frame[]} - Array of ID3 frame objects
     */


    var getID3Frames = function getID3Frames(id3Data) {
      var offset = 0;
      var frames = [];

      while (isHeader(id3Data, offset)) {
        var size = readSize(id3Data, offset + 6); // skip past ID3 header

        offset += 10;
        var end = offset + size; // loop through frames in the ID3 tag

        while (offset + 8 < end) {
          var frameData = getFrameData(id3Data.subarray(offset));
          var frame = decodeFrame(frameData);

          if (frame) {
            frames.push(frame);
          } // skip frame header and frame data


          offset += frameData.size + 10;
        }

        if (isFooter(id3Data, offset)) {
          offset += 10;
        }
      }

      return frames;
    };
    var decodeFrame = function decodeFrame(frame) {
      if (frame.type === 'PRIV') {
        return decodePrivFrame(frame);
      } else if (frame.type[0] === 'W') {
        return decodeURLFrame(frame);
      }

      return decodeTextFrame(frame);
    };

    var decodePrivFrame = function decodePrivFrame(frame) {
      /*
      Format: <text string>\0<binary data>
      */
      if (frame.size < 2) {
        return undefined;
      }

      var owner = utf8ArrayToStr(frame.data, true);
      var privateData = new Uint8Array(frame.data.subarray(owner.length + 1));
      return {
        key: frame.type,
        info: owner,
        data: privateData.buffer
      };
    };

    var decodeTextFrame = function decodeTextFrame(frame) {
      if (frame.size < 2) {
        return undefined;
      }

      if (frame.type === 'TXXX') {
        /*
        Format:
        [0]   = {Text Encoding}
        [1-?] = {Description}\0{Value}
        */
        var index = 1;
        var description = utf8ArrayToStr(frame.data.subarray(index), true);
        index += description.length + 1;
        var value = utf8ArrayToStr(frame.data.subarray(index));
        return {
          key: frame.type,
          info: description,
          data: value
        };
      }
      /*
      Format:
      [0]   = {Text Encoding}
      [1-?] = {Value}
      */


      var text = utf8ArrayToStr(frame.data.subarray(1));
      return {
        key: frame.type,
        data: text
      };
    };

    var decodeURLFrame = function decodeURLFrame(frame) {
      if (frame.type === 'WXXX') {
        /*
        Format:
        [0]   = {Text Encoding}
        [1-?] = {Description}\0{URL}
        */
        if (frame.size < 2) {
          return undefined;
        }

        var index = 1;
        var description = utf8ArrayToStr(frame.data.subarray(index), true);
        index += description.length + 1;
        var value = utf8ArrayToStr(frame.data.subarray(index));
        return {
          key: frame.type,
          info: description,
          data: value
        };
      }
      /*
      Format:
      [0-?] = {URL}
      */


      var url = utf8ArrayToStr(frame.data);
      return {
        key: frame.type,
        data: url
      };
    };

    var readTimeStamp = function readTimeStamp(timeStampFrame) {
      if (timeStampFrame.data.byteLength === 8) {
        var data = new Uint8Array(timeStampFrame.data); // timestamp is 33 bit expressed as a big-endian eight-octet number,
        // with the upper 31 bits set to zero.

        var pts33Bit = data[3] & 0x1;
        var timestamp = (data[4] << 23) + (data[5] << 15) + (data[6] << 7) + data[7];
        timestamp /= 45;

        if (pts33Bit) {
          timestamp += 47721858.84;
        } // 2^32 / 90


        return Math.round(timestamp);
      }

      return undefined;
    }; // http://stackoverflow.com/questions/8936984/uint8array-to-string-in-javascript/22373197
    // http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt

    /* utf.js - UTF-8 <=> UTF-16 convertion
     *
     * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>
     * Version: 1.0
     * LastModified: Dec 25 1999
     * This library is free.  You can redistribute it and/or modify it.
     */


    var utf8ArrayToStr = function utf8ArrayToStr(array, exitOnNull) {
      if (exitOnNull === void 0) {
        exitOnNull = false;
      }

      var decoder = getTextDecoder();

      if (decoder) {
        var decoded = decoder.decode(array);

        if (exitOnNull) {
          // grab up to the first null
          var idx = decoded.indexOf('\0');
          return idx !== -1 ? decoded.substring(0, idx) : decoded;
        } // remove any null characters


        return decoded.replace(/\0/g, '');
      }

      var len = array.length;
      var c;
      var char2;
      var char3;
      var out = '';
      var i = 0;

      while (i < len) {
        c = array[i++];

        if (c === 0x00 && exitOnNull) {
          return out;
        } else if (c === 0x00 || c === 0x03) {
          // If the character is 3 (END_OF_TEXT) or 0 (NULL) then skip it
          continue;
        }

        switch (c >> 4) {
          case 0:
          case 1:
          case 2:
          case 3:
          case 4:
          case 5:
          case 6:
          case 7:
            // 0xxxxxxx
            out += String.fromCharCode(c);
            break;

          case 12:
          case 13:
            // 110x xxxx   10xx xxxx
            char2 = array[i++];
            out += String.fromCharCode((c & 0x1f) << 6 | char2 & 0x3f);
            break;

          case 14:
            // 1110 xxxx  10xx xxxx  10xx xxxx
            char2 = array[i++];
            char3 = array[i++];
            out += String.fromCharCode((c & 0x0f) << 12 | (char2 & 0x3f) << 6 | (char3 & 0x3f) << 0);
            break;
        }
      }

      return out;
    };
    var testables = {
      decodeTextFrame: decodeTextFrame
    };
    var decoder;

    function getTextDecoder() {
      if (!decoder && typeof self.TextDecoder !== 'undefined') {
        decoder = new self.TextDecoder('utf-8');
      }

      return decoder;
    }

    /***/ }),

    /***/ "./src/demux/mp3demuxer.ts":
    /*!*********************************!*\
      !*** ./src/demux/mp3demuxer.ts ***!
      \*********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _base_audio_demuxer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base-audio-demuxer */ "./src/demux/base-audio-demuxer.ts");
    /* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _mpegaudio__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./mpegaudio */ "./src/demux/mpegaudio.ts");
    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }

    /**
     * MP3 demuxer
     */





    var MP3Demuxer = /*#__PURE__*/function (_BaseAudioDemuxer) {
      _inheritsLoose(MP3Demuxer, _BaseAudioDemuxer);

      function MP3Demuxer() {
        return _BaseAudioDemuxer.apply(this, arguments) || this;
      }

      var _proto = MP3Demuxer.prototype;

      _proto.resetInitSegment = function resetInitSegment(audioCodec, videoCodec, duration) {
        _BaseAudioDemuxer.prototype.resetInitSegment.call(this, audioCodec, videoCodec, duration);

        this._audioTrack = {
          container: 'audio/mpeg',
          type: 'audio',
          id: 2,
          pid: -1,
          sequenceNumber: 0,
          isAAC: false,
          samples: [],
          manifestCodec: audioCodec,
          duration: duration,
          inputTimeScale: 90000,
          dropped: 0
        };
      };

      MP3Demuxer.probe = function probe(data) {
        if (!data) {
          return false;
        } // check if data contains ID3 timestamp and MPEG sync word
        // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1
        // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)
        // More info http://www.mp3-tech.org/programmer/frame_header.html


        var id3Data = _demux_id3__WEBPACK_IMPORTED_MODULE_1__["getID3Data"](data, 0) || [];
        var offset = id3Data.length;

        for (var length = data.length; offset < length; offset++) {
          if (_mpegaudio__WEBPACK_IMPORTED_MODULE_3__["probe"](data, offset)) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].log('MPEG Audio sync word found !');
            return true;
          }
        }

        return false;
      };

      _proto.canParse = function canParse(data, offset) {
        return _mpegaudio__WEBPACK_IMPORTED_MODULE_3__["canParse"](data, offset);
      };

      _proto.appendFrame = function appendFrame(track, data, offset) {
        if (this.initPTS === null) {
          return;
        }

        return _mpegaudio__WEBPACK_IMPORTED_MODULE_3__["appendFrame"](track, data, offset, this.initPTS, this.frameIndex);
      };

      return MP3Demuxer;
    }(_base_audio_demuxer__WEBPACK_IMPORTED_MODULE_0__["default"]);

    MP3Demuxer.minProbeByteLength = 4;
    /* harmony default export */ __webpack_exports__["default"] = (MP3Demuxer);

    /***/ }),

    /***/ "./src/demux/mp4demuxer.ts":
    /*!*********************************!*\
      !*** ./src/demux/mp4demuxer.ts ***!
      \*********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
    /* harmony import */ var _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./dummy-demuxed-track */ "./src/demux/dummy-demuxed-track.ts");
    /**
     * MP4 demuxer
     */



    var MP4Demuxer = /*#__PURE__*/function () {
      function MP4Demuxer(observer, config) {
        this.remainderData = null;
        this.config = void 0;
        this.config = config;
      }

      var _proto = MP4Demuxer.prototype;

      _proto.resetTimeStamp = function resetTimeStamp() {};

      _proto.resetInitSegment = function resetInitSegment() {};

      _proto.resetContiguity = function resetContiguity() {};

      MP4Demuxer.probe = function probe(data) {
        // ensure we find a moof box in the first 16 kB
        return Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_0__["findBox"])({
          data: data,
          start: 0,
          end: Math.min(data.length, 16384)
        }, ['moof']).length > 0;
      };

      _proto.demux = function demux(data) {
        // Load all data into the avc track. The CMAF remuxer will look for the data in the samples object; the rest of the fields do not matter
        var avcSamples = data;
        var avcTrack = Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_1__["dummyTrack"])();

        if (this.config.progressive) {
          // Split the bytestream into two ranges: one encompassing all data up until the start of the last moof, and everything else.
          // This is done to guarantee that we're sending valid data to MSE - when demuxing progressively, we have no guarantee
          // that the fetch loader gives us flush moof+mdat pairs. If we push jagged data to MSE, it will throw an exception.
          if (this.remainderData) {
            avcSamples = Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_0__["appendUint8Array"])(this.remainderData, data);
          }

          var segmentedData = Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_0__["segmentValidRange"])(avcSamples);
          this.remainderData = segmentedData.remainder;
          avcTrack.samples = segmentedData.valid || new Uint8Array();
        } else {
          avcTrack.samples = avcSamples;
        }

        return {
          audioTrack: Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_1__["dummyTrack"])(),
          avcTrack: avcTrack,
          id3Track: Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_1__["dummyTrack"])(),
          textTrack: Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_1__["dummyTrack"])()
        };
      };

      _proto.flush = function flush() {
        var avcTrack = Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_1__["dummyTrack"])();
        avcTrack.samples = this.remainderData || new Uint8Array();
        this.remainderData = null;
        return {
          audioTrack: Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_1__["dummyTrack"])(),
          avcTrack: avcTrack,
          id3Track: Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_1__["dummyTrack"])(),
          textTrack: Object(_dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_1__["dummyTrack"])()
        };
      };

      _proto.demuxSampleAes = function demuxSampleAes(data, keyData, timeOffset) {
        return Promise.reject(new Error('The MP4 demuxer does not support SAMPLE-AES decryption'));
      };

      _proto.destroy = function destroy() {};

      return MP4Demuxer;
    }();

    MP4Demuxer.minProbeByteLength = 1024;
    /* harmony default export */ __webpack_exports__["default"] = (MP4Demuxer);

    /***/ }),

    /***/ "./src/demux/mpegaudio.ts":
    /*!********************************!*\
      !*** ./src/demux/mpegaudio.ts ***!
      \********************************/
    /*! exports provided: appendFrame, parseHeader, isHeaderPattern, isHeader, canParse, probe */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "appendFrame", function() { return appendFrame; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parseHeader", function() { return parseHeader; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isHeaderPattern", function() { return isHeaderPattern; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isHeader", function() { return isHeader; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "canParse", function() { return canParse; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "probe", function() { return probe; });
    /**
     *  MPEG parser helper
     */
    var chromeVersion = null;
    var BitratesMap = [32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 32, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 384, 32, 40, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 32, 48, 56, 64, 80, 96, 112, 128, 144, 160, 176, 192, 224, 256, 8, 16, 24, 32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160];
    var SamplingRateMap = [44100, 48000, 32000, 22050, 24000, 16000, 11025, 12000, 8000];
    var SamplesCoefficients = [// MPEG 2.5
    [0, // Reserved
    72, // Layer3
    144, // Layer2
    12 // Layer1
    ], // Reserved
    [0, // Reserved
    0, // Layer3
    0, // Layer2
    0 // Layer1
    ], // MPEG 2
    [0, // Reserved
    72, // Layer3
    144, // Layer2
    12 // Layer1
    ], // MPEG 1
    [0, // Reserved
    144, // Layer3
    144, // Layer2
    12 // Layer1
    ]];
    var BytesInSlot = [0, // Reserved
    1, // Layer3
    1, // Layer2
    4 // Layer1
    ];
    function appendFrame(track, data, offset, pts, frameIndex) {
      // Using http://www.datavoyage.com/mpgscript/mpeghdr.htm as a reference
      if (offset + 24 > data.length) {
        return;
      }

      var header = parseHeader(data, offset);

      if (header && offset + header.frameLength <= data.length) {
        var frameDuration = header.samplesPerFrame * 90000 / header.sampleRate;
        var stamp = pts + frameIndex * frameDuration;
        var sample = {
          unit: data.subarray(offset, offset + header.frameLength),
          pts: stamp,
          dts: stamp
        };
        track.config = [];
        track.channelCount = header.channelCount;
        track.samplerate = header.sampleRate;
        track.samples.push(sample);
        return {
          sample: sample,
          length: header.frameLength,
          missing: 0
        };
      }
    }
    function parseHeader(data, offset) {
      var mpegVersion = data[offset + 1] >> 3 & 3;
      var mpegLayer = data[offset + 1] >> 1 & 3;
      var bitRateIndex = data[offset + 2] >> 4 & 15;
      var sampleRateIndex = data[offset + 2] >> 2 & 3;

      if (mpegVersion !== 1 && bitRateIndex !== 0 && bitRateIndex !== 15 && sampleRateIndex !== 3) {
        var paddingBit = data[offset + 2] >> 1 & 1;
        var channelMode = data[offset + 3] >> 6;
        var columnInBitrates = mpegVersion === 3 ? 3 - mpegLayer : mpegLayer === 3 ? 3 : 4;
        var bitRate = BitratesMap[columnInBitrates * 14 + bitRateIndex - 1] * 1000;
        var columnInSampleRates = mpegVersion === 3 ? 0 : mpegVersion === 2 ? 1 : 2;
        var sampleRate = SamplingRateMap[columnInSampleRates * 3 + sampleRateIndex];
        var channelCount = channelMode === 3 ? 1 : 2; // If bits of channel mode are `11` then it is a single channel (Mono)

        var sampleCoefficient = SamplesCoefficients[mpegVersion][mpegLayer];
        var bytesInSlot = BytesInSlot[mpegLayer];
        var samplesPerFrame = sampleCoefficient * 8 * bytesInSlot;
        var frameLength = Math.floor(sampleCoefficient * bitRate / sampleRate + paddingBit) * bytesInSlot;

        if (chromeVersion === null) {
          var userAgent = navigator.userAgent || '';
          var result = userAgent.match(/Chrome\/(\d+)/i);
          chromeVersion = result ? parseInt(result[1]) : 0;
        }

        var needChromeFix = !!chromeVersion && chromeVersion <= 87;

        if (needChromeFix && mpegLayer === 2 && bitRate >= 224000 && channelMode === 0) {
          // Work around bug in Chromium by setting channelMode to dual-channel (01) instead of stereo (00)
          data[offset + 3] = data[offset + 3] | 0x80;
        }

        return {
          sampleRate: sampleRate,
          channelCount: channelCount,
          frameLength: frameLength,
          samplesPerFrame: samplesPerFrame
        };
      }
    }
    function isHeaderPattern(data, offset) {
      return data[offset] === 0xff && (data[offset + 1] & 0xe0) === 0xe0 && (data[offset + 1] & 0x06) !== 0x00;
    }
    function isHeader(data, offset) {
      // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1
      // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)
      // More info http://www.mp3-tech.org/programmer/frame_header.html
      return offset + 1 < data.length && isHeaderPattern(data, offset);
    }
    function canParse(data, offset) {
      var headerSize = 4;
      return isHeaderPattern(data, offset) && headerSize <= data.length - offset;
    }
    function probe(data, offset) {
      // same as isHeader but we also check that MPEG frame follows last MPEG frame
      // or end of data is reached
      if (offset + 1 < data.length && isHeaderPattern(data, offset)) {
        // MPEG header Length
        var headerLength = 4; // MPEG frame Length

        var header = parseHeader(data, offset);
        var frameLength = headerLength;

        if (header !== null && header !== void 0 && header.frameLength) {
          frameLength = header.frameLength;
        }

        var newOffset = offset + frameLength;
        return newOffset === data.length || isHeader(data, newOffset);
      }

      return false;
    }

    /***/ }),

    /***/ "./src/demux/sample-aes.ts":
    /*!*********************************!*\
      !*** ./src/demux/sample-aes.ts ***!
      \*********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _crypt_decrypter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../crypt/decrypter */ "./src/crypt/decrypter.ts");
    /* harmony import */ var _tsdemuxer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./tsdemuxer */ "./src/demux/tsdemuxer.ts");
    /**
     * SAMPLE-AES decrypter
     */



    var SampleAesDecrypter = /*#__PURE__*/function () {
      function SampleAesDecrypter(observer, config, keyData) {
        this.keyData = void 0;
        this.decrypter = void 0;
        this.keyData = keyData;
        this.decrypter = new _crypt_decrypter__WEBPACK_IMPORTED_MODULE_0__["default"](observer, config, {
          removePKCS7Padding: false
        });
      }

      var _proto = SampleAesDecrypter.prototype;

      _proto.decryptBuffer = function decryptBuffer(encryptedData, callback) {
        this.decrypter.decrypt(encryptedData, this.keyData.key.buffer, this.keyData.iv.buffer, callback);
      } // AAC - encrypt all full 16 bytes blocks starting from offset 16
      ;

      _proto.decryptAacSample = function decryptAacSample(samples, sampleIndex, callback, sync) {
        var curUnit = samples[sampleIndex].unit;
        var encryptedData = curUnit.subarray(16, curUnit.length - curUnit.length % 16);
        var encryptedBuffer = encryptedData.buffer.slice(encryptedData.byteOffset, encryptedData.byteOffset + encryptedData.length);
        var localthis = this;
        this.decryptBuffer(encryptedBuffer, function (decryptedBuffer) {
          var decryptedData = new Uint8Array(decryptedBuffer);
          curUnit.set(decryptedData, 16);

          if (!sync) {
            localthis.decryptAacSamples(samples, sampleIndex + 1, callback);
          }
        });
      };

      _proto.decryptAacSamples = function decryptAacSamples(samples, sampleIndex, callback) {
        for (;; sampleIndex++) {
          if (sampleIndex >= samples.length) {
            callback();
            return;
          }

          if (samples[sampleIndex].unit.length < 32) {
            continue;
          }

          var sync = this.decrypter.isSync();
          this.decryptAacSample(samples, sampleIndex, callback, sync);

          if (!sync) {
            return;
          }
        }
      } // AVC - encrypt one 16 bytes block out of ten, starting from offset 32
      ;

      _proto.getAvcEncryptedData = function getAvcEncryptedData(decodedData) {
        var encryptedDataLen = Math.floor((decodedData.length - 48) / 160) * 16 + 16;
        var encryptedData = new Int8Array(encryptedDataLen);
        var outputPos = 0;

        for (var inputPos = 32; inputPos < decodedData.length - 16; inputPos += 160, outputPos += 16) {
          encryptedData.set(decodedData.subarray(inputPos, inputPos + 16), outputPos);
        }

        return encryptedData;
      };

      _proto.getAvcDecryptedUnit = function getAvcDecryptedUnit(decodedData, decryptedData) {
        var uint8DecryptedData = new Uint8Array(decryptedData);
        var inputPos = 0;

        for (var outputPos = 32; outputPos < decodedData.length - 16; outputPos += 160, inputPos += 16) {
          decodedData.set(uint8DecryptedData.subarray(inputPos, inputPos + 16), outputPos);
        }

        return decodedData;
      };

      _proto.decryptAvcSample = function decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit, sync) {
        var decodedData = Object(_tsdemuxer__WEBPACK_IMPORTED_MODULE_1__["discardEPB"])(curUnit.data);
        var encryptedData = this.getAvcEncryptedData(decodedData);
        var localthis = this;
        this.decryptBuffer(encryptedData.buffer, function (decryptedBuffer) {
          curUnit.data = localthis.getAvcDecryptedUnit(decodedData, decryptedBuffer);

          if (!sync) {
            localthis.decryptAvcSamples(samples, sampleIndex, unitIndex + 1, callback);
          }
        });
      };

      _proto.decryptAvcSamples = function decryptAvcSamples(samples, sampleIndex, unitIndex, callback) {
        if (samples instanceof Uint8Array) {
          throw new Error('Cannot decrypt samples of type Uint8Array');
        }

        for (;; sampleIndex++, unitIndex = 0) {
          if (sampleIndex >= samples.length) {
            callback();
            return;
          }

          var curUnits = samples[sampleIndex].units;

          for (;; unitIndex++) {
            if (unitIndex >= curUnits.length) {
              break;
            }

            var curUnit = curUnits[unitIndex];

            if (curUnit.data.length <= 48 || curUnit.type !== 1 && curUnit.type !== 5) {
              continue;
            }

            var sync = this.decrypter.isSync();
            this.decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit, sync);

            if (!sync) {
              return;
            }
          }
        }
      };

      return SampleAesDecrypter;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (SampleAesDecrypter);

    /***/ }),

    /***/ "./src/demux/transmuxer-interface.ts":
    /*!*******************************************!*\
      !*** ./src/demux/transmuxer-interface.ts ***!
      \*******************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return TransmuxerInterface; });
    /* harmony import */ var webworkify_webpack__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! webworkify-webpack */ "./node_modules/webworkify-webpack/index.js");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../demux/transmuxer */ "./src/demux/transmuxer.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/mediasource-helper */ "./src/utils/mediasource-helper.ts");
    /* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! eventemitter3 */ "./node_modules/eventemitter3/index.js");







    var MediaSource = Object(_utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_5__["getMediaSource"])() || {
      isTypeSupported: function isTypeSupported() {
        return false;
      }
    };

    var TransmuxerInterface = /*#__PURE__*/function () {
      function TransmuxerInterface(hls, id, onTransmuxComplete, onFlush) {
        var _this = this;

        this.hls = void 0;
        this.id = void 0;
        this.observer = void 0;
        this.frag = null;
        this.part = null;
        this.worker = void 0;
        this.onwmsg = void 0;
        this.transmuxer = null;
        this.onTransmuxComplete = void 0;
        this.onFlush = void 0;
        this.hls = hls;
        this.id = id;
        this.onTransmuxComplete = onTransmuxComplete;
        this.onFlush = onFlush;
        var config = hls.config;

        var forwardMessage = function forwardMessage(ev, data) {
          data = data || {};
          data.frag = _this.frag;
          data.id = _this.id;
          hls.trigger(ev, data);
        }; // forward events to main thread


        this.observer = new eventemitter3__WEBPACK_IMPORTED_MODULE_6__["EventEmitter"]();
        this.observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_DECRYPTED, forwardMessage);
        this.observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, forwardMessage);
        var typeSupported = {
          mp4: MediaSource.isTypeSupported('video/mp4'),
          mpeg: MediaSource.isTypeSupported('audio/mpeg'),
          mp3: MediaSource.isTypeSupported('audio/mp4; codecs="mp3"')
        }; // navigator.vendor is not always available in Web Worker
        // refer to https://developer.mozilla.org/en-US/docs/Web/API/WorkerGlobalScope/navigator

        var vendor = navigator.vendor;

        if (config.enableWorker && typeof Worker !== 'undefined') {
          _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].log('demuxing in webworker');
          var worker;

          try {
            worker = this.worker = webworkify_webpack__WEBPACK_IMPORTED_MODULE_0__(/*require.resolve*/(/*! ../demux/transmuxer-worker.ts */ "./src/demux/transmuxer-worker.ts"));
            this.onwmsg = this.onWorkerMessage.bind(this);
            worker.addEventListener('message', this.onwmsg);

            worker.onerror = function (event) {
              hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, {
                type: _errors__WEBPACK_IMPORTED_MODULE_4__["ErrorTypes"].OTHER_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_4__["ErrorDetails"].INTERNAL_EXCEPTION,
                fatal: true,
                event: 'demuxerWorker',
                error: new Error(event.message + "  (" + event.filename + ":" + event.lineno + ")")
              });
            };

            worker.postMessage({
              cmd: 'init',
              typeSupported: typeSupported,
              vendor: vendor,
              id: id,
              config: JSON.stringify(config)
            });
          } catch (err) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn('Error in worker:', err);
            _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].error('Error while initializing DemuxerWorker, fallback to inline');

            if (worker) {
              // revoke the Object URL that was used to create transmuxer worker, so as not to leak it
              self.URL.revokeObjectURL(worker.objectURL);
            }

            this.transmuxer = new _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__["default"](this.observer, typeSupported, config, vendor, id);
            this.worker = null;
          }
        } else {
          this.transmuxer = new _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__["default"](this.observer, typeSupported, config, vendor, id);
        }
      }

      var _proto = TransmuxerInterface.prototype;

      _proto.destroy = function destroy() {
        var w = this.worker;

        if (w) {
          w.removeEventListener('message', this.onwmsg);
          w.terminate();
          this.worker = null;
        } else {
          var transmuxer = this.transmuxer;

          if (transmuxer) {
            transmuxer.destroy();
            this.transmuxer = null;
          }
        }

        var observer = this.observer;

        if (observer) {
          observer.removeAllListeners();
        } // @ts-ignore


        this.observer = null;
      };

      _proto.push = function push(data, initSegmentData, audioCodec, videoCodec, frag, part, duration, accurateTimeOffset, chunkMeta, defaultInitPTS) {
        var _frag$initSegment,
            _lastFrag$initSegment,
            _this2 = this;

        chunkMeta.transmuxing.start = self.performance.now();
        var transmuxer = this.transmuxer,
            worker = this.worker;
        var timeOffset = part ? part.start : frag.start;
        var decryptdata = frag.decryptdata;
        var lastFrag = this.frag;
        var discontinuity = !(lastFrag && frag.cc === lastFrag.cc);
        var trackSwitch = !(lastFrag && chunkMeta.level === lastFrag.level);
        var snDiff = lastFrag ? chunkMeta.sn - lastFrag.sn : -1;
        var partDiff = this.part ? chunkMeta.part - this.part.index : 1;
        var contiguous = !trackSwitch && (snDiff === 1 || snDiff === 0 && partDiff === 1);
        var now = self.performance.now();

        if (trackSwitch || snDiff || frag.stats.parsing.start === 0) {
          frag.stats.parsing.start = now;
        }

        if (part && (partDiff || !contiguous)) {
          part.stats.parsing.start = now;
        }

        var initSegmentChange = !(lastFrag && ((_frag$initSegment = frag.initSegment) === null || _frag$initSegment === void 0 ? void 0 : _frag$initSegment.url) === ((_lastFrag$initSegment = lastFrag.initSegment) === null || _lastFrag$initSegment === void 0 ? void 0 : _lastFrag$initSegment.url));
        var state = new _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__["TransmuxState"](discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange);

        if (!contiguous || discontinuity || initSegmentChange) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].log("[transmuxer-interface, " + frag.type + "]: Starting new transmux session for sn: " + chunkMeta.sn + " p: " + chunkMeta.part + " level: " + chunkMeta.level + " id: " + chunkMeta.id + "\n        discontinuity: " + discontinuity + "\n        trackSwitch: " + trackSwitch + "\n        contiguous: " + contiguous + "\n        accurateTimeOffset: " + accurateTimeOffset + "\n        timeOffset: " + timeOffset + "\n        initSegmentChange: " + initSegmentChange);
          var config = new _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__["TransmuxConfig"](audioCodec, videoCodec, initSegmentData, duration, defaultInitPTS);
          this.configureTransmuxer(config);
        }

        this.frag = frag;
        this.part = part; // Frags with sn of 'initSegment' are not transmuxed

        if (worker) {
          // post fragment payload as transferable objects for ArrayBuffer (no copy)
          worker.postMessage({
            cmd: 'demux',
            data: data,
            decryptdata: decryptdata,
            chunkMeta: chunkMeta,
            state: state
          }, data instanceof ArrayBuffer ? [data] : []);
        } else if (transmuxer) {
          var _transmuxResult = transmuxer.push(data, decryptdata, chunkMeta, state);

          if (Object(_demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__["isPromise"])(_transmuxResult)) {
            _transmuxResult.then(function (data) {
              _this2.handleTransmuxComplete(data);
            });
          } else {
            this.handleTransmuxComplete(_transmuxResult);
          }
        }
      };

      _proto.flush = function flush(chunkMeta) {
        var _this3 = this;

        chunkMeta.transmuxing.start = self.performance.now();
        var transmuxer = this.transmuxer,
            worker = this.worker;

        if (worker) {
          worker.postMessage({
            cmd: 'flush',
            chunkMeta: chunkMeta
          });
        } else if (transmuxer) {
          var _transmuxResult2 = transmuxer.flush(chunkMeta);

          if (Object(_demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__["isPromise"])(_transmuxResult2)) {
            _transmuxResult2.then(function (data) {
              _this3.handleFlushResult(data, chunkMeta);
            });
          } else {
            this.handleFlushResult(_transmuxResult2, chunkMeta);
          }
        }
      };

      _proto.handleFlushResult = function handleFlushResult(results, chunkMeta) {
        var _this4 = this;

        results.forEach(function (result) {
          _this4.handleTransmuxComplete(result);
        });
        this.onFlush(chunkMeta);
      };

      _proto.onWorkerMessage = function onWorkerMessage(ev) {
        var data = ev.data;
        var hls = this.hls;

        switch (data.event) {
          case 'init':
            {
              // revoke the Object URL that was used to create transmuxer worker, so as not to leak it
              self.URL.revokeObjectURL(this.worker.objectURL);
              break;
            }

          case 'transmuxComplete':
            {
              this.handleTransmuxComplete(data.data);
              break;
            }

          case 'flush':
            {
              this.onFlush(data.data);
              break;
            }

          /* falls through */

          default:
            {
              data.data = data.data || {};
              data.data.frag = this.frag;
              data.data.id = this.id;
              hls.trigger(data.event, data.data);
              break;
            }
        }
      };

      _proto.configureTransmuxer = function configureTransmuxer(config) {
        var worker = this.worker,
            transmuxer = this.transmuxer;

        if (worker) {
          worker.postMessage({
            cmd: 'configure',
            config: config
          });
        } else if (transmuxer) {
          transmuxer.configure(config);
        }
      };

      _proto.handleTransmuxComplete = function handleTransmuxComplete(result) {
        result.chunkMeta.transmuxing.end = self.performance.now();
        this.onTransmuxComplete(result);
      };

      return TransmuxerInterface;
    }();



    /***/ }),

    /***/ "./src/demux/transmuxer-worker.ts":
    /*!****************************************!*\
      !*** ./src/demux/transmuxer-worker.ts ***!
      \****************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return TransmuxerWorker; });
    /* harmony import */ var _demux_transmuxer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../demux/transmuxer */ "./src/demux/transmuxer.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! eventemitter3 */ "./node_modules/eventemitter3/index.js");




    function TransmuxerWorker(self) {
      var observer = new eventemitter3__WEBPACK_IMPORTED_MODULE_3__["EventEmitter"]();

      var forwardMessage = function forwardMessage(ev, data) {
        self.postMessage({
          event: ev,
          data: data
        });
      }; // forward events to main thread


      observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].FRAG_DECRYPTED, forwardMessage);
      observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, forwardMessage);
      self.addEventListener('message', function (ev) {
        var data = ev.data;

        switch (data.cmd) {
          case 'init':
            {
              var config = JSON.parse(data.config);
              self.transmuxer = new _demux_transmuxer__WEBPACK_IMPORTED_MODULE_0__["default"](observer, data.typeSupported, config, data.vendor, data.id);
              Object(_utils_logger__WEBPACK_IMPORTED_MODULE_2__["enableLogs"])(config.debug);
              forwardMessage('init', null);
              break;
            }

          case 'configure':
            {
              self.transmuxer.configure(data.config);
              break;
            }

          case 'demux':
            {
              var transmuxResult = self.transmuxer.push(data.data, data.decryptdata, data.chunkMeta, data.state);

              if (Object(_demux_transmuxer__WEBPACK_IMPORTED_MODULE_0__["isPromise"])(transmuxResult)) {
                transmuxResult.then(function (data) {
                  emitTransmuxComplete(self, data);
                });
              } else {
                emitTransmuxComplete(self, transmuxResult);
              }

              break;
            }

          case 'flush':
            {
              var id = data.chunkMeta;

              var _transmuxResult = self.transmuxer.flush(id);

              if (Object(_demux_transmuxer__WEBPACK_IMPORTED_MODULE_0__["isPromise"])(_transmuxResult)) {
                _transmuxResult.then(function (results) {
                  handleFlushResult(self, results, id);
                });
              } else {
                handleFlushResult(self, _transmuxResult, id);
              }

              break;
            }
        }
      });
    }

    function emitTransmuxComplete(self, transmuxResult) {
      if (isEmptyResult(transmuxResult.remuxResult)) {
        return;
      }

      var transferable = [];
      var _transmuxResult$remux = transmuxResult.remuxResult,
          audio = _transmuxResult$remux.audio,
          video = _transmuxResult$remux.video;

      if (audio) {
        addToTransferable(transferable, audio);
      }

      if (video) {
        addToTransferable(transferable, video);
      }

      self.postMessage({
        event: 'transmuxComplete',
        data: transmuxResult
      }, transferable);
    } // Converts data to a transferable object https://developers.google.com/web/updates/2011/12/Transferable-Objects-Lightning-Fast)
    // in order to minimize message passing overhead


    function addToTransferable(transferable, track) {
      if (track.data1) {
        transferable.push(track.data1.buffer);
      }

      if (track.data2) {
        transferable.push(track.data2.buffer);
      }
    }

    function handleFlushResult(self, results, chunkMeta) {
      results.forEach(function (result) {
        emitTransmuxComplete(self, result);
      });
      self.postMessage({
        event: 'flush',
        data: chunkMeta
      });
    }

    function isEmptyResult(remuxResult) {
      return !remuxResult.audio && !remuxResult.video && !remuxResult.text && !remuxResult.id3 && !remuxResult.initSegment;
    }

    /***/ }),

    /***/ "./src/demux/transmuxer.ts":
    /*!*********************************!*\
      !*** ./src/demux/transmuxer.ts ***!
      \*********************************/
    /*! exports provided: default, isPromise, TransmuxConfig, TransmuxState */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return Transmuxer; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isPromise", function() { return isPromise; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TransmuxConfig", function() { return TransmuxConfig; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TransmuxState", function() { return TransmuxState; });
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _crypt_decrypter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../crypt/decrypter */ "./src/crypt/decrypter.ts");
    /* harmony import */ var _demux_aacdemuxer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../demux/aacdemuxer */ "./src/demux/aacdemuxer.ts");
    /* harmony import */ var _demux_mp4demuxer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../demux/mp4demuxer */ "./src/demux/mp4demuxer.ts");
    /* harmony import */ var _demux_tsdemuxer__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../demux/tsdemuxer */ "./src/demux/tsdemuxer.ts");
    /* harmony import */ var _demux_mp3demuxer__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../demux/mp3demuxer */ "./src/demux/mp3demuxer.ts");
    /* harmony import */ var _remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../remux/mp4-remuxer */ "./src/remux/mp4-remuxer.ts");
    /* harmony import */ var _remux_passthrough_remuxer__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../remux/passthrough-remuxer */ "./src/remux/passthrough-remuxer.ts");
    /* harmony import */ var _chunk_cache__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./chunk-cache */ "./src/demux/chunk-cache.ts");
    /* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");












    var now; // performance.now() not available on WebWorker, at least on Safari Desktop

    try {
      now = self.performance.now.bind(self.performance);
    } catch (err) {
      _utils_logger__WEBPACK_IMPORTED_MODULE_11__["logger"].debug('Unable to use Performance API on this environment');
      now = self.Date.now;
    }

    var muxConfig = [{
      demux: _demux_tsdemuxer__WEBPACK_IMPORTED_MODULE_5__["default"],
      remux: _remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_7__["default"]
    }, {
      demux: _demux_mp4demuxer__WEBPACK_IMPORTED_MODULE_4__["default"],
      remux: _remux_passthrough_remuxer__WEBPACK_IMPORTED_MODULE_8__["default"]
    }, {
      demux: _demux_aacdemuxer__WEBPACK_IMPORTED_MODULE_3__["default"],
      remux: _remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_7__["default"]
    }, {
      demux: _demux_mp3demuxer__WEBPACK_IMPORTED_MODULE_6__["default"],
      remux: _remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_7__["default"]
    }];
    var minProbeByteLength = 1024;
    muxConfig.forEach(function (_ref) {
      var demux = _ref.demux;
      minProbeByteLength = Math.max(minProbeByteLength, demux.minProbeByteLength);
    });

    var Transmuxer = /*#__PURE__*/function () {
      function Transmuxer(observer, typeSupported, config, vendor, id) {
        this.observer = void 0;
        this.typeSupported = void 0;
        this.config = void 0;
        this.vendor = void 0;
        this.id = void 0;
        this.demuxer = void 0;
        this.remuxer = void 0;
        this.decrypter = void 0;
        this.probe = void 0;
        this.decryptionPromise = null;
        this.transmuxConfig = void 0;
        this.currentTransmuxState = void 0;
        this.cache = new _chunk_cache__WEBPACK_IMPORTED_MODULE_9__["default"]();
        this.observer = observer;
        this.typeSupported = typeSupported;
        this.config = config;
        this.vendor = vendor;
        this.id = id;
      }

      var _proto = Transmuxer.prototype;

      _proto.configure = function configure(transmuxConfig) {
        this.transmuxConfig = transmuxConfig;

        if (this.decrypter) {
          this.decrypter.reset();
        }
      };

      _proto.push = function push(data, decryptdata, chunkMeta, state) {
        var _this = this;

        var stats = chunkMeta.transmuxing;
        stats.executeStart = now();
        var uintData = new Uint8Array(data);
        var cache = this.cache,
            config = this.config,
            currentTransmuxState = this.currentTransmuxState,
            transmuxConfig = this.transmuxConfig;

        if (state) {
          this.currentTransmuxState = state;
        }

        var keyData = getEncryptionType(uintData, decryptdata);

        if (keyData && keyData.method === 'AES-128') {
          var decrypter = this.getDecrypter(); // Software decryption is synchronous; webCrypto is not

          if (config.enableSoftwareAES) {
            // Software decryption is progressive. Progressive decryption may not return a result on each call. Any cached
            // data is handled in the flush() call
            var decryptedData = decrypter.softwareDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer);

            if (!decryptedData) {
              stats.executeEnd = now();
              return emptyResult(chunkMeta);
            }

            uintData = new Uint8Array(decryptedData);
          } else {
            this.decryptionPromise = decrypter.webCryptoDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer).then(function (decryptedData) {
              // Calling push here is important; if flush() is called while this is still resolving, this ensures that
              // the decrypted data has been transmuxed
              var result = _this.push(decryptedData, null, chunkMeta);

              _this.decryptionPromise = null;
              return result;
            });
            return this.decryptionPromise;
          }
        }

        var _ref2 = state || currentTransmuxState,
            contiguous = _ref2.contiguous,
            discontinuity = _ref2.discontinuity,
            trackSwitch = _ref2.trackSwitch,
            accurateTimeOffset = _ref2.accurateTimeOffset,
            timeOffset = _ref2.timeOffset,
            initSegmentChange = _ref2.initSegmentChange;

        var audioCodec = transmuxConfig.audioCodec,
            videoCodec = transmuxConfig.videoCodec,
            defaultInitPts = transmuxConfig.defaultInitPts,
            duration = transmuxConfig.duration,
            initSegmentData = transmuxConfig.initSegmentData; // Reset muxers before probing to ensure that their state is clean, even if flushing occurs before a successful probe

        if (discontinuity || trackSwitch || initSegmentChange) {
          this.resetInitSegment(initSegmentData, audioCodec, videoCodec, duration);
        }

        if (discontinuity || initSegmentChange) {
          this.resetInitialTimestamp(defaultInitPts);
        }

        if (!contiguous) {
          this.resetContiguity();
        }

        if (this.needsProbing(uintData, discontinuity, trackSwitch)) {
          if (cache.dataLength) {
            var cachedData = cache.flush();
            uintData = Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_10__["appendUint8Array"])(cachedData, uintData);
          }

          this.configureTransmuxer(uintData, transmuxConfig);
        }

        var result = this.transmux(uintData, keyData, timeOffset, accurateTimeOffset, chunkMeta);
        var currentState = this.currentTransmuxState;
        currentState.contiguous = true;
        currentState.discontinuity = false;
        currentState.trackSwitch = false;
        stats.executeEnd = now();
        return result;
      } // Due to data caching, flush calls can produce more than one TransmuxerResult (hence the Array type)
      ;

      _proto.flush = function flush(chunkMeta) {
        var _this2 = this;

        var stats = chunkMeta.transmuxing;
        stats.executeStart = now();
        var decrypter = this.decrypter,
            cache = this.cache,
            currentTransmuxState = this.currentTransmuxState,
            decryptionPromise = this.decryptionPromise;

        if (decryptionPromise) {
          // Upon resolution, the decryption promise calls push() and returns its TransmuxerResult up the stack. Therefore
          // only flushing is required for async decryption
          return decryptionPromise.then(function () {
            return _this2.flush(chunkMeta);
          });
        }

        var transmuxResults = [];
        var timeOffset = currentTransmuxState.timeOffset;

        if (decrypter) {
          // The decrypter may have data cached, which needs to be demuxed. In this case we'll have two TransmuxResults
          // This happens in the case that we receive only 1 push call for a segment (either for non-progressive downloads,
          // or for progressive downloads with small segments)
          var decryptedData = decrypter.flush();

          if (decryptedData) {
            // Push always returns a TransmuxerResult if decryptdata is null
            transmuxResults.push(this.push(decryptedData, null, chunkMeta));
          }
        }

        var bytesSeen = cache.dataLength;
        cache.reset();
        var demuxer = this.demuxer,
            remuxer = this.remuxer;

        if (!demuxer || !remuxer) {
          // If probing failed, and each demuxer saw enough bytes to be able to probe, then Hls.js has been given content its not able to handle
          if (bytesSeen >= minProbeByteLength) {
            this.observer.emit(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, _events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
              type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].MEDIA_ERROR,
              details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].FRAG_PARSING_ERROR,
              fatal: true,
              reason: 'no demux matching with content found'
            });
          }

          stats.executeEnd = now();
          return [emptyResult(chunkMeta)];
        }

        var demuxResultOrPromise = demuxer.flush(timeOffset);

        if (isPromise(demuxResultOrPromise)) {
          // Decrypt final SAMPLE-AES samples
          return demuxResultOrPromise.then(function (demuxResult) {
            _this2.flushRemux(transmuxResults, demuxResult, chunkMeta);

            return transmuxResults;
          });
        }

        this.flushRemux(transmuxResults, demuxResultOrPromise, chunkMeta);
        return transmuxResults;
      };

      _proto.flushRemux = function flushRemux(transmuxResults, demuxResult, chunkMeta) {
        var audioTrack = demuxResult.audioTrack,
            avcTrack = demuxResult.avcTrack,
            id3Track = demuxResult.id3Track,
            textTrack = demuxResult.textTrack;
        var _this$currentTransmux = this.currentTransmuxState,
            accurateTimeOffset = _this$currentTransmux.accurateTimeOffset,
            timeOffset = _this$currentTransmux.timeOffset;
        _utils_logger__WEBPACK_IMPORTED_MODULE_11__["logger"].log("[transmuxer.ts]: Flushed fragment " + chunkMeta.sn + (chunkMeta.part > -1 ? ' p: ' + chunkMeta.part : '') + " of level " + chunkMeta.level);
        var remuxResult = this.remuxer.remux(audioTrack, avcTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, true, this.id);
        transmuxResults.push({
          remuxResult: remuxResult,
          chunkMeta: chunkMeta
        });
        chunkMeta.transmuxing.executeEnd = now();
      };

      _proto.resetInitialTimestamp = function resetInitialTimestamp(defaultInitPts) {
        var demuxer = this.demuxer,
            remuxer = this.remuxer;

        if (!demuxer || !remuxer) {
          return;
        }

        demuxer.resetTimeStamp(defaultInitPts);
        remuxer.resetTimeStamp(defaultInitPts);
      };

      _proto.resetContiguity = function resetContiguity() {
        var demuxer = this.demuxer,
            remuxer = this.remuxer;

        if (!demuxer || !remuxer) {
          return;
        }

        demuxer.resetContiguity();
        remuxer.resetNextTimestamp();
      };

      _proto.resetInitSegment = function resetInitSegment(initSegmentData, audioCodec, videoCodec, duration) {
        var demuxer = this.demuxer,
            remuxer = this.remuxer;

        if (!demuxer || !remuxer) {
          return;
        }

        demuxer.resetInitSegment(audioCodec, videoCodec, duration);
        remuxer.resetInitSegment(initSegmentData, audioCodec, videoCodec);
      };

      _proto.destroy = function destroy() {
        if (this.demuxer) {
          this.demuxer.destroy();
          this.demuxer = undefined;
        }

        if (this.remuxer) {
          this.remuxer.destroy();
          this.remuxer = undefined;
        }
      };

      _proto.transmux = function transmux(data, keyData, timeOffset, accurateTimeOffset, chunkMeta) {
        var result;

        if (keyData && keyData.method === 'SAMPLE-AES') {
          result = this.transmuxSampleAes(data, keyData, timeOffset, accurateTimeOffset, chunkMeta);
        } else {
          result = this.transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta);
        }

        return result;
      };

      _proto.transmuxUnencrypted = function transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta) {
        var _demux = this.demuxer.demux(data, timeOffset, false, !this.config.progressive),
            audioTrack = _demux.audioTrack,
            avcTrack = _demux.avcTrack,
            id3Track = _demux.id3Track,
            textTrack = _demux.textTrack;

        var remuxResult = this.remuxer.remux(audioTrack, avcTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, false, this.id);
        return {
          remuxResult: remuxResult,
          chunkMeta: chunkMeta
        };
      };

      _proto.transmuxSampleAes = function transmuxSampleAes(data, decryptData, timeOffset, accurateTimeOffset, chunkMeta) {
        var _this3 = this;

        return this.demuxer.demuxSampleAes(data, decryptData, timeOffset).then(function (demuxResult) {
          var remuxResult = _this3.remuxer.remux(demuxResult.audioTrack, demuxResult.avcTrack, demuxResult.id3Track, demuxResult.textTrack, timeOffset, accurateTimeOffset, false, _this3.id);

          return {
            remuxResult: remuxResult,
            chunkMeta: chunkMeta
          };
        });
      };

      _proto.configureTransmuxer = function configureTransmuxer(data, transmuxConfig) {
        var config = this.config,
            observer = this.observer,
            typeSupported = this.typeSupported,
            vendor = this.vendor;
        var audioCodec = transmuxConfig.audioCodec,
            defaultInitPts = transmuxConfig.defaultInitPts,
            duration = transmuxConfig.duration,
            initSegmentData = transmuxConfig.initSegmentData,
            videoCodec = transmuxConfig.videoCodec; // probe for content type

        var mux;

        for (var i = 0, len = muxConfig.length; i < len; i++) {
          if (muxConfig[i].demux.probe(data)) {
            mux = muxConfig[i];
            break;
          }
        }

        if (!mux) {
          // If probing previous configs fail, use mp4 passthrough
          _utils_logger__WEBPACK_IMPORTED_MODULE_11__["logger"].warn('Failed to find demuxer by probing frag, treating as mp4 passthrough');
          mux = {
            demux: _demux_mp4demuxer__WEBPACK_IMPORTED_MODULE_4__["default"],
            remux: _remux_passthrough_remuxer__WEBPACK_IMPORTED_MODULE_8__["default"]
          };
        } // so let's check that current remuxer and demuxer are still valid


        var demuxer = this.demuxer;
        var remuxer = this.remuxer;
        var Remuxer = mux.remux;
        var Demuxer = mux.demux;

        if (!remuxer || !(remuxer instanceof Remuxer)) {
          this.remuxer = new Remuxer(observer, config, typeSupported, vendor);
        }

        if (!demuxer || !(demuxer instanceof Demuxer)) {
          this.demuxer = new Demuxer(observer, config, typeSupported);
          this.probe = Demuxer.probe;
        } // Ensure that muxers are always initialized with an initSegment


        this.resetInitSegment(initSegmentData, audioCodec, videoCodec, duration);
        this.resetInitialTimestamp(defaultInitPts);
      };

      _proto.needsProbing = function needsProbing(data, discontinuity, trackSwitch) {
        // in case of continuity change, or track switch
        // we might switch from content type (AAC container to TS container, or TS to fmp4 for example)
        return !this.demuxer || !this.remuxer || discontinuity || trackSwitch;
      };

      _proto.getDecrypter = function getDecrypter() {
        var decrypter = this.decrypter;

        if (!decrypter) {
          decrypter = this.decrypter = new _crypt_decrypter__WEBPACK_IMPORTED_MODULE_2__["default"](this.observer, this.config);
        }

        return decrypter;
      };

      return Transmuxer;
    }();



    function getEncryptionType(data, decryptData) {
      var encryptionType = null;

      if (data.byteLength > 0 && decryptData != null && decryptData.key != null && decryptData.iv !== null && decryptData.method != null) {
        encryptionType = decryptData;
      }

      return encryptionType;
    }

    var emptyResult = function emptyResult(chunkMeta) {
      return {
        remuxResult: {},
        chunkMeta: chunkMeta
      };
    };

    function isPromise(p) {
      return 'then' in p && p.then instanceof Function;
    }
    var TransmuxConfig = function TransmuxConfig(audioCodec, videoCodec, initSegmentData, duration, defaultInitPts) {
      this.audioCodec = void 0;
      this.videoCodec = void 0;
      this.initSegmentData = void 0;
      this.duration = void 0;
      this.defaultInitPts = void 0;
      this.audioCodec = audioCodec;
      this.videoCodec = videoCodec;
      this.initSegmentData = initSegmentData;
      this.duration = duration;
      this.defaultInitPts = defaultInitPts;
    };
    var TransmuxState = function TransmuxState(discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange) {
      this.discontinuity = void 0;
      this.contiguous = void 0;
      this.accurateTimeOffset = void 0;
      this.trackSwitch = void 0;
      this.timeOffset = void 0;
      this.initSegmentChange = void 0;
      this.discontinuity = discontinuity;
      this.contiguous = contiguous;
      this.accurateTimeOffset = accurateTimeOffset;
      this.trackSwitch = trackSwitch;
      this.timeOffset = timeOffset;
      this.initSegmentChange = initSegmentChange;
    };

    /***/ }),

    /***/ "./src/demux/tsdemuxer.ts":
    /*!********************************!*\
      !*** ./src/demux/tsdemuxer.ts ***!
      \********************************/
    /*! exports provided: discardEPB, default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "discardEPB", function() { return discardEPB; });
    /* harmony import */ var _adts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./adts */ "./src/demux/adts.ts");
    /* harmony import */ var _mpegaudio__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./mpegaudio */ "./src/demux/mpegaudio.ts");
    /* harmony import */ var _exp_golomb__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./exp-golomb */ "./src/demux/exp-golomb.ts");
    /* harmony import */ var _id3__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./id3 */ "./src/demux/id3.ts");
    /* harmony import */ var _sample_aes__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./sample-aes */ "./src/demux/sample-aes.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /**
     * highly optimized TS demuxer:
     * parse PAT, PMT
     * extract PES packet from audio and video PIDs
     * extract AVC/H264 NAL units and AAC/ADTS samples from PES packet
     * trigger the remuxer upon parsing completion
     * it also tries to workaround as best as it can audio codec switch (HE-AAC to AAC and vice versa), without having to restart the MediaSource.
     * it also controls the remuxing process :
     * upon discontinuity or level switch detection, it will also notifies the remuxer so that it can reset its state.
     */









    // We are using fixed track IDs for driving the MP4 remuxer
    // instead of following the TS PIDs.
    // There is no reason not to do this and some browsers/SourceBuffer-demuxers
    // may not like if there are TrackID "switches"
    // See https://github.com/video-dev/hls.js/issues/1331
    // Here we are mapping our internal track types to constant MP4 track IDs
    // With MSE currently one can only have one track of each, and we are muxing
    // whatever video/audio rendition in them.
    var RemuxerTrackIdConfig = {
      video: 1,
      audio: 2,
      id3: 3,
      text: 4
    };

    var TSDemuxer = /*#__PURE__*/function () {
      function TSDemuxer(observer, config, typeSupported) {
        this.observer = void 0;
        this.config = void 0;
        this.typeSupported = void 0;
        this.sampleAes = null;
        this.pmtParsed = false;
        this.audioCodec = void 0;
        this.videoCodec = void 0;
        this._duration = 0;
        this.aacLastPTS = null;
        this._initPTS = null;
        this._initDTS = null;
        this._pmtId = -1;
        this._avcTrack = void 0;
        this._audioTrack = void 0;
        this._id3Track = void 0;
        this._txtTrack = void 0;
        this.aacOverFlow = null;
        this.avcSample = null;
        this.remainderData = null;
        this.observer = observer;
        this.config = config;
        this.typeSupported = typeSupported;
      }

      TSDemuxer.probe = function probe(data) {
        var syncOffset = TSDemuxer.syncOffset(data);

        if (syncOffset < 0) {
          return false;
        } else {
          if (syncOffset) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].warn("MPEG2-TS detected but first sync word found @ offset " + syncOffset + ", junk ahead ?");
          }

          return true;
        }
      };

      TSDemuxer.syncOffset = function syncOffset(data) {
        // scan 1000 first bytes
        var scanwindow = Math.min(1000, data.length - 3 * 188);
        var i = 0;

        while (i < scanwindow) {
          // a TS fragment should contain at least 3 TS packets, a PAT, a PMT, and one PID, each starting with 0x47
          if (data[i] === 0x47 && data[i + 188] === 0x47 && data[i + 2 * 188] === 0x47) {
            return i;
          } else {
            i++;
          }
        }

        return -1;
      }
      /**
       * Creates a track model internal to demuxer used to drive remuxing input
       *
       * @param type 'audio' | 'video' | 'id3' | 'text'
       * @param duration
       * @return TSDemuxer's internal track model
       */
      ;

      TSDemuxer.createTrack = function createTrack(type, duration) {
        return {
          container: type === 'video' || type === 'audio' ? 'video/mp2t' : undefined,
          type: type,
          id: RemuxerTrackIdConfig[type],
          pid: -1,
          inputTimeScale: 90000,
          sequenceNumber: 0,
          samples: [],
          dropped: 0,
          duration: type === 'audio' ? duration : undefined
        };
      }
      /**
       * Initializes a new init segment on the demuxer/remuxer interface. Needed for discontinuities/track-switches (or at stream start)
       * Resets all internal track instances of the demuxer.
       */
      ;

      var _proto = TSDemuxer.prototype;

      _proto.resetInitSegment = function resetInitSegment(audioCodec, videoCodec, duration) {
        this.pmtParsed = false;
        this._pmtId = -1;
        this._avcTrack = TSDemuxer.createTrack('video', duration);
        this._audioTrack = TSDemuxer.createTrack('audio', duration);
        this._id3Track = TSDemuxer.createTrack('id3', duration);
        this._txtTrack = TSDemuxer.createTrack('text', duration);
        this._audioTrack.isAAC = true; // flush any partial content

        this.aacOverFlow = null;
        this.aacLastPTS = null;
        this.avcSample = null;
        this.audioCodec = audioCodec;
        this.videoCodec = videoCodec;
        this._duration = duration;
      };

      _proto.resetTimeStamp = function resetTimeStamp() {};

      _proto.resetContiguity = function resetContiguity() {
        var _audioTrack = this._audioTrack,
            _avcTrack = this._avcTrack,
            _id3Track = this._id3Track;

        if (_audioTrack) {
          _audioTrack.pesData = null;
        }

        if (_avcTrack) {
          _avcTrack.pesData = null;
        }

        if (_id3Track) {
          _id3Track.pesData = null;
        }

        this.aacOverFlow = null;
        this.aacLastPTS = null;
      };

      _proto.demux = function demux(data, timeOffset, isSampleAes, flush) {
        if (isSampleAes === void 0) {
          isSampleAes = false;
        }

        if (flush === void 0) {
          flush = false;
        }

        if (!isSampleAes) {
          this.sampleAes = null;
        }

        var pes;
        var avcTrack = this._avcTrack;
        var audioTrack = this._audioTrack;
        var id3Track = this._id3Track;
        var avcId = avcTrack.pid;
        var avcData = avcTrack.pesData;
        var audioId = audioTrack.pid;
        var id3Id = id3Track.pid;
        var audioData = audioTrack.pesData;
        var id3Data = id3Track.pesData;
        var unknownPIDs = false;
        var pmtParsed = this.pmtParsed;
        var pmtId = this._pmtId;
        var len = data.length;

        if (this.remainderData) {
          data = Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_6__["appendUint8Array"])(this.remainderData, data);
          len = data.length;
          this.remainderData = null;
        }

        if (len < 188 && !flush) {
          this.remainderData = data;
          return {
            audioTrack: audioTrack,
            avcTrack: avcTrack,
            id3Track: id3Track,
            textTrack: this._txtTrack
          };
        }

        var syncOffset = Math.max(0, TSDemuxer.syncOffset(data));
        len -= (len + syncOffset) % 188;

        if (len < data.byteLength && !flush) {
          this.remainderData = new Uint8Array(data.buffer, len, data.buffer.byteLength - len);
        } // loop through TS packets


        var tsPacketErrors = 0;

        for (var start = syncOffset; start < len; start += 188) {
          if (data[start] === 0x47) {
            var stt = !!(data[start + 1] & 0x40); // pid is a 13-bit field starting at the last bit of TS[1]

            var pid = ((data[start + 1] & 0x1f) << 8) + data[start + 2];
            var atf = (data[start + 3] & 0x30) >> 4; // if an adaption field is present, its length is specified by the fifth byte of the TS packet header.

            var offset = void 0;

            if (atf > 1) {
              offset = start + 5 + data[start + 4]; // continue if there is only adaptation field

              if (offset === start + 188) {
                continue;
              }
            } else {
              offset = start + 4;
            }

            switch (pid) {
              case avcId:
                if (stt) {
                  if (avcData && (pes = parsePES(avcData))) {
                    this.parseAVCPES(pes, false);
                  }

                  avcData = {
                    data: [],
                    size: 0
                  };
                }

                if (avcData) {
                  avcData.data.push(data.subarray(offset, start + 188));
                  avcData.size += start + 188 - offset;
                }

                break;

              case audioId:
                if (stt) {
                  if (audioData && (pes = parsePES(audioData))) {
                    if (audioTrack.isAAC) {
                      this.parseAACPES(pes);
                    } else {
                      this.parseMPEGPES(pes);
                    }
                  }

                  audioData = {
                    data: [],
                    size: 0
                  };
                }

                if (audioData) {
                  audioData.data.push(data.subarray(offset, start + 188));
                  audioData.size += start + 188 - offset;
                }

                break;

              case id3Id:
                if (stt) {
                  if (id3Data && (pes = parsePES(id3Data))) {
                    this.parseID3PES(pes);
                  }

                  id3Data = {
                    data: [],
                    size: 0
                  };
                }

                if (id3Data) {
                  id3Data.data.push(data.subarray(offset, start + 188));
                  id3Data.size += start + 188 - offset;
                }

                break;

              case 0:
                if (stt) {
                  offset += data[offset] + 1;
                }

                pmtId = this._pmtId = parsePAT(data, offset);
                break;

              case pmtId:
                {
                  if (stt) {
                    offset += data[offset] + 1;
                  }

                  var parsedPIDs = parsePMT(data, offset, this.typeSupported.mpeg === true || this.typeSupported.mp3 === true, isSampleAes); // only update track id if track PID found while parsing PMT
                  // this is to avoid resetting the PID to -1 in case
                  // track PID transiently disappears from the stream
                  // this could happen in case of transient missing audio samples for example
                  // NOTE this is only the PID of the track as found in TS,
                  // but we are not using this for MP4 track IDs.

                  avcId = parsedPIDs.avc;

                  if (avcId > 0) {
                    avcTrack.pid = avcId;
                  }

                  audioId = parsedPIDs.audio;

                  if (audioId > 0) {
                    audioTrack.pid = audioId;
                    audioTrack.isAAC = parsedPIDs.isAAC;
                  }

                  id3Id = parsedPIDs.id3;

                  if (id3Id > 0) {
                    id3Track.pid = id3Id;
                  }

                  if (unknownPIDs && !pmtParsed) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].log('reparse from beginning');
                    unknownPIDs = false; // we set it to -188, the += 188 in the for loop will reset start to 0

                    start = syncOffset - 188;
                  }

                  pmtParsed = this.pmtParsed = true;
                  break;
                }

              case 17:
              case 0x1fff:
                break;

              default:
                unknownPIDs = true;
                break;
            }
          } else {
            tsPacketErrors++;
          }
        }

        if (tsPacketErrors > 0) {
          this.observer.emit(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].ERROR, _events__WEBPACK_IMPORTED_MODULE_5__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_8__["ErrorTypes"].MEDIA_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_8__["ErrorDetails"].FRAG_PARSING_ERROR,
            fatal: false,
            reason: "Found " + tsPacketErrors + " TS packet/s that do not start with 0x47"
          });
        }

        avcTrack.pesData = avcData;
        audioTrack.pesData = audioData;
        id3Track.pesData = id3Data;
        var demuxResult = {
          audioTrack: audioTrack,
          avcTrack: avcTrack,
          id3Track: id3Track,
          textTrack: this._txtTrack
        };

        if (flush) {
          this.extractRemainingSamples(demuxResult);
        }

        return demuxResult;
      };

      _proto.flush = function flush() {
        var remainderData = this.remainderData;
        this.remainderData = null;
        var result;

        if (remainderData) {
          result = this.demux(remainderData, -1, false, true);
        } else {
          result = {
            audioTrack: this._audioTrack,
            avcTrack: this._avcTrack,
            textTrack: this._txtTrack,
            id3Track: this._id3Track
          };
        }

        this.extractRemainingSamples(result);

        if (this.sampleAes) {
          return this.decrypt(result, this.sampleAes);
        }

        return result;
      };

      _proto.extractRemainingSamples = function extractRemainingSamples(demuxResult) {
        var audioTrack = demuxResult.audioTrack,
            avcTrack = demuxResult.avcTrack,
            id3Track = demuxResult.id3Track;
        var avcData = avcTrack.pesData;
        var audioData = audioTrack.pesData;
        var id3Data = id3Track.pesData; // try to parse last PES packets

        var pes;

        if (avcData && (pes = parsePES(avcData))) {
          this.parseAVCPES(pes, true);
          avcTrack.pesData = null;
        } else {
          // either avcData null or PES truncated, keep it for next frag parsing
          avcTrack.pesData = avcData;
        }

        if (audioData && (pes = parsePES(audioData))) {
          if (audioTrack.isAAC) {
            this.parseAACPES(pes);
          } else {
            this.parseMPEGPES(pes);
          }

          audioTrack.pesData = null;
        } else {
          if (audioData !== null && audioData !== void 0 && audioData.size) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].log('last AAC PES packet truncated,might overlap between fragments');
          } // either audioData null or PES truncated, keep it for next frag parsing


          audioTrack.pesData = audioData;
        }

        if (id3Data && (pes = parsePES(id3Data))) {
          this.parseID3PES(pes);
          id3Track.pesData = null;
        } else {
          // either id3Data null or PES truncated, keep it for next frag parsing
          id3Track.pesData = id3Data;
        }
      };

      _proto.demuxSampleAes = function demuxSampleAes(data, keyData, timeOffset) {
        var demuxResult = this.demux(data, timeOffset, true, !this.config.progressive);
        var sampleAes = this.sampleAes = new _sample_aes__WEBPACK_IMPORTED_MODULE_4__["default"](this.observer, this.config, keyData);
        return this.decrypt(demuxResult, sampleAes);
      };

      _proto.decrypt = function decrypt(demuxResult, sampleAes) {
        return new Promise(function (resolve) {
          var audioTrack = demuxResult.audioTrack,
              avcTrack = demuxResult.avcTrack;

          if (audioTrack.samples && audioTrack.isAAC) {
            sampleAes.decryptAacSamples(audioTrack.samples, 0, function () {
              if (avcTrack.samples) {
                sampleAes.decryptAvcSamples(avcTrack.samples, 0, 0, function () {
                  resolve(demuxResult);
                });
              } else {
                resolve(demuxResult);
              }
            });
          } else if (avcTrack.samples) {
            sampleAes.decryptAvcSamples(avcTrack.samples, 0, 0, function () {
              resolve(demuxResult);
            });
          }
        });
      };

      _proto.destroy = function destroy() {
        this._initPTS = this._initDTS = null;
        this._duration = 0;
      };

      _proto.parseAVCPES = function parseAVCPES(pes, last) {
        var _this = this;

        var track = this._avcTrack;
        var units = this.parseAVCNALu(pes.data);
        var avcSample = this.avcSample;
        var push;
        var spsfound = false; // free pes.data to save up some memory

        pes.data = null; // if new NAL units found and last sample still there, let's push ...
        // this helps parsing streams with missing AUD (only do this if AUD never found)

        if (avcSample && units.length && !track.audFound) {
          pushAccessUnit(avcSample, track);
          avcSample = this.avcSample = createAVCSample(false, pes.pts, pes.dts, '');
        }

        units.forEach(function (unit) {
          switch (unit.type) {
            // NDR
            case 1:
              {
                push = true;

                if (!avcSample) {
                  avcSample = _this.avcSample = createAVCSample(true, pes.pts, pes.dts, '');
                }

                avcSample.frame = true;
                var data = unit.data; // only check slice type to detect KF in case SPS found in same packet (any keyframe is preceded by SPS ...)

                if (spsfound && data.length > 4) {
                  // retrieve slice type by parsing beginning of NAL unit (follow H264 spec, slice_header definition) to detect keyframe embedded in NDR
                  var sliceType = new _exp_golomb__WEBPACK_IMPORTED_MODULE_2__["default"](data).readSliceType(); // 2 : I slice, 4 : SI slice, 7 : I slice, 9: SI slice
                  // SI slice : A slice that is coded using intra prediction only and using quantisation of the prediction samples.
                  // An SI slice can be coded such that its decoded samples can be constructed identically to an SP slice.
                  // I slice: A slice that is not an SI slice that is decoded using intra prediction only.
                  // if (sliceType === 2 || sliceType === 7) {

                  if (sliceType === 2 || sliceType === 4 || sliceType === 7 || sliceType === 9) {
                    avcSample.key = true;
                  }
                }

                break; // IDR
              }

            case 5:
              push = true; // handle PES not starting with AUD

              if (!avcSample) {
                avcSample = _this.avcSample = createAVCSample(true, pes.pts, pes.dts, '');
              }

              avcSample.key = true;
              avcSample.frame = true;
              break;
            // SEI

            case 6:
              {
                push = true;

                var expGolombDecoder = new _exp_golomb__WEBPACK_IMPORTED_MODULE_2__["default"](discardEPB(unit.data)); // skip frameType

                expGolombDecoder.readUByte();
                var payloadType = 0;
                var payloadSize = 0;
                var endOfCaptions = false;
                var b = 0;

                while (!endOfCaptions && expGolombDecoder.bytesAvailable > 1) {
                  payloadType = 0;

                  do {
                    b = expGolombDecoder.readUByte();
                    payloadType += b;
                  } while (b === 0xff); // Parse payload size.


                  payloadSize = 0;

                  do {
                    b = expGolombDecoder.readUByte();
                    payloadSize += b;
                  } while (b === 0xff); // TODO: there can be more than one payload in an SEI packet...
                  // TODO: need to read type and size in a while loop to get them all


                  if (payloadType === 4 && expGolombDecoder.bytesAvailable !== 0) {
                    endOfCaptions = true;
                    var countryCode = expGolombDecoder.readUByte();

                    if (countryCode === 181) {
                      var providerCode = expGolombDecoder.readUShort();

                      if (providerCode === 49) {
                        var userStructure = expGolombDecoder.readUInt();

                        if (userStructure === 0x47413934) {
                          var userDataType = expGolombDecoder.readUByte(); // Raw CEA-608 bytes wrapped in CEA-708 packet

                          if (userDataType === 3) {
                            var firstByte = expGolombDecoder.readUByte();
                            var secondByte = expGolombDecoder.readUByte();
                            var totalCCs = 31 & firstByte;
                            var byteArray = [firstByte, secondByte];

                            for (var i = 0; i < totalCCs; i++) {
                              // 3 bytes per CC
                              byteArray.push(expGolombDecoder.readUByte());
                              byteArray.push(expGolombDecoder.readUByte());
                              byteArray.push(expGolombDecoder.readUByte());
                            }

                            insertSampleInOrder(_this._txtTrack.samples, {
                              type: 3,
                              pts: pes.pts,
                              bytes: byteArray
                            });
                          }
                        }
                      }
                    }
                  } else if (payloadType === 5 && expGolombDecoder.bytesAvailable !== 0) {
                    endOfCaptions = true;

                    if (payloadSize > 16) {
                      var uuidStrArray = [];

                      for (var _i = 0; _i < 16; _i++) {
                        uuidStrArray.push(expGolombDecoder.readUByte().toString(16));

                        if (_i === 3 || _i === 5 || _i === 7 || _i === 9) {
                          uuidStrArray.push('-');
                        }
                      }

                      var length = payloadSize - 16;
                      var userDataPayloadBytes = new Uint8Array(length);

                      for (var _i2 = 0; _i2 < length; _i2++) {
                        userDataPayloadBytes[_i2] = expGolombDecoder.readUByte();
                      }

                      insertSampleInOrder(_this._txtTrack.samples, {
                        pts: pes.pts,
                        payloadType: payloadType,
                        uuid: uuidStrArray.join(''),
                        userData: Object(_id3__WEBPACK_IMPORTED_MODULE_3__["utf8ArrayToStr"])(userDataPayloadBytes),
                        userDataBytes: userDataPayloadBytes
                      });
                    }
                  } else if (payloadSize < expGolombDecoder.bytesAvailable) {
                    for (var _i3 = 0; _i3 < payloadSize; _i3++) {
                      expGolombDecoder.readUByte();
                    }
                  }
                }

                break; // SPS
              }

            case 7:
              push = true;
              spsfound = true;

              if (!track.sps) {
                var _expGolombDecoder = new _exp_golomb__WEBPACK_IMPORTED_MODULE_2__["default"](unit.data);

                var config = _expGolombDecoder.readSPS();

                track.width = config.width;
                track.height = config.height;
                track.pixelRatio = config.pixelRatio; // TODO: `track.sps` is defined as a `number[]`, but we're setting it to a `Uint8Array[]`.

                track.sps = [unit.data];
                track.duration = _this._duration;
                var codecarray = unit.data.subarray(1, 4);
                var codecstring = 'avc1.';

                for (var _i4 = 0; _i4 < 3; _i4++) {
                  var h = codecarray[_i4].toString(16);

                  if (h.length < 2) {
                    h = '0' + h;
                  }

                  codecstring += h;
                }

                track.codec = codecstring;
              }

              break;
            // PPS

            case 8:
              push = true;

              if (!track.pps) {
                // TODO: `track.pss` is defined as a `number[]`, but we're setting it to a `Uint8Array[]`.
                track.pps = [unit.data];
              }

              break;
            // AUD

            case 9:
              push = false;
              track.audFound = true;

              if (avcSample) {
                pushAccessUnit(avcSample, track);
              }

              avcSample = _this.avcSample = createAVCSample(false, pes.pts, pes.dts, '');
              break;
            // Filler Data

            case 12:
              push = false;
              break;

            default:
              push = false;

              if (avcSample) {
                avcSample.debug += 'unknown NAL ' + unit.type + ' ';
              }

              break;
          }

          if (avcSample && push) {
            var _units = avcSample.units;

            _units.push(unit);
          }
        }); // if last PES packet, push samples

        if (last && avcSample) {
          pushAccessUnit(avcSample, track);
          this.avcSample = null;
        }
      };

      _proto.getLastNalUnit = function getLastNalUnit() {
        var _avcSample;

        var avcSample = this.avcSample;
        var lastUnit; // try to fallback to previous sample if current one is empty

        if (!avcSample || avcSample.units.length === 0) {
          var samples = this._avcTrack.samples;
          avcSample = samples[samples.length - 1];
        }

        if ((_avcSample = avcSample) !== null && _avcSample !== void 0 && _avcSample.units) {
          var units = avcSample.units;
          lastUnit = units[units.length - 1];
        }

        return lastUnit;
      };

      _proto.parseAVCNALu = function parseAVCNALu(array) {
        var len = array.byteLength;
        var track = this._avcTrack;
        var state = track.naluState || 0;
        var lastState = state;
        var units = [];
        var i = 0;
        var value;
        var overflow;
        var unitType;
        var lastUnitStart = -1;
        var lastUnitType = 0; // logger.log('PES:' + Hex.hexDump(array));

        if (state === -1) {
          // special use case where we found 3 or 4-byte start codes exactly at the end of previous PES packet
          lastUnitStart = 0; // NALu type is value read from offset 0

          lastUnitType = array[0] & 0x1f;
          state = 0;
          i = 1;
        }

        while (i < len) {
          value = array[i++]; // optimization. state 0 and 1 are the predominant case. let's handle them outside of the switch/case

          if (!state) {
            state = value ? 0 : 1;
            continue;
          }

          if (state === 1) {
            state = value ? 0 : 2;
            continue;
          } // here we have state either equal to 2 or 3


          if (!value) {
            state = 3;
          } else if (value === 1) {
            if (lastUnitStart >= 0) {
              var unit = {
                data: array.subarray(lastUnitStart, i - state - 1),
                type: lastUnitType
              }; // logger.log('pushing NALU, type/size:' + unit.type + '/' + unit.data.byteLength);

              units.push(unit);
            } else {
              // lastUnitStart is undefined => this is the first start code found in this PES packet
              // first check if start code delimiter is overlapping between 2 PES packets,
              // ie it started in last packet (lastState not zero)
              // and ended at the beginning of this PES packet (i <= 4 - lastState)
              var lastUnit = this.getLastNalUnit();

              if (lastUnit) {
                if (lastState && i <= 4 - lastState) {
                  // start delimiter overlapping between PES packets
                  // strip start delimiter bytes from the end of last NAL unit
                  // check if lastUnit had a state different from zero
                  if (lastUnit.state) {
                    // strip last bytes
                    lastUnit.data = lastUnit.data.subarray(0, lastUnit.data.byteLength - lastState);
                  }
                } // If NAL units are not starting right at the beginning of the PES packet, push preceding data into previous NAL unit.


                overflow = i - state - 1;

                if (overflow > 0) {
                  // logger.log('first NALU found with overflow:' + overflow);
                  var tmp = new Uint8Array(lastUnit.data.byteLength + overflow);
                  tmp.set(lastUnit.data, 0);
                  tmp.set(array.subarray(0, overflow), lastUnit.data.byteLength);
                  lastUnit.data = tmp;
                  lastUnit.state = 0;
                }
              }
            } // check if we can read unit type


            if (i < len) {
              unitType = array[i] & 0x1f; // logger.log('find NALU @ offset:' + i + ',type:' + unitType);

              lastUnitStart = i;
              lastUnitType = unitType;
              state = 0;
            } else {
              // not enough byte to read unit type. let's read it on next PES parsing
              state = -1;
            }
          } else {
            state = 0;
          }
        }

        if (lastUnitStart >= 0 && state >= 0) {
          var _unit = {
            data: array.subarray(lastUnitStart, len),
            type: lastUnitType,
            state: state
          };
          units.push(_unit); // logger.log('pushing NALU, type/size/state:' + unit.type + '/' + unit.data.byteLength + '/' + state);
        } // no NALu found


        if (units.length === 0) {
          // append pes.data to previous NAL unit
          var _lastUnit = this.getLastNalUnit();

          if (_lastUnit) {
            var _tmp = new Uint8Array(_lastUnit.data.byteLength + array.byteLength);

            _tmp.set(_lastUnit.data, 0);

            _tmp.set(array, _lastUnit.data.byteLength);

            _lastUnit.data = _tmp;
          }
        }

        track.naluState = state;
        return units;
      };

      _proto.parseAACPES = function parseAACPES(pes) {
        var startOffset = 0;
        var track = this._audioTrack;
        var aacOverFlow = this.aacOverFlow;
        var data = pes.data;

        if (aacOverFlow) {
          this.aacOverFlow = null;
          var sampleLength = aacOverFlow.sample.unit.byteLength;
          var frameMissingBytes = Math.min(aacOverFlow.missing, sampleLength);
          var frameOverflowBytes = sampleLength - frameMissingBytes;
          aacOverFlow.sample.unit.set(data.subarray(0, frameMissingBytes), frameOverflowBytes);
          track.samples.push(aacOverFlow.sample); // logger.log(`AAC: append overflowing ${frameOverflowBytes} bytes to beginning of new PES`);

          startOffset = aacOverFlow.missing;
        } // look for ADTS header (0xFFFx)


        var offset;
        var len;

        for (offset = startOffset, len = data.length; offset < len - 1; offset++) {
          if (_adts__WEBPACK_IMPORTED_MODULE_0__["isHeader"](data, offset)) {
            break;
          }
        } // if ADTS header does not start straight from the beginning of the PES payload, raise an error


        if (offset !== startOffset) {
          var reason;
          var fatal;

          if (offset < len - 1) {
            reason = "AAC PES did not start with ADTS header,offset:" + offset;
            fatal = false;
          } else {
            reason = 'no ADTS header found in AAC PES';
            fatal = true;
          }

          _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].warn("parsing error:" + reason);
          this.observer.emit(_events__WEBPACK_IMPORTED_MODULE_5__["Events"].ERROR, _events__WEBPACK_IMPORTED_MODULE_5__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_8__["ErrorTypes"].MEDIA_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_8__["ErrorDetails"].FRAG_PARSING_ERROR,
            fatal: fatal,
            reason: reason
          });

          if (fatal) {
            return;
          }
        }

        _adts__WEBPACK_IMPORTED_MODULE_0__["initTrackConfig"](track, this.observer, data, offset, this.audioCodec);
        var pts;

        if (pes.pts !== undefined) {
          pts = pes.pts;
        } else if (aacOverFlow) {
          // if last AAC frame is overflowing, we should ensure timestamps are contiguous:
          // first sample PTS should be equal to last sample PTS + frameDuration
          var frameDuration = _adts__WEBPACK_IMPORTED_MODULE_0__["getFrameDuration"](track.samplerate);
          pts = aacOverFlow.sample.pts + frameDuration;
        } else {
          _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].warn('[tsdemuxer]: AAC PES unknown PTS');
          return;
        } // scan for aac samples


        var frameIndex = 0;

        while (offset < len) {
          if (_adts__WEBPACK_IMPORTED_MODULE_0__["isHeader"](data, offset)) {
            if (offset + 5 < len) {
              var frame = _adts__WEBPACK_IMPORTED_MODULE_0__["appendFrame"](track, data, offset, pts, frameIndex);

              if (frame) {
                if (frame.missing) {
                  this.aacOverFlow = frame;
                } else {
                  offset += frame.length;
                  frameIndex++;
                  continue;
                }
              }
            } // We are at an ADTS header, but do not have enough data for a frame
            // Remaining data will be added to aacOverFlow


            break;
          } else {
            // nothing found, keep looking
            offset++;
          }
        }
      };

      _proto.parseMPEGPES = function parseMPEGPES(pes) {
        var data = pes.data;
        var length = data.length;
        var frameIndex = 0;
        var offset = 0;
        var pts = pes.pts;

        if (pts === undefined) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].warn('[tsdemuxer]: MPEG PES unknown PTS');
          return;
        }

        while (offset < length) {
          if (_mpegaudio__WEBPACK_IMPORTED_MODULE_1__["isHeader"](data, offset)) {
            var frame = _mpegaudio__WEBPACK_IMPORTED_MODULE_1__["appendFrame"](this._audioTrack, data, offset, pts, frameIndex);

            if (frame) {
              offset += frame.length;
              frameIndex++;
            } else {
              // logger.log('Unable to parse Mpeg audio frame');
              break;
            }
          } else {
            // nothing found, keep looking
            offset++;
          }
        }
      };

      _proto.parseID3PES = function parseID3PES(pes) {
        if (pes.pts === undefined) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].warn('[tsdemuxer]: ID3 PES unknown PTS');
          return;
        }

        this._id3Track.samples.push(pes);
      };

      return TSDemuxer;
    }();

    TSDemuxer.minProbeByteLength = 188;

    function createAVCSample(key, pts, dts, debug) {
      return {
        key: key,
        frame: false,
        pts: pts,
        dts: dts,
        units: [],
        debug: debug,
        length: 0
      };
    }

    function parsePAT(data, offset) {
      // skip the PSI header and parse the first PMT entry
      return (data[offset + 10] & 0x1f) << 8 | data[offset + 11]; // logger.log('PMT PID:'  + this._pmtId);
    }

    function parsePMT(data, offset, mpegSupported, isSampleAes) {
      var result = {
        audio: -1,
        avc: -1,
        id3: -1,
        isAAC: true
      };
      var sectionLength = (data[offset + 1] & 0x0f) << 8 | data[offset + 2];
      var tableEnd = offset + 3 + sectionLength - 4; // to determine where the table is, we have to figure out how
      // long the program info descriptors are

      var programInfoLength = (data[offset + 10] & 0x0f) << 8 | data[offset + 11]; // advance the offset to the first entry in the mapping table

      offset += 12 + programInfoLength;

      while (offset < tableEnd) {
        var pid = (data[offset + 1] & 0x1f) << 8 | data[offset + 2];

        switch (data[offset]) {
          case 0xcf:
            // SAMPLE-AES AAC
            if (!isSampleAes) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].log('ADTS AAC with AES-128-CBC frame encryption found in unencrypted stream');
              break;
            }

          /* falls through */

          case 0x0f:
            // ISO/IEC 13818-7 ADTS AAC (MPEG-2 lower bit-rate audio)
            // logger.log('AAC PID:'  + pid);
            if (result.audio === -1) {
              result.audio = pid;
            }

            break;
          // Packetized metadata (ID3)

          case 0x15:
            // logger.log('ID3 PID:'  + pid);
            if (result.id3 === -1) {
              result.id3 = pid;
            }

            break;

          case 0xdb:
            // SAMPLE-AES AVC
            if (!isSampleAes) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].log('H.264 with AES-128-CBC slice encryption found in unencrypted stream');
              break;
            }

          /* falls through */

          case 0x1b:
            // ITU-T Rec. H.264 and ISO/IEC 14496-10 (lower bit-rate video)
            // logger.log('AVC PID:'  + pid);
            if (result.avc === -1) {
              result.avc = pid;
            }

            break;
          // ISO/IEC 11172-3 (MPEG-1 audio)
          // or ISO/IEC 13818-3 (MPEG-2 halved sample rate audio)

          case 0x03:
          case 0x04:
            // logger.log('MPEG PID:'  + pid);
            if (!mpegSupported) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].log('MPEG audio found, not supported in this browser');
            } else if (result.audio === -1) {
              result.audio = pid;
              result.isAAC = false;
            }

            break;

          case 0x24:
            _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].warn('Unsupported HEVC stream type found');
            break;
        } // move to the next table entry
        // skip past the elementary stream descriptors, if present


        offset += ((data[offset + 3] & 0x0f) << 8 | data[offset + 4]) + 5;
      }

      return result;
    }

    function parsePES(stream) {
      var i = 0;
      var frag;
      var pesLen;
      var pesHdrLen;
      var pesPts;
      var pesDts;
      var data = stream.data; // safety check

      if (!stream || stream.size === 0) {
        return null;
      } // we might need up to 19 bytes to read PES header
      // if first chunk of data is less than 19 bytes, let's merge it with following ones until we get 19 bytes
      // usually only one merge is needed (and this is rare ...)


      while (data[0].length < 19 && data.length > 1) {
        var newData = new Uint8Array(data[0].length + data[1].length);
        newData.set(data[0]);
        newData.set(data[1], data[0].length);
        data[0] = newData;
        data.splice(1, 1);
      } // retrieve PTS/DTS from first fragment


      frag = data[0];
      var pesPrefix = (frag[0] << 16) + (frag[1] << 8) + frag[2];

      if (pesPrefix === 1) {
        pesLen = (frag[4] << 8) + frag[5]; // if PES parsed length is not zero and greater than total received length, stop parsing. PES might be truncated
        // minus 6 : PES header size

        if (pesLen && pesLen > stream.size - 6) {
          return null;
        }

        var pesFlags = frag[7];

        if (pesFlags & 0xc0) {
          /* PES header described here : http://dvd.sourceforge.net/dvdinfo/pes-hdr.html
              as PTS / DTS is 33 bit we cannot use bitwise operator in JS,
              as Bitwise operators treat their operands as a sequence of 32 bits */
          pesPts = (frag[9] & 0x0e) * 536870912 + // 1 << 29
          (frag[10] & 0xff) * 4194304 + // 1 << 22
          (frag[11] & 0xfe) * 16384 + // 1 << 14
          (frag[12] & 0xff) * 128 + // 1 << 7
          (frag[13] & 0xfe) / 2;

          if (pesFlags & 0x40) {
            pesDts = (frag[14] & 0x0e) * 536870912 + // 1 << 29
            (frag[15] & 0xff) * 4194304 + // 1 << 22
            (frag[16] & 0xfe) * 16384 + // 1 << 14
            (frag[17] & 0xff) * 128 + // 1 << 7
            (frag[18] & 0xfe) / 2;

            if (pesPts - pesDts > 60 * 90000) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].warn(Math.round((pesPts - pesDts) / 90000) + "s delta between PTS and DTS, align them");
              pesPts = pesDts;
            }
          } else {
            pesDts = pesPts;
          }
        }

        pesHdrLen = frag[8]; // 9 bytes : 6 bytes for PES header + 3 bytes for PES extension

        var payloadStartOffset = pesHdrLen + 9;

        if (stream.size <= payloadStartOffset) {
          return null;
        }

        stream.size -= payloadStartOffset; // reassemble PES packet

        var pesData = new Uint8Array(stream.size);

        for (var j = 0, dataLen = data.length; j < dataLen; j++) {
          frag = data[j];
          var len = frag.byteLength;

          if (payloadStartOffset) {
            if (payloadStartOffset > len) {
              // trim full frag if PES header bigger than frag
              payloadStartOffset -= len;
              continue;
            } else {
              // trim partial frag if PES header smaller than frag
              frag = frag.subarray(payloadStartOffset);
              len -= payloadStartOffset;
              payloadStartOffset = 0;
            }
          }

          pesData.set(frag, i);
          i += len;
        }

        if (pesLen) {
          // payload size : remove PES header + PES extension
          pesLen -= pesHdrLen + 3;
        }

        return {
          data: pesData,
          pts: pesPts,
          dts: pesDts,
          len: pesLen
        };
      }

      return null;
    }

    function pushAccessUnit(avcSample, avcTrack) {
      if (avcSample.units.length && avcSample.frame) {
        // if sample does not have PTS/DTS, patch with last sample PTS/DTS
        if (avcSample.pts === undefined) {
          var samples = avcTrack.samples;
          var nbSamples = samples.length;

          if (nbSamples) {
            var lastSample = samples[nbSamples - 1];
            avcSample.pts = lastSample.pts;
            avcSample.dts = lastSample.dts;
          } else {
            // dropping samples, no timestamp found
            avcTrack.dropped++;
            return;
          }
        }

        avcTrack.samples.push(avcSample);
      }

      if (avcSample.debug.length) {
        _utils_logger__WEBPACK_IMPORTED_MODULE_7__["logger"].log(avcSample.pts + '/' + avcSample.dts + ':' + avcSample.debug);
      }
    }

    function insertSampleInOrder(arr, data) {
      var len = arr.length;

      if (len > 0) {
        if (data.pts >= arr[len - 1].pts) {
          arr.push(data);
        } else {
          for (var pos = len - 1; pos >= 0; pos--) {
            if (data.pts < arr[pos].pts) {
              arr.splice(pos, 0, data);
              break;
            }
          }
        }
      } else {
        arr.push(data);
      }
    }
    /**
     * remove Emulation Prevention bytes from a RBSP
     */


    function discardEPB(data) {
      var length = data.byteLength;
      var EPBPositions = [];
      var i = 1; // Find all `Emulation Prevention Bytes`

      while (i < length - 2) {
        if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {
          EPBPositions.push(i + 2);
          i += 2;
        } else {
          i++;
        }
      } // If no Emulation Prevention Bytes were found just return the original
      // array


      if (EPBPositions.length === 0) {
        return data;
      } // Create a new array to hold the NAL unit data


      var newLength = length - EPBPositions.length;
      var newData = new Uint8Array(newLength);
      var sourceIndex = 0;

      for (i = 0; i < newLength; sourceIndex++, i++) {
        if (sourceIndex === EPBPositions[0]) {
          // Skip this byte
          sourceIndex++; // Remove this position index

          EPBPositions.shift();
        }

        newData[i] = data[sourceIndex];
      }

      return newData;
    }
    /* harmony default export */ __webpack_exports__["default"] = (TSDemuxer);

    /***/ }),

    /***/ "./src/errors.ts":
    /*!***********************!*\
      !*** ./src/errors.ts ***!
      \***********************/
    /*! exports provided: ErrorTypes, ErrorDetails */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ErrorTypes", function() { return ErrorTypes; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ErrorDetails", function() { return ErrorDetails; });
    var ErrorTypes;
    /**
     * @enum {ErrorDetails}
     * @typedef {string} ErrorDetail
     */

    (function (ErrorTypes) {
      ErrorTypes["NETWORK_ERROR"] = "networkError";
      ErrorTypes["MEDIA_ERROR"] = "mediaError";
      ErrorTypes["KEY_SYSTEM_ERROR"] = "keySystemError";
      ErrorTypes["MUX_ERROR"] = "muxError";
      ErrorTypes["OTHER_ERROR"] = "otherError";
    })(ErrorTypes || (ErrorTypes = {}));

    var ErrorDetails;

    (function (ErrorDetails) {
      ErrorDetails["KEY_SYSTEM_NO_KEYS"] = "keySystemNoKeys";
      ErrorDetails["KEY_SYSTEM_NO_ACCESS"] = "keySystemNoAccess";
      ErrorDetails["KEY_SYSTEM_NO_SESSION"] = "keySystemNoSession";
      ErrorDetails["KEY_SYSTEM_LICENSE_REQUEST_FAILED"] = "keySystemLicenseRequestFailed";
      ErrorDetails["KEY_SYSTEM_NO_INIT_DATA"] = "keySystemNoInitData";
      ErrorDetails["MANIFEST_LOAD_ERROR"] = "manifestLoadError";
      ErrorDetails["MANIFEST_LOAD_TIMEOUT"] = "manifestLoadTimeOut";
      ErrorDetails["MANIFEST_PARSING_ERROR"] = "manifestParsingError";
      ErrorDetails["MANIFEST_INCOMPATIBLE_CODECS_ERROR"] = "manifestIncompatibleCodecsError";
      ErrorDetails["LEVEL_EMPTY_ERROR"] = "levelEmptyError";
      ErrorDetails["LEVEL_LOAD_ERROR"] = "levelLoadError";
      ErrorDetails["LEVEL_LOAD_TIMEOUT"] = "levelLoadTimeOut";
      ErrorDetails["LEVEL_SWITCH_ERROR"] = "levelSwitchError";
      ErrorDetails["AUDIO_TRACK_LOAD_ERROR"] = "audioTrackLoadError";
      ErrorDetails["AUDIO_TRACK_LOAD_TIMEOUT"] = "audioTrackLoadTimeOut";
      ErrorDetails["SUBTITLE_LOAD_ERROR"] = "subtitleTrackLoadError";
      ErrorDetails["SUBTITLE_TRACK_LOAD_TIMEOUT"] = "subtitleTrackLoadTimeOut";
      ErrorDetails["FRAG_LOAD_ERROR"] = "fragLoadError";
      ErrorDetails["FRAG_LOAD_TIMEOUT"] = "fragLoadTimeOut";
      ErrorDetails["FRAG_DECRYPT_ERROR"] = "fragDecryptError";
      ErrorDetails["FRAG_PARSING_ERROR"] = "fragParsingError";
      ErrorDetails["REMUX_ALLOC_ERROR"] = "remuxAllocError";
      ErrorDetails["KEY_LOAD_ERROR"] = "keyLoadError";
      ErrorDetails["KEY_LOAD_TIMEOUT"] = "keyLoadTimeOut";
      ErrorDetails["BUFFER_ADD_CODEC_ERROR"] = "bufferAddCodecError";
      ErrorDetails["BUFFER_INCOMPATIBLE_CODECS_ERROR"] = "bufferIncompatibleCodecsError";
      ErrorDetails["BUFFER_APPEND_ERROR"] = "bufferAppendError";
      ErrorDetails["BUFFER_APPENDING_ERROR"] = "bufferAppendingError";
      ErrorDetails["BUFFER_STALLED_ERROR"] = "bufferStalledError";
      ErrorDetails["BUFFER_FULL_ERROR"] = "bufferFullError";
      ErrorDetails["BUFFER_SEEK_OVER_HOLE"] = "bufferSeekOverHole";
      ErrorDetails["BUFFER_NUDGE_ON_STALL"] = "bufferNudgeOnStall";
      ErrorDetails["INTERNAL_EXCEPTION"] = "internalException";
      ErrorDetails["INTERNAL_ABORTED"] = "aborted";
      ErrorDetails["UNKNOWN"] = "unknown";
    })(ErrorDetails || (ErrorDetails = {}));

    /***/ }),

    /***/ "./src/events.ts":
    /*!***********************!*\
      !*** ./src/events.ts ***!
      \***********************/
    /*! exports provided: Events */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Events", function() { return Events; });
    /**
     * @readonly
     * @enum {string}
     */
    var Events;

    (function (Events) {
      Events["MEDIA_ATTACHING"] = "hlsMediaAttaching";
      Events["MEDIA_ATTACHED"] = "hlsMediaAttached";
      Events["MEDIA_DETACHING"] = "hlsMediaDetaching";
      Events["MEDIA_DETACHED"] = "hlsMediaDetached";
      Events["BUFFER_RESET"] = "hlsBufferReset";
      Events["BUFFER_CODECS"] = "hlsBufferCodecs";
      Events["BUFFER_CREATED"] = "hlsBufferCreated";
      Events["BUFFER_APPENDING"] = "hlsBufferAppending";
      Events["BUFFER_APPENDED"] = "hlsBufferAppended";
      Events["BUFFER_EOS"] = "hlsBufferEos";
      Events["BUFFER_FLUSHING"] = "hlsBufferFlushing";
      Events["BUFFER_FLUSHED"] = "hlsBufferFlushed";
      Events["MANIFEST_LOADING"] = "hlsManifestLoading";
      Events["MANIFEST_LOADED"] = "hlsManifestLoaded";
      Events["MANIFEST_PARSED"] = "hlsManifestParsed";
      Events["LEVEL_SWITCHING"] = "hlsLevelSwitching";
      Events["LEVEL_SWITCHED"] = "hlsLevelSwitched";
      Events["LEVEL_LOADING"] = "hlsLevelLoading";
      Events["LEVEL_LOADED"] = "hlsLevelLoaded";
      Events["LEVEL_UPDATED"] = "hlsLevelUpdated";
      Events["LEVEL_PTS_UPDATED"] = "hlsLevelPtsUpdated";
      Events["LEVELS_UPDATED"] = "hlsLevelsUpdated";
      Events["AUDIO_TRACKS_UPDATED"] = "hlsAudioTracksUpdated";
      Events["AUDIO_TRACK_SWITCHING"] = "hlsAudioTrackSwitching";
      Events["AUDIO_TRACK_SWITCHED"] = "hlsAudioTrackSwitched";
      Events["AUDIO_TRACK_LOADING"] = "hlsAudioTrackLoading";
      Events["AUDIO_TRACK_LOADED"] = "hlsAudioTrackLoaded";
      Events["SUBTITLE_TRACKS_UPDATED"] = "hlsSubtitleTracksUpdated";
      Events["SUBTITLE_TRACKS_CLEARED"] = "hlsSubtitleTracksCleared";
      Events["SUBTITLE_TRACK_SWITCH"] = "hlsSubtitleTrackSwitch";
      Events["SUBTITLE_TRACK_LOADING"] = "hlsSubtitleTrackLoading";
      Events["SUBTITLE_TRACK_LOADED"] = "hlsSubtitleTrackLoaded";
      Events["SUBTITLE_FRAG_PROCESSED"] = "hlsSubtitleFragProcessed";
      Events["CUES_PARSED"] = "hlsCuesParsed";
      Events["NON_NATIVE_TEXT_TRACKS_FOUND"] = "hlsNonNativeTextTracksFound";
      Events["INIT_PTS_FOUND"] = "hlsInitPtsFound";
      Events["FRAG_LOADING"] = "hlsFragLoading";
      Events["FRAG_LOAD_EMERGENCY_ABORTED"] = "hlsFragLoadEmergencyAborted";
      Events["FRAG_LOADED"] = "hlsFragLoaded";
      Events["FRAG_DECRYPTED"] = "hlsFragDecrypted";
      Events["FRAG_PARSING_INIT_SEGMENT"] = "hlsFragParsingInitSegment";
      Events["FRAG_PARSING_USERDATA"] = "hlsFragParsingUserdata";
      Events["FRAG_PARSING_METADATA"] = "hlsFragParsingMetadata";
      Events["FRAG_PARSED"] = "hlsFragParsed";
      Events["FRAG_BUFFERED"] = "hlsFragBuffered";
      Events["FRAG_CHANGED"] = "hlsFragChanged";
      Events["FPS_DROP"] = "hlsFpsDrop";
      Events["FPS_DROP_LEVEL_CAPPING"] = "hlsFpsDropLevelCapping";
      Events["ERROR"] = "hlsError";
      Events["DESTROYING"] = "hlsDestroying";
      Events["KEY_LOADING"] = "hlsKeyLoading";
      Events["KEY_LOADED"] = "hlsKeyLoaded";
      Events["LIVE_BACK_BUFFER_REACHED"] = "hlsLiveBackBufferReached";
      Events["BACK_BUFFER_REACHED"] = "hlsBackBufferReached";
    })(Events || (Events = {}));

    /***/ }),

    /***/ "./src/hls.ts":
    /*!********************!*\
      !*** ./src/hls.ts ***!
      \********************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return Hls; });
    /* harmony import */ var url_toolkit__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! url-toolkit */ "./node_modules/url-toolkit/src/url-toolkit.js");
    /* harmony import */ var _loader_playlist_loader__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./loader/playlist-loader */ "./src/loader/playlist-loader.ts");
    /* harmony import */ var _loader_key_loader__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./loader/key-loader */ "./src/loader/key-loader.ts");
    /* harmony import */ var _controller_id3_track_controller__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./controller/id3-track-controller */ "./src/controller/id3-track-controller.ts");
    /* harmony import */ var _controller_latency_controller__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./controller/latency-controller */ "./src/controller/latency-controller.ts");
    /* harmony import */ var _controller_level_controller__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./controller/level-controller */ "./src/controller/level-controller.ts");
    /* harmony import */ var _controller_fragment_tracker__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./controller/fragment-tracker */ "./src/controller/fragment-tracker.ts");
    /* harmony import */ var _controller_stream_controller__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./controller/stream-controller */ "./src/controller/stream-controller.ts");
    /* harmony import */ var _is_supported__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./is-supported */ "./src/is-supported.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _config__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./config */ "./src/config.ts");
    /* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! eventemitter3 */ "./node_modules/eventemitter3/index.js");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./events */ "./src/events.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./errors */ "./src/errors.ts");
    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }
















    /**
     * @module Hls
     * @class
     * @constructor
     */
    var Hls = /*#__PURE__*/function () {
      Hls.isSupported = function isSupported() {
        return Object(_is_supported__WEBPACK_IMPORTED_MODULE_8__["isSupported"])();
      };

      /**
       * Creates an instance of an HLS client that can attach to exactly one `HTMLMediaElement`.
       *
       * @constructs Hls
       * @param {HlsConfig} config
       */
      function Hls(userConfig) {
        if (userConfig === void 0) {
          userConfig = {};
        }

        this.config = void 0;
        this.userConfig = void 0;
        this.coreComponents = void 0;
        this.networkControllers = void 0;
        this._emitter = new eventemitter3__WEBPACK_IMPORTED_MODULE_11__["EventEmitter"]();
        this._autoLevelCapping = void 0;
        this.abrController = void 0;
        this.bufferController = void 0;
        this.capLevelController = void 0;
        this.latencyController = void 0;
        this.levelController = void 0;
        this.streamController = void 0;
        this.audioTrackController = void 0;
        this.subtitleTrackController = void 0;
        this.emeController = void 0;
        this.cmcdController = void 0;
        this._media = null;
        this.url = null;
        var config = this.config = Object(_config__WEBPACK_IMPORTED_MODULE_10__["mergeConfig"])(Hls.DefaultConfig, userConfig);
        this.userConfig = userConfig;
        Object(_utils_logger__WEBPACK_IMPORTED_MODULE_9__["enableLogs"])(config.debug);
        this._autoLevelCapping = -1;

        if (config.progressive) {
          Object(_config__WEBPACK_IMPORTED_MODULE_10__["enableStreamingMode"])(config);
        } // core controllers and network loaders


        var ConfigAbrController = config.abrController,
            ConfigBufferController = config.bufferController,
            ConfigCapLevelController = config.capLevelController,
            ConfigFpsController = config.fpsController;
        var abrController = this.abrController = new ConfigAbrController(this);
        var bufferController = this.bufferController = new ConfigBufferController(this);
        var capLevelController = this.capLevelController = new ConfigCapLevelController(this);
        var fpsController = new ConfigFpsController(this);
        var playListLoader = new _loader_playlist_loader__WEBPACK_IMPORTED_MODULE_1__["default"](this);
        var keyLoader = new _loader_key_loader__WEBPACK_IMPORTED_MODULE_2__["default"](this);
        var id3TrackController = new _controller_id3_track_controller__WEBPACK_IMPORTED_MODULE_3__["default"](this); // network controllers

        var levelController = this.levelController = new _controller_level_controller__WEBPACK_IMPORTED_MODULE_5__["default"](this); // FragmentTracker must be defined before StreamController because the order of event handling is important

        var fragmentTracker = new _controller_fragment_tracker__WEBPACK_IMPORTED_MODULE_6__["FragmentTracker"](this);
        var streamController = this.streamController = new _controller_stream_controller__WEBPACK_IMPORTED_MODULE_7__["default"](this, fragmentTracker); // Cap level controller uses streamController to flush the buffer

        capLevelController.setStreamController(streamController); // fpsController uses streamController to switch when frames are being dropped

        fpsController.setStreamController(streamController);
        var networkControllers = [levelController, streamController];
        this.networkControllers = networkControllers;
        var coreComponents = [playListLoader, keyLoader, abrController, bufferController, capLevelController, fpsController, id3TrackController, fragmentTracker];
        this.audioTrackController = this.createController(config.audioTrackController, null, networkControllers);
        this.createController(config.audioStreamController, fragmentTracker, networkControllers); // subtitleTrackController must be defined before  because the order of event handling is important

        this.subtitleTrackController = this.createController(config.subtitleTrackController, null, networkControllers);
        this.createController(config.subtitleStreamController, fragmentTracker, networkControllers);
        this.createController(config.timelineController, null, coreComponents);
        this.emeController = this.createController(config.emeController, null, coreComponents);
        this.cmcdController = this.createController(config.cmcdController, null, coreComponents);
        this.latencyController = this.createController(_controller_latency_controller__WEBPACK_IMPORTED_MODULE_4__["default"], null, coreComponents);
        this.coreComponents = coreComponents;
      }

      var _proto = Hls.prototype;

      _proto.createController = function createController(ControllerClass, fragmentTracker, components) {
        if (ControllerClass) {
          var controllerInstance = fragmentTracker ? new ControllerClass(this, fragmentTracker) : new ControllerClass(this);

          if (components) {
            components.push(controllerInstance);
          }

          return controllerInstance;
        }

        return null;
      } // Delegate the EventEmitter through the public API of Hls.js
      ;

      _proto.on = function on(event, listener, context) {
        if (context === void 0) {
          context = this;
        }

        this._emitter.on(event, listener, context);
      };

      _proto.once = function once(event, listener, context) {
        if (context === void 0) {
          context = this;
        }

        this._emitter.once(event, listener, context);
      };

      _proto.removeAllListeners = function removeAllListeners(event) {
        this._emitter.removeAllListeners(event);
      };

      _proto.off = function off(event, listener, context, once) {
        if (context === void 0) {
          context = this;
        }

        this._emitter.off(event, listener, context, once);
      };

      _proto.listeners = function listeners(event) {
        return this._emitter.listeners(event);
      };

      _proto.emit = function emit(event, name, eventObject) {
        return this._emitter.emit(event, name, eventObject);
      };

      _proto.trigger = function trigger(event, eventObject) {
        if (this.config.debug) {
          return this.emit(event, event, eventObject);
        } else {
          try {
            return this.emit(event, event, eventObject);
          } catch (e) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].error('An internal error happened while handling event ' + event + '. Error message: "' + e.message + '". Here is a stacktrace:', e);
            this.trigger(_events__WEBPACK_IMPORTED_MODULE_12__["Events"].ERROR, {
              type: _errors__WEBPACK_IMPORTED_MODULE_13__["ErrorTypes"].OTHER_ERROR,
              details: _errors__WEBPACK_IMPORTED_MODULE_13__["ErrorDetails"].INTERNAL_EXCEPTION,
              fatal: false,
              event: event,
              error: e
            });
          }
        }

        return false;
      };

      _proto.listenerCount = function listenerCount(event) {
        return this._emitter.listenerCount(event);
      }
      /**
       * Dispose of the instance
       */
      ;

      _proto.destroy = function destroy() {
        _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log('destroy');
        this.trigger(_events__WEBPACK_IMPORTED_MODULE_12__["Events"].DESTROYING, undefined);
        this.detachMedia();
        this.removeAllListeners();
        this._autoLevelCapping = -1;
        this.url = null;
        this.networkControllers.forEach(function (component) {
          return component.destroy();
        });
        this.networkControllers.length = 0;
        this.coreComponents.forEach(function (component) {
          return component.destroy();
        });
        this.coreComponents.length = 0;
      }
      /**
       * Attaches Hls.js to a media element
       * @param {HTMLMediaElement} media
       */
      ;

      _proto.attachMedia = function attachMedia(media) {
        _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log('attachMedia');
        this._media = media;
        this.trigger(_events__WEBPACK_IMPORTED_MODULE_12__["Events"].MEDIA_ATTACHING, {
          media: media
        });
      }
      /**
       * Detach Hls.js from the media
       */
      ;

      _proto.detachMedia = function detachMedia() {
        _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log('detachMedia');
        this.trigger(_events__WEBPACK_IMPORTED_MODULE_12__["Events"].MEDIA_DETACHING, undefined);
        this._media = null;
      }
      /**
       * Set the source URL. Can be relative or absolute.
       * @param {string} url
       */
      ;

      _proto.loadSource = function loadSource(url) {
        this.stopLoad();
        var media = this.media;
        var loadedSource = this.url;
        var loadingSource = this.url = url_toolkit__WEBPACK_IMPORTED_MODULE_0__["buildAbsoluteURL"](self.location.href, url, {
          alwaysNormalize: true
        });
        _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log("loadSource:" + loadingSource);

        if (media && loadedSource && loadedSource !== loadingSource && this.bufferController.hasSourceTypes()) {
          this.detachMedia();
          this.attachMedia(media);
        } // when attaching to a source URL, trigger a playlist load


        this.trigger(_events__WEBPACK_IMPORTED_MODULE_12__["Events"].MANIFEST_LOADING, {
          url: url
        });
      }
      /**
       * Start loading data from the stream source.
       * Depending on default config, client starts loading automatically when a source is set.
       *
       * @param {number} startPosition Set the start position to stream from
       * @default -1 None (from earliest point)
       */
      ;

      _proto.startLoad = function startLoad(startPosition) {
        if (startPosition === void 0) {
          startPosition = -1;
        }

        _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log("startLoad(" + startPosition + ")");
        this.networkControllers.forEach(function (controller) {
          controller.startLoad(startPosition);
        });
      }
      /**
       * Stop loading of any stream data.
       */
      ;

      _proto.stopLoad = function stopLoad() {
        _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log('stopLoad');
        this.networkControllers.forEach(function (controller) {
          controller.stopLoad();
        });
      }
      /**
       * Swap through possible audio codecs in the stream (for example to switch from stereo to 5.1)
       */
      ;

      _proto.swapAudioCodec = function swapAudioCodec() {
        _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log('swapAudioCodec');
        this.streamController.swapAudioCodec();
      }
      /**
       * When the media-element fails, this allows to detach and then re-attach it
       * as one call (convenience method).
       *
       * Automatic recovery of media-errors by this process is configurable.
       */
      ;

      _proto.recoverMediaError = function recoverMediaError() {
        _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log('recoverMediaError');
        var media = this._media;
        this.detachMedia();

        if (media) {
          this.attachMedia(media);
        }
      };

      _proto.removeLevel = function removeLevel(levelIndex, urlId) {
        if (urlId === void 0) {
          urlId = 0;
        }

        this.levelController.removeLevel(levelIndex, urlId);
      }
      /**
       * @type {Level[]}
       */
      ;

      _createClass(Hls, [{
        key: "levels",
        get: function get() {
          var levels = this.levelController.levels;
          return levels ? levels : [];
        }
        /**
         * Index of quality level currently played
         * @type {number}
         */

      }, {
        key: "currentLevel",
        get: function get() {
          return this.streamController.currentLevel;
        }
        /**
         * Set quality level index immediately .
         * This will flush the current buffer to replace the quality asap.
         * That means playback will interrupt at least shortly to re-buffer and re-sync eventually.
         * @type {number} -1 for automatic level selection
         */
        ,
        set: function set(newLevel) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log("set currentLevel:" + newLevel);
          this.loadLevel = newLevel;
          this.abrController.clearTimer();
          this.streamController.immediateLevelSwitch();
        }
        /**
         * Index of next quality level loaded as scheduled by stream controller.
         * @type {number}
         */

      }, {
        key: "nextLevel",
        get: function get() {
          return this.streamController.nextLevel;
        }
        /**
         * Set quality level index for next loaded data.
         * This will switch the video quality asap, without interrupting playback.
         * May abort current loading of data, and flush parts of buffer (outside currently played fragment region).
         * @type {number} -1 for automatic level selection
         */
        ,
        set: function set(newLevel) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log("set nextLevel:" + newLevel);
          this.levelController.manualLevel = newLevel;
          this.streamController.nextLevelSwitch();
        }
        /**
         * Return the quality level of the currently or last (of none is loaded currently) segment
         * @type {number}
         */

      }, {
        key: "loadLevel",
        get: function get() {
          return this.levelController.level;
        }
        /**
         * Set quality level index for next loaded data in a conservative way.
         * This will switch the quality without flushing, but interrupt current loading.
         * Thus the moment when the quality switch will appear in effect will only be after the already existing buffer.
         * @type {number} newLevel -1 for automatic level selection
         */
        ,
        set: function set(newLevel) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log("set loadLevel:" + newLevel);
          this.levelController.manualLevel = newLevel;
        }
        /**
         * get next quality level loaded
         * @type {number}
         */

      }, {
        key: "nextLoadLevel",
        get: function get() {
          return this.levelController.nextLoadLevel;
        }
        /**
         * Set quality level of next loaded segment in a fully "non-destructive" way.
         * Same as `loadLevel` but will wait for next switch (until current loading is done).
         * @type {number} level
         */
        ,
        set: function set(level) {
          this.levelController.nextLoadLevel = level;
        }
        /**
         * Return "first level": like a default level, if not set,
         * falls back to index of first level referenced in manifest
         * @type {number}
         */

      }, {
        key: "firstLevel",
        get: function get() {
          return Math.max(this.levelController.firstLevel, this.minAutoLevel);
        }
        /**
         * Sets "first-level", see getter.
         * @type {number}
         */
        ,
        set: function set(newLevel) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log("set firstLevel:" + newLevel);
          this.levelController.firstLevel = newLevel;
        }
        /**
         * Return start level (level of first fragment that will be played back)
         * if not overrided by user, first level appearing in manifest will be used as start level
         * if -1 : automatic start level selection, playback will start from level matching download bandwidth
         * (determined from download of first segment)
         * @type {number}
         */

      }, {
        key: "startLevel",
        get: function get() {
          return this.levelController.startLevel;
        }
        /**
         * set  start level (level of first fragment that will be played back)
         * if not overrided by user, first level appearing in manifest will be used as start level
         * if -1 : automatic start level selection, playback will start from level matching download bandwidth
         * (determined from download of first segment)
         * @type {number} newLevel
         */
        ,
        set: function set(newLevel) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log("set startLevel:" + newLevel); // if not in automatic start level detection, ensure startLevel is greater than minAutoLevel

          if (newLevel !== -1) {
            newLevel = Math.max(newLevel, this.minAutoLevel);
          }

          this.levelController.startLevel = newLevel;
        }
        /**
         * Get the current setting for capLevelToPlayerSize
         *
         * @type {boolean}
         */

      }, {
        key: "capLevelToPlayerSize",
        get: function get() {
          return this.config.capLevelToPlayerSize;
        }
        /**
         * set  dynamically set capLevelToPlayerSize against (`CapLevelController`)
         *
         * @type {boolean}
         */
        ,
        set: function set(shouldStartCapping) {
          var newCapLevelToPlayerSize = !!shouldStartCapping;

          if (newCapLevelToPlayerSize !== this.config.capLevelToPlayerSize) {
            if (newCapLevelToPlayerSize) {
              this.capLevelController.startCapping(); // If capping occurs, nextLevelSwitch will happen based on size.
            } else {
              this.capLevelController.stopCapping();
              this.autoLevelCapping = -1;
              this.streamController.nextLevelSwitch(); // Now we're uncapped, get the next level asap.
            }

            this.config.capLevelToPlayerSize = newCapLevelToPlayerSize;
          }
        }
        /**
         * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)
         * @type {number}
         */

      }, {
        key: "autoLevelCapping",
        get: function get() {
          return this._autoLevelCapping;
        }
        /**
         * get bandwidth estimate
         * @type {number}
         */
        ,
        set:
        /**
         * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)
         * @type {number}
         */
        function set(newLevel) {
          if (this._autoLevelCapping !== newLevel) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_9__["logger"].log("set autoLevelCapping:" + newLevel);
            this._autoLevelCapping = newLevel;
          }
        }
        /**
         * True when automatic level selection enabled
         * @type {boolean}
         */

      }, {
        key: "bandwidthEstimate",
        get: function get() {
          var bwEstimator = this.abrController.bwEstimator;

          if (!bwEstimator) {
            return NaN;
          }

          return bwEstimator.getEstimate();
        }
      }, {
        key: "autoLevelEnabled",
        get: function get() {
          return this.levelController.manualLevel === -1;
        }
        /**
         * Level set manually (if any)
         * @type {number}
         */

      }, {
        key: "manualLevel",
        get: function get() {
          return this.levelController.manualLevel;
        }
        /**
         * min level selectable in auto mode according to config.minAutoBitrate
         * @type {number}
         */

      }, {
        key: "minAutoLevel",
        get: function get() {
          var levels = this.levels,
              minAutoBitrate = this.config.minAutoBitrate;
          if (!levels) return 0;
          var len = levels.length;

          for (var i = 0; i < len; i++) {
            if (levels[i].maxBitrate > minAutoBitrate) {
              return i;
            }
          }

          return 0;
        }
        /**
         * max level selectable in auto mode according to autoLevelCapping
         * @type {number}
         */

      }, {
        key: "maxAutoLevel",
        get: function get() {
          var levels = this.levels,
              autoLevelCapping = this.autoLevelCapping;
          var maxAutoLevel;

          if (autoLevelCapping === -1 && levels && levels.length) {
            maxAutoLevel = levels.length - 1;
          } else {
            maxAutoLevel = autoLevelCapping;
          }

          return maxAutoLevel;
        }
        /**
         * next automatically selected quality level
         * @type {number}
         */

      }, {
        key: "nextAutoLevel",
        get: function get() {
          // ensure next auto level is between  min and max auto level
          return Math.min(Math.max(this.abrController.nextAutoLevel, this.minAutoLevel), this.maxAutoLevel);
        }
        /**
         * this setter is used to force next auto level.
         * this is useful to force a switch down in auto mode:
         * in case of load error on level N, hls.js can set nextAutoLevel to N-1 for example)
         * forced value is valid for one fragment. upon successful frag loading at forced level,
         * this value will be resetted to -1 by ABR controller.
         * @type {number}
         */
        ,
        set: function set(nextLevel) {
          this.abrController.nextAutoLevel = Math.max(this.minAutoLevel, nextLevel);
        }
        /**
         * @type {AudioTrack[]}
         */

      }, {
        key: "audioTracks",
        get: function get() {
          var audioTrackController = this.audioTrackController;
          return audioTrackController ? audioTrackController.audioTracks : [];
        }
        /**
         * index of the selected audio track (index in audio track lists)
         * @type {number}
         */

      }, {
        key: "audioTrack",
        get: function get() {
          var audioTrackController = this.audioTrackController;
          return audioTrackController ? audioTrackController.audioTrack : -1;
        }
        /**
         * selects an audio track, based on its index in audio track lists
         * @type {number}
         */
        ,
        set: function set(audioTrackId) {
          var audioTrackController = this.audioTrackController;

          if (audioTrackController) {
            audioTrackController.audioTrack = audioTrackId;
          }
        }
        /**
         * get alternate subtitle tracks list from playlist
         * @type {MediaPlaylist[]}
         */

      }, {
        key: "subtitleTracks",
        get: function get() {
          var subtitleTrackController = this.subtitleTrackController;
          return subtitleTrackController ? subtitleTrackController.subtitleTracks : [];
        }
        /**
         * index of the selected subtitle track (index in subtitle track lists)
         * @type {number}
         */

      }, {
        key: "subtitleTrack",
        get: function get() {
          var subtitleTrackController = this.subtitleTrackController;
          return subtitleTrackController ? subtitleTrackController.subtitleTrack : -1;
        },
        set:
        /**
         * select an subtitle track, based on its index in subtitle track lists
         * @type {number}
         */
        function set(subtitleTrackId) {
          var subtitleTrackController = this.subtitleTrackController;

          if (subtitleTrackController) {
            subtitleTrackController.subtitleTrack = subtitleTrackId;
          }
        }
        /**
         * @type {boolean}
         */

      }, {
        key: "media",
        get: function get() {
          return this._media;
        }
      }, {
        key: "subtitleDisplay",
        get: function get() {
          var subtitleTrackController = this.subtitleTrackController;
          return subtitleTrackController ? subtitleTrackController.subtitleDisplay : false;
        }
        /**
         * Enable/disable subtitle display rendering
         * @type {boolean}
         */
        ,
        set: function set(value) {
          var subtitleTrackController = this.subtitleTrackController;

          if (subtitleTrackController) {
            subtitleTrackController.subtitleDisplay = value;
          }
        }
        /**
         * get mode for Low-Latency HLS loading
         * @type {boolean}
         */

      }, {
        key: "lowLatencyMode",
        get: function get() {
          return this.config.lowLatencyMode;
        }
        /**
         * Enable/disable Low-Latency HLS part playlist and segment loading, and start live streams at playlist PART-HOLD-BACK rather than HOLD-BACK.
         * @type {boolean}
         */
        ,
        set: function set(mode) {
          this.config.lowLatencyMode = mode;
        }
        /**
         * position (in seconds) of live sync point (ie edge of live position minus safety delay defined by ```hls.config.liveSyncDuration```)
         * @type {number}
         */

      }, {
        key: "liveSyncPosition",
        get: function get() {
          return this.latencyController.liveSyncPosition;
        }
        /**
         * estimated position (in seconds) of live edge (ie edge of live playlist plus time sync playlist advanced)
         * returns 0 before first playlist is loaded
         * @type {number}
         */

      }, {
        key: "latency",
        get: function get() {
          return this.latencyController.latency;
        }
        /**
         * maximum distance from the edge before the player seeks forward to ```hls.liveSyncPosition```
         * configured using ```liveMaxLatencyDurationCount``` (multiple of target duration) or ```liveMaxLatencyDuration```
         * returns 0 before first playlist is loaded
         * @type {number}
         */

      }, {
        key: "maxLatency",
        get: function get() {
          return this.latencyController.maxLatency;
        }
        /**
         * target distance from the edge as calculated by the latency controller
         * @type {number}
         */

      }, {
        key: "targetLatency",
        get: function get() {
          return this.latencyController.targetLatency;
        }
        /**
         * the rate at which the edge of the current live playlist is advancing or 1 if there is none
         * @type {number}
         */

      }, {
        key: "drift",
        get: function get() {
          return this.latencyController.drift;
        }
        /**
         * set to true when startLoad is called before MANIFEST_PARSED event
         * @type {boolean}
         */

      }, {
        key: "forceStartLoad",
        get: function get() {
          return this.streamController.forceStartLoad;
        }
      }], [{
        key: "version",
        get: function get() {
          return "1.1.5";
        }
      }, {
        key: "Events",
        get: function get() {
          return _events__WEBPACK_IMPORTED_MODULE_12__["Events"];
        }
      }, {
        key: "ErrorTypes",
        get: function get() {
          return _errors__WEBPACK_IMPORTED_MODULE_13__["ErrorTypes"];
        }
      }, {
        key: "ErrorDetails",
        get: function get() {
          return _errors__WEBPACK_IMPORTED_MODULE_13__["ErrorDetails"];
        }
      }, {
        key: "DefaultConfig",
        get: function get() {
          if (!Hls.defaultConfig) {
            return _config__WEBPACK_IMPORTED_MODULE_10__["hlsDefaultConfig"];
          }

          return Hls.defaultConfig;
        }
        /**
         * @type {HlsConfig}
         */
        ,
        set: function set(defaultConfig) {
          Hls.defaultConfig = defaultConfig;
        }
      }]);

      return Hls;
    }();

    Hls.defaultConfig = void 0;


    /***/ }),

    /***/ "./src/is-supported.ts":
    /*!*****************************!*\
      !*** ./src/is-supported.ts ***!
      \*****************************/
    /*! exports provided: isSupported, changeTypeSupported */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isSupported", function() { return isSupported; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "changeTypeSupported", function() { return changeTypeSupported; });
    /* harmony import */ var _utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils/mediasource-helper */ "./src/utils/mediasource-helper.ts");


    function getSourceBuffer() {
      return self.SourceBuffer || self.WebKitSourceBuffer;
    }

    function isSupported() {
      var mediaSource = Object(_utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_0__["getMediaSource"])();

      if (!mediaSource) {
        return false;
      }

      var sourceBuffer = getSourceBuffer();
      var isTypeSupported = mediaSource && typeof mediaSource.isTypeSupported === 'function' && mediaSource.isTypeSupported('video/mp4; codecs="avc1.42E01E,mp4a.40.2"'); // if SourceBuffer is exposed ensure its API is valid
      // safari and old version of Chrome doe not expose SourceBuffer globally so checking SourceBuffer.prototype is impossible

      var sourceBufferValidAPI = !sourceBuffer || sourceBuffer.prototype && typeof sourceBuffer.prototype.appendBuffer === 'function' && typeof sourceBuffer.prototype.remove === 'function';
      return !!isTypeSupported && !!sourceBufferValidAPI;
    }
    function changeTypeSupported() {
      var _sourceBuffer$prototy;

      var sourceBuffer = getSourceBuffer();
      return typeof (sourceBuffer === null || sourceBuffer === void 0 ? void 0 : (_sourceBuffer$prototy = sourceBuffer.prototype) === null || _sourceBuffer$prototy === void 0 ? void 0 : _sourceBuffer$prototy.changeType) === 'function';
    }

    /***/ }),

    /***/ "./src/loader/fragment-loader.ts":
    /*!***************************************!*\
      !*** ./src/loader/fragment-loader.ts ***!
      \***************************************/
    /*! exports provided: default, LoadError */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return FragmentLoader; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "LoadError", function() { return LoadError; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");



    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _wrapNativeSuper(Class) { var _cache = typeof Map === "function" ? new Map() : undefined; _wrapNativeSuper = function _wrapNativeSuper(Class) { if (Class === null || !_isNativeFunction(Class)) return Class; if (typeof Class !== "function") { throw new TypeError("Super expression must either be null or a function"); } if (typeof _cache !== "undefined") { if (_cache.has(Class)) return _cache.get(Class); _cache.set(Class, Wrapper); } function Wrapper() { return _construct(Class, arguments, _getPrototypeOf(this).constructor); } Wrapper.prototype = Object.create(Class.prototype, { constructor: { value: Wrapper, enumerable: false, writable: true, configurable: true } }); return _setPrototypeOf(Wrapper, Class); }; return _wrapNativeSuper(Class); }

    function _construct(Parent, args, Class) { if (_isNativeReflectConstruct()) { _construct = Reflect.construct; } else { _construct = function _construct(Parent, args, Class) { var a = [null]; a.push.apply(a, args); var Constructor = Function.bind.apply(Parent, a); var instance = new Constructor(); if (Class) _setPrototypeOf(instance, Class.prototype); return instance; }; } return _construct.apply(null, arguments); }

    function _isNativeReflectConstruct() { if (typeof Reflect === "undefined" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === "function") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }

    function _isNativeFunction(fn) { return Function.toString.call(fn).indexOf("[native code]") !== -1; }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }

    function _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }


    var MIN_CHUNK_SIZE = Math.pow(2, 17); // 128kb

    var FragmentLoader = /*#__PURE__*/function () {
      function FragmentLoader(config) {
        this.config = void 0;
        this.loader = null;
        this.partLoadTimeout = -1;
        this.config = config;
      }

      var _proto = FragmentLoader.prototype;

      _proto.destroy = function destroy() {
        if (this.loader) {
          this.loader.destroy();
          this.loader = null;
        }
      };

      _proto.abort = function abort() {
        if (this.loader) {
          // Abort the loader for current fragment. Only one may load at any given time
          this.loader.abort();
        }
      };

      _proto.load = function load(frag, _onProgress) {
        var _this = this;

        var url = frag.url;

        if (!url) {
          return Promise.reject(new LoadError({
            type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].NETWORK_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].FRAG_LOAD_ERROR,
            fatal: false,
            frag: frag,
            networkDetails: null
          }, "Fragment does not have a " + (url ? 'part list' : 'url')));
        }

        this.abort();
        var config = this.config;
        var FragmentILoader = config.fLoader;
        var DefaultILoader = config.loader;
        return new Promise(function (resolve, reject) {
          if (_this.loader) {
            _this.loader.destroy();
          }

          var loader = _this.loader = frag.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config);
          var loaderContext = createLoaderContext(frag);
          var loaderConfig = {
            timeout: config.fragLoadingTimeOut,
            maxRetry: 0,
            retryDelay: 0,
            maxRetryDelay: config.fragLoadingMaxRetryTimeout,
            highWaterMark: MIN_CHUNK_SIZE
          }; // Assign frag stats to the loader's stats reference

          frag.stats = loader.stats;
          loader.load(loaderContext, loaderConfig, {
            onSuccess: function onSuccess(response, stats, context, networkDetails) {
              _this.resetLoader(frag, loader);

              resolve({
                frag: frag,
                part: null,
                payload: response.data,
                networkDetails: networkDetails
              });
            },
            onError: function onError(response, context, networkDetails) {
              _this.resetLoader(frag, loader);

              reject(new LoadError({
                type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].NETWORK_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].FRAG_LOAD_ERROR,
                fatal: false,
                frag: frag,
                response: response,
                networkDetails: networkDetails
              }));
            },
            onAbort: function onAbort(stats, context, networkDetails) {
              _this.resetLoader(frag, loader);

              reject(new LoadError({
                type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].NETWORK_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].INTERNAL_ABORTED,
                fatal: false,
                frag: frag,
                networkDetails: networkDetails
              }));
            },
            onTimeout: function onTimeout(response, context, networkDetails) {
              _this.resetLoader(frag, loader);

              reject(new LoadError({
                type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].NETWORK_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].FRAG_LOAD_TIMEOUT,
                fatal: false,
                frag: frag,
                networkDetails: networkDetails
              }));
            },
            onProgress: function onProgress(stats, context, data, networkDetails) {
              if (_onProgress) {
                _onProgress({
                  frag: frag,
                  part: null,
                  payload: data,
                  networkDetails: networkDetails
                });
              }
            }
          });
        });
      };

      _proto.loadPart = function loadPart(frag, part, onProgress) {
        var _this2 = this;

        this.abort();
        var config = this.config;
        var FragmentILoader = config.fLoader;
        var DefaultILoader = config.loader;
        return new Promise(function (resolve, reject) {
          if (_this2.loader) {
            _this2.loader.destroy();
          }

          var loader = _this2.loader = frag.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config);
          var loaderContext = createLoaderContext(frag, part);
          var loaderConfig = {
            timeout: config.fragLoadingTimeOut,
            maxRetry: 0,
            retryDelay: 0,
            maxRetryDelay: config.fragLoadingMaxRetryTimeout,
            highWaterMark: MIN_CHUNK_SIZE
          }; // Assign part stats to the loader's stats reference

          part.stats = loader.stats;
          loader.load(loaderContext, loaderConfig, {
            onSuccess: function onSuccess(response, stats, context, networkDetails) {
              _this2.resetLoader(frag, loader);

              _this2.updateStatsFromPart(frag, part);

              var partLoadedData = {
                frag: frag,
                part: part,
                payload: response.data,
                networkDetails: networkDetails
              };
              onProgress(partLoadedData);
              resolve(partLoadedData);
            },
            onError: function onError(response, context, networkDetails) {
              _this2.resetLoader(frag, loader);

              reject(new LoadError({
                type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].NETWORK_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].FRAG_LOAD_ERROR,
                fatal: false,
                frag: frag,
                part: part,
                response: response,
                networkDetails: networkDetails
              }));
            },
            onAbort: function onAbort(stats, context, networkDetails) {
              frag.stats.aborted = part.stats.aborted;

              _this2.resetLoader(frag, loader);

              reject(new LoadError({
                type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].NETWORK_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].INTERNAL_ABORTED,
                fatal: false,
                frag: frag,
                part: part,
                networkDetails: networkDetails
              }));
            },
            onTimeout: function onTimeout(response, context, networkDetails) {
              _this2.resetLoader(frag, loader);

              reject(new LoadError({
                type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].NETWORK_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].FRAG_LOAD_TIMEOUT,
                fatal: false,
                frag: frag,
                part: part,
                networkDetails: networkDetails
              }));
            }
          });
        });
      };

      _proto.updateStatsFromPart = function updateStatsFromPart(frag, part) {
        var fragStats = frag.stats;
        var partStats = part.stats;
        var partTotal = partStats.total;
        fragStats.loaded += partStats.loaded;

        if (partTotal) {
          var estTotalParts = Math.round(frag.duration / part.duration);
          var estLoadedParts = Math.min(Math.round(fragStats.loaded / partTotal), estTotalParts);
          var estRemainingParts = estTotalParts - estLoadedParts;
          var estRemainingBytes = estRemainingParts * Math.round(fragStats.loaded / estLoadedParts);
          fragStats.total = fragStats.loaded + estRemainingBytes;
        } else {
          fragStats.total = Math.max(fragStats.loaded, fragStats.total);
        }

        var fragLoading = fragStats.loading;
        var partLoading = partStats.loading;

        if (fragLoading.start) {
          // add to fragment loader latency
          fragLoading.first += partLoading.first - partLoading.start;
        } else {
          fragLoading.start = partLoading.start;
          fragLoading.first = partLoading.first;
        }

        fragLoading.end = partLoading.end;
      };

      _proto.resetLoader = function resetLoader(frag, loader) {
        frag.loader = null;

        if (this.loader === loader) {
          self.clearTimeout(this.partLoadTimeout);
          this.loader = null;
        }

        loader.destroy();
      };

      return FragmentLoader;
    }();



    function createLoaderContext(frag, part) {
      if (part === void 0) {
        part = null;
      }

      var segment = part || frag;
      var loaderContext = {
        frag: frag,
        part: part,
        responseType: 'arraybuffer',
        url: segment.url,
        headers: {},
        rangeStart: 0,
        rangeEnd: 0
      };
      var start = segment.byteRangeStartOffset;
      var end = segment.byteRangeEndOffset;

      if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(start) && Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(end)) {
        loaderContext.rangeStart = start;
        loaderContext.rangeEnd = end;
      }

      return loaderContext;
    }

    var LoadError = /*#__PURE__*/function (_Error) {
      _inheritsLoose(LoadError, _Error);

      function LoadError(data) {
        var _this3;

        for (var _len = arguments.length, params = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {
          params[_key - 1] = arguments[_key];
        }

        _this3 = _Error.call.apply(_Error, [this].concat(params)) || this;
        _this3.data = void 0;
        _this3.data = data;
        return _this3;
      }

      return LoadError;
    }( /*#__PURE__*/_wrapNativeSuper(Error));

    /***/ }),

    /***/ "./src/loader/fragment.ts":
    /*!********************************!*\
      !*** ./src/loader/fragment.ts ***!
      \********************************/
    /*! exports provided: ElementaryStreamTypes, BaseSegment, Fragment, Part */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ElementaryStreamTypes", function() { return ElementaryStreamTypes; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "BaseSegment", function() { return BaseSegment; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Fragment", function() { return Fragment; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Part", function() { return Part; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var url_toolkit__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! url-toolkit */ "./node_modules/url-toolkit/src/url-toolkit.js");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _level_key__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./level-key */ "./src/loader/level-key.ts");
    /* harmony import */ var _load_stats__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./load-stats */ "./src/loader/load-stats.ts");



    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }

    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }





    var ElementaryStreamTypes;

    (function (ElementaryStreamTypes) {
      ElementaryStreamTypes["AUDIO"] = "audio";
      ElementaryStreamTypes["VIDEO"] = "video";
      ElementaryStreamTypes["AUDIOVIDEO"] = "audiovideo";
    })(ElementaryStreamTypes || (ElementaryStreamTypes = {}));

    var BaseSegment = /*#__PURE__*/function () {
      // baseurl is the URL to the playlist
      // relurl is the portion of the URL that comes from inside the playlist.
      // Holds the types of data this fragment supports
      function BaseSegment(baseurl) {
        var _this$elementaryStrea;

        this._byteRange = null;
        this._url = null;
        this.baseurl = void 0;
        this.relurl = void 0;
        this.elementaryStreams = (_this$elementaryStrea = {}, _this$elementaryStrea[ElementaryStreamTypes.AUDIO] = null, _this$elementaryStrea[ElementaryStreamTypes.VIDEO] = null, _this$elementaryStrea[ElementaryStreamTypes.AUDIOVIDEO] = null, _this$elementaryStrea);
        this.baseurl = baseurl;
      } // setByteRange converts a EXT-X-BYTERANGE attribute into a two element array


      var _proto = BaseSegment.prototype;

      _proto.setByteRange = function setByteRange(value, previous) {
        var params = value.split('@', 2);
        var byteRange = [];

        if (params.length === 1) {
          byteRange[0] = previous ? previous.byteRangeEndOffset : 0;
        } else {
          byteRange[0] = parseInt(params[1]);
        }

        byteRange[1] = parseInt(params[0]) + byteRange[0];
        this._byteRange = byteRange;
      };

      _createClass(BaseSegment, [{
        key: "byteRange",
        get: function get() {
          if (!this._byteRange) {
            return [];
          }

          return this._byteRange;
        }
      }, {
        key: "byteRangeStartOffset",
        get: function get() {
          return this.byteRange[0];
        }
      }, {
        key: "byteRangeEndOffset",
        get: function get() {
          return this.byteRange[1];
        }
      }, {
        key: "url",
        get: function get() {
          if (!this._url && this.baseurl && this.relurl) {
            this._url = Object(url_toolkit__WEBPACK_IMPORTED_MODULE_1__["buildAbsoluteURL"])(this.baseurl, this.relurl, {
              alwaysNormalize: true
            });
          }

          return this._url || '';
        },
        set: function set(value) {
          this._url = value;
        }
      }]);

      return BaseSegment;
    }();
    var Fragment = /*#__PURE__*/function (_BaseSegment) {
      _inheritsLoose(Fragment, _BaseSegment);

      // EXTINF has to be present for a m38 to be considered valid
      // sn notates the sequence number for a segment, and if set to a string can be 'initSegment'
      // levelkey is the EXT-X-KEY that applies to this segment for decryption
      // core difference from the private field _decryptdata is the lack of the initialized IV
      // _decryptdata will set the IV for this segment based on the segment number in the fragment
      // A string representing the fragment type
      // A reference to the loader. Set while the fragment is loading, and removed afterwards. Used to abort fragment loading
      // The level/track index to which the fragment belongs
      // The continuity counter of the fragment
      // The starting Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.
      // The ending Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.
      // The latest Presentation Time Stamp (PTS) appended to the buffer.
      // The starting Decode Time Stamp (DTS) of the fragment. Set after transmux complete.
      // The ending Decode Time Stamp (DTS) of the fragment. Set after transmux complete.
      // The start time of the fragment, as listed in the manifest. Updated after transmux complete.
      // Set by `updateFragPTSDTS` in level-helper
      // The maximum starting Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.
      // The minimum ending Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.
      // Load/parse timing information
      // A flag indicating whether the segment was downloaded in order to test bitrate, and was not buffered
      // #EXTINF  segment title
      // The Media Initialization Section for this segment
      function Fragment(type, baseurl) {
        var _this;

        _this = _BaseSegment.call(this, baseurl) || this;
        _this._decryptdata = null;
        _this.rawProgramDateTime = null;
        _this.programDateTime = null;
        _this.tagList = [];
        _this.duration = 0;
        _this.sn = 0;
        _this.levelkey = void 0;
        _this.type = void 0;
        _this.loader = null;
        _this.level = -1;
        _this.cc = 0;
        _this.startPTS = void 0;
        _this.endPTS = void 0;
        _this.appendedPTS = void 0;
        _this.startDTS = void 0;
        _this.endDTS = void 0;
        _this.start = 0;
        _this.deltaPTS = void 0;
        _this.maxStartPTS = void 0;
        _this.minEndPTS = void 0;
        _this.stats = new _load_stats__WEBPACK_IMPORTED_MODULE_4__["LoadStats"]();
        _this.urlId = 0;
        _this.data = void 0;
        _this.bitrateTest = false;
        _this.title = null;
        _this.initSegment = null;
        _this.type = type;
        return _this;
      }

      var _proto2 = Fragment.prototype;

      /**
       * Utility method for parseLevelPlaylist to create an initialization vector for a given segment
       * @param {number} segmentNumber - segment number to generate IV with
       * @returns {Uint8Array}
       */
      _proto2.createInitializationVector = function createInitializationVector(segmentNumber) {
        var uint8View = new Uint8Array(16);

        for (var i = 12; i < 16; i++) {
          uint8View[i] = segmentNumber >> 8 * (15 - i) & 0xff;
        }

        return uint8View;
      }
      /**
       * Utility method for parseLevelPlaylist to get a fragment's decryption data from the currently parsed encryption key data
       * @param levelkey - a playlist's encryption info
       * @param segmentNumber - the fragment's segment number
       * @returns {LevelKey} - an object to be applied as a fragment's decryptdata
       */
      ;

      _proto2.setDecryptDataFromLevelKey = function setDecryptDataFromLevelKey(levelkey, segmentNumber) {
        var decryptdata = levelkey;

        if ((levelkey === null || levelkey === void 0 ? void 0 : levelkey.method) === 'AES-128' && levelkey.uri && !levelkey.iv) {
          decryptdata = _level_key__WEBPACK_IMPORTED_MODULE_3__["LevelKey"].fromURI(levelkey.uri);
          decryptdata.method = levelkey.method;
          decryptdata.iv = this.createInitializationVector(segmentNumber);
          decryptdata.keyFormat = 'identity';
        }

        return decryptdata;
      };

      _proto2.setElementaryStreamInfo = function setElementaryStreamInfo(type, startPTS, endPTS, startDTS, endDTS, partial) {
        if (partial === void 0) {
          partial = false;
        }

        var elementaryStreams = this.elementaryStreams;
        var info = elementaryStreams[type];

        if (!info) {
          elementaryStreams[type] = {
            startPTS: startPTS,
            endPTS: endPTS,
            startDTS: startDTS,
            endDTS: endDTS,
            partial: partial
          };
          return;
        }

        info.startPTS = Math.min(info.startPTS, startPTS);
        info.endPTS = Math.max(info.endPTS, endPTS);
        info.startDTS = Math.min(info.startDTS, startDTS);
        info.endDTS = Math.max(info.endDTS, endDTS);
      };

      _proto2.clearElementaryStreamInfo = function clearElementaryStreamInfo() {
        var elementaryStreams = this.elementaryStreams;
        elementaryStreams[ElementaryStreamTypes.AUDIO] = null;
        elementaryStreams[ElementaryStreamTypes.VIDEO] = null;
        elementaryStreams[ElementaryStreamTypes.AUDIOVIDEO] = null;
      };

      _createClass(Fragment, [{
        key: "decryptdata",
        get: function get() {
          if (!this.levelkey && !this._decryptdata) {
            return null;
          }

          if (!this._decryptdata && this.levelkey) {
            var sn = this.sn;

            if (typeof sn !== 'number') {
              // We are fetching decryption data for a initialization segment
              // If the segment was encrypted with AES-128
              // It must have an IV defined. We cannot substitute the Segment Number in.
              if (this.levelkey && this.levelkey.method === 'AES-128' && !this.levelkey.iv) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn("missing IV for initialization segment with method=\"" + this.levelkey.method + "\" - compliance issue");
              }
              /*
              Be converted to a Number.
              'initSegment' will become NaN.
              NaN, which when converted through ToInt32() -> +0.
              ---
              Explicitly set sn to resulting value from implicit conversions 'initSegment' values for IV generation.
              */


              sn = 0;
            }

            this._decryptdata = this.setDecryptDataFromLevelKey(this.levelkey, sn);
          }

          return this._decryptdata;
        }
      }, {
        key: "end",
        get: function get() {
          return this.start + this.duration;
        }
      }, {
        key: "endProgramDateTime",
        get: function get() {
          if (this.programDateTime === null) {
            return null;
          }

          if (!Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(this.programDateTime)) {
            return null;
          }

          var duration = !Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(this.duration) ? 0 : this.duration;
          return this.programDateTime + duration * 1000;
        }
      }, {
        key: "encrypted",
        get: function get() {
          var _this$decryptdata;

          // At the m3u8-parser level we need to add support for manifest signalled keyformats
          // when we want the fragment to start reporting that it is encrypted.
          // Currently, keyFormat will only be set for identity keys
          if ((_this$decryptdata = this.decryptdata) !== null && _this$decryptdata !== void 0 && _this$decryptdata.keyFormat && this.decryptdata.uri) {
            return true;
          }

          return false;
        }
      }]);

      return Fragment;
    }(BaseSegment);
    var Part = /*#__PURE__*/function (_BaseSegment2) {
      _inheritsLoose(Part, _BaseSegment2);

      function Part(partAttrs, frag, baseurl, index, previous) {
        var _this2;

        _this2 = _BaseSegment2.call(this, baseurl) || this;
        _this2.fragOffset = 0;
        _this2.duration = 0;
        _this2.gap = false;
        _this2.independent = false;
        _this2.relurl = void 0;
        _this2.fragment = void 0;
        _this2.index = void 0;
        _this2.stats = new _load_stats__WEBPACK_IMPORTED_MODULE_4__["LoadStats"]();
        _this2.duration = partAttrs.decimalFloatingPoint('DURATION');
        _this2.gap = partAttrs.bool('GAP');
        _this2.independent = partAttrs.bool('INDEPENDENT');
        _this2.relurl = partAttrs.enumeratedString('URI');
        _this2.fragment = frag;
        _this2.index = index;
        var byteRange = partAttrs.enumeratedString('BYTERANGE');

        if (byteRange) {
          _this2.setByteRange(byteRange, previous);
        }

        if (previous) {
          _this2.fragOffset = previous.fragOffset + previous.duration;
        }

        return _this2;
      }

      _createClass(Part, [{
        key: "start",
        get: function get() {
          return this.fragment.start + this.fragOffset;
        }
      }, {
        key: "end",
        get: function get() {
          return this.start + this.duration;
        }
      }, {
        key: "loaded",
        get: function get() {
          var elementaryStreams = this.elementaryStreams;
          return !!(elementaryStreams.audio || elementaryStreams.video || elementaryStreams.audiovideo);
        }
      }]);

      return Part;
    }(BaseSegment);

    /***/ }),

    /***/ "./src/loader/key-loader.ts":
    /*!**********************************!*\
      !*** ./src/loader/key-loader.ts ***!
      \**********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return KeyLoader; });
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /*
     * Decrypt key Loader
     */




    var KeyLoader = /*#__PURE__*/function () {
      function KeyLoader(hls) {
        this.hls = void 0;
        this.loaders = {};
        this.decryptkey = null;
        this.decrypturl = null;
        this.hls = hls;

        this._registerListeners();
      }

      var _proto = KeyLoader.prototype;

      _proto._registerListeners = function _registerListeners() {
        this.hls.on(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].KEY_LOADING, this.onKeyLoading, this);
      };

      _proto._unregisterListeners = function _unregisterListeners() {
        this.hls.off(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].KEY_LOADING, this.onKeyLoading);
      };

      _proto.destroy = function destroy() {
        this._unregisterListeners();

        for (var loaderName in this.loaders) {
          var loader = this.loaders[loaderName];

          if (loader) {
            loader.destroy();
          }
        }

        this.loaders = {};
      };

      _proto.onKeyLoading = function onKeyLoading(event, data) {
        var frag = data.frag;
        var type = frag.type;
        var loader = this.loaders[type];

        if (!frag.decryptdata) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn('Missing decryption data on fragment in onKeyLoading');
          return;
        } // Load the key if the uri is different from previous one, or if the decrypt key has not yet been retrieved


        var uri = frag.decryptdata.uri;

        if (uri !== this.decrypturl || this.decryptkey === null) {
          var config = this.hls.config;

          if (loader) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn("abort previous key loader for type:" + type);
            loader.abort();
          }

          if (!uri) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].warn('key uri is falsy');
            return;
          }

          var Loader = config.loader;
          var fragLoader = frag.loader = this.loaders[type] = new Loader(config);
          this.decrypturl = uri;
          this.decryptkey = null;
          var loaderContext = {
            url: uri,
            frag: frag,
            responseType: 'arraybuffer'
          }; // maxRetry is 0 so that instead of retrying the same key on the same variant multiple times,
          // key-loader will trigger an error and rely on stream-controller to handle retry logic.
          // this will also align retry logic with fragment-loader

          var loaderConfig = {
            timeout: config.fragLoadingTimeOut,
            maxRetry: 0,
            retryDelay: config.fragLoadingRetryDelay,
            maxRetryDelay: config.fragLoadingMaxRetryTimeout,
            highWaterMark: 0
          };
          var loaderCallbacks = {
            onSuccess: this.loadsuccess.bind(this),
            onError: this.loaderror.bind(this),
            onTimeout: this.loadtimeout.bind(this)
          };
          fragLoader.load(loaderContext, loaderConfig, loaderCallbacks);
        } else if (this.decryptkey) {
          // Return the key if it's already been loaded
          frag.decryptdata.key = this.decryptkey;
          this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].KEY_LOADED, {
            frag: frag
          });
        }
      };

      _proto.loadsuccess = function loadsuccess(response, stats, context) {
        var frag = context.frag;

        if (!frag.decryptdata) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_2__["logger"].error('after key load, decryptdata unset');
          return;
        }

        this.decryptkey = frag.decryptdata.key = new Uint8Array(response.data); // detach fragment loader on load success

        frag.loader = null;
        delete this.loaders[frag.type];
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].KEY_LOADED, {
          frag: frag
        });
      };

      _proto.loaderror = function loaderror(response, context) {
        var frag = context.frag;
        var loader = frag.loader;

        if (loader) {
          loader.abort();
        }

        delete this.loaders[frag.type];
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
          type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].NETWORK_ERROR,
          details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].KEY_LOAD_ERROR,
          fatal: false,
          frag: frag,
          response: response
        });
      };

      _proto.loadtimeout = function loadtimeout(stats, context) {
        var frag = context.frag;
        var loader = frag.loader;

        if (loader) {
          loader.abort();
        }

        delete this.loaders[frag.type];
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__["Events"].ERROR, {
          type: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorTypes"].NETWORK_ERROR,
          details: _errors__WEBPACK_IMPORTED_MODULE_1__["ErrorDetails"].KEY_LOAD_TIMEOUT,
          fatal: false,
          frag: frag
        });
      };

      return KeyLoader;
    }();



    /***/ }),

    /***/ "./src/loader/level-details.ts":
    /*!*************************************!*\
      !*** ./src/loader/level-details.ts ***!
      \*************************************/
    /*! exports provided: LevelDetails */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "LevelDetails", function() { return LevelDetails; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");


    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

    var DEFAULT_TARGET_DURATION = 10;
    var LevelDetails = /*#__PURE__*/function () {
      // Manifest reload synchronization
      function LevelDetails(baseUrl) {
        this.PTSKnown = false;
        this.alignedSliding = false;
        this.averagetargetduration = void 0;
        this.endCC = 0;
        this.endSN = 0;
        this.fragments = void 0;
        this.fragmentHint = void 0;
        this.partList = null;
        this.live = true;
        this.ageHeader = 0;
        this.advancedDateTime = void 0;
        this.updated = true;
        this.advanced = true;
        this.availabilityDelay = void 0;
        this.misses = 0;
        this.needSidxRanges = false;
        this.startCC = 0;
        this.startSN = 0;
        this.startTimeOffset = null;
        this.targetduration = 0;
        this.totalduration = 0;
        this.type = null;
        this.url = void 0;
        this.m3u8 = '';
        this.version = null;
        this.canBlockReload = false;
        this.canSkipUntil = 0;
        this.canSkipDateRanges = false;
        this.skippedSegments = 0;
        this.recentlyRemovedDateranges = void 0;
        this.partHoldBack = 0;
        this.holdBack = 0;
        this.partTarget = 0;
        this.preloadHint = void 0;
        this.renditionReports = void 0;
        this.tuneInGoal = 0;
        this.deltaUpdateFailed = void 0;
        this.driftStartTime = 0;
        this.driftEndTime = 0;
        this.driftStart = 0;
        this.driftEnd = 0;
        this.fragments = [];
        this.url = baseUrl;
      }

      var _proto = LevelDetails.prototype;

      _proto.reloaded = function reloaded(previous) {
        if (!previous) {
          this.advanced = true;
          this.updated = true;
          return;
        }

        var partSnDiff = this.lastPartSn - previous.lastPartSn;
        var partIndexDiff = this.lastPartIndex - previous.lastPartIndex;
        this.updated = this.endSN !== previous.endSN || !!partIndexDiff || !!partSnDiff;
        this.advanced = this.endSN > previous.endSN || partSnDiff > 0 || partSnDiff === 0 && partIndexDiff > 0;

        if (this.updated || this.advanced) {
          this.misses = Math.floor(previous.misses * 0.6);
        } else {
          this.misses = previous.misses + 1;
        }

        this.availabilityDelay = previous.availabilityDelay;
      };

      _createClass(LevelDetails, [{
        key: "hasProgramDateTime",
        get: function get() {
          if (this.fragments.length) {
            return Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(this.fragments[this.fragments.length - 1].programDateTime);
          }

          return false;
        }
      }, {
        key: "levelTargetDuration",
        get: function get() {
          return this.averagetargetduration || this.targetduration || DEFAULT_TARGET_DURATION;
        }
      }, {
        key: "drift",
        get: function get() {
          var runTime = this.driftEndTime - this.driftStartTime;

          if (runTime > 0) {
            var runDuration = this.driftEnd - this.driftStart;
            return runDuration * 1000 / runTime;
          }

          return 1;
        }
      }, {
        key: "edge",
        get: function get() {
          return this.partEnd || this.fragmentEnd;
        }
      }, {
        key: "partEnd",
        get: function get() {
          var _this$partList;

          if ((_this$partList = this.partList) !== null && _this$partList !== void 0 && _this$partList.length) {
            return this.partList[this.partList.length - 1].end;
          }

          return this.fragmentEnd;
        }
      }, {
        key: "fragmentEnd",
        get: function get() {
          var _this$fragments;

          if ((_this$fragments = this.fragments) !== null && _this$fragments !== void 0 && _this$fragments.length) {
            return this.fragments[this.fragments.length - 1].end;
          }

          return 0;
        }
      }, {
        key: "age",
        get: function get() {
          if (this.advancedDateTime) {
            return Math.max(Date.now() - this.advancedDateTime, 0) / 1000;
          }

          return 0;
        }
      }, {
        key: "lastPartIndex",
        get: function get() {
          var _this$partList2;

          if ((_this$partList2 = this.partList) !== null && _this$partList2 !== void 0 && _this$partList2.length) {
            return this.partList[this.partList.length - 1].index;
          }

          return -1;
        }
      }, {
        key: "lastPartSn",
        get: function get() {
          var _this$partList3;

          if ((_this$partList3 = this.partList) !== null && _this$partList3 !== void 0 && _this$partList3.length) {
            return this.partList[this.partList.length - 1].fragment.sn;
          }

          return this.endSN;
        }
      }]);

      return LevelDetails;
    }();

    /***/ }),

    /***/ "./src/loader/level-key.ts":
    /*!*********************************!*\
      !*** ./src/loader/level-key.ts ***!
      \*********************************/
    /*! exports provided: LevelKey */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "LevelKey", function() { return LevelKey; });
    /* harmony import */ var url_toolkit__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! url-toolkit */ "./node_modules/url-toolkit/src/url-toolkit.js");
    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }


    var LevelKey = /*#__PURE__*/function () {
      LevelKey.fromURL = function fromURL(baseUrl, relativeUrl) {
        return new LevelKey(baseUrl, relativeUrl);
      };

      LevelKey.fromURI = function fromURI(uri) {
        return new LevelKey(uri);
      };

      function LevelKey(absoluteOrBaseURI, relativeURL) {
        this._uri = null;
        this.method = null;
        this.keyFormat = null;
        this.keyFormatVersions = null;
        this.keyID = null;
        this.key = null;
        this.iv = null;

        if (relativeURL) {
          this._uri = Object(url_toolkit__WEBPACK_IMPORTED_MODULE_0__["buildAbsoluteURL"])(absoluteOrBaseURI, relativeURL, {
            alwaysNormalize: true
          });
        } else {
          this._uri = absoluteOrBaseURI;
        }
      }

      _createClass(LevelKey, [{
        key: "uri",
        get: function get() {
          return this._uri;
        }
      }]);

      return LevelKey;
    }();

    /***/ }),

    /***/ "./src/loader/load-stats.ts":
    /*!**********************************!*\
      !*** ./src/loader/load-stats.ts ***!
      \**********************************/
    /*! exports provided: LoadStats */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "LoadStats", function() { return LoadStats; });
    var LoadStats = function LoadStats() {
      this.aborted = false;
      this.loaded = 0;
      this.retry = 0;
      this.total = 0;
      this.chunkCount = 0;
      this.bwEstimate = 0;
      this.loading = {
        start: 0,
        first: 0,
        end: 0
      };
      this.parsing = {
        start: 0,
        end: 0
      };
      this.buffering = {
        start: 0,
        first: 0,
        end: 0
      };
    };

    /***/ }),

    /***/ "./src/loader/m3u8-parser.ts":
    /*!***********************************!*\
      !*** ./src/loader/m3u8-parser.ts ***!
      \***********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return M3U8Parser; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var url_toolkit__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! url-toolkit */ "./node_modules/url-toolkit/src/url-toolkit.js");
    /* harmony import */ var _fragment__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./fragment */ "./src/loader/fragment.ts");
    /* harmony import */ var _level_details__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./level-details */ "./src/loader/level-details.ts");
    /* harmony import */ var _level_key__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./level-key */ "./src/loader/level-key.ts");
    /* harmony import */ var _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/attr-list */ "./src/utils/attr-list.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _utils_codecs__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../utils/codecs */ "./src/utils/codecs.ts");











    // https://regex101.com is your friend
    var MASTER_PLAYLIST_REGEX = /#EXT-X-STREAM-INF:([^\r\n]*)(?:[\r\n](?:#[^\r\n]*)?)*([^\r\n]+)|#EXT-X-SESSION-DATA:([^\r\n]*)[\r\n]+/g;
    var MASTER_PLAYLIST_MEDIA_REGEX = /#EXT-X-MEDIA:(.*)/g;
    var LEVEL_PLAYLIST_REGEX_FAST = new RegExp([/#EXTINF:\s*(\d*(?:\.\d+)?)(?:,(.*)\s+)?/.source, // duration (#EXTINF:<duration>,<title>), group 1 => duration, group 2 => title
    /(?!#) *(\S[\S ]*)/.source, // segment URI, group 3 => the URI (note newline is not eaten)
    /#EXT-X-BYTERANGE:*(.+)/.source, // next segment's byterange, group 4 => range spec (x@y)
    /#EXT-X-PROGRAM-DATE-TIME:(.+)/.source, // next segment's program date/time group 5 => the datetime spec
    /#.*/.source // All other non-segment oriented tags will match with all groups empty
    ].join('|'), 'g');
    var LEVEL_PLAYLIST_REGEX_SLOW = new RegExp([/#(EXTM3U)/.source, /#EXT-X-(PLAYLIST-TYPE):(.+)/.source, /#EXT-X-(MEDIA-SEQUENCE): *(\d+)/.source, /#EXT-X-(SKIP):(.+)/.source, /#EXT-X-(TARGETDURATION): *(\d+)/.source, /#EXT-X-(KEY):(.+)/.source, /#EXT-X-(START):(.+)/.source, /#EXT-X-(ENDLIST)/.source, /#EXT-X-(DISCONTINUITY-SEQ)UENCE: *(\d+)/.source, /#EXT-X-(DIS)CONTINUITY/.source, /#EXT-X-(VERSION):(\d+)/.source, /#EXT-X-(MAP):(.+)/.source, /#EXT-X-(SERVER-CONTROL):(.+)/.source, /#EXT-X-(PART-INF):(.+)/.source, /#EXT-X-(GAP)/.source, /#EXT-X-(BITRATE):\s*(\d+)/.source, /#EXT-X-(PART):(.+)/.source, /#EXT-X-(PRELOAD-HINT):(.+)/.source, /#EXT-X-(RENDITION-REPORT):(.+)/.source, /(#)([^:]*):(.*)/.source, /(#)(.*)(?:.*)\r?\n?/.source].join('|'));
    var MP4_REGEX_SUFFIX = /\.(mp4|m4s|m4v|m4a)$/i;

    function isMP4Url(url) {
      var _URLToolkit$parseURL$, _URLToolkit$parseURL;

      return MP4_REGEX_SUFFIX.test((_URLToolkit$parseURL$ = (_URLToolkit$parseURL = url_toolkit__WEBPACK_IMPORTED_MODULE_1__["parseURL"](url)) === null || _URLToolkit$parseURL === void 0 ? void 0 : _URLToolkit$parseURL.path) != null ? _URLToolkit$parseURL$ : '');
    }

    var M3U8Parser = /*#__PURE__*/function () {
      function M3U8Parser() {}

      M3U8Parser.findGroup = function findGroup(groups, mediaGroupId) {
        for (var i = 0; i < groups.length; i++) {
          var group = groups[i];

          if (group.id === mediaGroupId) {
            return group;
          }
        }
      };

      M3U8Parser.convertAVC1ToAVCOTI = function convertAVC1ToAVCOTI(codec) {
        // Convert avc1 codec string from RFC-4281 to RFC-6381 for MediaSource.isTypeSupported
        var avcdata = codec.split('.');

        if (avcdata.length > 2) {
          var result = avcdata.shift() + '.';
          result += parseInt(avcdata.shift()).toString(16);
          result += ('000' + parseInt(avcdata.shift()).toString(16)).substr(-4);
          return result;
        }

        return codec;
      };

      M3U8Parser.resolve = function resolve(url, baseUrl) {
        return url_toolkit__WEBPACK_IMPORTED_MODULE_1__["buildAbsoluteURL"](baseUrl, url, {
          alwaysNormalize: true
        });
      };

      M3U8Parser.parseMasterPlaylist = function parseMasterPlaylist(string, baseurl) {
        var levels = [];
        var sessionData = {};
        var hasSessionData = false;
        MASTER_PLAYLIST_REGEX.lastIndex = 0;
        var result;

        while ((result = MASTER_PLAYLIST_REGEX.exec(string)) != null) {
          if (result[1]) {
            // '#EXT-X-STREAM-INF' is found, parse level tag  in group 1
            var attrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](result[1]);
            var level = {
              attrs: attrs,
              bitrate: attrs.decimalInteger('AVERAGE-BANDWIDTH') || attrs.decimalInteger('BANDWIDTH'),
              name: attrs.NAME,
              url: M3U8Parser.resolve(result[2], baseurl)
            };
            var resolution = attrs.decimalResolution('RESOLUTION');

            if (resolution) {
              level.width = resolution.width;
              level.height = resolution.height;
            }

            setCodecs((attrs.CODECS || '').split(/[ ,]+/).filter(function (c) {
              return c;
            }), level);

            if (level.videoCodec && level.videoCodec.indexOf('avc1') !== -1) {
              level.videoCodec = M3U8Parser.convertAVC1ToAVCOTI(level.videoCodec);
            }

            levels.push(level);
          } else if (result[3]) {
            // '#EXT-X-SESSION-DATA' is found, parse session data in group 3
            var sessionAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](result[3]);

            if (sessionAttrs['DATA-ID']) {
              hasSessionData = true;
              sessionData[sessionAttrs['DATA-ID']] = sessionAttrs;
            }
          }
        }

        return {
          levels: levels,
          sessionData: hasSessionData ? sessionData : null
        };
      };

      M3U8Parser.parseMasterPlaylistMedia = function parseMasterPlaylistMedia(string, baseurl, type, groups) {
        if (groups === void 0) {
          groups = [];
        }

        var result;
        var medias = [];
        var id = 0;
        MASTER_PLAYLIST_MEDIA_REGEX.lastIndex = 0;

        while ((result = MASTER_PLAYLIST_MEDIA_REGEX.exec(string)) !== null) {
          var attrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](result[1]);

          if (attrs.TYPE === type) {
            var media = {
              attrs: attrs,
              bitrate: 0,
              id: id++,
              groupId: attrs['GROUP-ID'],
              instreamId: attrs['INSTREAM-ID'],
              name: attrs.NAME || attrs.LANGUAGE || '',
              type: type,
              default: attrs.bool('DEFAULT'),
              autoselect: attrs.bool('AUTOSELECT'),
              forced: attrs.bool('FORCED'),
              lang: attrs.LANGUAGE,
              url: attrs.URI ? M3U8Parser.resolve(attrs.URI, baseurl) : ''
            };

            if (groups.length) {
              // If there are audio or text groups signalled in the manifest, let's look for a matching codec string for this track
              // If we don't find the track signalled, lets use the first audio groups codec we have
              // Acting as a best guess
              var groupCodec = M3U8Parser.findGroup(groups, media.groupId) || groups[0];
              assignCodec(media, groupCodec, 'audioCodec');
              assignCodec(media, groupCodec, 'textCodec');
            }

            medias.push(media);
          }
        }

        return medias;
      };

      M3U8Parser.parseLevelPlaylist = function parseLevelPlaylist(string, baseurl, id, type, levelUrlId) {
        var level = new _level_details__WEBPACK_IMPORTED_MODULE_3__["LevelDetails"](baseurl);
        var fragments = level.fragments; // The most recent init segment seen (applies to all subsequent segments)

        var currentInitSegment = null;
        var currentSN = 0;
        var currentPart = 0;
        var totalduration = 0;
        var discontinuityCounter = 0;
        var prevFrag = null;
        var frag = new _fragment__WEBPACK_IMPORTED_MODULE_2__["Fragment"](type, baseurl);
        var result;
        var i;
        var levelkey;
        var firstPdtIndex = -1;
        var createNextFrag = false;
        LEVEL_PLAYLIST_REGEX_FAST.lastIndex = 0;
        level.m3u8 = string;

        while ((result = LEVEL_PLAYLIST_REGEX_FAST.exec(string)) !== null) {
          if (createNextFrag) {
            createNextFrag = false;
            frag = new _fragment__WEBPACK_IMPORTED_MODULE_2__["Fragment"](type, baseurl); // setup the next fragment for part loading

            frag.start = totalduration;
            frag.sn = currentSN;
            frag.cc = discontinuityCounter;
            frag.level = id;

            if (currentInitSegment) {
              frag.initSegment = currentInitSegment;
              frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;
            }
          }

          var duration = result[1];

          if (duration) {
            // INF
            frag.duration = parseFloat(duration); // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939

            var title = (' ' + result[2]).slice(1);
            frag.title = title || null;
            frag.tagList.push(title ? ['INF', duration, title] : ['INF', duration]);
          } else if (result[3]) {
            // url
            if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(frag.duration)) {
              frag.start = totalduration;

              if (levelkey) {
                frag.levelkey = levelkey;
              }

              frag.sn = currentSN;
              frag.level = id;
              frag.cc = discontinuityCounter;
              frag.urlId = levelUrlId;
              fragments.push(frag); // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939

              frag.relurl = (' ' + result[3]).slice(1);
              assignProgramDateTime(frag, prevFrag);
              prevFrag = frag;
              totalduration += frag.duration;
              currentSN++;
              currentPart = 0;
              createNextFrag = true;
            }
          } else if (result[4]) {
            // X-BYTERANGE
            var data = (' ' + result[4]).slice(1);

            if (prevFrag) {
              frag.setByteRange(data, prevFrag);
            } else {
              frag.setByteRange(data);
            }
          } else if (result[5]) {
            // PROGRAM-DATE-TIME
            // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939
            frag.rawProgramDateTime = (' ' + result[5]).slice(1);
            frag.tagList.push(['PROGRAM-DATE-TIME', frag.rawProgramDateTime]);

            if (firstPdtIndex === -1) {
              firstPdtIndex = fragments.length;
            }
          } else {
            result = result[0].match(LEVEL_PLAYLIST_REGEX_SLOW);

            if (!result) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_6__["logger"].warn('No matches on slow regex match for level playlist!');
              continue;
            }

            for (i = 1; i < result.length; i++) {
              if (typeof result[i] !== 'undefined') {
                break;
              }
            } // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939


            var tag = (' ' + result[i]).slice(1);
            var value1 = (' ' + result[i + 1]).slice(1);
            var value2 = result[i + 2] ? (' ' + result[i + 2]).slice(1) : '';

            switch (tag) {
              case 'PLAYLIST-TYPE':
                level.type = value1.toUpperCase();
                break;

              case 'MEDIA-SEQUENCE':
                currentSN = level.startSN = parseInt(value1);
                break;

              case 'SKIP':
                {
                  var skipAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](value1);
                  var skippedSegments = skipAttrs.decimalInteger('SKIPPED-SEGMENTS');

                  if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(skippedSegments)) {
                    level.skippedSegments = skippedSegments; // This will result in fragments[] containing undefined values, which we will fill in with `mergeDetails`

                    for (var _i = skippedSegments; _i--;) {
                      fragments.unshift(null);
                    }

                    currentSN += skippedSegments;
                  }

                  var recentlyRemovedDateranges = skipAttrs.enumeratedString('RECENTLY-REMOVED-DATERANGES');

                  if (recentlyRemovedDateranges) {
                    level.recentlyRemovedDateranges = recentlyRemovedDateranges.split('\t');
                  }

                  break;
                }

              case 'TARGETDURATION':
                level.targetduration = parseFloat(value1);
                break;

              case 'VERSION':
                level.version = parseInt(value1);
                break;

              case 'EXTM3U':
                break;

              case 'ENDLIST':
                level.live = false;
                break;

              case '#':
                if (value1 || value2) {
                  frag.tagList.push(value2 ? [value1, value2] : [value1]);
                }

                break;

              case 'DIS':
                discontinuityCounter++;

              /* falls through */

              case 'GAP':
                frag.tagList.push([tag]);
                break;

              case 'BITRATE':
                frag.tagList.push([tag, value1]);
                break;

              case 'DISCONTINUITY-SEQ':
                discontinuityCounter = parseInt(value1);
                break;

              case 'KEY':
                {
                  var _keyAttrs$enumeratedS;

                  // https://tools.ietf.org/html/rfc8216#section-4.3.2.4
                  var keyAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](value1);
                  var decryptmethod = keyAttrs.enumeratedString('METHOD');
                  var decrypturi = keyAttrs.URI;
                  var decryptiv = keyAttrs.hexadecimalInteger('IV');
                  var decryptkeyformatversions = keyAttrs.enumeratedString('KEYFORMATVERSIONS');
                  var decryptkeyid = keyAttrs.enumeratedString('KEYID'); // From RFC: This attribute is OPTIONAL; its absence indicates an implicit value of "identity".

                  var decryptkeyformat = (_keyAttrs$enumeratedS = keyAttrs.enumeratedString('KEYFORMAT')) != null ? _keyAttrs$enumeratedS : 'identity';
                  var unsupportedKnownKeyformatsInManifest = ['com.apple.streamingkeydelivery', 'com.microsoft.playready', 'urn:uuid:edef8ba9-79d6-4ace-a3c8-27dcd51d21ed', // widevine (v2)
                  'com.widevine' // earlier widevine (v1)
                  ];

                  if (unsupportedKnownKeyformatsInManifest.indexOf(decryptkeyformat) > -1) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_6__["logger"].warn("Keyformat " + decryptkeyformat + " is not supported from the manifest");
                    continue;
                  } else if (decryptkeyformat !== 'identity') {
                    // We are supposed to skip keys we don't understand.
                    // As we currently only officially support identity keys
                    // from the manifest we shouldn't save any other key.
                    continue;
                  } // TODO: multiple keys can be defined on a fragment, and we need to support this
                  // for clients that support both playready and widevine


                  if (decryptmethod) {
                    // TODO: need to determine if the level key is actually a relative URL
                    // if it isn't, then we should instead construct the LevelKey using fromURI.
                    levelkey = _level_key__WEBPACK_IMPORTED_MODULE_4__["LevelKey"].fromURL(baseurl, decrypturi);

                    if (decrypturi && ['AES-128', 'SAMPLE-AES', 'SAMPLE-AES-CENC'].indexOf(decryptmethod) >= 0) {
                      levelkey.method = decryptmethod;
                      levelkey.keyFormat = decryptkeyformat;

                      if (decryptkeyid) {
                        levelkey.keyID = decryptkeyid;
                      }

                      if (decryptkeyformatversions) {
                        levelkey.keyFormatVersions = decryptkeyformatversions;
                      } // Initialization Vector (IV)


                      levelkey.iv = decryptiv;
                    }
                  }

                  break;
                }

              case 'START':
                {
                  var startAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](value1);
                  var startTimeOffset = startAttrs.decimalFloatingPoint('TIME-OFFSET'); // TIME-OFFSET can be 0

                  if (Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(startTimeOffset)) {
                    level.startTimeOffset = startTimeOffset;
                  }

                  break;
                }

              case 'MAP':
                {
                  var mapAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](value1);
                  frag.relurl = mapAttrs.URI;

                  if (mapAttrs.BYTERANGE) {
                    frag.setByteRange(mapAttrs.BYTERANGE);
                  }

                  frag.level = id;
                  frag.sn = 'initSegment';

                  if (levelkey) {
                    frag.levelkey = levelkey;
                  }

                  frag.initSegment = null;
                  currentInitSegment = frag;
                  createNextFrag = true;
                  break;
                }

              case 'SERVER-CONTROL':
                {
                  var serverControlAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](value1);
                  level.canBlockReload = serverControlAttrs.bool('CAN-BLOCK-RELOAD');
                  level.canSkipUntil = serverControlAttrs.optionalFloat('CAN-SKIP-UNTIL', 0);
                  level.canSkipDateRanges = level.canSkipUntil > 0 && serverControlAttrs.bool('CAN-SKIP-DATERANGES');
                  level.partHoldBack = serverControlAttrs.optionalFloat('PART-HOLD-BACK', 0);
                  level.holdBack = serverControlAttrs.optionalFloat('HOLD-BACK', 0);
                  break;
                }

              case 'PART-INF':
                {
                  var partInfAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](value1);
                  level.partTarget = partInfAttrs.decimalFloatingPoint('PART-TARGET');
                  break;
                }

              case 'PART':
                {
                  var partList = level.partList;

                  if (!partList) {
                    partList = level.partList = [];
                  }

                  var previousFragmentPart = currentPart > 0 ? partList[partList.length - 1] : undefined;
                  var index = currentPart++;
                  var part = new _fragment__WEBPACK_IMPORTED_MODULE_2__["Part"](new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](value1), frag, baseurl, index, previousFragmentPart);
                  partList.push(part);
                  frag.duration += part.duration;
                  break;
                }

              case 'PRELOAD-HINT':
                {
                  var preloadHintAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](value1);
                  level.preloadHint = preloadHintAttrs;
                  break;
                }

              case 'RENDITION-REPORT':
                {
                  var renditionReportAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__["AttrList"](value1);
                  level.renditionReports = level.renditionReports || [];
                  level.renditionReports.push(renditionReportAttrs);
                  break;
                }

              default:
                _utils_logger__WEBPACK_IMPORTED_MODULE_6__["logger"].warn("line parsed but not handled: " + result);
                break;
            }
          }
        }

        if (prevFrag && !prevFrag.relurl) {
          fragments.pop();
          totalduration -= prevFrag.duration;

          if (level.partList) {
            level.fragmentHint = prevFrag;
          }
        } else if (level.partList) {
          assignProgramDateTime(frag, prevFrag);
          frag.cc = discontinuityCounter;
          level.fragmentHint = frag;
        }

        var fragmentLength = fragments.length;
        var firstFragment = fragments[0];
        var lastFragment = fragments[fragmentLength - 1];
        totalduration += level.skippedSegments * level.targetduration;

        if (totalduration > 0 && fragmentLength && lastFragment) {
          level.averagetargetduration = totalduration / fragmentLength;
          var lastSn = lastFragment.sn;
          level.endSN = lastSn !== 'initSegment' ? lastSn : 0;

          if (firstFragment) {
            level.startCC = firstFragment.cc;

            if (!firstFragment.initSegment) {
              // this is a bit lurky but HLS really has no other way to tell us
              // if the fragments are TS or MP4, except if we download them :/
              // but this is to be able to handle SIDX.
              if (level.fragments.every(function (frag) {
                return frag.relurl && isMP4Url(frag.relurl);
              })) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_6__["logger"].warn('MP4 fragments found but no init segment (probably no MAP, incomplete M3U8), trying to fetch SIDX');
                frag = new _fragment__WEBPACK_IMPORTED_MODULE_2__["Fragment"](type, baseurl);
                frag.relurl = lastFragment.relurl;
                frag.level = id;
                frag.sn = 'initSegment';
                firstFragment.initSegment = frag;
                level.needSidxRanges = true;
              }
            }
          }
        } else {
          level.endSN = 0;
          level.startCC = 0;
        }

        if (level.fragmentHint) {
          totalduration += level.fragmentHint.duration;
        }

        level.totalduration = totalduration;
        level.endCC = discontinuityCounter;
        /**
         * Backfill any missing PDT values
         * "If the first EXT-X-PROGRAM-DATE-TIME tag in a Playlist appears after
         * one or more Media Segment URIs, the client SHOULD extrapolate
         * backward from that tag (using EXTINF durations and/or media
         * timestamps) to associate dates with those segments."
         * We have already extrapolated forward, but all fragments up to the first instance of PDT do not have their PDTs
         * computed.
         */

        if (firstPdtIndex > 0) {
          backfillProgramDateTimes(fragments, firstPdtIndex);
        }

        return level;
      };

      return M3U8Parser;
    }();



    function setCodecs(codecs, level) {
      ['video', 'audio', 'text'].forEach(function (type) {
        var filtered = codecs.filter(function (codec) {
          return Object(_utils_codecs__WEBPACK_IMPORTED_MODULE_7__["isCodecType"])(codec, type);
        });

        if (filtered.length) {
          var preferred = filtered.filter(function (codec) {
            return codec.lastIndexOf('avc1', 0) === 0 || codec.lastIndexOf('mp4a', 0) === 0;
          });
          level[type + "Codec"] = preferred.length > 0 ? preferred[0] : filtered[0]; // remove from list

          codecs = codecs.filter(function (codec) {
            return filtered.indexOf(codec) === -1;
          });
        }
      });
      level.unknownCodecs = codecs;
    }

    function assignCodec(media, groupItem, codecProperty) {
      var codecValue = groupItem[codecProperty];

      if (codecValue) {
        media[codecProperty] = codecValue;
      }
    }

    function backfillProgramDateTimes(fragments, firstPdtIndex) {
      var fragPrev = fragments[firstPdtIndex];

      for (var i = firstPdtIndex; i--;) {
        var frag = fragments[i]; // Exit on delta-playlist skipped segments

        if (!frag) {
          return;
        }

        frag.programDateTime = fragPrev.programDateTime - frag.duration * 1000;
        fragPrev = frag;
      }
    }

    function assignProgramDateTime(frag, prevFrag) {
      if (frag.rawProgramDateTime) {
        frag.programDateTime = Date.parse(frag.rawProgramDateTime);
      } else if (prevFrag !== null && prevFrag !== void 0 && prevFrag.programDateTime) {
        frag.programDateTime = prevFrag.endProgramDateTime;
      }

      if (!Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(frag.programDateTime)) {
        frag.programDateTime = null;
        frag.rawProgramDateTime = null;
      }
    }

    /***/ }),

    /***/ "./src/loader/playlist-loader.ts":
    /*!***************************************!*\
      !*** ./src/loader/playlist-loader.ts ***!
      \***************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
    /* harmony import */ var _m3u8_parser__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./m3u8-parser */ "./src/loader/m3u8-parser.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
    /* harmony import */ var _utils_attr_list__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../utils/attr-list */ "./src/utils/attr-list.ts");



    /**
     * PlaylistLoader - delegate for media manifest/playlist loading tasks. Takes care of parsing media to internal data-models.
     *
     * Once loaded, dispatches events with parsed data-models of manifest/levels/audio/subtitle tracks.
     *
     * Uses loader(s) set in config to do actual internal loading of resource tasks.
     *
     * @module
     *
     */








    function mapContextToLevelType(context) {
      var type = context.type;

      switch (type) {
        case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].AUDIO_TRACK:
          return _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].AUDIO;

        case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].SUBTITLE_TRACK:
          return _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].SUBTITLE;

        default:
          return _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].MAIN;
      }
    }

    function getResponseUrl(response, context) {
      var url = response.url; // responseURL not supported on some browsers (it is used to detect URL redirection)
      // data-uri mode also not supported (but no need to detect redirection)

      if (url === undefined || url.indexOf('data:') === 0) {
        // fallback to initial URL
        url = context.url;
      }

      return url;
    }

    var PlaylistLoader = /*#__PURE__*/function () {
      function PlaylistLoader(hls) {
        this.hls = void 0;
        this.loaders = Object.create(null);
        this.hls = hls;
        this.registerListeners();
      }

      var _proto = PlaylistLoader.prototype;

      _proto.registerListeners = function registerListeners() {
        var hls = this.hls;
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVEL_LOADING, this.onLevelLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);
        hls.on(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);
      };

      _proto.unregisterListeners = function unregisterListeners() {
        var hls = this.hls;
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADING, this.onManifestLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVEL_LOADING, this.onLevelLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);
        hls.off(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);
      }
      /**
       * Returns defaults or configured loader-type overloads (pLoader and loader config params)
       */
      ;

      _proto.createInternalLoader = function createInternalLoader(context) {
        var config = this.hls.config;
        var PLoader = config.pLoader;
        var Loader = config.loader;
        var InternalLoader = PLoader || Loader;
        var loader = new InternalLoader(config);
        context.loader = loader;
        this.loaders[context.type] = loader;
        return loader;
      };

      _proto.getInternalLoader = function getInternalLoader(context) {
        return this.loaders[context.type];
      };

      _proto.resetInternalLoader = function resetInternalLoader(contextType) {
        if (this.loaders[contextType]) {
          delete this.loaders[contextType];
        }
      }
      /**
       * Call `destroy` on all internal loader instances mapped (one per context type)
       */
      ;

      _proto.destroyInternalLoaders = function destroyInternalLoaders() {
        for (var contextType in this.loaders) {
          var loader = this.loaders[contextType];

          if (loader) {
            loader.destroy();
          }

          this.resetInternalLoader(contextType);
        }
      };

      _proto.destroy = function destroy() {
        this.unregisterListeners();
        this.destroyInternalLoaders();
      };

      _proto.onManifestLoading = function onManifestLoading(event, data) {
        var url = data.url;
        this.load({
          id: null,
          groupId: null,
          level: 0,
          responseType: 'text',
          type: _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].MANIFEST,
          url: url,
          deliveryDirectives: null
        });
      };

      _proto.onLevelLoading = function onLevelLoading(event, data) {
        var id = data.id,
            level = data.level,
            url = data.url,
            deliveryDirectives = data.deliveryDirectives;
        this.load({
          id: id,
          groupId: null,
          level: level,
          responseType: 'text',
          type: _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].LEVEL,
          url: url,
          deliveryDirectives: deliveryDirectives
        });
      };

      _proto.onAudioTrackLoading = function onAudioTrackLoading(event, data) {
        var id = data.id,
            groupId = data.groupId,
            url = data.url,
            deliveryDirectives = data.deliveryDirectives;
        this.load({
          id: id,
          groupId: groupId,
          level: null,
          responseType: 'text',
          type: _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].AUDIO_TRACK,
          url: url,
          deliveryDirectives: deliveryDirectives
        });
      };

      _proto.onSubtitleTrackLoading = function onSubtitleTrackLoading(event, data) {
        var id = data.id,
            groupId = data.groupId,
            url = data.url,
            deliveryDirectives = data.deliveryDirectives;
        this.load({
          id: id,
          groupId: groupId,
          level: null,
          responseType: 'text',
          type: _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].SUBTITLE_TRACK,
          url: url,
          deliveryDirectives: deliveryDirectives
        });
      };

      _proto.load = function load(context) {
        var _context$deliveryDire;

        var config = this.hls.config; // logger.debug(`[playlist-loader]: Loading playlist of type ${context.type}, level: ${context.level}, id: ${context.id}`);
        // Check if a loader for this context already exists

        var loader = this.getInternalLoader(context);

        if (loader) {
          var loaderContext = loader.context;

          if (loaderContext && loaderContext.url === context.url) {
            // same URL can't overlap
            _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].trace('[playlist-loader]: playlist request ongoing');
            return;
          }

          _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].log("[playlist-loader]: aborting previous loader for type: " + context.type);
          loader.abort();
        }

        var maxRetry;
        var timeout;
        var retryDelay;
        var maxRetryDelay; // apply different configs for retries depending on
        // context (manifest, level, audio/subs playlist)

        switch (context.type) {
          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].MANIFEST:
            maxRetry = config.manifestLoadingMaxRetry;
            timeout = config.manifestLoadingTimeOut;
            retryDelay = config.manifestLoadingRetryDelay;
            maxRetryDelay = config.manifestLoadingMaxRetryTimeout;
            break;

          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].LEVEL:
          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].AUDIO_TRACK:
          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].SUBTITLE_TRACK:
            // Manage retries in Level/Track Controller
            maxRetry = 0;
            timeout = config.levelLoadingTimeOut;
            break;

          default:
            maxRetry = config.levelLoadingMaxRetry;
            timeout = config.levelLoadingTimeOut;
            retryDelay = config.levelLoadingRetryDelay;
            maxRetryDelay = config.levelLoadingMaxRetryTimeout;
            break;
        }

        loader = this.createInternalLoader(context); // Override level/track timeout for LL-HLS requests
        // (the default of 10000ms is counter productive to blocking playlist reload requests)

        if ((_context$deliveryDire = context.deliveryDirectives) !== null && _context$deliveryDire !== void 0 && _context$deliveryDire.part) {
          var levelDetails;

          if (context.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].LEVEL && context.level !== null) {
            levelDetails = this.hls.levels[context.level].details;
          } else if (context.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].AUDIO_TRACK && context.id !== null) {
            levelDetails = this.hls.audioTracks[context.id].details;
          } else if (context.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].SUBTITLE_TRACK && context.id !== null) {
            levelDetails = this.hls.subtitleTracks[context.id].details;
          }

          if (levelDetails) {
            var partTarget = levelDetails.partTarget;
            var targetDuration = levelDetails.targetduration;

            if (partTarget && targetDuration) {
              timeout = Math.min(Math.max(partTarget * 3, targetDuration * 0.8) * 1000, timeout);
            }
          }
        }

        var loaderConfig = {
          timeout: timeout,
          maxRetry: maxRetry,
          retryDelay: retryDelay,
          maxRetryDelay: maxRetryDelay,
          highWaterMark: 0
        };
        var loaderCallbacks = {
          onSuccess: this.loadsuccess.bind(this),
          onError: this.loaderror.bind(this),
          onTimeout: this.loadtimeout.bind(this)
        }; // logger.debug(`[playlist-loader]: Calling internal loader delegate for URL: ${context.url}`);

        loader.load(context, loaderConfig, loaderCallbacks);
      };

      _proto.loadsuccess = function loadsuccess(response, stats, context, networkDetails) {
        if (networkDetails === void 0) {
          networkDetails = null;
        }

        if (context.isSidxRequest) {
          this.handleSidxRequest(response, context);
          this.handlePlaylistLoaded(response, stats, context, networkDetails);
          return;
        }

        this.resetInternalLoader(context.type);
        var string = response.data; // Validate if it is an M3U8 at all

        if (string.indexOf('#EXTM3U') !== 0) {
          this.handleManifestParsingError(response, context, 'no EXTM3U delimiter', networkDetails);
          return;
        }

        stats.parsing.start = performance.now(); // Check if chunk-list or master. handle empty chunk list case (first EXTINF not signaled, but TARGETDURATION present)

        if (string.indexOf('#EXTINF:') > 0 || string.indexOf('#EXT-X-TARGETDURATION:') > 0) {
          this.handleTrackOrLevelPlaylist(response, stats, context, networkDetails);
        } else {
          this.handleMasterPlaylist(response, stats, context, networkDetails);
        }
      };

      _proto.loaderror = function loaderror(response, context, networkDetails) {
        if (networkDetails === void 0) {
          networkDetails = null;
        }

        this.handleNetworkError(context, networkDetails, false, response);
      };

      _proto.loadtimeout = function loadtimeout(stats, context, networkDetails) {
        if (networkDetails === void 0) {
          networkDetails = null;
        }

        this.handleNetworkError(context, networkDetails, true);
      };

      _proto.handleMasterPlaylist = function handleMasterPlaylist(response, stats, context, networkDetails) {
        var hls = this.hls;
        var string = response.data;
        var url = getResponseUrl(response, context);

        var _M3U8Parser$parseMast = _m3u8_parser__WEBPACK_IMPORTED_MODULE_5__["default"].parseMasterPlaylist(string, url),
            levels = _M3U8Parser$parseMast.levels,
            sessionData = _M3U8Parser$parseMast.sessionData;

        if (!levels.length) {
          this.handleManifestParsingError(response, context, 'no level found in manifest', networkDetails);
          return;
        } // multi level playlist, parse level info


        var audioGroups = levels.map(function (level) {
          return {
            id: level.attrs.AUDIO,
            audioCodec: level.audioCodec
          };
        });
        var subtitleGroups = levels.map(function (level) {
          return {
            id: level.attrs.SUBTITLES,
            textCodec: level.textCodec
          };
        });
        var audioTracks = _m3u8_parser__WEBPACK_IMPORTED_MODULE_5__["default"].parseMasterPlaylistMedia(string, url, 'AUDIO', audioGroups);
        var subtitles = _m3u8_parser__WEBPACK_IMPORTED_MODULE_5__["default"].parseMasterPlaylistMedia(string, url, 'SUBTITLES', subtitleGroups);
        var captions = _m3u8_parser__WEBPACK_IMPORTED_MODULE_5__["default"].parseMasterPlaylistMedia(string, url, 'CLOSED-CAPTIONS');

        if (audioTracks.length) {
          // check if we have found an audio track embedded in main playlist (audio track without URI attribute)
          var embeddedAudioFound = audioTracks.some(function (audioTrack) {
            return !audioTrack.url;
          }); // if no embedded audio track defined, but audio codec signaled in quality level,
          // we need to signal this main audio track this could happen with playlists with
          // alt audio rendition in which quality levels (main)
          // contains both audio+video. but with mixed audio track not signaled

          if (!embeddedAudioFound && levels[0].audioCodec && !levels[0].attrs.AUDIO) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].log('[playlist-loader]: audio codec signaled in quality level, but no embedded audio track signaled, create one');
            audioTracks.unshift({
              type: 'main',
              name: 'main',
              default: false,
              autoselect: false,
              forced: false,
              id: -1,
              attrs: new _utils_attr_list__WEBPACK_IMPORTED_MODULE_7__["AttrList"]({}),
              bitrate: 0,
              url: ''
            });
          }
        }

        hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADED, {
          levels: levels,
          audioTracks: audioTracks,
          subtitles: subtitles,
          captions: captions,
          url: url,
          stats: stats,
          networkDetails: networkDetails,
          sessionData: sessionData
        });
      };

      _proto.handleTrackOrLevelPlaylist = function handleTrackOrLevelPlaylist(response, stats, context, networkDetails) {
        var hls = this.hls;
        var id = context.id,
            level = context.level,
            type = context.type;
        var url = getResponseUrl(response, context);
        var levelUrlId = Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(id) ? id : 0;
        var levelId = Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(level) ? level : levelUrlId;
        var levelType = mapContextToLevelType(context);
        var levelDetails = _m3u8_parser__WEBPACK_IMPORTED_MODULE_5__["default"].parseLevelPlaylist(response.data, url, levelId, levelType, levelUrlId);

        if (!levelDetails.fragments.length) {
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorTypes"].NETWORK_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].LEVEL_EMPTY_ERROR,
            fatal: false,
            url: url,
            reason: 'no fragments found in level',
            level: typeof context.level === 'number' ? context.level : undefined
          });
          return;
        } // We have done our first request (Manifest-type) and receive
        // not a master playlist but a chunk-list (track/level)
        // We fire the manifest-loaded event anyway with the parsed level-details
        // by creating a single-level structure for it.


        if (type === _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].MANIFEST) {
          var singleLevel = {
            attrs: new _utils_attr_list__WEBPACK_IMPORTED_MODULE_7__["AttrList"]({}),
            bitrate: 0,
            details: levelDetails,
            name: '',
            url: url
          };
          hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].MANIFEST_LOADED, {
            levels: [singleLevel],
            audioTracks: [],
            url: url,
            stats: stats,
            networkDetails: networkDetails,
            sessionData: null
          });
        } // save parsing time


        stats.parsing.end = performance.now(); // in case we need SIDX ranges
        // return early after calling load for
        // the SIDX box.

        if (levelDetails.needSidxRanges) {
          var _levelDetails$fragmen;

          var sidxUrl = (_levelDetails$fragmen = levelDetails.fragments[0].initSegment) === null || _levelDetails$fragmen === void 0 ? void 0 : _levelDetails$fragmen.url;
          this.load({
            url: sidxUrl,
            isSidxRequest: true,
            type: type,
            level: level,
            levelDetails: levelDetails,
            id: id,
            groupId: null,
            rangeStart: 0,
            rangeEnd: 2048,
            responseType: 'arraybuffer',
            deliveryDirectives: null
          });
          return;
        } // extend the context with the new levelDetails property


        context.levelDetails = levelDetails;
        this.handlePlaylistLoaded(response, stats, context, networkDetails);
      };

      _proto.handleSidxRequest = function handleSidxRequest(response, context) {
        var sidxInfo = Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_4__["parseSegmentIndex"])(new Uint8Array(response.data)); // if provided fragment does not contain sidx, early return

        if (!sidxInfo) {
          return;
        }

        var sidxReferences = sidxInfo.references;
        var levelDetails = context.levelDetails;
        sidxReferences.forEach(function (segmentRef, index) {
          var segRefInfo = segmentRef.info;
          var frag = levelDetails.fragments[index];

          if (frag.byteRange.length === 0) {
            frag.setByteRange(String(1 + segRefInfo.end - segRefInfo.start) + '@' + String(segRefInfo.start));
          }

          if (frag.initSegment) {
            frag.initSegment.setByteRange(String(sidxInfo.moovEndOffset) + '@0');
          }
        });
      };

      _proto.handleManifestParsingError = function handleManifestParsingError(response, context, reason, networkDetails) {
        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, {
          type: _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorTypes"].NETWORK_ERROR,
          details: _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].MANIFEST_PARSING_ERROR,
          fatal: context.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].MANIFEST,
          url: response.url,
          reason: reason,
          response: response,
          context: context,
          networkDetails: networkDetails
        });
      };

      _proto.handleNetworkError = function handleNetworkError(context, networkDetails, timeout, response) {
        if (timeout === void 0) {
          timeout = false;
        }

        _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn("[playlist-loader]: A network " + (timeout ? 'timeout' : 'error') + " occurred while loading " + context.type + " level: " + context.level + " id: " + context.id + " group-id: \"" + context.groupId + "\"");
        var details = _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].UNKNOWN;
        var fatal = false;
        var loader = this.getInternalLoader(context);

        switch (context.type) {
          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].MANIFEST:
            details = timeout ? _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].MANIFEST_LOAD_TIMEOUT : _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].MANIFEST_LOAD_ERROR;
            fatal = true;
            break;

          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].LEVEL:
            details = timeout ? _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].LEVEL_LOAD_TIMEOUT : _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].LEVEL_LOAD_ERROR;
            fatal = false;
            break;

          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].AUDIO_TRACK:
            details = timeout ? _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].AUDIO_TRACK_LOAD_TIMEOUT : _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].AUDIO_TRACK_LOAD_ERROR;
            fatal = false;
            break;

          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].SUBTITLE_TRACK:
            details = timeout ? _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].SUBTITLE_TRACK_LOAD_TIMEOUT : _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorDetails"].SUBTITLE_LOAD_ERROR;
            fatal = false;
            break;
        }

        if (loader) {
          this.resetInternalLoader(context.type);
        }

        var errorData = {
          type: _errors__WEBPACK_IMPORTED_MODULE_2__["ErrorTypes"].NETWORK_ERROR,
          details: details,
          fatal: fatal,
          url: context.url,
          loader: loader,
          context: context,
          networkDetails: networkDetails
        };

        if (response) {
          errorData.response = response;
        }

        this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].ERROR, errorData);
      };

      _proto.handlePlaylistLoaded = function handlePlaylistLoaded(response, stats, context, networkDetails) {
        var type = context.type,
            level = context.level,
            id = context.id,
            groupId = context.groupId,
            loader = context.loader,
            levelDetails = context.levelDetails,
            deliveryDirectives = context.deliveryDirectives;

        if (!(levelDetails !== null && levelDetails !== void 0 && levelDetails.targetduration)) {
          this.handleManifestParsingError(response, context, 'invalid target duration', networkDetails);
          return;
        }

        if (!loader) {
          return;
        }

        if (levelDetails.live) {
          if (loader.getCacheAge) {
            levelDetails.ageHeader = loader.getCacheAge() || 0;
          }

          if (!loader.getCacheAge || isNaN(levelDetails.ageHeader)) {
            levelDetails.ageHeader = 0;
          }
        }

        switch (type) {
          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].MANIFEST:
          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].LEVEL:
            this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].LEVEL_LOADED, {
              details: levelDetails,
              level: level || 0,
              id: id || 0,
              stats: stats,
              networkDetails: networkDetails,
              deliveryDirectives: deliveryDirectives
            });
            break;

          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].AUDIO_TRACK:
            this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].AUDIO_TRACK_LOADED, {
              details: levelDetails,
              id: id || 0,
              groupId: groupId || '',
              stats: stats,
              networkDetails: networkDetails,
              deliveryDirectives: deliveryDirectives
            });
            break;

          case _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistContextType"].SUBTITLE_TRACK:
            this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["Events"].SUBTITLE_TRACK_LOADED, {
              details: levelDetails,
              id: id || 0,
              groupId: groupId || '',
              stats: stats,
              networkDetails: networkDetails,
              deliveryDirectives: deliveryDirectives
            });
            break;
        }
      };

      return PlaylistLoader;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (PlaylistLoader);

    /***/ }),

    /***/ "./src/polyfills/number.ts":
    /*!*********************************!*\
      !*** ./src/polyfills/number.ts ***!
      \*********************************/
    /*! exports provided: isFiniteNumber, MAX_SAFE_INTEGER */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isFiniteNumber", function() { return isFiniteNumber; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "MAX_SAFE_INTEGER", function() { return MAX_SAFE_INTEGER; });
    var isFiniteNumber = Number.isFinite || function (value) {
      return typeof value === 'number' && isFinite(value);
    };
    var MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER || 9007199254740991;

    /***/ }),

    /***/ "./src/remux/aac-helper.ts":
    /*!*********************************!*\
      !*** ./src/remux/aac-helper.ts ***!
      \*********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /**
     *  AAC helper
     */
    var AAC = /*#__PURE__*/function () {
      function AAC() {}

      AAC.getSilentFrame = function getSilentFrame(codec, channelCount) {
        switch (codec) {
          case 'mp4a.40.2':
            if (channelCount === 1) {
              return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x23, 0x80]);
            } else if (channelCount === 2) {
              return new Uint8Array([0x21, 0x00, 0x49, 0x90, 0x02, 0x19, 0x00, 0x23, 0x80]);
            } else if (channelCount === 3) {
              return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x8e]);
            } else if (channelCount === 4) {
              return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x80, 0x2c, 0x80, 0x08, 0x02, 0x38]);
            } else if (channelCount === 5) {
              return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x38]);
            } else if (channelCount === 6) {
              return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x00, 0xb2, 0x00, 0x20, 0x08, 0xe0]);
            }

            break;
          // handle HE-AAC below (mp4a.40.5 / mp4a.40.29)

          default:
            if (channelCount === 1) {
              // ffmpeg -y -f lavfi -i "aevalsrc=0:d=0.05" -c:a libfdk_aac -profile:a aac_he -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\n"' -v output.aac
              return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x4e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x1c, 0x6, 0xf1, 0xc1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);
            } else if (channelCount === 2) {
              // ffmpeg -y -f lavfi -i "aevalsrc=0|0:d=0.05" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\n"' -v output.aac
              return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);
            } else if (channelCount === 3) {
              // ffmpeg -y -f lavfi -i "aevalsrc=0|0|0:d=0.05" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\n"' -v output.aac
              return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);
            }

            break;
        }

        return undefined;
      };

      return AAC;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (AAC);

    /***/ }),

    /***/ "./src/remux/mp4-generator.ts":
    /*!************************************!*\
      !*** ./src/remux/mp4-generator.ts ***!
      \************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /**
     * Generate MP4 Box
     */
    var UINT32_MAX = Math.pow(2, 32) - 1;

    var MP4 = /*#__PURE__*/function () {
      function MP4() {}

      MP4.init = function init() {
        MP4.types = {
          avc1: [],
          // codingname
          avcC: [],
          btrt: [],
          dinf: [],
          dref: [],
          esds: [],
          ftyp: [],
          hdlr: [],
          mdat: [],
          mdhd: [],
          mdia: [],
          mfhd: [],
          minf: [],
          moof: [],
          moov: [],
          mp4a: [],
          '.mp3': [],
          mvex: [],
          mvhd: [],
          pasp: [],
          sdtp: [],
          stbl: [],
          stco: [],
          stsc: [],
          stsd: [],
          stsz: [],
          stts: [],
          tfdt: [],
          tfhd: [],
          traf: [],
          trak: [],
          trun: [],
          trex: [],
          tkhd: [],
          vmhd: [],
          smhd: []
        };
        var i;

        for (i in MP4.types) {
          if (MP4.types.hasOwnProperty(i)) {
            MP4.types[i] = [i.charCodeAt(0), i.charCodeAt(1), i.charCodeAt(2), i.charCodeAt(3)];
          }
        }

        var videoHdlr = new Uint8Array([0x00, // version 0
        0x00, 0x00, 0x00, // flags
        0x00, 0x00, 0x00, 0x00, // pre_defined
        0x76, 0x69, 0x64, 0x65, // handler_type: 'vide'
        0x00, 0x00, 0x00, 0x00, // reserved
        0x00, 0x00, 0x00, 0x00, // reserved
        0x00, 0x00, 0x00, 0x00, // reserved
        0x56, 0x69, 0x64, 0x65, 0x6f, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'
        ]);
        var audioHdlr = new Uint8Array([0x00, // version 0
        0x00, 0x00, 0x00, // flags
        0x00, 0x00, 0x00, 0x00, // pre_defined
        0x73, 0x6f, 0x75, 0x6e, // handler_type: 'soun'
        0x00, 0x00, 0x00, 0x00, // reserved
        0x00, 0x00, 0x00, 0x00, // reserved
        0x00, 0x00, 0x00, 0x00, // reserved
        0x53, 0x6f, 0x75, 0x6e, 0x64, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'SoundHandler'
        ]);
        MP4.HDLR_TYPES = {
          video: videoHdlr,
          audio: audioHdlr
        };
        var dref = new Uint8Array([0x00, // version 0
        0x00, 0x00, 0x00, // flags
        0x00, 0x00, 0x00, 0x01, // entry_count
        0x00, 0x00, 0x00, 0x0c, // entry_size
        0x75, 0x72, 0x6c, 0x20, // 'url' type
        0x00, // version 0
        0x00, 0x00, 0x01 // entry_flags
        ]);
        var stco = new Uint8Array([0x00, // version
        0x00, 0x00, 0x00, // flags
        0x00, 0x00, 0x00, 0x00 // entry_count
        ]);
        MP4.STTS = MP4.STSC = MP4.STCO = stco;
        MP4.STSZ = new Uint8Array([0x00, // version
        0x00, 0x00, 0x00, // flags
        0x00, 0x00, 0x00, 0x00, // sample_size
        0x00, 0x00, 0x00, 0x00 // sample_count
        ]);
        MP4.VMHD = new Uint8Array([0x00, // version
        0x00, 0x00, 0x01, // flags
        0x00, 0x00, // graphicsmode
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00 // opcolor
        ]);
        MP4.SMHD = new Uint8Array([0x00, // version
        0x00, 0x00, 0x00, // flags
        0x00, 0x00, // balance
        0x00, 0x00 // reserved
        ]);
        MP4.STSD = new Uint8Array([0x00, // version 0
        0x00, 0x00, 0x00, // flags
        0x00, 0x00, 0x00, 0x01]); // entry_count

        var majorBrand = new Uint8Array([105, 115, 111, 109]); // isom

        var avc1Brand = new Uint8Array([97, 118, 99, 49]); // avc1

        var minorVersion = new Uint8Array([0, 0, 0, 1]);
        MP4.FTYP = MP4.box(MP4.types.ftyp, majorBrand, minorVersion, majorBrand, avc1Brand);
        MP4.DINF = MP4.box(MP4.types.dinf, MP4.box(MP4.types.dref, dref));
      };

      MP4.box = function box(type) {
        var size = 8;

        for (var _len = arguments.length, payload = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {
          payload[_key - 1] = arguments[_key];
        }

        var i = payload.length;
        var len = i; // calculate the total size we need to allocate

        while (i--) {
          size += payload[i].byteLength;
        }

        var result = new Uint8Array(size);
        result[0] = size >> 24 & 0xff;
        result[1] = size >> 16 & 0xff;
        result[2] = size >> 8 & 0xff;
        result[3] = size & 0xff;
        result.set(type, 4); // copy the payload into the result

        for (i = 0, size = 8; i < len; i++) {
          // copy payload[i] array @ offset size
          result.set(payload[i], size);
          size += payload[i].byteLength;
        }

        return result;
      };

      MP4.hdlr = function hdlr(type) {
        return MP4.box(MP4.types.hdlr, MP4.HDLR_TYPES[type]);
      };

      MP4.mdat = function mdat(data) {
        return MP4.box(MP4.types.mdat, data);
      };

      MP4.mdhd = function mdhd(timescale, duration) {
        duration *= timescale;
        var upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));
        var lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));
        return MP4.box(MP4.types.mdhd, new Uint8Array([0x01, // version 1
        0x00, 0x00, 0x00, // flags
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, // creation_time
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, // modification_time
        timescale >> 24 & 0xff, timescale >> 16 & 0xff, timescale >> 8 & 0xff, timescale & 0xff, // timescale
        upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x55, 0xc4, // 'und' language (undetermined)
        0x00, 0x00]));
      };

      MP4.mdia = function mdia(track) {
        return MP4.box(MP4.types.mdia, MP4.mdhd(track.timescale, track.duration), MP4.hdlr(track.type), MP4.minf(track));
      };

      MP4.mfhd = function mfhd(sequenceNumber) {
        return MP4.box(MP4.types.mfhd, new Uint8Array([0x00, 0x00, 0x00, 0x00, // flags
        sequenceNumber >> 24, sequenceNumber >> 16 & 0xff, sequenceNumber >> 8 & 0xff, sequenceNumber & 0xff // sequence_number
        ]));
      };

      MP4.minf = function minf(track) {
        if (track.type === 'audio') {
          return MP4.box(MP4.types.minf, MP4.box(MP4.types.smhd, MP4.SMHD), MP4.DINF, MP4.stbl(track));
        } else {
          return MP4.box(MP4.types.minf, MP4.box(MP4.types.vmhd, MP4.VMHD), MP4.DINF, MP4.stbl(track));
        }
      };

      MP4.moof = function moof(sn, baseMediaDecodeTime, track) {
        return MP4.box(MP4.types.moof, MP4.mfhd(sn), MP4.traf(track, baseMediaDecodeTime));
      }
      /**
       * @param tracks... (optional) {array} the tracks associated with this movie
       */
      ;

      MP4.moov = function moov(tracks) {
        var i = tracks.length;
        var boxes = [];

        while (i--) {
          boxes[i] = MP4.trak(tracks[i]);
        }

        return MP4.box.apply(null, [MP4.types.moov, MP4.mvhd(tracks[0].timescale, tracks[0].duration)].concat(boxes).concat(MP4.mvex(tracks)));
      };

      MP4.mvex = function mvex(tracks) {
        var i = tracks.length;
        var boxes = [];

        while (i--) {
          boxes[i] = MP4.trex(tracks[i]);
        }

        return MP4.box.apply(null, [MP4.types.mvex].concat(boxes));
      };

      MP4.mvhd = function mvhd(timescale, duration) {
        duration *= timescale;
        var upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));
        var lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));
        var bytes = new Uint8Array([0x01, // version 1
        0x00, 0x00, 0x00, // flags
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, // creation_time
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, // modification_time
        timescale >> 24 & 0xff, timescale >> 16 & 0xff, timescale >> 8 & 0xff, timescale & 0xff, // timescale
        upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x00, 0x01, 0x00, 0x00, // 1.0 rate
        0x01, 0x00, // 1.0 volume
        0x00, 0x00, // reserved
        0x00, 0x00, 0x00, 0x00, // reserved
        0x00, 0x00, 0x00, 0x00, // reserved
        0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // transformation: unity matrix
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre_defined
        0xff, 0xff, 0xff, 0xff // next_track_ID
        ]);
        return MP4.box(MP4.types.mvhd, bytes);
      };

      MP4.sdtp = function sdtp(track) {
        var samples = track.samples || [];
        var bytes = new Uint8Array(4 + samples.length);
        var i;
        var flags; // leave the full box header (4 bytes) all zero
        // write the sample table

        for (i = 0; i < samples.length; i++) {
          flags = samples[i].flags;
          bytes[i + 4] = flags.dependsOn << 4 | flags.isDependedOn << 2 | flags.hasRedundancy;
        }

        return MP4.box(MP4.types.sdtp, bytes);
      };

      MP4.stbl = function stbl(track) {
        return MP4.box(MP4.types.stbl, MP4.stsd(track), MP4.box(MP4.types.stts, MP4.STTS), MP4.box(MP4.types.stsc, MP4.STSC), MP4.box(MP4.types.stsz, MP4.STSZ), MP4.box(MP4.types.stco, MP4.STCO));
      };

      MP4.avc1 = function avc1(track) {
        var sps = [];
        var pps = [];
        var i;
        var data;
        var len; // assemble the SPSs

        for (i = 0; i < track.sps.length; i++) {
          data = track.sps[i];
          len = data.byteLength;
          sps.push(len >>> 8 & 0xff);
          sps.push(len & 0xff); // SPS

          sps = sps.concat(Array.prototype.slice.call(data));
        } // assemble the PPSs


        for (i = 0; i < track.pps.length; i++) {
          data = track.pps[i];
          len = data.byteLength;
          pps.push(len >>> 8 & 0xff);
          pps.push(len & 0xff);
          pps = pps.concat(Array.prototype.slice.call(data));
        }

        var avcc = MP4.box(MP4.types.avcC, new Uint8Array([0x01, // version
        sps[3], // profile
        sps[4], // profile compat
        sps[5], // level
        0xfc | 3, // lengthSizeMinusOne, hard-coded to 4 bytes
        0xe0 | track.sps.length // 3bit reserved (111) + numOfSequenceParameterSets
        ].concat(sps).concat([track.pps.length // numOfPictureParameterSets
        ]).concat(pps))); // "PPS"

        var width = track.width;
        var height = track.height;
        var hSpacing = track.pixelRatio[0];
        var vSpacing = track.pixelRatio[1];
        return MP4.box(MP4.types.avc1, new Uint8Array([0x00, 0x00, 0x00, // reserved
        0x00, 0x00, 0x00, // reserved
        0x00, 0x01, // data_reference_index
        0x00, 0x00, // pre_defined
        0x00, 0x00, // reserved
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre_defined
        width >> 8 & 0xff, width & 0xff, // width
        height >> 8 & 0xff, height & 0xff, // height
        0x00, 0x48, 0x00, 0x00, // horizresolution
        0x00, 0x48, 0x00, 0x00, // vertresolution
        0x00, 0x00, 0x00, 0x00, // reserved
        0x00, 0x01, // frame_count
        0x12, 0x64, 0x61, 0x69, 0x6c, // dailymotion/hls.js
        0x79, 0x6d, 0x6f, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x68, 0x6c, 0x73, 0x2e, 0x6a, 0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // compressorname
        0x00, 0x18, // depth = 24
        0x11, 0x11]), // pre_defined = -1
        avcc, MP4.box(MP4.types.btrt, new Uint8Array([0x00, 0x1c, 0x9c, 0x80, // bufferSizeDB
        0x00, 0x2d, 0xc6, 0xc0, // maxBitrate
        0x00, 0x2d, 0xc6, 0xc0])), // avgBitrate
        MP4.box(MP4.types.pasp, new Uint8Array([hSpacing >> 24, // hSpacing
        hSpacing >> 16 & 0xff, hSpacing >> 8 & 0xff, hSpacing & 0xff, vSpacing >> 24, // vSpacing
        vSpacing >> 16 & 0xff, vSpacing >> 8 & 0xff, vSpacing & 0xff])));
      };

      MP4.esds = function esds(track) {
        var configlen = track.config.length;
        return new Uint8Array([0x00, // version 0
        0x00, 0x00, 0x00, // flags
        0x03, // descriptor_type
        0x17 + configlen, // length
        0x00, 0x01, // es_id
        0x00, // stream_priority
        0x04, // descriptor_type
        0x0f + configlen, // length
        0x40, // codec : mpeg4_audio
        0x15, // stream_type
        0x00, 0x00, 0x00, // buffer_size
        0x00, 0x00, 0x00, 0x00, // maxBitrate
        0x00, 0x00, 0x00, 0x00, // avgBitrate
        0x05 // descriptor_type
        ].concat([configlen]).concat(track.config).concat([0x06, 0x01, 0x02])); // GASpecificConfig)); // length + audio config descriptor
      };

      MP4.mp4a = function mp4a(track) {
        var samplerate = track.samplerate;
        return MP4.box(MP4.types.mp4a, new Uint8Array([0x00, 0x00, 0x00, // reserved
        0x00, 0x00, 0x00, // reserved
        0x00, 0x01, // data_reference_index
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved
        0x00, track.channelCount, // channelcount
        0x00, 0x10, // sampleSize:16bits
        0x00, 0x00, 0x00, 0x00, // reserved2
        samplerate >> 8 & 0xff, samplerate & 0xff, //
        0x00, 0x00]), MP4.box(MP4.types.esds, MP4.esds(track)));
      };

      MP4.mp3 = function mp3(track) {
        var samplerate = track.samplerate;
        return MP4.box(MP4.types['.mp3'], new Uint8Array([0x00, 0x00, 0x00, // reserved
        0x00, 0x00, 0x00, // reserved
        0x00, 0x01, // data_reference_index
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved
        0x00, track.channelCount, // channelcount
        0x00, 0x10, // sampleSize:16bits
        0x00, 0x00, 0x00, 0x00, // reserved2
        samplerate >> 8 & 0xff, samplerate & 0xff, //
        0x00, 0x00]));
      };

      MP4.stsd = function stsd(track) {
        if (track.type === 'audio') {
          if (!track.isAAC && track.codec === 'mp3') {
            return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp3(track));
          }

          return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp4a(track));
        } else {
          return MP4.box(MP4.types.stsd, MP4.STSD, MP4.avc1(track));
        }
      };

      MP4.tkhd = function tkhd(track) {
        var id = track.id;
        var duration = track.duration * track.timescale;
        var width = track.width;
        var height = track.height;
        var upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));
        var lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));
        return MP4.box(MP4.types.tkhd, new Uint8Array([0x01, // version 1
        0x00, 0x00, 0x07, // flags
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, // creation_time
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, // modification_time
        id >> 24 & 0xff, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff, // track_ID
        0x00, 0x00, 0x00, 0x00, // reserved
        upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved
        0x00, 0x00, // layer
        0x00, 0x00, // alternate_group
        0x00, 0x00, // non-audio track volume
        0x00, 0x00, // reserved
        0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // transformation: unity matrix
        width >> 8 & 0xff, width & 0xff, 0x00, 0x00, // width
        height >> 8 & 0xff, height & 0xff, 0x00, 0x00 // height
        ]));
      };

      MP4.traf = function traf(track, baseMediaDecodeTime) {
        var sampleDependencyTable = MP4.sdtp(track);
        var id = track.id;
        var upperWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1));
        var lowerWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));
        return MP4.box(MP4.types.traf, MP4.box(MP4.types.tfhd, new Uint8Array([0x00, // version 0
        0x00, 0x00, 0x00, // flags
        id >> 24, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff // track_ID
        ])), MP4.box(MP4.types.tfdt, new Uint8Array([0x01, // version 1
        0x00, 0x00, 0x00, // flags
        upperWordBaseMediaDecodeTime >> 24, upperWordBaseMediaDecodeTime >> 16 & 0xff, upperWordBaseMediaDecodeTime >> 8 & 0xff, upperWordBaseMediaDecodeTime & 0xff, lowerWordBaseMediaDecodeTime >> 24, lowerWordBaseMediaDecodeTime >> 16 & 0xff, lowerWordBaseMediaDecodeTime >> 8 & 0xff, lowerWordBaseMediaDecodeTime & 0xff])), MP4.trun(track, sampleDependencyTable.length + 16 + // tfhd
        20 + // tfdt
        8 + // traf header
        16 + // mfhd
        8 + // moof header
        8), // mdat header
        sampleDependencyTable);
      }
      /**
       * Generate a track box.
       * @param track {object} a track definition
       * @return {Uint8Array} the track box
       */
      ;

      MP4.trak = function trak(track) {
        track.duration = track.duration || 0xffffffff;
        return MP4.box(MP4.types.trak, MP4.tkhd(track), MP4.mdia(track));
      };

      MP4.trex = function trex(track) {
        var id = track.id;
        return MP4.box(MP4.types.trex, new Uint8Array([0x00, // version 0
        0x00, 0x00, 0x00, // flags
        id >> 24, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff, // track_ID
        0x00, 0x00, 0x00, 0x01, // default_sample_description_index
        0x00, 0x00, 0x00, 0x00, // default_sample_duration
        0x00, 0x00, 0x00, 0x00, // default_sample_size
        0x00, 0x01, 0x00, 0x01 // default_sample_flags
        ]));
      };

      MP4.trun = function trun(track, offset) {
        var samples = track.samples || [];
        var len = samples.length;
        var arraylen = 12 + 16 * len;
        var array = new Uint8Array(arraylen);
        var i;
        var sample;
        var duration;
        var size;
        var flags;
        var cts;
        offset += 8 + arraylen;
        array.set([0x00, // version 0
        0x00, 0x0f, 0x01, // flags
        len >>> 24 & 0xff, len >>> 16 & 0xff, len >>> 8 & 0xff, len & 0xff, // sample_count
        offset >>> 24 & 0xff, offset >>> 16 & 0xff, offset >>> 8 & 0xff, offset & 0xff // data_offset
        ], 0);

        for (i = 0; i < len; i++) {
          sample = samples[i];
          duration = sample.duration;
          size = sample.size;
          flags = sample.flags;
          cts = sample.cts;
          array.set([duration >>> 24 & 0xff, duration >>> 16 & 0xff, duration >>> 8 & 0xff, duration & 0xff, // sample_duration
          size >>> 24 & 0xff, size >>> 16 & 0xff, size >>> 8 & 0xff, size & 0xff, // sample_size
          flags.isLeading << 2 | flags.dependsOn, flags.isDependedOn << 6 | flags.hasRedundancy << 4 | flags.paddingValue << 1 | flags.isNonSync, flags.degradPrio & 0xf0 << 8, flags.degradPrio & 0x0f, // sample_flags
          cts >>> 24 & 0xff, cts >>> 16 & 0xff, cts >>> 8 & 0xff, cts & 0xff // sample_composition_time_offset
          ], 12 + 16 * i);
        }

        return MP4.box(MP4.types.trun, array);
      };

      MP4.initSegment = function initSegment(tracks) {
        if (!MP4.types) {
          MP4.init();
        }

        var movie = MP4.moov(tracks);
        var result = new Uint8Array(MP4.FTYP.byteLength + movie.byteLength);
        result.set(MP4.FTYP);
        result.set(movie, MP4.FTYP.byteLength);
        return result;
      };

      return MP4;
    }();

    MP4.types = void 0;
    MP4.HDLR_TYPES = void 0;
    MP4.STTS = void 0;
    MP4.STSC = void 0;
    MP4.STCO = void 0;
    MP4.STSZ = void 0;
    MP4.VMHD = void 0;
    MP4.SMHD = void 0;
    MP4.STSD = void 0;
    MP4.FTYP = void 0;
    MP4.DINF = void 0;
    /* harmony default export */ __webpack_exports__["default"] = (MP4);

    /***/ }),

    /***/ "./src/remux/mp4-remuxer.ts":
    /*!**********************************!*\
      !*** ./src/remux/mp4-remuxer.ts ***!
      \**********************************/
    /*! exports provided: default, normalizePts */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return MP4Remuxer; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "normalizePts", function() { return normalizePts; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _aac_helper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./aac-helper */ "./src/remux/aac-helper.ts");
    /* harmony import */ var _mp4_generator__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./mp4-generator */ "./src/remux/mp4-generator.ts");
    /* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../events */ "./src/events.ts");
    /* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
    /* harmony import */ var _utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../utils/timescale-conversion */ "./src/utils/timescale-conversion.ts");


    function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }








    var MAX_SILENT_FRAME_DURATION = 10 * 1000; // 10 seconds

    var AAC_SAMPLES_PER_FRAME = 1024;
    var MPEG_AUDIO_SAMPLE_PER_FRAME = 1152;
    var chromeVersion = null;
    var safariWebkitVersion = null;
    var requiresPositiveDts = false;

    var MP4Remuxer = /*#__PURE__*/function () {
      function MP4Remuxer(observer, config, typeSupported, vendor) {

        this.observer = void 0;
        this.config = void 0;
        this.typeSupported = void 0;
        this.ISGenerated = false;
        this._initPTS = void 0;
        this._initDTS = void 0;
        this.nextAvcDts = null;
        this.nextAudioPts = null;
        this.isAudioContiguous = false;
        this.isVideoContiguous = false;
        this.observer = observer;
        this.config = config;
        this.typeSupported = typeSupported;
        this.ISGenerated = false;

        if (chromeVersion === null) {
          var userAgent = navigator.userAgent || '';
          var result = userAgent.match(/Chrome\/(\d+)/i);
          chromeVersion = result ? parseInt(result[1]) : 0;
        }

        if (safariWebkitVersion === null) {
          var _result = navigator.userAgent.match(/Safari\/(\d+)/i);

          safariWebkitVersion = _result ? parseInt(_result[1]) : 0;
        }

        requiresPositiveDts = !!chromeVersion && chromeVersion < 75 || !!safariWebkitVersion && safariWebkitVersion < 600;
      }

      var _proto = MP4Remuxer.prototype;

      _proto.destroy = function destroy() {};

      _proto.resetTimeStamp = function resetTimeStamp(defaultTimeStamp) {
        _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].log('[mp4-remuxer]: initPTS & initDTS reset');
        this._initPTS = this._initDTS = defaultTimeStamp;
      };

      _proto.resetNextTimestamp = function resetNextTimestamp() {
        _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].log('[mp4-remuxer]: reset next timestamp');
        this.isVideoContiguous = false;
        this.isAudioContiguous = false;
      };

      _proto.resetInitSegment = function resetInitSegment() {
        _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].log('[mp4-remuxer]: ISGenerated flag reset');
        this.ISGenerated = false;
      };

      _proto.getVideoStartPts = function getVideoStartPts(videoSamples) {
        var rolloverDetected = false;
        var startPTS = videoSamples.reduce(function (minPTS, sample) {
          var delta = sample.pts - minPTS;

          if (delta < -4294967296) {
            // 2^32, see PTSNormalize for reasoning, but we're hitting a rollover here, and we don't want that to impact the timeOffset calculation
            rolloverDetected = true;
            return normalizePts(minPTS, sample.pts);
          } else if (delta > 0) {
            return minPTS;
          } else {
            return sample.pts;
          }
        }, videoSamples[0].pts);

        if (rolloverDetected) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].debug('PTS rollover detected');
        }

        return startPTS;
      };

      _proto.remux = function remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, flush, playlistType) {
        var video;
        var audio;
        var initSegment;
        var text;
        var id3;
        var independent;
        var audioTimeOffset = timeOffset;
        var videoTimeOffset = timeOffset; // If we're remuxing audio and video progressively, wait until we've received enough samples for each track before proceeding.
        // This is done to synchronize the audio and video streams. We know if the current segment will have samples if the "pid"
        // parameter is greater than -1. The pid is set when the PMT is parsed, which contains the tracks list.
        // However, if the initSegment has already been generated, or we've reached the end of a segment (flush),
        // then we can remux one track without waiting for the other.

        var hasAudio = audioTrack.pid > -1;
        var hasVideo = videoTrack.pid > -1;
        var length = videoTrack.samples.length;
        var enoughAudioSamples = audioTrack.samples.length > 0;
        var enoughVideoSamples = length > 1;
        var canRemuxAvc = (!hasAudio || enoughAudioSamples) && (!hasVideo || enoughVideoSamples) || this.ISGenerated || flush;

        if (canRemuxAvc) {
          if (!this.ISGenerated) {
            initSegment = this.generateIS(audioTrack, videoTrack, timeOffset);
          }

          var isVideoContiguous = this.isVideoContiguous;
          var firstKeyFrameIndex = -1;

          if (enoughVideoSamples) {
            firstKeyFrameIndex = findKeyframeIndex(videoTrack.samples);

            if (!isVideoContiguous && this.config.forceKeyFrameOnDiscontinuity) {
              independent = true;

              if (firstKeyFrameIndex > 0) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].warn("[mp4-remuxer]: Dropped " + firstKeyFrameIndex + " out of " + length + " video samples due to a missing keyframe");
                var startPTS = this.getVideoStartPts(videoTrack.samples);
                videoTrack.samples = videoTrack.samples.slice(firstKeyFrameIndex);
                videoTrack.dropped += firstKeyFrameIndex;
                videoTimeOffset += (videoTrack.samples[0].pts - startPTS) / (videoTrack.timescale || 90000);
              } else if (firstKeyFrameIndex === -1) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].warn("[mp4-remuxer]: No keyframe found out of " + length + " video samples");
                independent = false;
              }
            }
          }

          if (this.ISGenerated) {
            if (enoughAudioSamples && enoughVideoSamples) {
              // timeOffset is expected to be the offset of the first timestamp of this fragment (first DTS)
              // if first audio DTS is not aligned with first video DTS then we need to take that into account
              // when providing timeOffset to remuxAudio / remuxVideo. if we don't do that, there might be a permanent / small
              // drift between audio and video streams
              var _startPTS = this.getVideoStartPts(videoTrack.samples);

              var tsDelta = normalizePts(audioTrack.samples[0].pts, _startPTS) - _startPTS;

              var audiovideoTimestampDelta = tsDelta / videoTrack.inputTimeScale;
              audioTimeOffset += Math.max(0, audiovideoTimestampDelta);
              videoTimeOffset += Math.max(0, -audiovideoTimestampDelta);
            } // Purposefully remuxing audio before video, so that remuxVideo can use nextAudioPts, which is calculated in remuxAudio.


            if (enoughAudioSamples) {
              // if initSegment was generated without audio samples, regenerate it again
              if (!audioTrack.samplerate) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].warn('[mp4-remuxer]: regenerate InitSegment as audio detected');
                initSegment = this.generateIS(audioTrack, videoTrack, timeOffset);
              }

              audio = this.remuxAudio(audioTrack, audioTimeOffset, this.isAudioContiguous, accurateTimeOffset, hasVideo || enoughVideoSamples || playlistType === _types_loader__WEBPACK_IMPORTED_MODULE_6__["PlaylistLevelType"].AUDIO ? videoTimeOffset : undefined);

              if (enoughVideoSamples) {
                var audioTrackLength = audio ? audio.endPTS - audio.startPTS : 0; // if initSegment was generated without video samples, regenerate it again

                if (!videoTrack.inputTimeScale) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].warn('[mp4-remuxer]: regenerate InitSegment as video detected');
                  initSegment = this.generateIS(audioTrack, videoTrack, timeOffset);
                }

                video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, audioTrackLength);
              }
            } else if (enoughVideoSamples) {
              video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, 0);
            }

            if (video) {
              video.firstKeyFrame = firstKeyFrameIndex;
              video.independent = firstKeyFrameIndex !== -1;
            }
          }
        } // Allow ID3 and text to remux, even if more audio/video samples are required


        if (this.ISGenerated) {
          if (id3Track.samples.length) {
            id3 = this.remuxID3(id3Track, timeOffset);
          }

          if (textTrack.samples.length) {
            text = this.remuxText(textTrack, timeOffset);
          }
        }

        return {
          audio: audio,
          video: video,
          initSegment: initSegment,
          independent: independent,
          text: text,
          id3: id3
        };
      };

      _proto.generateIS = function generateIS(audioTrack, videoTrack, timeOffset) {
        var audioSamples = audioTrack.samples;
        var videoSamples = videoTrack.samples;
        var typeSupported = this.typeSupported;
        var tracks = {};
        var computePTSDTS = !Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(this._initPTS);
        var container = 'audio/mp4';
        var initPTS;
        var initDTS;
        var timescale;

        if (computePTSDTS) {
          initPTS = initDTS = Infinity;
        }

        if (audioTrack.config && audioSamples.length) {
          // let's use audio sampling rate as MP4 time scale.
          // rationale is that there is a integer nb of audio frames per audio sample (1024 for AAC)
          // using audio sampling rate here helps having an integer MP4 frame duration
          // this avoids potential rounding issue and AV sync issue
          audioTrack.timescale = audioTrack.samplerate;

          if (!audioTrack.isAAC) {
            if (typeSupported.mpeg) {
              // Chrome and Safari
              container = 'audio/mpeg';
              audioTrack.codec = '';
            } else if (typeSupported.mp3) {
              // Firefox
              audioTrack.codec = 'mp3';
            }
          }

          tracks.audio = {
            id: 'audio',
            container: container,
            codec: audioTrack.codec,
            initSegment: !audioTrack.isAAC && typeSupported.mpeg ? new Uint8Array(0) : _mp4_generator__WEBPACK_IMPORTED_MODULE_2__["default"].initSegment([audioTrack]),
            metadata: {
              channelCount: audioTrack.channelCount
            }
          };

          if (computePTSDTS) {
            timescale = audioTrack.inputTimeScale; // remember first PTS of this demuxing context. for audio, PTS = DTS

            initPTS = initDTS = audioSamples[0].pts - Math.round(timescale * timeOffset);
          }
        }

        if (videoTrack.sps && videoTrack.pps && videoSamples.length) {
          // let's use input time scale as MP4 video timescale
          // we use input time scale straight away to avoid rounding issues on frame duration / cts computation
          videoTrack.timescale = videoTrack.inputTimeScale;
          tracks.video = {
            id: 'main',
            container: 'video/mp4',
            codec: videoTrack.codec,
            initSegment: _mp4_generator__WEBPACK_IMPORTED_MODULE_2__["default"].initSegment([videoTrack]),
            metadata: {
              width: videoTrack.width,
              height: videoTrack.height
            }
          };

          if (computePTSDTS) {
            timescale = videoTrack.inputTimeScale;
            var startPTS = this.getVideoStartPts(videoSamples);
            var startOffset = Math.round(timescale * timeOffset);
            initDTS = Math.min(initDTS, normalizePts(videoSamples[0].dts, startPTS) - startOffset);
            initPTS = Math.min(initPTS, startPTS - startOffset);
          }
        }

        if (Object.keys(tracks).length) {
          this.ISGenerated = true;

          if (computePTSDTS) {
            this._initPTS = initPTS;
            this._initDTS = initDTS;
          }

          return {
            tracks: tracks,
            initPTS: initPTS,
            timescale: timescale
          };
        }
      };

      _proto.remuxVideo = function remuxVideo(track, timeOffset, contiguous, audioTrackLength) {
        var timeScale = track.inputTimeScale;
        var inputSamples = track.samples;
        var outputSamples = [];
        var nbSamples = inputSamples.length;
        var initPTS = this._initPTS;
        var nextAvcDts = this.nextAvcDts;
        var offset = 8;
        var mp4SampleDuration;
        var firstDTS;
        var lastDTS;
        var minPTS = Number.POSITIVE_INFINITY;
        var maxPTS = Number.NEGATIVE_INFINITY;
        var ptsDtsShift = 0;
        var sortSamples = false; // if parsed fragment is contiguous with last one, let's use last DTS value as reference

        if (!contiguous || nextAvcDts === null) {
          var pts = timeOffset * timeScale;
          var cts = inputSamples[0].pts - normalizePts(inputSamples[0].dts, inputSamples[0].pts); // if not contiguous, let's use target timeOffset

          nextAvcDts = pts - cts;
        } // PTS is coded on 33bits, and can loop from -2^32 to 2^32
        // PTSNormalize will make PTS/DTS value monotonic, we use last known DTS value as reference value


        for (var i = 0; i < nbSamples; i++) {
          var sample = inputSamples[i];
          sample.pts = normalizePts(sample.pts - initPTS, nextAvcDts);
          sample.dts = normalizePts(sample.dts - initPTS, nextAvcDts);

          if (sample.dts > sample.pts) {
            var PTS_DTS_SHIFT_TOLERANCE_90KHZ = 90000 * 0.2;
            ptsDtsShift = Math.max(Math.min(ptsDtsShift, sample.pts - sample.dts), -1 * PTS_DTS_SHIFT_TOLERANCE_90KHZ);
          }

          if (sample.dts < inputSamples[i > 0 ? i - 1 : i].dts) {
            sortSamples = true;
          }
        } // sort video samples by DTS then PTS then demux id order


        if (sortSamples) {
          inputSamples.sort(function (a, b) {
            var deltadts = a.dts - b.dts;
            var deltapts = a.pts - b.pts;
            return deltadts || deltapts;
          });
        } // Get first/last DTS


        firstDTS = inputSamples[0].dts;
        lastDTS = inputSamples[inputSamples.length - 1].dts; // on Safari let's signal the same sample duration for all samples
        // sample duration (as expected by trun MP4 boxes), should be the delta between sample DTS
        // set this constant duration as being the avg delta between consecutive DTS.

        var averageSampleDuration = Math.round((lastDTS - firstDTS) / (nbSamples - 1)); // handle broken streams with PTS < DTS, tolerance up 0.2 seconds

        if (ptsDtsShift < 0) {
          if (ptsDtsShift < averageSampleDuration * -2) {
            // Fix for "CNN special report, with CC" in test-streams (including Safari browser)
            // With large PTS < DTS errors such as this, we want to correct CTS while maintaining increasing DTS values
            _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].warn("PTS < DTS detected in video samples, offsetting DTS from PTS by " + Object(_utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_7__["toMsFromMpegTsClock"])(-averageSampleDuration, true) + " ms");
            var lastDts = ptsDtsShift;

            for (var _i = 0; _i < nbSamples; _i++) {
              inputSamples[_i].dts = lastDts = Math.max(lastDts, inputSamples[_i].pts - averageSampleDuration);
              inputSamples[_i].pts = Math.max(lastDts, inputSamples[_i].pts);
            }
          } else {
            // Fix for "Custom IV with bad PTS DTS" in test-streams
            // With smaller PTS < DTS errors we can simply move all DTS back. This increases CTS without causing buffer gaps or decode errors in Safari
            _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].warn("PTS < DTS detected in video samples, shifting DTS by " + Object(_utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_7__["toMsFromMpegTsClock"])(ptsDtsShift, true) + " ms to overcome this issue");

            for (var _i2 = 0; _i2 < nbSamples; _i2++) {
              inputSamples[_i2].dts = inputSamples[_i2].dts + ptsDtsShift;
            }
          }

          firstDTS = inputSamples[0].dts;
        } // if fragment are contiguous, detect hole/overlapping between fragments


        if (contiguous) {
          // check timestamp continuity across consecutive fragments (this is to remove inter-fragment gap/hole)
          var delta = firstDTS - nextAvcDts;
          var foundHole = delta > averageSampleDuration;
          var foundOverlap = delta < -1;

          if (foundHole || foundOverlap) {
            if (foundHole) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].warn("AVC: " + Object(_utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_7__["toMsFromMpegTsClock"])(delta, true) + " ms (" + delta + "dts) hole between fragments detected, filling it");
            } else {
              _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].warn("AVC: " + Object(_utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_7__["toMsFromMpegTsClock"])(-delta, true) + " ms (" + delta + "dts) overlapping between fragments detected");
            }

            firstDTS = nextAvcDts;
            var firstPTS = inputSamples[0].pts - delta;
            inputSamples[0].dts = firstDTS;
            inputSamples[0].pts = firstPTS;
            _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].log("Video: First PTS/DTS adjusted: " + Object(_utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_7__["toMsFromMpegTsClock"])(firstPTS, true) + "/" + Object(_utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_7__["toMsFromMpegTsClock"])(firstDTS, true) + ", delta: " + Object(_utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_7__["toMsFromMpegTsClock"])(delta, true) + " ms");
          }
        }

        if (requiresPositiveDts) {
          firstDTS = Math.max(0, firstDTS);
        }

        var nbNalu = 0;
        var naluLen = 0;

        for (var _i3 = 0; _i3 < nbSamples; _i3++) {
          // compute total/avc sample length and nb of NAL units
          var _sample = inputSamples[_i3];
          var units = _sample.units;
          var nbUnits = units.length;
          var sampleLen = 0;

          for (var j = 0; j < nbUnits; j++) {
            sampleLen += units[j].data.length;
          }

          naluLen += sampleLen;
          nbNalu += nbUnits;
          _sample.length = sampleLen; // normalize PTS/DTS
          // ensure sample monotonic DTS

          _sample.dts = Math.max(_sample.dts, firstDTS); // ensure that computed value is greater or equal than sample DTS

          _sample.pts = Math.max(_sample.pts, _sample.dts, 0);
          minPTS = Math.min(_sample.pts, minPTS);
          maxPTS = Math.max(_sample.pts, maxPTS);
        }

        lastDTS = inputSamples[nbSamples - 1].dts;
        /* concatenate the video data and construct the mdat in place
          (need 8 more bytes to fill length and mpdat type) */

        var mdatSize = naluLen + 4 * nbNalu + 8;
        var mdat;

        try {
          mdat = new Uint8Array(mdatSize);
        } catch (err) {
          this.observer.emit(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].ERROR, _events__WEBPACK_IMPORTED_MODULE_3__["Events"].ERROR, {
            type: _errors__WEBPACK_IMPORTED_MODULE_4__["ErrorTypes"].MUX_ERROR,
            details: _errors__WEBPACK_IMPORTED_MODULE_4__["ErrorDetails"].REMUX_ALLOC_ERROR,
            fatal: false,
            bytes: mdatSize,
            reason: "fail allocating video mdat " + mdatSize
          });
          return;
        }

        var view = new DataView(mdat.buffer);
        view.setUint32(0, mdatSize);
        mdat.set(_mp4_generator__WEBPACK_IMPORTED_MODULE_2__["default"].types.mdat, 4);

        for (var _i4 = 0; _i4 < nbSamples; _i4++) {
          var avcSample = inputSamples[_i4];
          var avcSampleUnits = avcSample.units;
          var mp4SampleLength = 0; // convert NALU bitstream to MP4 format (prepend NALU with size field)

          for (var _j = 0, _nbUnits = avcSampleUnits.length; _j < _nbUnits; _j++) {
            var unit = avcSampleUnits[_j];
            var unitData = unit.data;
            var unitDataLen = unit.data.byteLength;
            view.setUint32(offset, unitDataLen);
            offset += 4;
            mdat.set(unitData, offset);
            offset += unitDataLen;
            mp4SampleLength += 4 + unitDataLen;
          } // expected sample duration is the Decoding Timestamp diff of consecutive samples


          if (_i4 < nbSamples - 1) {
            mp4SampleDuration = inputSamples[_i4 + 1].dts - avcSample.dts;
          } else {
            var config = this.config;
            var lastFrameDuration = avcSample.dts - inputSamples[_i4 > 0 ? _i4 - 1 : _i4].dts;

            if (config.stretchShortVideoTrack && this.nextAudioPts !== null) {
              // In some cases, a segment's audio track duration may exceed the video track duration.
              // Since we've already remuxed audio, and we know how long the audio track is, we look to
              // see if the delta to the next segment is longer than maxBufferHole.
              // If so, playback would potentially get stuck, so we artificially inflate
              // the duration of the last frame to minimize any potential gap between segments.
              var gapTolerance = Math.floor(config.maxBufferHole * timeScale);
              var deltaToFrameEnd = (audioTrackLength ? minPTS + audioTrackLength * timeScale : this.nextAudioPts) - avcSample.pts;

              if (deltaToFrameEnd > gapTolerance) {
                // We subtract lastFrameDuration from deltaToFrameEnd to try to prevent any video
                // frame overlap. maxBufferHole should be >> lastFrameDuration anyway.
                mp4SampleDuration = deltaToFrameEnd - lastFrameDuration;

                if (mp4SampleDuration < 0) {
                  mp4SampleDuration = lastFrameDuration;
                }

                _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].log("[mp4-remuxer]: It is approximately " + deltaToFrameEnd / 90 + " ms to the next segment; using duration " + mp4SampleDuration / 90 + " ms for the last video frame.");
              } else {
                mp4SampleDuration = lastFrameDuration;
              }
            } else {
              mp4SampleDuration = lastFrameDuration;
            }
          }

          var compositionTimeOffset = Math.round(avcSample.pts - avcSample.dts);
          outputSamples.push(new Mp4Sample(avcSample.key, mp4SampleDuration, mp4SampleLength, compositionTimeOffset));
        }

        if (outputSamples.length && chromeVersion && chromeVersion < 70) {
          // Chrome workaround, mark first sample as being a Random Access Point (keyframe) to avoid sourcebuffer append issue
          // https://code.google.com/p/chromium/issues/detail?id=229412
          var flags = outputSamples[0].flags;
          flags.dependsOn = 2;
          flags.isNonSync = 0;
        }

        console.assert(mp4SampleDuration !== undefined, 'mp4SampleDuration must be computed'); // next AVC sample DTS should be equal to last sample DTS + last sample duration (in PES timescale)

        this.nextAvcDts = nextAvcDts = lastDTS + mp4SampleDuration;
        this.isVideoContiguous = true;
        var moof = _mp4_generator__WEBPACK_IMPORTED_MODULE_2__["default"].moof(track.sequenceNumber++, firstDTS, _extends({}, track, {
          samples: outputSamples
        }));
        var type = 'video';
        var data = {
          data1: moof,
          data2: mdat,
          startPTS: minPTS / timeScale,
          endPTS: (maxPTS + mp4SampleDuration) / timeScale,
          startDTS: firstDTS / timeScale,
          endDTS: nextAvcDts / timeScale,
          type: type,
          hasAudio: false,
          hasVideo: true,
          nb: outputSamples.length,
          dropped: track.dropped
        };
        track.samples = [];
        track.dropped = 0;
        console.assert(mdat.length, 'MDAT length must not be zero');
        return data;
      };

      _proto.remuxAudio = function remuxAudio(track, timeOffset, contiguous, accurateTimeOffset, videoTimeOffset) {
        var inputTimeScale = track.inputTimeScale;
        var mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale;
        var scaleFactor = inputTimeScale / mp4timeScale;
        var mp4SampleDuration = track.isAAC ? AAC_SAMPLES_PER_FRAME : MPEG_AUDIO_SAMPLE_PER_FRAME;
        var inputSampleDuration = mp4SampleDuration * scaleFactor;
        var initPTS = this._initPTS;
        var rawMPEG = !track.isAAC && this.typeSupported.mpeg;
        var outputSamples = [];
        var inputSamples = track.samples;
        var offset = rawMPEG ? 0 : 8;
        var nextAudioPts = this.nextAudioPts || -1; // window.audioSamples ? window.audioSamples.push(inputSamples.map(s => s.pts)) : (window.audioSamples = [inputSamples.map(s => s.pts)]);
        // for audio samples, also consider consecutive fragments as being contiguous (even if a level switch occurs),
        // for sake of clarity:
        // consecutive fragments are frags with
        //  - less than 100ms gaps between new time offset (if accurate) and next expected PTS OR
        //  - less than 20 audio frames distance
        // contiguous fragments are consecutive fragments from same quality level (same level, new SN = old SN + 1)
        // this helps ensuring audio continuity
        // and this also avoids audio glitches/cut when switching quality, or reporting wrong duration on first audio frame

        var timeOffsetMpegTS = timeOffset * inputTimeScale;
        this.isAudioContiguous = contiguous = contiguous || inputSamples.length && nextAudioPts > 0 && (accurateTimeOffset && Math.abs(timeOffsetMpegTS - nextAudioPts) < 9000 || Math.abs(normalizePts(inputSamples[0].pts - initPTS, timeOffsetMpegTS) - nextAudioPts) < 20 * inputSampleDuration); // compute normalized PTS

        inputSamples.forEach(function (sample) {
          sample.pts = normalizePts(sample.pts - initPTS, timeOffsetMpegTS);
        });

        if (!contiguous || nextAudioPts < 0) {
          // filter out sample with negative PTS that are not playable anyway
          // if we don't remove these negative samples, they will shift all audio samples forward.
          // leading to audio overlap between current / next fragment
          inputSamples = inputSamples.filter(function (sample) {
            return sample.pts >= 0;
          }); // in case all samples have negative PTS, and have been filtered out, return now

          if (!inputSamples.length) {
            return;
          }

          if (videoTimeOffset === 0) {
            // Set the start to 0 to match video so that start gaps larger than inputSampleDuration are filled with silence
            nextAudioPts = 0;
          } else if (accurateTimeOffset) {
            // When not seeking, not live, and LevelDetails.PTSKnown, use fragment start as predicted next audio PTS
            nextAudioPts = Math.max(0, timeOffsetMpegTS);
          } else {
            // if frags are not contiguous and if we cant trust time offset, let's use first sample PTS as next audio PTS
            nextAudioPts = inputSamples[0].pts;
          }
        } // If the audio track is missing samples, the frames seem to get "left-shifted" within the
        // resulting mp4 segment, causing sync issues and leaving gaps at the end of the audio segment.
        // In an effort to prevent this from happening, we inject frames here where there are gaps.
        // When possible, we inject a silent frame; when that's not possible, we duplicate the last
        // frame.


        if (track.isAAC) {
          var alignedWithVideo = videoTimeOffset !== undefined;
          var maxAudioFramesDrift = this.config.maxAudioFramesDrift;

          for (var i = 0, nextPts = nextAudioPts; i < inputSamples.length; i++) {
            // First, let's see how far off this frame is from where we expect it to be
            var sample = inputSamples[i];
            var pts = sample.pts;
            var delta = pts - nextPts;
            var duration = Math.abs(1000 * delta / inputTimeScale); // When remuxing with video, if we're overlapping by more than a duration, drop this sample to stay in sync

            if (delta <= -maxAudioFramesDrift * inputSampleDuration && alignedWithVideo) {
              if (i === 0) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].warn("Audio frame @ " + (pts / inputTimeScale).toFixed(3) + "s overlaps nextAudioPts by " + Math.round(1000 * delta / inputTimeScale) + " ms.");
                this.nextAudioPts = nextAudioPts = nextPts = pts;
              }
            } // eslint-disable-line brace-style
            // Insert missing frames if:
            // 1: We're more than maxAudioFramesDrift frame away
            // 2: Not more than MAX_SILENT_FRAME_DURATION away
            // 3: currentTime (aka nextPtsNorm) is not 0
            // 4: remuxing with video (videoTimeOffset !== undefined)
            else if (delta >= maxAudioFramesDrift * inputSampleDuration && duration < MAX_SILENT_FRAME_DURATION && alignedWithVideo) {
              var missing = Math.round(delta / inputSampleDuration); // Adjust nextPts so that silent samples are aligned with media pts. This will prevent media samples from
              // later being shifted if nextPts is based on timeOffset and delta is not a multiple of inputSampleDuration.

              nextPts = pts - missing * inputSampleDuration;

              if (nextPts < 0) {
                missing--;
                nextPts += inputSampleDuration;
              }

              if (i === 0) {
                this.nextAudioPts = nextAudioPts = nextPts;
              }

              _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].warn("[mp4-remuxer]: Injecting " + missing + " audio frame @ " + (nextPts / inputTimeScale).toFixed(3) + "s due to " + Math.round(1000 * delta / inputTimeScale) + " ms gap.");

              for (var j = 0; j < missing; j++) {
                var newStamp = Math.max(nextPts, 0);
                var fillFrame = _aac_helper__WEBPACK_IMPORTED_MODULE_1__["default"].getSilentFrame(track.manifestCodec || track.codec, track.channelCount);

                if (!fillFrame) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].log('[mp4-remuxer]: Unable to get silent frame for given audio codec; duplicating last frame instead.');
                  fillFrame = sample.unit.subarray();
                }

                inputSamples.splice(i, 0, {
                  unit: fillFrame,
                  pts: newStamp
                });
                nextPts += inputSampleDuration;
                i++;
              }
            }

            sample.pts = nextPts;
            nextPts += inputSampleDuration;
          }
        }

        var firstPTS = null;
        var lastPTS = null;
        var mdat;
        var mdatSize = 0;
        var sampleLength = inputSamples.length;

        while (sampleLength--) {
          mdatSize += inputSamples[sampleLength].unit.byteLength;
        }

        for (var _j2 = 0, _nbSamples = inputSamples.length; _j2 < _nbSamples; _j2++) {
          var audioSample = inputSamples[_j2];
          var unit = audioSample.unit;
          var _pts = audioSample.pts;

          if (lastPTS !== null) {
            // If we have more than one sample, set the duration of the sample to the "real" duration; the PTS diff with
            // the previous sample
            var prevSample = outputSamples[_j2 - 1];
            prevSample.duration = Math.round((_pts - lastPTS) / scaleFactor);
          } else {
            if (contiguous && track.isAAC) {
              // set PTS/DTS to expected PTS/DTS
              _pts = nextAudioPts;
            } // remember first PTS of our audioSamples


            firstPTS = _pts;

            if (mdatSize > 0) {
              /* concatenate the audio data and construct the mdat in place
                (need 8 more bytes to fill length and mdat type) */
              mdatSize += offset;

              try {
                mdat = new Uint8Array(mdatSize);
              } catch (err) {
                this.observer.emit(_events__WEBPACK_IMPORTED_MODULE_3__["Events"].ERROR, _events__WEBPACK_IMPORTED_MODULE_3__["Events"].ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_4__["ErrorTypes"].MUX_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_4__["ErrorDetails"].REMUX_ALLOC_ERROR,
                  fatal: false,
                  bytes: mdatSize,
                  reason: "fail allocating audio mdat " + mdatSize
                });
                return;
              }

              if (!rawMPEG) {
                var view = new DataView(mdat.buffer);
                view.setUint32(0, mdatSize);
                mdat.set(_mp4_generator__WEBPACK_IMPORTED_MODULE_2__["default"].types.mdat, 4);
              }
            } else {
              // no audio samples
              return;
            }
          }

          mdat.set(unit, offset);
          var unitLen = unit.byteLength;
          offset += unitLen; // Default the sample's duration to the computed mp4SampleDuration, which will either be 1024 for AAC or 1152 for MPEG
          // In the case that we have 1 sample, this will be the duration. If we have more than one sample, the duration
          // becomes the PTS diff with the previous sample

          outputSamples.push(new Mp4Sample(true, mp4SampleDuration, unitLen, 0));
          lastPTS = _pts;
        } // We could end up with no audio samples if all input samples were overlapping with the previously remuxed ones


        var nbSamples = outputSamples.length;

        if (!nbSamples) {
          return;
        } // The next audio sample PTS should be equal to last sample PTS + duration


        var lastSample = outputSamples[outputSamples.length - 1];
        this.nextAudioPts = nextAudioPts = lastPTS + scaleFactor * lastSample.duration; // Set the track samples from inputSamples to outputSamples before remuxing

        var moof = rawMPEG ? new Uint8Array(0) : _mp4_generator__WEBPACK_IMPORTED_MODULE_2__["default"].moof(track.sequenceNumber++, firstPTS / scaleFactor, _extends({}, track, {
          samples: outputSamples
        })); // Clear the track samples. This also clears the samples array in the demuxer, since the reference is shared

        track.samples = [];
        var start = firstPTS / inputTimeScale;
        var end = nextAudioPts / inputTimeScale;
        var type = 'audio';
        var audioData = {
          data1: moof,
          data2: mdat,
          startPTS: start,
          endPTS: end,
          startDTS: start,
          endDTS: end,
          type: type,
          hasAudio: true,
          hasVideo: false,
          nb: nbSamples
        };
        this.isAudioContiguous = true;
        console.assert(mdat.length, 'MDAT length must not be zero');
        return audioData;
      };

      _proto.remuxEmptyAudio = function remuxEmptyAudio(track, timeOffset, contiguous, videoData) {
        var inputTimeScale = track.inputTimeScale;
        var mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale;
        var scaleFactor = inputTimeScale / mp4timeScale;
        var nextAudioPts = this.nextAudioPts; // sync with video's timestamp

        var startDTS = (nextAudioPts !== null ? nextAudioPts : videoData.startDTS * inputTimeScale) + this._initDTS;
        var endDTS = videoData.endDTS * inputTimeScale + this._initDTS; // one sample's duration value

        var frameDuration = scaleFactor * AAC_SAMPLES_PER_FRAME; // samples count of this segment's duration

        var nbSamples = Math.ceil((endDTS - startDTS) / frameDuration); // silent frame

        var silentFrame = _aac_helper__WEBPACK_IMPORTED_MODULE_1__["default"].getSilentFrame(track.manifestCodec || track.codec, track.channelCount);
        _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].warn('[mp4-remuxer]: remux empty Audio'); // Can't remux if we can't generate a silent frame...

        if (!silentFrame) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_5__["logger"].trace('[mp4-remuxer]: Unable to remuxEmptyAudio since we were unable to get a silent frame for given audio codec');
          return;
        }

        var samples = [];

        for (var i = 0; i < nbSamples; i++) {
          var stamp = startDTS + i * frameDuration;
          samples.push({
            unit: silentFrame,
            pts: stamp,
            dts: stamp
          });
        }

        track.samples = samples;
        return this.remuxAudio(track, timeOffset, contiguous, false);
      };

      _proto.remuxID3 = function remuxID3(track, timeOffset) {
        var length = track.samples.length;

        if (!length) {
          return;
        }

        var inputTimeScale = track.inputTimeScale;
        var initPTS = this._initPTS;
        var initDTS = this._initDTS;

        for (var index = 0; index < length; index++) {
          var sample = track.samples[index]; // setting id3 pts, dts to relative time
          // using this._initPTS and this._initDTS to calculate relative time

          sample.pts = normalizePts(sample.pts - initPTS, timeOffset * inputTimeScale) / inputTimeScale;
          sample.dts = normalizePts(sample.dts - initDTS, timeOffset * inputTimeScale) / inputTimeScale;
        }

        var samples = track.samples;
        track.samples = [];
        return {
          samples: samples
        };
      };

      _proto.remuxText = function remuxText(track, timeOffset) {
        var length = track.samples.length;

        if (!length) {
          return;
        }

        var inputTimeScale = track.inputTimeScale;
        var initPTS = this._initPTS;

        for (var index = 0; index < length; index++) {
          var sample = track.samples[index]; // setting text pts, dts to relative time
          // using this._initPTS and this._initDTS to calculate relative time

          sample.pts = normalizePts(sample.pts - initPTS, timeOffset * inputTimeScale) / inputTimeScale;
        }

        track.samples.sort(function (a, b) {
          return a.pts - b.pts;
        });
        var samples = track.samples;
        track.samples = [];
        return {
          samples: samples
        };
      };

      return MP4Remuxer;
    }();


    function normalizePts(value, reference) {
      var offset;

      if (reference === null) {
        return value;
      }

      if (reference < value) {
        // - 2^33
        offset = -8589934592;
      } else {
        // + 2^33
        offset = 8589934592;
      }
      /* PTS is 33bit (from 0 to 2^33 -1)
        if diff between value and reference is bigger than half of the amplitude (2^32) then it means that
        PTS looping occured. fill the gap */


      while (Math.abs(value - reference) > 4294967296) {
        value += offset;
      }

      return value;
    }

    function findKeyframeIndex(samples) {
      for (var i = 0; i < samples.length; i++) {
        if (samples[i].key) {
          return i;
        }
      }

      return -1;
    }

    var Mp4Sample = function Mp4Sample(isKeyframe, duration, size, cts) {
      this.size = void 0;
      this.duration = void 0;
      this.cts = void 0;
      this.flags = void 0;
      this.duration = duration;
      this.size = size;
      this.cts = cts;
      this.flags = new Mp4SampleFlags(isKeyframe);
    };

    var Mp4SampleFlags = function Mp4SampleFlags(isKeyframe) {
      this.isLeading = 0;
      this.isDependedOn = 0;
      this.hasRedundancy = 0;
      this.degradPrio = 0;
      this.dependsOn = 1;
      this.isNonSync = 1;
      this.dependsOn = isKeyframe ? 2 : 1;
      this.isNonSync = isKeyframe ? 0 : 1;
    };

    /***/ }),

    /***/ "./src/remux/passthrough-remuxer.ts":
    /*!******************************************!*\
      !*** ./src/remux/passthrough-remuxer.ts ***!
      \******************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
    /* harmony import */ var _loader_fragment__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../loader/fragment */ "./src/loader/fragment.ts");
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");






    var PassThroughRemuxer = /*#__PURE__*/function () {
      function PassThroughRemuxer() {
        this.emitInitSegment = false;
        this.audioCodec = void 0;
        this.videoCodec = void 0;
        this.initData = void 0;
        this.initPTS = void 0;
        this.initTracks = void 0;
        this.lastEndDTS = null;
      }

      var _proto = PassThroughRemuxer.prototype;

      _proto.destroy = function destroy() {};

      _proto.resetTimeStamp = function resetTimeStamp(defaultInitPTS) {
        this.initPTS = defaultInitPTS;
        this.lastEndDTS = null;
      };

      _proto.resetNextTimestamp = function resetNextTimestamp() {
        this.lastEndDTS = null;
      };

      _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec) {
        this.audioCodec = audioCodec;
        this.videoCodec = videoCodec;
        this.generateInitSegment(initSegment);
        this.emitInitSegment = true;
      };

      _proto.generateInitSegment = function generateInitSegment(initSegment) {
        var audioCodec = this.audioCodec,
            videoCodec = this.videoCodec;

        if (!initSegment || !initSegment.byteLength) {
          this.initTracks = undefined;
          this.initData = undefined;
          return;
        }

        var initData = this.initData = Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__["parseInitSegment"])(initSegment); // Get codec from initSegment or fallback to default

        if (!audioCodec) {
          audioCodec = getParsedTrackCodec(initData.audio, _loader_fragment__WEBPACK_IMPORTED_MODULE_2__["ElementaryStreamTypes"].AUDIO);
        }

        if (!videoCodec) {
          videoCodec = getParsedTrackCodec(initData.video, _loader_fragment__WEBPACK_IMPORTED_MODULE_2__["ElementaryStreamTypes"].VIDEO);
        }

        var tracks = {};

        if (initData.audio && initData.video) {
          tracks.audiovideo = {
            container: 'video/mp4',
            codec: audioCodec + ',' + videoCodec,
            initSegment: initSegment,
            id: 'main'
          };
        } else if (initData.audio) {
          tracks.audio = {
            container: 'audio/mp4',
            codec: audioCodec,
            initSegment: initSegment,
            id: 'audio'
          };
        } else if (initData.video) {
          tracks.video = {
            container: 'video/mp4',
            codec: videoCodec,
            initSegment: initSegment,
            id: 'main'
          };
        } else {
          _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn('[passthrough-remuxer.ts]: initSegment does not contain moov or trak boxes.');
        }

        this.initTracks = tracks;
      };

      _proto.remux = function remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset) {
        var initPTS = this.initPTS,
            lastEndDTS = this.lastEndDTS;
        var result = {
          audio: undefined,
          video: undefined,
          text: textTrack,
          id3: id3Track,
          initSegment: undefined
        }; // If we haven't yet set a lastEndDTS, or it was reset, set it to the provided timeOffset. We want to use the
        // lastEndDTS over timeOffset whenever possible; during progressive playback, the media source will not update
        // the media duration (which is what timeOffset is provided as) before we need to process the next chunk.

        if (!Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(lastEndDTS)) {
          lastEndDTS = this.lastEndDTS = timeOffset || 0;
        } // The binary segment data is added to the videoTrack in the mp4demuxer. We don't check to see if the data is only
        // audio or video (or both); adding it to video was an arbitrary choice.


        var data = videoTrack.samples;

        if (!data || !data.length) {
          return result;
        }

        var initSegment = {
          initPTS: undefined,
          timescale: 1
        };
        var initData = this.initData;

        if (!initData || !initData.length) {
          this.generateInitSegment(data);
          initData = this.initData;
        }

        if (!initData || !initData.length) {
          // We can't remux if the initSegment could not be generated
          _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn('[passthrough-remuxer.ts]: Failed to generate initSegment.');
          return result;
        }

        if (this.emitInitSegment) {
          initSegment.tracks = this.initTracks;
          this.emitInitSegment = false;
        }

        if (!Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(initPTS)) {
          this.initPTS = initSegment.initPTS = initPTS = computeInitPTS(initData, data, lastEndDTS);
        }

        var duration = Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__["getDuration"])(data, initData);
        var startDTS = lastEndDTS;
        var endDTS = duration + startDTS;
        Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__["offsetStartDTS"])(initData, data, initPTS);

        if (duration > 0) {
          this.lastEndDTS = endDTS;
        } else {
          _utils_logger__WEBPACK_IMPORTED_MODULE_3__["logger"].warn('Duration parsed from mp4 should be greater than zero');
          this.resetNextTimestamp();
        }

        var hasAudio = !!initData.audio;
        var hasVideo = !!initData.video;
        var type = '';

        if (hasAudio) {
          type += 'audio';
        }

        if (hasVideo) {
          type += 'video';
        }

        var track = {
          data1: data,
          startPTS: startDTS,
          startDTS: startDTS,
          endPTS: endDTS,
          endDTS: endDTS,
          type: type,
          hasAudio: hasAudio,
          hasVideo: hasVideo,
          nb: 1,
          dropped: 0
        };
        result.audio = track.type === 'audio' ? track : undefined;
        result.video = track.type !== 'audio' ? track : undefined;
        result.text = textTrack;
        result.id3 = id3Track;
        result.initSegment = initSegment;
        return result;
      };

      return PassThroughRemuxer;
    }();

    var computeInitPTS = function computeInitPTS(initData, data, timeOffset) {
      return Object(_utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__["getStartDTS"])(initData, data) - timeOffset;
    };

    function getParsedTrackCodec(track, type) {
      var parsedCodec = track === null || track === void 0 ? void 0 : track.codec;

      if (parsedCodec && parsedCodec.length > 4) {
        return parsedCodec;
      } // Since mp4-tools cannot parse full codec string (see 'TODO: Parse codec details'... in mp4-tools)
      // Provide defaults based on codec type
      // This allows for some playback of some fmp4 playlists without CODECS defined in manifest


      if (parsedCodec === 'hvc1') {
        return 'hvc1.1.c.L120.90';
      }

      if (parsedCodec === 'av01') {
        return 'av01.0.04M.08';
      }

      if (parsedCodec === 'avc1' || type === _loader_fragment__WEBPACK_IMPORTED_MODULE_2__["ElementaryStreamTypes"].VIDEO) {
        return 'avc1.42e01e';
      }

      return 'mp4a.40.5';
    }

    /* harmony default export */ __webpack_exports__["default"] = (PassThroughRemuxer);

    /***/ }),

    /***/ "./src/task-loop.ts":
    /*!**************************!*\
      !*** ./src/task-loop.ts ***!
      \**************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return TaskLoop; });
    /**
     * Sub-class specialization of EventHandler base class.
     *
     * TaskLoop allows to schedule a task function being called (optionnaly repeatedly) on the main loop,
     * scheduled asynchroneously, avoiding recursive calls in the same tick.
     *
     * The task itself is implemented in `doTick`. It can be requested and called for single execution
     * using the `tick` method.
     *
     * It will be assured that the task execution method (`tick`) only gets called once per main loop "tick",
     * no matter how often it gets requested for execution. Execution in further ticks will be scheduled accordingly.
     *
     * If further execution requests have already been scheduled on the next tick, it can be checked with `hasNextTick`,
     * and cancelled with `clearNextTick`.
     *
     * The task can be scheduled as an interval repeatedly with a period as parameter (see `setInterval`, `clearInterval`).
     *
     * Sub-classes need to implement the `doTick` method which will effectively have the task execution routine.
     *
     * Further explanations:
     *
     * The baseclass has a `tick` method that will schedule the doTick call. It may be called synchroneously
     * only for a stack-depth of one. On re-entrant calls, sub-sequent calls are scheduled for next main loop ticks.
     *
     * When the task execution (`tick` method) is called in re-entrant way this is detected and
     * we are limiting the task execution per call stack to exactly one, but scheduling/post-poning further
     * task processing on the next main loop iteration (also known as "next tick" in the Node/JS runtime lingo).
     */
    var TaskLoop = /*#__PURE__*/function () {
      function TaskLoop() {
        this._boundTick = void 0;
        this._tickTimer = null;
        this._tickInterval = null;
        this._tickCallCount = 0;
        this._boundTick = this.tick.bind(this);
      }

      var _proto = TaskLoop.prototype;

      _proto.destroy = function destroy() {
        this.onHandlerDestroying();
        this.onHandlerDestroyed();
      };

      _proto.onHandlerDestroying = function onHandlerDestroying() {
        // clear all timers before unregistering from event bus
        this.clearNextTick();
        this.clearInterval();
      };

      _proto.onHandlerDestroyed = function onHandlerDestroyed() {}
      /**
       * @returns {boolean}
       */
      ;

      _proto.hasInterval = function hasInterval() {
        return !!this._tickInterval;
      }
      /**
       * @returns {boolean}
       */
      ;

      _proto.hasNextTick = function hasNextTick() {
        return !!this._tickTimer;
      }
      /**
       * @param {number} millis Interval time (ms)
       * @returns {boolean} True when interval has been scheduled, false when already scheduled (no effect)
       */
      ;

      _proto.setInterval = function setInterval(millis) {
        if (!this._tickInterval) {
          this._tickInterval = self.setInterval(this._boundTick, millis);
          return true;
        }

        return false;
      }
      /**
       * @returns {boolean} True when interval was cleared, false when none was set (no effect)
       */
      ;

      _proto.clearInterval = function clearInterval() {
        if (this._tickInterval) {
          self.clearInterval(this._tickInterval);
          this._tickInterval = null;
          return true;
        }

        return false;
      }
      /**
       * @returns {boolean} True when timeout was cleared, false when none was set (no effect)
       */
      ;

      _proto.clearNextTick = function clearNextTick() {
        if (this._tickTimer) {
          self.clearTimeout(this._tickTimer);
          this._tickTimer = null;
          return true;
        }

        return false;
      }
      /**
       * Will call the subclass doTick implementation in this main loop tick
       * or in the next one (via setTimeout(,0)) in case it has already been called
       * in this tick (in case this is a re-entrant call).
       */
      ;

      _proto.tick = function tick() {
        this._tickCallCount++;

        if (this._tickCallCount === 1) {
          this.doTick(); // re-entrant call to tick from previous doTick call stack
          // -> schedule a call on the next main loop iteration to process this task processing request

          if (this._tickCallCount > 1) {
            // make sure only one timer exists at any time at max
            this.tickImmediate();
          }

          this._tickCallCount = 0;
        }
      };

      _proto.tickImmediate = function tickImmediate() {
        this.clearNextTick();
        this._tickTimer = self.setTimeout(this._boundTick, 0);
      }
      /**
       * For subclass to implement task logic
       * @abstract
       */
      ;

      _proto.doTick = function doTick() {};

      return TaskLoop;
    }();



    /***/ }),

    /***/ "./src/types/cmcd.ts":
    /*!***************************!*\
      !*** ./src/types/cmcd.ts ***!
      \***************************/
    /*! exports provided: CMCDVersion, CMCDObjectType, CMCDStreamingFormat, CMCDStreamType */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CMCDVersion", function() { return CMCDVersion; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CMCDObjectType", function() { return CMCDObjectType; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CMCDStreamingFormat", function() { return CMCDStreamingFormat; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CMCDStreamType", function() { return CMCDStreamType; });
    /**
     * CMCD spec version
     */
    var CMCDVersion = 1;
    /**
     * CMCD Object Type
     */

    var CMCDObjectType;
    /**
     * CMCD Streaming Format
     */

    (function (CMCDObjectType) {
      CMCDObjectType["MANIFEST"] = "m";
      CMCDObjectType["AUDIO"] = "a";
      CMCDObjectType["VIDEO"] = "v";
      CMCDObjectType["MUXED"] = "av";
      CMCDObjectType["INIT"] = "i";
      CMCDObjectType["CAPTION"] = "c";
      CMCDObjectType["TIMED_TEXT"] = "tt";
      CMCDObjectType["KEY"] = "k";
      CMCDObjectType["OTHER"] = "o";
    })(CMCDObjectType || (CMCDObjectType = {}));

    var CMCDStreamingFormat;
    /**
     * CMCD Streaming Type
     */

    (function (CMCDStreamingFormat) {
      CMCDStreamingFormat["DASH"] = "d";
      CMCDStreamingFormat["HLS"] = "h";
      CMCDStreamingFormat["SMOOTH"] = "s";
      CMCDStreamingFormat["OTHER"] = "o";
    })(CMCDStreamingFormat || (CMCDStreamingFormat = {}));

    var CMCDStreamType;
    /**
     * CMCD Headers
     */

    (function (CMCDStreamType) {
      CMCDStreamType["VOD"] = "v";
      CMCDStreamType["LIVE"] = "l";
    })(CMCDStreamType || (CMCDStreamType = {}));

    /***/ }),

    /***/ "./src/types/level.ts":
    /*!****************************!*\
      !*** ./src/types/level.ts ***!
      \****************************/
    /*! exports provided: HlsSkip, getSkipValue, HlsUrlParameters, Level */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "HlsSkip", function() { return HlsSkip; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getSkipValue", function() { return getSkipValue; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "HlsUrlParameters", function() { return HlsUrlParameters; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Level", function() { return Level; });
    function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

    function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

    var HlsSkip;

    (function (HlsSkip) {
      HlsSkip["No"] = "";
      HlsSkip["Yes"] = "YES";
      HlsSkip["v2"] = "v2";
    })(HlsSkip || (HlsSkip = {}));

    function getSkipValue(details, msn) {
      var canSkipUntil = details.canSkipUntil,
          canSkipDateRanges = details.canSkipDateRanges,
          endSN = details.endSN;
      var snChangeGoal = msn !== undefined ? msn - endSN : 0;

      if (canSkipUntil && snChangeGoal < canSkipUntil) {
        if (canSkipDateRanges) {
          return HlsSkip.v2;
        }

        return HlsSkip.Yes;
      }

      return HlsSkip.No;
    }
    var HlsUrlParameters = /*#__PURE__*/function () {
      function HlsUrlParameters(msn, part, skip) {
        this.msn = void 0;
        this.part = void 0;
        this.skip = void 0;
        this.msn = msn;
        this.part = part;
        this.skip = skip;
      }

      var _proto = HlsUrlParameters.prototype;

      _proto.addDirectives = function addDirectives(uri) {
        var url = new self.URL(uri);

        if (this.msn !== undefined) {
          url.searchParams.set('_HLS_msn', this.msn.toString());
        }

        if (this.part !== undefined) {
          url.searchParams.set('_HLS_part', this.part.toString());
        }

        if (this.skip) {
          url.searchParams.set('_HLS_skip', this.skip);
        }

        return url.toString();
      };

      return HlsUrlParameters;
    }();
    var Level = /*#__PURE__*/function () {
      function Level(data) {
        this.attrs = void 0;
        this.audioCodec = void 0;
        this.bitrate = void 0;
        this.codecSet = void 0;
        this.height = void 0;
        this.id = void 0;
        this.name = void 0;
        this.videoCodec = void 0;
        this.width = void 0;
        this.unknownCodecs = void 0;
        this.audioGroupIds = void 0;
        this.details = void 0;
        this.fragmentError = 0;
        this.loadError = 0;
        this.loaded = void 0;
        this.realBitrate = 0;
        this.textGroupIds = void 0;
        this.url = void 0;
        this._urlId = 0;
        this.url = [data.url];
        this.attrs = data.attrs;
        this.bitrate = data.bitrate;

        if (data.details) {
          this.details = data.details;
        }

        this.id = data.id || 0;
        this.name = data.name;
        this.width = data.width || 0;
        this.height = data.height || 0;
        this.audioCodec = data.audioCodec;
        this.videoCodec = data.videoCodec;
        this.unknownCodecs = data.unknownCodecs;
        this.codecSet = [data.videoCodec, data.audioCodec].filter(function (c) {
          return c;
        }).join(',').replace(/\.[^.,]+/g, '');
      }

      _createClass(Level, [{
        key: "maxBitrate",
        get: function get() {
          return Math.max(this.realBitrate, this.bitrate);
        }
      }, {
        key: "uri",
        get: function get() {
          return this.url[this._urlId] || '';
        }
      }, {
        key: "urlId",
        get: function get() {
          return this._urlId;
        },
        set: function set(value) {
          var newValue = value % this.url.length;

          if (this._urlId !== newValue) {
            this.details = undefined;
            this._urlId = newValue;
          }
        }
      }]);

      return Level;
    }();

    /***/ }),

    /***/ "./src/types/loader.ts":
    /*!*****************************!*\
      !*** ./src/types/loader.ts ***!
      \*****************************/
    /*! exports provided: PlaylistContextType, PlaylistLevelType */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PlaylistContextType", function() { return PlaylistContextType; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PlaylistLevelType", function() { return PlaylistLevelType; });
    var PlaylistContextType;

    (function (PlaylistContextType) {
      PlaylistContextType["MANIFEST"] = "manifest";
      PlaylistContextType["LEVEL"] = "level";
      PlaylistContextType["AUDIO_TRACK"] = "audioTrack";
      PlaylistContextType["SUBTITLE_TRACK"] = "subtitleTrack";
    })(PlaylistContextType || (PlaylistContextType = {}));

    var PlaylistLevelType;

    (function (PlaylistLevelType) {
      PlaylistLevelType["MAIN"] = "main";
      PlaylistLevelType["AUDIO"] = "audio";
      PlaylistLevelType["SUBTITLE"] = "subtitle";
    })(PlaylistLevelType || (PlaylistLevelType = {}));

    /***/ }),

    /***/ "./src/types/transmuxer.ts":
    /*!*********************************!*\
      !*** ./src/types/transmuxer.ts ***!
      \*********************************/
    /*! exports provided: ChunkMetadata */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ChunkMetadata", function() { return ChunkMetadata; });
    var ChunkMetadata = function ChunkMetadata(level, sn, id, size, part, partial) {
      if (size === void 0) {
        size = 0;
      }

      if (part === void 0) {
        part = -1;
      }

      if (partial === void 0) {
        partial = false;
      }

      this.level = void 0;
      this.sn = void 0;
      this.part = void 0;
      this.id = void 0;
      this.size = void 0;
      this.partial = void 0;
      this.transmuxing = getNewPerformanceTiming();
      this.buffering = {
        audio: getNewPerformanceTiming(),
        video: getNewPerformanceTiming(),
        audiovideo: getNewPerformanceTiming()
      };
      this.level = level;
      this.sn = sn;
      this.id = id;
      this.size = size;
      this.part = part;
      this.partial = partial;
    };

    function getNewPerformanceTiming() {
      return {
        start: 0,
        executeStart: 0,
        executeEnd: 0,
        end: 0
      };
    }

    /***/ }),

    /***/ "./src/utils/attr-list.ts":
    /*!********************************!*\
      !*** ./src/utils/attr-list.ts ***!
      \********************************/
    /*! exports provided: AttrList */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AttrList", function() { return AttrList; });
    var DECIMAL_RESOLUTION_REGEX = /^(\d+)x(\d+)$/; // eslint-disable-line no-useless-escape

    var ATTR_LIST_REGEX = /\s*(.+?)\s*=((?:\".*?\")|.*?)(?:,|$)/g; // eslint-disable-line no-useless-escape
    // adapted from https://github.com/kanongil/node-m3u8parse/blob/master/attrlist.js

    var AttrList = /*#__PURE__*/function () {
      function AttrList(attrs) {
        if (typeof attrs === 'string') {
          attrs = AttrList.parseAttrList(attrs);
        }

        for (var attr in attrs) {
          if (attrs.hasOwnProperty(attr)) {
            this[attr] = attrs[attr];
          }
        }
      }

      var _proto = AttrList.prototype;

      _proto.decimalInteger = function decimalInteger(attrName) {
        var intValue = parseInt(this[attrName], 10);

        if (intValue > Number.MAX_SAFE_INTEGER) {
          return Infinity;
        }

        return intValue;
      };

      _proto.hexadecimalInteger = function hexadecimalInteger(attrName) {
        if (this[attrName]) {
          var stringValue = (this[attrName] || '0x').slice(2);
          stringValue = (stringValue.length & 1 ? '0' : '') + stringValue;
          var value = new Uint8Array(stringValue.length / 2);

          for (var i = 0; i < stringValue.length / 2; i++) {
            value[i] = parseInt(stringValue.slice(i * 2, i * 2 + 2), 16);
          }

          return value;
        } else {
          return null;
        }
      };

      _proto.hexadecimalIntegerAsNumber = function hexadecimalIntegerAsNumber(attrName) {
        var intValue = parseInt(this[attrName], 16);

        if (intValue > Number.MAX_SAFE_INTEGER) {
          return Infinity;
        }

        return intValue;
      };

      _proto.decimalFloatingPoint = function decimalFloatingPoint(attrName) {
        return parseFloat(this[attrName]);
      };

      _proto.optionalFloat = function optionalFloat(attrName, defaultValue) {
        var value = this[attrName];
        return value ? parseFloat(value) : defaultValue;
      };

      _proto.enumeratedString = function enumeratedString(attrName) {
        return this[attrName];
      };

      _proto.bool = function bool(attrName) {
        return this[attrName] === 'YES';
      };

      _proto.decimalResolution = function decimalResolution(attrName) {
        var res = DECIMAL_RESOLUTION_REGEX.exec(this[attrName]);

        if (res === null) {
          return undefined;
        }

        return {
          width: parseInt(res[1], 10),
          height: parseInt(res[2], 10)
        };
      };

      AttrList.parseAttrList = function parseAttrList(input) {
        var match;
        var attrs = {};
        var quote = '"';
        ATTR_LIST_REGEX.lastIndex = 0;

        while ((match = ATTR_LIST_REGEX.exec(input)) !== null) {
          var value = match[2];

          if (value.indexOf(quote) === 0 && value.lastIndexOf(quote) === value.length - 1) {
            value = value.slice(1, -1);
          }

          attrs[match[1]] = value;
        }

        return attrs;
      };

      return AttrList;
    }();

    /***/ }),

    /***/ "./src/utils/binary-search.ts":
    /*!************************************!*\
      !*** ./src/utils/binary-search.ts ***!
      \************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    var BinarySearch = {
      /**
       * Searches for an item in an array which matches a certain condition.
       * This requires the condition to only match one item in the array,
       * and for the array to be ordered.
       *
       * @param {Array<T>} list The array to search.
       * @param {BinarySearchComparison<T>} comparisonFn
       *      Called and provided a candidate item as the first argument.
       *      Should return:
       *          > -1 if the item should be located at a lower index than the provided item.
       *          > 1 if the item should be located at a higher index than the provided item.
       *          > 0 if the item is the item you're looking for.
       *
       * @return {T | null} The object if it is found or null otherwise.
       */
      search: function search(list, comparisonFn) {
        var minIndex = 0;
        var maxIndex = list.length - 1;
        var currentIndex = null;
        var currentElement = null;

        while (minIndex <= maxIndex) {
          currentIndex = (minIndex + maxIndex) / 2 | 0;
          currentElement = list[currentIndex];
          var comparisonResult = comparisonFn(currentElement);

          if (comparisonResult > 0) {
            minIndex = currentIndex + 1;
          } else if (comparisonResult < 0) {
            maxIndex = currentIndex - 1;
          } else {
            return currentElement;
          }
        }

        return null;
      }
    };
    /* harmony default export */ __webpack_exports__["default"] = (BinarySearch);

    /***/ }),

    /***/ "./src/utils/buffer-helper.ts":
    /*!************************************!*\
      !*** ./src/utils/buffer-helper.ts ***!
      \************************************/
    /*! exports provided: BufferHelper */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "BufferHelper", function() { return BufferHelper; });
    /* harmony import */ var _logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./logger */ "./src/utils/logger.ts");
    /**
     * @module BufferHelper
     *
     * Providing methods dealing with buffer length retrieval for example.
     *
     * In general, a helper around HTML5 MediaElement TimeRanges gathered from `buffered` property.
     *
     * Also @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/buffered
     */

    var noopBuffered = {
      length: 0,
      start: function start() {
        return 0;
      },
      end: function end() {
        return 0;
      }
    };
    var BufferHelper = /*#__PURE__*/function () {
      function BufferHelper() {}

      /**
       * Return true if `media`'s buffered include `position`
       * @param {Bufferable} media
       * @param {number} position
       * @returns {boolean}
       */
      BufferHelper.isBuffered = function isBuffered(media, position) {
        try {
          if (media) {
            var buffered = BufferHelper.getBuffered(media);

            for (var i = 0; i < buffered.length; i++) {
              if (position >= buffered.start(i) && position <= buffered.end(i)) {
                return true;
              }
            }
          }
        } catch (error) {// this is to catch
          // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':
          // This SourceBuffer has been removed from the parent media source
        }

        return false;
      };

      BufferHelper.bufferInfo = function bufferInfo(media, pos, maxHoleDuration) {
        try {
          if (media) {
            var vbuffered = BufferHelper.getBuffered(media);
            var buffered = [];
            var i;

            for (i = 0; i < vbuffered.length; i++) {
              buffered.push({
                start: vbuffered.start(i),
                end: vbuffered.end(i)
              });
            }

            return this.bufferedInfo(buffered, pos, maxHoleDuration);
          }
        } catch (error) {// this is to catch
          // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':
          // This SourceBuffer has been removed from the parent media source
        }

        return {
          len: 0,
          start: pos,
          end: pos,
          nextStart: undefined
        };
      };

      BufferHelper.bufferedInfo = function bufferedInfo(buffered, pos, maxHoleDuration) {
        pos = Math.max(0, pos); // sort on buffer.start/smaller end (IE does not always return sorted buffered range)

        buffered.sort(function (a, b) {
          var diff = a.start - b.start;

          if (diff) {
            return diff;
          } else {
            return b.end - a.end;
          }
        });
        var buffered2 = [];

        if (maxHoleDuration) {
          // there might be some small holes between buffer time range
          // consider that holes smaller than maxHoleDuration are irrelevant and build another
          // buffer time range representations that discards those holes
          for (var i = 0; i < buffered.length; i++) {
            var buf2len = buffered2.length;

            if (buf2len) {
              var buf2end = buffered2[buf2len - 1].end; // if small hole (value between 0 or maxHoleDuration ) or overlapping (negative)

              if (buffered[i].start - buf2end < maxHoleDuration) {
                // merge overlapping time ranges
                // update lastRange.end only if smaller than item.end
                // e.g.  [ 1, 15] with  [ 2,8] => [ 1,15] (no need to modify lastRange.end)
                // whereas [ 1, 8] with  [ 2,15] => [ 1,15] ( lastRange should switch from [1,8] to [1,15])
                if (buffered[i].end > buf2end) {
                  buffered2[buf2len - 1].end = buffered[i].end;
                }
              } else {
                // big hole
                buffered2.push(buffered[i]);
              }
            } else {
              // first value
              buffered2.push(buffered[i]);
            }
          }
        } else {
          buffered2 = buffered;
        }

        var bufferLen = 0; // bufferStartNext can possibly be undefined based on the conditional logic below

        var bufferStartNext; // bufferStart and bufferEnd are buffer boundaries around current video position

        var bufferStart = pos;
        var bufferEnd = pos;

        for (var _i = 0; _i < buffered2.length; _i++) {
          var start = buffered2[_i].start;
          var end = buffered2[_i].end; // logger.log('buf start/end:' + buffered.start(i) + '/' + buffered.end(i));

          if (pos + maxHoleDuration >= start && pos < end) {
            // play position is inside this buffer TimeRange, retrieve end of buffer position and buffer length
            bufferStart = start;
            bufferEnd = end;
            bufferLen = bufferEnd - pos;
          } else if (pos + maxHoleDuration < start) {
            bufferStartNext = start;
            break;
          }
        }

        return {
          len: bufferLen,
          start: bufferStart || 0,
          end: bufferEnd || 0,
          nextStart: bufferStartNext
        };
      }
      /**
       * Safe method to get buffered property.
       * SourceBuffer.buffered may throw if SourceBuffer is removed from it's MediaSource
       */
      ;

      BufferHelper.getBuffered = function getBuffered(media) {
        try {
          return media.buffered;
        } catch (e) {
          _logger__WEBPACK_IMPORTED_MODULE_0__["logger"].log('failed to get media.buffered', e);
          return noopBuffered;
        }
      };

      return BufferHelper;
    }();

    /***/ }),

    /***/ "./src/utils/cea-608-parser.ts":
    /*!*************************************!*\
      !*** ./src/utils/cea-608-parser.ts ***!
      \*************************************/
    /*! exports provided: Row, CaptionScreen, default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Row", function() { return Row; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CaptionScreen", function() { return CaptionScreen; });
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");

    /**
     *
     * This code was ported from the dash.js project at:
     *   https://github.com/Dash-Industry-Forum/dash.js/blob/development/externals/cea608-parser.js
     *   https://github.com/Dash-Industry-Forum/dash.js/commit/8269b26a761e0853bb21d78780ed945144ecdd4d#diff-71bc295a2d6b6b7093a1d3290d53a4b2
     *
     * The original copyright appears below:
     *
     * The copyright in this software is being made available under the BSD License,
     * included below. This software may be subject to other third party and contributor
     * rights, including patent rights, and no such rights are granted under this license.
     *
     * Copyright (c) 2015-2016, DASH Industry Forum.
     * All rights reserved.
     *
     * Redistribution and use in source and binary forms, with or without modification,
     * are permitted provided that the following conditions are met:
     *  1. Redistributions of source code must retain the above copyright notice, this
     *  list of conditions and the following disclaimer.
     *  * Redistributions in binary form must reproduce the above copyright notice,
     *  this list of conditions and the following disclaimer in the documentation and/or
     *  other materials provided with the distribution.
     *  2. Neither the name of Dash Industry Forum nor the names of its
     *  contributors may be used to endorse or promote products derived from this software
     *  without specific prior written permission.
     *
     *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS AS IS AND ANY
     *  EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
     *  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
     *  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
     *  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
     *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
     *  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
     *  WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
     *  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
     *  POSSIBILITY OF SUCH DAMAGE.
     */

    /**
     *  Exceptions from regular ASCII. CodePoints are mapped to UTF-16 codes
     */

    var specialCea608CharsCodes = {
      0x2a: 0xe1,
      // lowercase a, acute accent
      0x5c: 0xe9,
      // lowercase e, acute accent
      0x5e: 0xed,
      // lowercase i, acute accent
      0x5f: 0xf3,
      // lowercase o, acute accent
      0x60: 0xfa,
      // lowercase u, acute accent
      0x7b: 0xe7,
      // lowercase c with cedilla
      0x7c: 0xf7,
      // division symbol
      0x7d: 0xd1,
      // uppercase N tilde
      0x7e: 0xf1,
      // lowercase n tilde
      0x7f: 0x2588,
      // Full block
      // THIS BLOCK INCLUDES THE 16 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS
      // THAT COME FROM HI BYTE=0x11 AND LOW BETWEEN 0x30 AND 0x3F
      // THIS MEANS THAT \x50 MUST BE ADDED TO THE VALUES
      0x80: 0xae,
      // Registered symbol (R)
      0x81: 0xb0,
      // degree sign
      0x82: 0xbd,
      // 1/2 symbol
      0x83: 0xbf,
      // Inverted (open) question mark
      0x84: 0x2122,
      // Trademark symbol (TM)
      0x85: 0xa2,
      // Cents symbol
      0x86: 0xa3,
      // Pounds sterling
      0x87: 0x266a,
      // Music 8'th note
      0x88: 0xe0,
      // lowercase a, grave accent
      0x89: 0x20,
      // transparent space (regular)
      0x8a: 0xe8,
      // lowercase e, grave accent
      0x8b: 0xe2,
      // lowercase a, circumflex accent
      0x8c: 0xea,
      // lowercase e, circumflex accent
      0x8d: 0xee,
      // lowercase i, circumflex accent
      0x8e: 0xf4,
      // lowercase o, circumflex accent
      0x8f: 0xfb,
      // lowercase u, circumflex accent
      // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS
      // THAT COME FROM HI BYTE=0x12 AND LOW BETWEEN 0x20 AND 0x3F
      0x90: 0xc1,
      // capital letter A with acute
      0x91: 0xc9,
      // capital letter E with acute
      0x92: 0xd3,
      // capital letter O with acute
      0x93: 0xda,
      // capital letter U with acute
      0x94: 0xdc,
      // capital letter U with diaresis
      0x95: 0xfc,
      // lowercase letter U with diaeresis
      0x96: 0x2018,
      // opening single quote
      0x97: 0xa1,
      // inverted exclamation mark
      0x98: 0x2a,
      // asterisk
      0x99: 0x2019,
      // closing single quote
      0x9a: 0x2501,
      // box drawings heavy horizontal
      0x9b: 0xa9,
      // copyright sign
      0x9c: 0x2120,
      // Service mark
      0x9d: 0x2022,
      // (round) bullet
      0x9e: 0x201c,
      // Left double quotation mark
      0x9f: 0x201d,
      // Right double quotation mark
      0xa0: 0xc0,
      // uppercase A, grave accent
      0xa1: 0xc2,
      // uppercase A, circumflex
      0xa2: 0xc7,
      // uppercase C with cedilla
      0xa3: 0xc8,
      // uppercase E, grave accent
      0xa4: 0xca,
      // uppercase E, circumflex
      0xa5: 0xcb,
      // capital letter E with diaresis
      0xa6: 0xeb,
      // lowercase letter e with diaresis
      0xa7: 0xce,
      // uppercase I, circumflex
      0xa8: 0xcf,
      // uppercase I, with diaresis
      0xa9: 0xef,
      // lowercase i, with diaresis
      0xaa: 0xd4,
      // uppercase O, circumflex
      0xab: 0xd9,
      // uppercase U, grave accent
      0xac: 0xf9,
      // lowercase u, grave accent
      0xad: 0xdb,
      // uppercase U, circumflex
      0xae: 0xab,
      // left-pointing double angle quotation mark
      0xaf: 0xbb,
      // right-pointing double angle quotation mark
      // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS
      // THAT COME FROM HI BYTE=0x13 AND LOW BETWEEN 0x20 AND 0x3F
      0xb0: 0xc3,
      // Uppercase A, tilde
      0xb1: 0xe3,
      // Lowercase a, tilde
      0xb2: 0xcd,
      // Uppercase I, acute accent
      0xb3: 0xcc,
      // Uppercase I, grave accent
      0xb4: 0xec,
      // Lowercase i, grave accent
      0xb5: 0xd2,
      // Uppercase O, grave accent
      0xb6: 0xf2,
      // Lowercase o, grave accent
      0xb7: 0xd5,
      // Uppercase O, tilde
      0xb8: 0xf5,
      // Lowercase o, tilde
      0xb9: 0x7b,
      // Open curly brace
      0xba: 0x7d,
      // Closing curly brace
      0xbb: 0x5c,
      // Backslash
      0xbc: 0x5e,
      // Caret
      0xbd: 0x5f,
      // Underscore
      0xbe: 0x7c,
      // Pipe (vertical line)
      0xbf: 0x223c,
      // Tilde operator
      0xc0: 0xc4,
      // Uppercase A, umlaut
      0xc1: 0xe4,
      // Lowercase A, umlaut
      0xc2: 0xd6,
      // Uppercase O, umlaut
      0xc3: 0xf6,
      // Lowercase o, umlaut
      0xc4: 0xdf,
      // Esszett (sharp S)
      0xc5: 0xa5,
      // Yen symbol
      0xc6: 0xa4,
      // Generic currency sign
      0xc7: 0x2503,
      // Box drawings heavy vertical
      0xc8: 0xc5,
      // Uppercase A, ring
      0xc9: 0xe5,
      // Lowercase A, ring
      0xca: 0xd8,
      // Uppercase O, stroke
      0xcb: 0xf8,
      // Lowercase o, strok
      0xcc: 0x250f,
      // Box drawings heavy down and right
      0xcd: 0x2513,
      // Box drawings heavy down and left
      0xce: 0x2517,
      // Box drawings heavy up and right
      0xcf: 0x251b // Box drawings heavy up and left

    };
    /**
     * Utils
     */

    var getCharForByte = function getCharForByte(_byte) {
      var charCode = _byte;

      if (specialCea608CharsCodes.hasOwnProperty(_byte)) {
        charCode = specialCea608CharsCodes[_byte];
      }

      return String.fromCharCode(charCode);
    };

    var NR_ROWS = 15;
    var NR_COLS = 100; // Tables to look up row from PAC data

    var rowsLowCh1 = {
      0x11: 1,
      0x12: 3,
      0x15: 5,
      0x16: 7,
      0x17: 9,
      0x10: 11,
      0x13: 12,
      0x14: 14
    };
    var rowsHighCh1 = {
      0x11: 2,
      0x12: 4,
      0x15: 6,
      0x16: 8,
      0x17: 10,
      0x13: 13,
      0x14: 15
    };
    var rowsLowCh2 = {
      0x19: 1,
      0x1a: 3,
      0x1d: 5,
      0x1e: 7,
      0x1f: 9,
      0x18: 11,
      0x1b: 12,
      0x1c: 14
    };
    var rowsHighCh2 = {
      0x19: 2,
      0x1a: 4,
      0x1d: 6,
      0x1e: 8,
      0x1f: 10,
      0x1b: 13,
      0x1c: 15
    };
    var backgroundColors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'black', 'transparent'];
    var VerboseLevel;

    (function (VerboseLevel) {
      VerboseLevel[VerboseLevel["ERROR"] = 0] = "ERROR";
      VerboseLevel[VerboseLevel["TEXT"] = 1] = "TEXT";
      VerboseLevel[VerboseLevel["WARNING"] = 2] = "WARNING";
      VerboseLevel[VerboseLevel["INFO"] = 2] = "INFO";
      VerboseLevel[VerboseLevel["DEBUG"] = 3] = "DEBUG";
      VerboseLevel[VerboseLevel["DATA"] = 3] = "DATA";
    })(VerboseLevel || (VerboseLevel = {}));

    var CaptionsLogger = /*#__PURE__*/function () {
      function CaptionsLogger() {
        this.time = null;
        this.verboseLevel = VerboseLevel.ERROR;
      }

      var _proto = CaptionsLogger.prototype;

      _proto.log = function log(severity, msg) {
        if (this.verboseLevel >= severity) {
          _utils_logger__WEBPACK_IMPORTED_MODULE_0__["logger"].log(this.time + " [" + severity + "] " + msg);
        }
      };

      return CaptionsLogger;
    }();

    var numArrayToHexArray = function numArrayToHexArray(numArray) {
      var hexArray = [];

      for (var j = 0; j < numArray.length; j++) {
        hexArray.push(numArray[j].toString(16));
      }

      return hexArray;
    };

    var PenState = /*#__PURE__*/function () {
      function PenState(foreground, underline, italics, background, flash) {
        this.foreground = void 0;
        this.underline = void 0;
        this.italics = void 0;
        this.background = void 0;
        this.flash = void 0;
        this.foreground = foreground || 'white';
        this.underline = underline || false;
        this.italics = italics || false;
        this.background = background || 'black';
        this.flash = flash || false;
      }

      var _proto2 = PenState.prototype;

      _proto2.reset = function reset() {
        this.foreground = 'white';
        this.underline = false;
        this.italics = false;
        this.background = 'black';
        this.flash = false;
      };

      _proto2.setStyles = function setStyles(styles) {
        var attribs = ['foreground', 'underline', 'italics', 'background', 'flash'];

        for (var i = 0; i < attribs.length; i++) {
          var style = attribs[i];

          if (styles.hasOwnProperty(style)) {
            this[style] = styles[style];
          }
        }
      };

      _proto2.isDefault = function isDefault() {
        return this.foreground === 'white' && !this.underline && !this.italics && this.background === 'black' && !this.flash;
      };

      _proto2.equals = function equals(other) {
        return this.foreground === other.foreground && this.underline === other.underline && this.italics === other.italics && this.background === other.background && this.flash === other.flash;
      };

      _proto2.copy = function copy(newPenState) {
        this.foreground = newPenState.foreground;
        this.underline = newPenState.underline;
        this.italics = newPenState.italics;
        this.background = newPenState.background;
        this.flash = newPenState.flash;
      };

      _proto2.toString = function toString() {
        return 'color=' + this.foreground + ', underline=' + this.underline + ', italics=' + this.italics + ', background=' + this.background + ', flash=' + this.flash;
      };

      return PenState;
    }();
    /**
     * Unicode character with styling and background.
     * @constructor
     */


    var StyledUnicodeChar = /*#__PURE__*/function () {
      function StyledUnicodeChar(uchar, foreground, underline, italics, background, flash) {
        this.uchar = void 0;
        this.penState = void 0;
        this.uchar = uchar || ' '; // unicode character

        this.penState = new PenState(foreground, underline, italics, background, flash);
      }

      var _proto3 = StyledUnicodeChar.prototype;

      _proto3.reset = function reset() {
        this.uchar = ' ';
        this.penState.reset();
      };

      _proto3.setChar = function setChar(uchar, newPenState) {
        this.uchar = uchar;
        this.penState.copy(newPenState);
      };

      _proto3.setPenState = function setPenState(newPenState) {
        this.penState.copy(newPenState);
      };

      _proto3.equals = function equals(other) {
        return this.uchar === other.uchar && this.penState.equals(other.penState);
      };

      _proto3.copy = function copy(newChar) {
        this.uchar = newChar.uchar;
        this.penState.copy(newChar.penState);
      };

      _proto3.isEmpty = function isEmpty() {
        return this.uchar === ' ' && this.penState.isDefault();
      };

      return StyledUnicodeChar;
    }();
    /**
     * CEA-608 row consisting of NR_COLS instances of StyledUnicodeChar.
     * @constructor
     */


    var Row = /*#__PURE__*/function () {
      function Row(logger) {
        this.chars = void 0;
        this.pos = void 0;
        this.currPenState = void 0;
        this.cueStartTime = void 0;
        this.logger = void 0;
        this.chars = [];

        for (var i = 0; i < NR_COLS; i++) {
          this.chars.push(new StyledUnicodeChar());
        }

        this.logger = logger;
        this.pos = 0;
        this.currPenState = new PenState();
      }

      var _proto4 = Row.prototype;

      _proto4.equals = function equals(other) {
        var equal = true;

        for (var i = 0; i < NR_COLS; i++) {
          if (!this.chars[i].equals(other.chars[i])) {
            equal = false;
            break;
          }
        }

        return equal;
      };

      _proto4.copy = function copy(other) {
        for (var i = 0; i < NR_COLS; i++) {
          this.chars[i].copy(other.chars[i]);
        }
      };

      _proto4.isEmpty = function isEmpty() {
        var empty = true;

        for (var i = 0; i < NR_COLS; i++) {
          if (!this.chars[i].isEmpty()) {
            empty = false;
            break;
          }
        }

        return empty;
      }
      /**
       *  Set the cursor to a valid column.
       */
      ;

      _proto4.setCursor = function setCursor(absPos) {
        if (this.pos !== absPos) {
          this.pos = absPos;
        }

        if (this.pos < 0) {
          this.logger.log(VerboseLevel.DEBUG, 'Negative cursor position ' + this.pos);
          this.pos = 0;
        } else if (this.pos > NR_COLS) {
          this.logger.log(VerboseLevel.DEBUG, 'Too large cursor position ' + this.pos);
          this.pos = NR_COLS;
        }
      }
      /**
       * Move the cursor relative to current position.
       */
      ;

      _proto4.moveCursor = function moveCursor(relPos) {
        var newPos = this.pos + relPos;

        if (relPos > 1) {
          for (var i = this.pos + 1; i < newPos + 1; i++) {
            this.chars[i].setPenState(this.currPenState);
          }
        }

        this.setCursor(newPos);
      }
      /**
       * Backspace, move one step back and clear character.
       */
      ;

      _proto4.backSpace = function backSpace() {
        this.moveCursor(-1);
        this.chars[this.pos].setChar(' ', this.currPenState);
      };

      _proto4.insertChar = function insertChar(_byte2) {
        if (_byte2 >= 0x90) {
          // Extended char
          this.backSpace();
        }

        var _char = getCharForByte(_byte2);

        if (this.pos >= NR_COLS) {
          this.logger.log(VerboseLevel.ERROR, 'Cannot insert ' + _byte2.toString(16) + ' (' + _char + ') at position ' + this.pos + '. Skipping it!');
          return;
        }

        this.chars[this.pos].setChar(_char, this.currPenState);
        this.moveCursor(1);
      };

      _proto4.clearFromPos = function clearFromPos(startPos) {
        var i;

        for (i = startPos; i < NR_COLS; i++) {
          this.chars[i].reset();
        }
      };

      _proto4.clear = function clear() {
        this.clearFromPos(0);
        this.pos = 0;
        this.currPenState.reset();
      };

      _proto4.clearToEndOfRow = function clearToEndOfRow() {
        this.clearFromPos(this.pos);
      };

      _proto4.getTextString = function getTextString() {
        var chars = [];
        var empty = true;

        for (var i = 0; i < NR_COLS; i++) {
          var _char2 = this.chars[i].uchar;

          if (_char2 !== ' ') {
            empty = false;
          }

          chars.push(_char2);
        }

        if (empty) {
          return '';
        } else {
          return chars.join('');
        }
      };

      _proto4.setPenStyles = function setPenStyles(styles) {
        this.currPenState.setStyles(styles);
        var currChar = this.chars[this.pos];
        currChar.setPenState(this.currPenState);
      };

      return Row;
    }();
    /**
     * Keep a CEA-608 screen of 32x15 styled characters
     * @constructor
     */

    var CaptionScreen = /*#__PURE__*/function () {
      function CaptionScreen(logger) {
        this.rows = void 0;
        this.currRow = void 0;
        this.nrRollUpRows = void 0;
        this.lastOutputScreen = void 0;
        this.logger = void 0;
        this.rows = [];

        for (var i = 0; i < NR_ROWS; i++) {
          this.rows.push(new Row(logger));
        } // Note that we use zero-based numbering (0-14)


        this.logger = logger;
        this.currRow = NR_ROWS - 1;
        this.nrRollUpRows = null;
        this.lastOutputScreen = null;
        this.reset();
      }

      var _proto5 = CaptionScreen.prototype;

      _proto5.reset = function reset() {
        for (var i = 0; i < NR_ROWS; i++) {
          this.rows[i].clear();
        }

        this.currRow = NR_ROWS - 1;
      };

      _proto5.equals = function equals(other) {
        var equal = true;

        for (var i = 0; i < NR_ROWS; i++) {
          if (!this.rows[i].equals(other.rows[i])) {
            equal = false;
            break;
          }
        }

        return equal;
      };

      _proto5.copy = function copy(other) {
        for (var i = 0; i < NR_ROWS; i++) {
          this.rows[i].copy(other.rows[i]);
        }
      };

      _proto5.isEmpty = function isEmpty() {
        var empty = true;

        for (var i = 0; i < NR_ROWS; i++) {
          if (!this.rows[i].isEmpty()) {
            empty = false;
            break;
          }
        }

        return empty;
      };

      _proto5.backSpace = function backSpace() {
        var row = this.rows[this.currRow];
        row.backSpace();
      };

      _proto5.clearToEndOfRow = function clearToEndOfRow() {
        var row = this.rows[this.currRow];
        row.clearToEndOfRow();
      }
      /**
       * Insert a character (without styling) in the current row.
       */
      ;

      _proto5.insertChar = function insertChar(_char3) {
        var row = this.rows[this.currRow];
        row.insertChar(_char3);
      };

      _proto5.setPen = function setPen(styles) {
        var row = this.rows[this.currRow];
        row.setPenStyles(styles);
      };

      _proto5.moveCursor = function moveCursor(relPos) {
        var row = this.rows[this.currRow];
        row.moveCursor(relPos);
      };

      _proto5.setCursor = function setCursor(absPos) {
        this.logger.log(VerboseLevel.INFO, 'setCursor: ' + absPos);
        var row = this.rows[this.currRow];
        row.setCursor(absPos);
      };

      _proto5.setPAC = function setPAC(pacData) {
        this.logger.log(VerboseLevel.INFO, 'pacData = ' + JSON.stringify(pacData));
        var newRow = pacData.row - 1;

        if (this.nrRollUpRows && newRow < this.nrRollUpRows - 1) {
          newRow = this.nrRollUpRows - 1;
        } // Make sure this only affects Roll-up Captions by checking this.nrRollUpRows


        if (this.nrRollUpRows && this.currRow !== newRow) {
          // clear all rows first
          for (var i = 0; i < NR_ROWS; i++) {
            this.rows[i].clear();
          } // Copy this.nrRollUpRows rows from lastOutputScreen and place it in the newRow location
          // topRowIndex - the start of rows to copy (inclusive index)


          var topRowIndex = this.currRow + 1 - this.nrRollUpRows; // We only copy if the last position was already shown.
          // We use the cueStartTime value to check this.

          var lastOutputScreen = this.lastOutputScreen;

          if (lastOutputScreen) {
            var prevLineTime = lastOutputScreen.rows[topRowIndex].cueStartTime;
            var time = this.logger.time;

            if (prevLineTime && time !== null && prevLineTime < time) {
              for (var _i = 0; _i < this.nrRollUpRows; _i++) {
                this.rows[newRow - this.nrRollUpRows + _i + 1].copy(lastOutputScreen.rows[topRowIndex + _i]);
              }
            }
          }
        }

        this.currRow = newRow;
        var row = this.rows[this.currRow];

        if (pacData.indent !== null) {
          var indent = pacData.indent;
          var prevPos = Math.max(indent - 1, 0);
          row.setCursor(pacData.indent);
          pacData.color = row.chars[prevPos].penState.foreground;
        }

        var styles = {
          foreground: pacData.color,
          underline: pacData.underline,
          italics: pacData.italics,
          background: 'black',
          flash: false
        };
        this.setPen(styles);
      }
      /**
       * Set background/extra foreground, but first do back_space, and then insert space (backwards compatibility).
       */
      ;

      _proto5.setBkgData = function setBkgData(bkgData) {
        this.logger.log(VerboseLevel.INFO, 'bkgData = ' + JSON.stringify(bkgData));
        this.backSpace();
        this.setPen(bkgData);
        this.insertChar(0x20); // Space
      };

      _proto5.setRollUpRows = function setRollUpRows(nrRows) {
        this.nrRollUpRows = nrRows;
      };

      _proto5.rollUp = function rollUp() {
        if (this.nrRollUpRows === null) {
          this.logger.log(VerboseLevel.DEBUG, 'roll_up but nrRollUpRows not set yet');
          return; // Not properly setup
        }

        this.logger.log(VerboseLevel.TEXT, this.getDisplayText());
        var topRowIndex = this.currRow + 1 - this.nrRollUpRows;
        var topRow = this.rows.splice(topRowIndex, 1)[0];
        topRow.clear();
        this.rows.splice(this.currRow, 0, topRow);
        this.logger.log(VerboseLevel.INFO, 'Rolling up'); // this.logger.log(VerboseLevel.TEXT, this.get_display_text())
      }
      /**
       * Get all non-empty rows with as unicode text.
       */
      ;

      _proto5.getDisplayText = function getDisplayText(asOneRow) {
        asOneRow = asOneRow || false;
        var displayText = [];
        var text = '';
        var rowNr = -1;

        for (var i = 0; i < NR_ROWS; i++) {
          var rowText = this.rows[i].getTextString();

          if (rowText) {
            rowNr = i + 1;

            if (asOneRow) {
              displayText.push('Row ' + rowNr + ": '" + rowText + "'");
            } else {
              displayText.push(rowText.trim());
            }
          }
        }

        if (displayText.length > 0) {
          if (asOneRow) {
            text = '[' + displayText.join(' | ') + ']';
          } else {
            text = displayText.join('\n');
          }
        }

        return text;
      };

      _proto5.getTextAndFormat = function getTextAndFormat() {
        return this.rows;
      };

      return CaptionScreen;
    }(); // var modes = ['MODE_ROLL-UP', 'MODE_POP-ON', 'MODE_PAINT-ON', 'MODE_TEXT'];

    var Cea608Channel = /*#__PURE__*/function () {
      function Cea608Channel(channelNumber, outputFilter, logger) {
        this.chNr = void 0;
        this.outputFilter = void 0;
        this.mode = void 0;
        this.verbose = void 0;
        this.displayedMemory = void 0;
        this.nonDisplayedMemory = void 0;
        this.lastOutputScreen = void 0;
        this.currRollUpRow = void 0;
        this.writeScreen = void 0;
        this.cueStartTime = void 0;
        this.logger = void 0;
        this.chNr = channelNumber;
        this.outputFilter = outputFilter;
        this.mode = null;
        this.verbose = 0;
        this.displayedMemory = new CaptionScreen(logger);
        this.nonDisplayedMemory = new CaptionScreen(logger);
        this.lastOutputScreen = new CaptionScreen(logger);
        this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];
        this.writeScreen = this.displayedMemory;
        this.mode = null;
        this.cueStartTime = null; // Keeps track of where a cue started.

        this.logger = logger;
      }

      var _proto6 = Cea608Channel.prototype;

      _proto6.reset = function reset() {
        this.mode = null;
        this.displayedMemory.reset();
        this.nonDisplayedMemory.reset();
        this.lastOutputScreen.reset();
        this.outputFilter.reset();
        this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];
        this.writeScreen = this.displayedMemory;
        this.mode = null;
        this.cueStartTime = null;
      };

      _proto6.getHandler = function getHandler() {
        return this.outputFilter;
      };

      _proto6.setHandler = function setHandler(newHandler) {
        this.outputFilter = newHandler;
      };

      _proto6.setPAC = function setPAC(pacData) {
        this.writeScreen.setPAC(pacData);
      };

      _proto6.setBkgData = function setBkgData(bkgData) {
        this.writeScreen.setBkgData(bkgData);
      };

      _proto6.setMode = function setMode(newMode) {
        if (newMode === this.mode) {
          return;
        }

        this.mode = newMode;
        this.logger.log(VerboseLevel.INFO, 'MODE=' + newMode);

        if (this.mode === 'MODE_POP-ON') {
          this.writeScreen = this.nonDisplayedMemory;
        } else {
          this.writeScreen = this.displayedMemory;
          this.writeScreen.reset();
        }

        if (this.mode !== 'MODE_ROLL-UP') {
          this.displayedMemory.nrRollUpRows = null;
          this.nonDisplayedMemory.nrRollUpRows = null;
        }

        this.mode = newMode;
      };

      _proto6.insertChars = function insertChars(chars) {
        for (var i = 0; i < chars.length; i++) {
          this.writeScreen.insertChar(chars[i]);
        }

        var screen = this.writeScreen === this.displayedMemory ? 'DISP' : 'NON_DISP';
        this.logger.log(VerboseLevel.INFO, screen + ': ' + this.writeScreen.getDisplayText(true));

        if (this.mode === 'MODE_PAINT-ON' || this.mode === 'MODE_ROLL-UP') {
          this.logger.log(VerboseLevel.TEXT, 'DISPLAYED: ' + this.displayedMemory.getDisplayText(true));
          this.outputDataUpdate();
        }
      };

      _proto6.ccRCL = function ccRCL() {
        // Resume Caption Loading (switch mode to Pop On)
        this.logger.log(VerboseLevel.INFO, 'RCL - Resume Caption Loading');
        this.setMode('MODE_POP-ON');
      };

      _proto6.ccBS = function ccBS() {
        // BackSpace
        this.logger.log(VerboseLevel.INFO, 'BS - BackSpace');

        if (this.mode === 'MODE_TEXT') {
          return;
        }

        this.writeScreen.backSpace();

        if (this.writeScreen === this.displayedMemory) {
          this.outputDataUpdate();
        }
      };

      _proto6.ccAOF = function ccAOF() {// Reserved (formerly Alarm Off)
      };

      _proto6.ccAON = function ccAON() {// Reserved (formerly Alarm On)
      };

      _proto6.ccDER = function ccDER() {
        // Delete to End of Row
        this.logger.log(VerboseLevel.INFO, 'DER- Delete to End of Row');
        this.writeScreen.clearToEndOfRow();
        this.outputDataUpdate();
      };

      _proto6.ccRU = function ccRU(nrRows) {
        // Roll-Up Captions-2,3,or 4 Rows
        this.logger.log(VerboseLevel.INFO, 'RU(' + nrRows + ') - Roll Up');
        this.writeScreen = this.displayedMemory;
        this.setMode('MODE_ROLL-UP');
        this.writeScreen.setRollUpRows(nrRows);
      };

      _proto6.ccFON = function ccFON() {
        // Flash On
        this.logger.log(VerboseLevel.INFO, 'FON - Flash On');
        this.writeScreen.setPen({
          flash: true
        });
      };

      _proto6.ccRDC = function ccRDC() {
        // Resume Direct Captioning (switch mode to PaintOn)
        this.logger.log(VerboseLevel.INFO, 'RDC - Resume Direct Captioning');
        this.setMode('MODE_PAINT-ON');
      };

      _proto6.ccTR = function ccTR() {
        // Text Restart in text mode (not supported, however)
        this.logger.log(VerboseLevel.INFO, 'TR');
        this.setMode('MODE_TEXT');
      };

      _proto6.ccRTD = function ccRTD() {
        // Resume Text Display in Text mode (not supported, however)
        this.logger.log(VerboseLevel.INFO, 'RTD');
        this.setMode('MODE_TEXT');
      };

      _proto6.ccEDM = function ccEDM() {
        // Erase Displayed Memory
        this.logger.log(VerboseLevel.INFO, 'EDM - Erase Displayed Memory');
        this.displayedMemory.reset();
        this.outputDataUpdate(true);
      };

      _proto6.ccCR = function ccCR() {
        // Carriage Return
        this.logger.log(VerboseLevel.INFO, 'CR - Carriage Return');
        this.writeScreen.rollUp();
        this.outputDataUpdate(true);
      };

      _proto6.ccENM = function ccENM() {
        // Erase Non-Displayed Memory
        this.logger.log(VerboseLevel.INFO, 'ENM - Erase Non-displayed Memory');
        this.nonDisplayedMemory.reset();
      };

      _proto6.ccEOC = function ccEOC() {
        // End of Caption (Flip Memories)
        this.logger.log(VerboseLevel.INFO, 'EOC - End Of Caption');

        if (this.mode === 'MODE_POP-ON') {
          var tmp = this.displayedMemory;
          this.displayedMemory = this.nonDisplayedMemory;
          this.nonDisplayedMemory = tmp;
          this.writeScreen = this.nonDisplayedMemory;
          this.logger.log(VerboseLevel.TEXT, 'DISP: ' + this.displayedMemory.getDisplayText());
        }

        this.outputDataUpdate(true);
      };

      _proto6.ccTO = function ccTO(nrCols) {
        // Tab Offset 1,2, or 3 columns
        this.logger.log(VerboseLevel.INFO, 'TO(' + nrCols + ') - Tab Offset');
        this.writeScreen.moveCursor(nrCols);
      };

      _proto6.ccMIDROW = function ccMIDROW(secondByte) {
        // Parse MIDROW command
        var styles = {
          flash: false
        };
        styles.underline = secondByte % 2 === 1;
        styles.italics = secondByte >= 0x2e;

        if (!styles.italics) {
          var colorIndex = Math.floor(secondByte / 2) - 0x10;
          var colors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta'];
          styles.foreground = colors[colorIndex];
        } else {
          styles.foreground = 'white';
        }

        this.logger.log(VerboseLevel.INFO, 'MIDROW: ' + JSON.stringify(styles));
        this.writeScreen.setPen(styles);
      };

      _proto6.outputDataUpdate = function outputDataUpdate(dispatch) {
        if (dispatch === void 0) {
          dispatch = false;
        }

        var time = this.logger.time;

        if (time === null) {
          return;
        }

        if (this.outputFilter) {
          if (this.cueStartTime === null && !this.displayedMemory.isEmpty()) {
            // Start of a new cue
            this.cueStartTime = time;
          } else {
            if (!this.displayedMemory.equals(this.lastOutputScreen)) {
              this.outputFilter.newCue(this.cueStartTime, time, this.lastOutputScreen);

              if (dispatch && this.outputFilter.dispatchCue) {
                this.outputFilter.dispatchCue();
              }

              this.cueStartTime = this.displayedMemory.isEmpty() ? null : time;
            }
          }

          this.lastOutputScreen.copy(this.displayedMemory);
        }
      };

      _proto6.cueSplitAtTime = function cueSplitAtTime(t) {
        if (this.outputFilter) {
          if (!this.displayedMemory.isEmpty()) {
            if (this.outputFilter.newCue) {
              this.outputFilter.newCue(this.cueStartTime, t, this.displayedMemory);
            }

            this.cueStartTime = t;
          }
        }
      };

      return Cea608Channel;
    }();

    var Cea608Parser = /*#__PURE__*/function () {
      function Cea608Parser(field, out1, out2) {
        this.channels = void 0;
        this.currentChannel = 0;
        this.cmdHistory = void 0;
        this.logger = void 0;
        var logger = new CaptionsLogger();
        this.channels = [null, new Cea608Channel(field, out1, logger), new Cea608Channel(field + 1, out2, logger)];
        this.cmdHistory = createCmdHistory();
        this.logger = logger;
      }

      var _proto7 = Cea608Parser.prototype;

      _proto7.getHandler = function getHandler(channel) {
        return this.channels[channel].getHandler();
      };

      _proto7.setHandler = function setHandler(channel, newHandler) {
        this.channels[channel].setHandler(newHandler);
      }
      /**
       * Add data for time t in forms of list of bytes (unsigned ints). The bytes are treated as pairs.
       */
      ;

      _proto7.addData = function addData(time, byteList) {
        var cmdFound;
        var a;
        var b;
        var charsFound = false;
        this.logger.time = time;

        for (var i = 0; i < byteList.length; i += 2) {
          a = byteList[i] & 0x7f;
          b = byteList[i + 1] & 0x7f;

          if (a === 0 && b === 0) {
            continue;
          } else {
            this.logger.log(VerboseLevel.DATA, '[' + numArrayToHexArray([byteList[i], byteList[i + 1]]) + '] -> (' + numArrayToHexArray([a, b]) + ')');
          }

          cmdFound = this.parseCmd(a, b);

          if (!cmdFound) {
            cmdFound = this.parseMidrow(a, b);
          }

          if (!cmdFound) {
            cmdFound = this.parsePAC(a, b);
          }

          if (!cmdFound) {
            cmdFound = this.parseBackgroundAttributes(a, b);
          }

          if (!cmdFound) {
            charsFound = this.parseChars(a, b);

            if (charsFound) {
              var currChNr = this.currentChannel;

              if (currChNr && currChNr > 0) {
                var channel = this.channels[currChNr];
                channel.insertChars(charsFound);
              } else {
                this.logger.log(VerboseLevel.WARNING, 'No channel found yet. TEXT-MODE?');
              }
            }
          }

          if (!cmdFound && !charsFound) {
            this.logger.log(VerboseLevel.WARNING, "Couldn't parse cleaned data " + numArrayToHexArray([a, b]) + ' orig: ' + numArrayToHexArray([byteList[i], byteList[i + 1]]));
          }
        }
      }
      /**
       * Parse Command.
       * @returns {Boolean} Tells if a command was found
       */
      ;

      _proto7.parseCmd = function parseCmd(a, b) {
        var cmdHistory = this.cmdHistory;
        var cond1 = (a === 0x14 || a === 0x1c || a === 0x15 || a === 0x1d) && b >= 0x20 && b <= 0x2f;
        var cond2 = (a === 0x17 || a === 0x1f) && b >= 0x21 && b <= 0x23;

        if (!(cond1 || cond2)) {
          return false;
        }

        if (hasCmdRepeated(a, b, cmdHistory)) {
          setLastCmd(null, null, cmdHistory);
          this.logger.log(VerboseLevel.DEBUG, 'Repeated command (' + numArrayToHexArray([a, b]) + ') is dropped');
          return true;
        }

        var chNr = a === 0x14 || a === 0x15 || a === 0x17 ? 1 : 2;
        var channel = this.channels[chNr];

        if (a === 0x14 || a === 0x15 || a === 0x1c || a === 0x1d) {
          if (b === 0x20) {
            channel.ccRCL();
          } else if (b === 0x21) {
            channel.ccBS();
          } else if (b === 0x22) {
            channel.ccAOF();
          } else if (b === 0x23) {
            channel.ccAON();
          } else if (b === 0x24) {
            channel.ccDER();
          } else if (b === 0x25) {
            channel.ccRU(2);
          } else if (b === 0x26) {
            channel.ccRU(3);
          } else if (b === 0x27) {
            channel.ccRU(4);
          } else if (b === 0x28) {
            channel.ccFON();
          } else if (b === 0x29) {
            channel.ccRDC();
          } else if (b === 0x2a) {
            channel.ccTR();
          } else if (b === 0x2b) {
            channel.ccRTD();
          } else if (b === 0x2c) {
            channel.ccEDM();
          } else if (b === 0x2d) {
            channel.ccCR();
          } else if (b === 0x2e) {
            channel.ccENM();
          } else if (b === 0x2f) {
            channel.ccEOC();
          }
        } else {
          // a == 0x17 || a == 0x1F
          channel.ccTO(b - 0x20);
        }

        setLastCmd(a, b, cmdHistory);
        this.currentChannel = chNr;
        return true;
      }
      /**
       * Parse midrow styling command
       * @returns {Boolean}
       */
      ;

      _proto7.parseMidrow = function parseMidrow(a, b) {
        var chNr = 0;

        if ((a === 0x11 || a === 0x19) && b >= 0x20 && b <= 0x2f) {
          if (a === 0x11) {
            chNr = 1;
          } else {
            chNr = 2;
          }

          if (chNr !== this.currentChannel) {
            this.logger.log(VerboseLevel.ERROR, 'Mismatch channel in midrow parsing');
            return false;
          }

          var channel = this.channels[chNr];

          if (!channel) {
            return false;
          }

          channel.ccMIDROW(b);
          this.logger.log(VerboseLevel.DEBUG, 'MIDROW (' + numArrayToHexArray([a, b]) + ')');
          return true;
        }

        return false;
      }
      /**
       * Parse Preable Access Codes (Table 53).
       * @returns {Boolean} Tells if PAC found
       */
      ;

      _proto7.parsePAC = function parsePAC(a, b) {
        var row;
        var cmdHistory = this.cmdHistory;
        var case1 = (a >= 0x11 && a <= 0x17 || a >= 0x19 && a <= 0x1f) && b >= 0x40 && b <= 0x7f;
        var case2 = (a === 0x10 || a === 0x18) && b >= 0x40 && b <= 0x5f;

        if (!(case1 || case2)) {
          return false;
        }

        if (hasCmdRepeated(a, b, cmdHistory)) {
          setLastCmd(null, null, cmdHistory);
          return true; // Repeated commands are dropped (once)
        }

        var chNr = a <= 0x17 ? 1 : 2;

        if (b >= 0x40 && b <= 0x5f) {
          row = chNr === 1 ? rowsLowCh1[a] : rowsLowCh2[a];
        } else {
          // 0x60 <= b <= 0x7F
          row = chNr === 1 ? rowsHighCh1[a] : rowsHighCh2[a];
        }

        var channel = this.channels[chNr];

        if (!channel) {
          return false;
        }

        channel.setPAC(this.interpretPAC(row, b));
        setLastCmd(a, b, cmdHistory);
        this.currentChannel = chNr;
        return true;
      }
      /**
       * Interpret the second byte of the pac, and return the information.
       * @returns {Object} pacData with style parameters.
       */
      ;

      _proto7.interpretPAC = function interpretPAC(row, _byte3) {
        var pacIndex;
        var pacData = {
          color: null,
          italics: false,
          indent: null,
          underline: false,
          row: row
        };

        if (_byte3 > 0x5f) {
          pacIndex = _byte3 - 0x60;
        } else {
          pacIndex = _byte3 - 0x40;
        }

        pacData.underline = (pacIndex & 1) === 1;

        if (pacIndex <= 0xd) {
          pacData.color = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'white'][Math.floor(pacIndex / 2)];
        } else if (pacIndex <= 0xf) {
          pacData.italics = true;
          pacData.color = 'white';
        } else {
          pacData.indent = Math.floor((pacIndex - 0x10) / 2) * 4;
        }

        return pacData; // Note that row has zero offset. The spec uses 1.
      }
      /**
       * Parse characters.
       * @returns An array with 1 to 2 codes corresponding to chars, if found. null otherwise.
       */
      ;

      _proto7.parseChars = function parseChars(a, b) {
        var channelNr;
        var charCodes = null;
        var charCode1 = null;

        if (a >= 0x19) {
          channelNr = 2;
          charCode1 = a - 8;
        } else {
          channelNr = 1;
          charCode1 = a;
        }

        if (charCode1 >= 0x11 && charCode1 <= 0x13) {
          // Special character
          var oneCode;

          if (charCode1 === 0x11) {
            oneCode = b + 0x50;
          } else if (charCode1 === 0x12) {
            oneCode = b + 0x70;
          } else {
            oneCode = b + 0x90;
          }

          this.logger.log(VerboseLevel.INFO, "Special char '" + getCharForByte(oneCode) + "' in channel " + channelNr);
          charCodes = [oneCode];
        } else if (a >= 0x20 && a <= 0x7f) {
          charCodes = b === 0 ? [a] : [a, b];
        }

        if (charCodes) {
          var hexCodes = numArrayToHexArray(charCodes);
          this.logger.log(VerboseLevel.DEBUG, 'Char codes =  ' + hexCodes.join(','));
          setLastCmd(a, b, this.cmdHistory);
        }

        return charCodes;
      }
      /**
       * Parse extended background attributes as well as new foreground color black.
       * @returns {Boolean} Tells if background attributes are found
       */
      ;

      _proto7.parseBackgroundAttributes = function parseBackgroundAttributes(a, b) {
        var case1 = (a === 0x10 || a === 0x18) && b >= 0x20 && b <= 0x2f;
        var case2 = (a === 0x17 || a === 0x1f) && b >= 0x2d && b <= 0x2f;

        if (!(case1 || case2)) {
          return false;
        }

        var index;
        var bkgData = {};

        if (a === 0x10 || a === 0x18) {
          index = Math.floor((b - 0x20) / 2);
          bkgData.background = backgroundColors[index];

          if (b % 2 === 1) {
            bkgData.background = bkgData.background + '_semi';
          }
        } else if (b === 0x2d) {
          bkgData.background = 'transparent';
        } else {
          bkgData.foreground = 'black';

          if (b === 0x2f) {
            bkgData.underline = true;
          }
        }

        var chNr = a <= 0x17 ? 1 : 2;
        var channel = this.channels[chNr];
        channel.setBkgData(bkgData);
        setLastCmd(a, b, this.cmdHistory);
        return true;
      }
      /**
       * Reset state of parser and its channels.
       */
      ;

      _proto7.reset = function reset() {
        for (var i = 0; i < Object.keys(this.channels).length; i++) {
          var channel = this.channels[i];

          if (channel) {
            channel.reset();
          }
        }

        this.cmdHistory = createCmdHistory();
      }
      /**
       * Trigger the generation of a cue, and the start of a new one if displayScreens are not empty.
       */
      ;

      _proto7.cueSplitAtTime = function cueSplitAtTime(t) {
        for (var i = 0; i < this.channels.length; i++) {
          var channel = this.channels[i];

          if (channel) {
            channel.cueSplitAtTime(t);
          }
        }
      };

      return Cea608Parser;
    }();

    function setLastCmd(a, b, cmdHistory) {
      cmdHistory.a = a;
      cmdHistory.b = b;
    }

    function hasCmdRepeated(a, b, cmdHistory) {
      return cmdHistory.a === a && cmdHistory.b === b;
    }

    function createCmdHistory() {
      return {
        a: null,
        b: null
      };
    }

    /* harmony default export */ __webpack_exports__["default"] = (Cea608Parser);

    /***/ }),

    /***/ "./src/utils/codecs.ts":
    /*!*****************************!*\
      !*** ./src/utils/codecs.ts ***!
      \*****************************/
    /*! exports provided: isCodecType, isCodecSupportedInMp4 */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isCodecType", function() { return isCodecType; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isCodecSupportedInMp4", function() { return isCodecSupportedInMp4; });
    // from http://mp4ra.org/codecs.html
    var sampleEntryCodesISO = {
      audio: {
        a3ds: true,
        'ac-3': true,
        'ac-4': true,
        alac: true,
        alaw: true,
        dra1: true,
        'dts+': true,
        'dts-': true,
        dtsc: true,
        dtse: true,
        dtsh: true,
        'ec-3': true,
        enca: true,
        g719: true,
        g726: true,
        m4ae: true,
        mha1: true,
        mha2: true,
        mhm1: true,
        mhm2: true,
        mlpa: true,
        mp4a: true,
        'raw ': true,
        Opus: true,
        samr: true,
        sawb: true,
        sawp: true,
        sevc: true,
        sqcp: true,
        ssmv: true,
        twos: true,
        ulaw: true
      },
      video: {
        avc1: true,
        avc2: true,
        avc3: true,
        avc4: true,
        avcp: true,
        av01: true,
        drac: true,
        dvav: true,
        dvhe: true,
        encv: true,
        hev1: true,
        hvc1: true,
        mjp2: true,
        mp4v: true,
        mvc1: true,
        mvc2: true,
        mvc3: true,
        mvc4: true,
        resv: true,
        rv60: true,
        s263: true,
        svc1: true,
        svc2: true,
        'vc-1': true,
        vp08: true,
        vp09: true
      },
      text: {
        stpp: true,
        wvtt: true
      }
    };
    function isCodecType(codec, type) {
      var typeCodes = sampleEntryCodesISO[type];
      return !!typeCodes && typeCodes[codec.slice(0, 4)] === true;
    }
    function isCodecSupportedInMp4(codec, type) {
      return MediaSource.isTypeSupported((type || 'video') + "/mp4;codecs=\"" + codec + "\"");
    }

    /***/ }),

    /***/ "./src/utils/cues.ts":
    /*!***************************!*\
      !*** ./src/utils/cues.ts ***!
      \***************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _vttparser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./vttparser */ "./src/utils/vttparser.ts");
    /* harmony import */ var _webvtt_parser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./webvtt-parser */ "./src/utils/webvtt-parser.ts");
    /* harmony import */ var _texttrack_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./texttrack-utils */ "./src/utils/texttrack-utils.ts");



    var WHITESPACE_CHAR = /\s/;
    var Cues = {
      newCue: function newCue(track, startTime, endTime, captionScreen) {
        var result = [];
        var row; // the type data states this is VTTCue, but it can potentially be a TextTrackCue on old browsers

        var cue;
        var indenting;
        var indent;
        var text;
        var Cue = self.VTTCue || self.TextTrackCue;

        for (var r = 0; r < captionScreen.rows.length; r++) {
          row = captionScreen.rows[r];
          indenting = true;
          indent = 0;
          text = '';

          if (!row.isEmpty()) {
            for (var c = 0; c < row.chars.length; c++) {
              if (WHITESPACE_CHAR.test(row.chars[c].uchar) && indenting) {
                indent++;
              } else {
                text += row.chars[c].uchar;
                indenting = false;
              }
            } // To be used for cleaning-up orphaned roll-up captions


            row.cueStartTime = startTime; // Give a slight bump to the endTime if it's equal to startTime to avoid a SyntaxError in IE

            if (startTime === endTime) {
              endTime += 0.0001;
            }

            if (indent >= 16) {
              indent--;
            } else {
              indent++;
            }

            var cueText = Object(_vttparser__WEBPACK_IMPORTED_MODULE_0__["fixLineBreaks"])(text.trim());
            var id = Object(_webvtt_parser__WEBPACK_IMPORTED_MODULE_1__["generateCueId"])(startTime, endTime, cueText); // If this cue already exists in the track do not push it

            if (!track || !track.cues || !track.cues.getCueById(id)) {
              cue = new Cue(startTime, endTime, cueText);
              cue.id = id;
              cue.line = r + 1;
              cue.align = 'left'; // Clamp the position between 10 and 80 percent (CEA-608 PAC indent code)
              // https://dvcs.w3.org/hg/text-tracks/raw-file/default/608toVTT/608toVTT.html#positioning-in-cea-608
              // Firefox throws an exception and captions break with out of bounds 0-100 values

              cue.position = 10 + Math.min(80, Math.floor(indent * 8 / 32) * 10);
              result.push(cue);
            }
          }
        }

        if (track && result.length) {
          // Sort bottom cues in reverse order so that they render in line order when overlapping in Chrome
          result.sort(function (cueA, cueB) {
            if (cueA.line === 'auto' || cueB.line === 'auto') {
              return 0;
            }

            if (cueA.line > 8 && cueB.line > 8) {
              return cueB.line - cueA.line;
            }

            return cueA.line - cueB.line;
          });
          result.forEach(function (cue) {
            return Object(_texttrack_utils__WEBPACK_IMPORTED_MODULE_2__["addCueToTrack"])(track, cue);
          });
        }

        return result;
      }
    };
    /* harmony default export */ __webpack_exports__["default"] = (Cues);

    /***/ }),

    /***/ "./src/utils/discontinuities.ts":
    /*!**************************************!*\
      !*** ./src/utils/discontinuities.ts ***!
      \**************************************/
    /*! exports provided: findFirstFragWithCC, shouldAlignOnDiscontinuities, findDiscontinuousReferenceFrag, adjustSlidingStart, alignStream, alignPDT, alignFragmentByPDTDelta, alignMediaPlaylistByPDT */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "findFirstFragWithCC", function() { return findFirstFragWithCC; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shouldAlignOnDiscontinuities", function() { return shouldAlignOnDiscontinuities; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "findDiscontinuousReferenceFrag", function() { return findDiscontinuousReferenceFrag; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "adjustSlidingStart", function() { return adjustSlidingStart; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "alignStream", function() { return alignStream; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "alignPDT", function() { return alignPDT; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "alignFragmentByPDTDelta", function() { return alignFragmentByPDTDelta; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "alignMediaPlaylistByPDT", function() { return alignMediaPlaylistByPDT; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./logger */ "./src/utils/logger.ts");
    /* harmony import */ var _controller_level_helper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../controller/level-helper */ "./src/controller/level-helper.ts");




    function findFirstFragWithCC(fragments, cc) {
      var firstFrag = null;

      for (var i = 0, len = fragments.length; i < len; i++) {
        var currentFrag = fragments[i];

        if (currentFrag && currentFrag.cc === cc) {
          firstFrag = currentFrag;
          break;
        }
      }

      return firstFrag;
    }
    function shouldAlignOnDiscontinuities(lastFrag, lastLevel, details) {
      if (lastLevel.details) {
        if (details.endCC > details.startCC || lastFrag && lastFrag.cc < details.startCC) {
          return true;
        }
      }

      return false;
    } // Find the first frag in the previous level which matches the CC of the first frag of the new level

    function findDiscontinuousReferenceFrag(prevDetails, curDetails) {
      var prevFrags = prevDetails.fragments;
      var curFrags = curDetails.fragments;

      if (!curFrags.length || !prevFrags.length) {
        _logger__WEBPACK_IMPORTED_MODULE_1__["logger"].log('No fragments to align');
        return;
      }

      var prevStartFrag = findFirstFragWithCC(prevFrags, curFrags[0].cc);

      if (!prevStartFrag || prevStartFrag && !prevStartFrag.startPTS) {
        _logger__WEBPACK_IMPORTED_MODULE_1__["logger"].log('No frag in previous level to align on');
        return;
      }

      return prevStartFrag;
    }

    function adjustFragmentStart(frag, sliding) {
      if (frag) {
        var start = frag.start + sliding;
        frag.start = frag.startPTS = start;
        frag.endPTS = start + frag.duration;
      }
    }

    function adjustSlidingStart(sliding, details) {
      // Update segments
      var fragments = details.fragments;

      for (var i = 0, len = fragments.length; i < len; i++) {
        adjustFragmentStart(fragments[i], sliding);
      } // Update LL-HLS parts at the end of the playlist


      if (details.fragmentHint) {
        adjustFragmentStart(details.fragmentHint, sliding);
      }

      details.alignedSliding = true;
    }
    /**
     * Using the parameters of the last level, this function computes PTS' of the new fragments so that they form a
     * contiguous stream with the last fragments.
     * The PTS of a fragment lets Hls.js know where it fits into a stream - by knowing every PTS, we know which fragment to
     * download at any given time. PTS is normally computed when the fragment is demuxed, so taking this step saves us time
     * and an extra download.
     * @param lastFrag
     * @param lastLevel
     * @param details
     */

    function alignStream(lastFrag, lastLevel, details) {
      if (!lastLevel) {
        return;
      }

      alignDiscontinuities(lastFrag, details, lastLevel);

      if (!details.alignedSliding && lastLevel.details) {
        // If the PTS wasn't figured out via discontinuity sequence that means there was no CC increase within the level.
        // Aligning via Program Date Time should therefore be reliable, since PDT should be the same within the same
        // discontinuity sequence.
        alignPDT(details, lastLevel.details);
      }

      if (!details.alignedSliding && lastLevel.details && !details.skippedSegments) {
        // Try to align on sn so that we pick a better start fragment.
        // Do not perform this on playlists with delta updates as this is only to align levels on switch
        // and adjustSliding only adjusts fragments after skippedSegments.
        Object(_controller_level_helper__WEBPACK_IMPORTED_MODULE_2__["adjustSliding"])(lastLevel.details, details);
      }
    }
    /**
     * Computes the PTS if a new level's fragments using the PTS of a fragment in the last level which shares the same
     * discontinuity sequence.
     * @param lastFrag - The last Fragment which shares the same discontinuity sequence
     * @param lastLevel - The details of the last loaded level
     * @param details - The details of the new level
     */

    function alignDiscontinuities(lastFrag, details, lastLevel) {
      if (shouldAlignOnDiscontinuities(lastFrag, lastLevel, details)) {
        var referenceFrag = findDiscontinuousReferenceFrag(lastLevel.details, details);

        if (referenceFrag && Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(referenceFrag.start)) {
          _logger__WEBPACK_IMPORTED_MODULE_1__["logger"].log("Adjusting PTS using last level due to CC increase within current level " + details.url);
          adjustSlidingStart(referenceFrag.start, details);
        }
      }
    }
    /**
     * Computes the PTS of a new level's fragments using the difference in Program Date Time from the last level.
     * @param details - The details of the new level
     * @param lastDetails - The details of the last loaded level
     */


    function alignPDT(details, lastDetails) {
      // This check protects the unsafe "!" usage below for null program date time access.
      if (!lastDetails.fragments.length || !details.hasProgramDateTime || !lastDetails.hasProgramDateTime) {
        return;
      } // if last level sliding is 1000 and its first frag PROGRAM-DATE-TIME is 2017-08-20 1:10:00 AM
      // and if new details first frag PROGRAM DATE-TIME is 2017-08-20 1:10:08 AM
      // then we can deduce that playlist B sliding is 1000+8 = 1008s


      var lastPDT = lastDetails.fragments[0].programDateTime; // hasProgramDateTime check above makes this safe.

      var newPDT = details.fragments[0].programDateTime; // date diff is in ms. frag.start is in seconds

      var sliding = (newPDT - lastPDT) / 1000 + lastDetails.fragments[0].start;

      if (sliding && Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(sliding)) {
        _logger__WEBPACK_IMPORTED_MODULE_1__["logger"].log("Adjusting PTS using programDateTime delta " + (newPDT - lastPDT) + "ms, sliding:" + sliding.toFixed(3) + " " + details.url + " ");
        adjustSlidingStart(sliding, details);
      }
    }
    function alignFragmentByPDTDelta(frag, delta) {
      var programDateTime = frag.programDateTime;
      if (!programDateTime) return;
      var start = (programDateTime - delta) / 1000;
      frag.start = frag.startPTS = start;
      frag.endPTS = start + frag.duration;
    }
    /**
     * Ensures appropriate time-alignment between renditions based on PDT. Unlike `alignPDT`, which adjusts
     * the timeline based on the delta between PDTs of the 0th fragment of two playlists/`LevelDetails`,
     * this function assumes the timelines represented in `refDetails` are accurate, including the PDTs,
     * and uses the "wallclock"/PDT timeline as a cross-reference to `details`, adjusting the presentation
     * times/timelines of `details` accordingly.
     * Given the asynchronous nature of fetches and initial loads of live `main` and audio/subtitle tracks,
     * the primary purpose of this function is to ensure the "local timelines" of audio/subtitle tracks
     * are aligned to the main/video timeline, using PDT as the cross-reference/"anchor" that should
     * be consistent across playlists, per the HLS spec.
     * @param details - The details of the rendition you'd like to time-align (e.g. an audio rendition).
     * @param refDetails - The details of the reference rendition with start and PDT times for alignment.
     */

    function alignMediaPlaylistByPDT(details, refDetails) {
      // This check protects the unsafe "!" usage below for null program date time access.
      if (!refDetails.fragments.length || !details.hasProgramDateTime || !refDetails.hasProgramDateTime) {
        return;
      }

      var refPDT = refDetails.fragments[0].programDateTime; // hasProgramDateTime check above makes this safe.

      var refStart = refDetails.fragments[0].start; // Use the delta between the reference details' presentation timeline's start time and its PDT
      // to align the other rendtion's timeline.

      var delta = refPDT - refStart * 1000; // Per spec: "If any Media Playlist in a Master Playlist contains an EXT-X-PROGRAM-DATE-TIME tag, then all
      // Media Playlists in that Master Playlist MUST contain EXT-X-PROGRAM-DATE-TIME tags with consistent mappings
      // of date and time to media timestamps."
      // So we should be able to use each rendition's PDT as a reference time and use the delta to compute our relevant
      // start and end times.
      // NOTE: This code assumes each level/details timelines have already been made "internally consistent"

      details.fragments.forEach(function (frag) {
        alignFragmentByPDTDelta(frag, delta);
      });

      if (details.fragmentHint) {
        alignFragmentByPDTDelta(details.fragmentHint, delta);
      }

      details.alignedSliding = true;
    }

    /***/ }),

    /***/ "./src/utils/ewma-bandwidth-estimator.ts":
    /*!***********************************************!*\
      !*** ./src/utils/ewma-bandwidth-estimator.ts ***!
      \***********************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _utils_ewma__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/ewma */ "./src/utils/ewma.ts");
    /*
     * EWMA Bandwidth Estimator
     *  - heavily inspired from shaka-player
     * Tracks bandwidth samples and estimates available bandwidth.
     * Based on the minimum of two exponentially-weighted moving averages with
     * different half-lives.
     */


    var EwmaBandWidthEstimator = /*#__PURE__*/function () {
      function EwmaBandWidthEstimator(slow, fast, defaultEstimate) {
        this.defaultEstimate_ = void 0;
        this.minWeight_ = void 0;
        this.minDelayMs_ = void 0;
        this.slow_ = void 0;
        this.fast_ = void 0;
        this.defaultEstimate_ = defaultEstimate;
        this.minWeight_ = 0.001;
        this.minDelayMs_ = 50;
        this.slow_ = new _utils_ewma__WEBPACK_IMPORTED_MODULE_0__["default"](slow);
        this.fast_ = new _utils_ewma__WEBPACK_IMPORTED_MODULE_0__["default"](fast);
      }

      var _proto = EwmaBandWidthEstimator.prototype;

      _proto.update = function update(slow, fast) {
        var slow_ = this.slow_,
            fast_ = this.fast_;

        if (this.slow_.halfLife !== slow) {
          this.slow_ = new _utils_ewma__WEBPACK_IMPORTED_MODULE_0__["default"](slow, slow_.getEstimate(), slow_.getTotalWeight());
        }

        if (this.fast_.halfLife !== fast) {
          this.fast_ = new _utils_ewma__WEBPACK_IMPORTED_MODULE_0__["default"](fast, fast_.getEstimate(), fast_.getTotalWeight());
        }
      };

      _proto.sample = function sample(durationMs, numBytes) {
        durationMs = Math.max(durationMs, this.minDelayMs_);
        var numBits = 8 * numBytes; // weight is duration in seconds

        var durationS = durationMs / 1000; // value is bandwidth in bits/s

        var bandwidthInBps = numBits / durationS;
        this.fast_.sample(durationS, bandwidthInBps);
        this.slow_.sample(durationS, bandwidthInBps);
      };

      _proto.canEstimate = function canEstimate() {
        var fast = this.fast_;
        return fast && fast.getTotalWeight() >= this.minWeight_;
      };

      _proto.getEstimate = function getEstimate() {
        if (this.canEstimate()) {
          // console.log('slow estimate:'+ Math.round(this.slow_.getEstimate()));
          // console.log('fast estimate:'+ Math.round(this.fast_.getEstimate()));
          // Take the minimum of these two estimates.  This should have the effect of
          // adapting down quickly, but up more slowly.
          return Math.min(this.fast_.getEstimate(), this.slow_.getEstimate());
        } else {
          return this.defaultEstimate_;
        }
      };

      _proto.destroy = function destroy() {};

      return EwmaBandWidthEstimator;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (EwmaBandWidthEstimator);

    /***/ }),

    /***/ "./src/utils/ewma.ts":
    /*!***************************!*\
      !*** ./src/utils/ewma.ts ***!
      \***************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /*
     * compute an Exponential Weighted moving average
     * - https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average
     *  - heavily inspired from shaka-player
     */
    var EWMA = /*#__PURE__*/function () {
      //  About half of the estimated value will be from the last |halfLife| samples by weight.
      function EWMA(halfLife, estimate, weight) {
        if (estimate === void 0) {
          estimate = 0;
        }

        if (weight === void 0) {
          weight = 0;
        }

        this.halfLife = void 0;
        this.alpha_ = void 0;
        this.estimate_ = void 0;
        this.totalWeight_ = void 0;
        this.halfLife = halfLife; // Larger values of alpha expire historical data more slowly.

        this.alpha_ = halfLife ? Math.exp(Math.log(0.5) / halfLife) : 0;
        this.estimate_ = estimate;
        this.totalWeight_ = weight;
      }

      var _proto = EWMA.prototype;

      _proto.sample = function sample(weight, value) {
        var adjAlpha = Math.pow(this.alpha_, weight);
        this.estimate_ = value * (1 - adjAlpha) + adjAlpha * this.estimate_;
        this.totalWeight_ += weight;
      };

      _proto.getTotalWeight = function getTotalWeight() {
        return this.totalWeight_;
      };

      _proto.getEstimate = function getEstimate() {
        if (this.alpha_) {
          var zeroFactor = 1 - Math.pow(this.alpha_, this.totalWeight_);

          if (zeroFactor) {
            return this.estimate_ / zeroFactor;
          }
        }

        return this.estimate_;
      };

      return EWMA;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (EWMA);

    /***/ }),

    /***/ "./src/utils/fetch-loader.ts":
    /*!***********************************!*\
      !*** ./src/utils/fetch-loader.ts ***!
      \***********************************/
    /*! exports provided: fetchSupported, default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "fetchSupported", function() { return fetchSupported; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _loader_load_stats__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../loader/load-stats */ "./src/loader/load-stats.ts");
    /* harmony import */ var _demux_chunk_cache__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../demux/chunk-cache */ "./src/demux/chunk-cache.ts");



    function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; _setPrototypeOf(subClass, superClass); }

    function _wrapNativeSuper(Class) { var _cache = typeof Map === "function" ? new Map() : undefined; _wrapNativeSuper = function _wrapNativeSuper(Class) { if (Class === null || !_isNativeFunction(Class)) return Class; if (typeof Class !== "function") { throw new TypeError("Super expression must either be null or a function"); } if (typeof _cache !== "undefined") { if (_cache.has(Class)) return _cache.get(Class); _cache.set(Class, Wrapper); } function Wrapper() { return _construct(Class, arguments, _getPrototypeOf(this).constructor); } Wrapper.prototype = Object.create(Class.prototype, { constructor: { value: Wrapper, enumerable: false, writable: true, configurable: true } }); return _setPrototypeOf(Wrapper, Class); }; return _wrapNativeSuper(Class); }

    function _construct(Parent, args, Class) { if (_isNativeReflectConstruct()) { _construct = Reflect.construct; } else { _construct = function _construct(Parent, args, Class) { var a = [null]; a.push.apply(a, args); var Constructor = Function.bind.apply(Parent, a); var instance = new Constructor(); if (Class) _setPrototypeOf(instance, Class.prototype); return instance; }; } return _construct.apply(null, arguments); }

    function _isNativeReflectConstruct() { if (typeof Reflect === "undefined" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === "function") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }

    function _isNativeFunction(fn) { return Function.toString.call(fn).indexOf("[native code]") !== -1; }

    function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }

    function _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }

    function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }



    function fetchSupported() {
      if ( // @ts-ignore
      self.fetch && self.AbortController && self.ReadableStream && self.Request) {
        try {
          new self.ReadableStream({}); // eslint-disable-line no-new

          return true;
        } catch (e) {
          /* noop */
        }
      }

      return false;
    }

    var FetchLoader = /*#__PURE__*/function () {
      function FetchLoader(config
      /* HlsConfig */
      ) {
        this.fetchSetup = void 0;
        this.requestTimeout = void 0;
        this.request = void 0;
        this.response = void 0;
        this.controller = void 0;
        this.context = void 0;
        this.config = null;
        this.callbacks = null;
        this.stats = void 0;
        this.loader = null;
        this.fetchSetup = config.fetchSetup || getRequest;
        this.controller = new self.AbortController();
        this.stats = new _loader_load_stats__WEBPACK_IMPORTED_MODULE_1__["LoadStats"]();
      }

      var _proto = FetchLoader.prototype;

      _proto.destroy = function destroy() {
        this.loader = this.callbacks = null;
        this.abortInternal();
      };

      _proto.abortInternal = function abortInternal() {
        var response = this.response;

        if (!response || !response.ok) {
          this.stats.aborted = true;
          this.controller.abort();
        }
      };

      _proto.abort = function abort() {
        var _this$callbacks;

        this.abortInternal();

        if ((_this$callbacks = this.callbacks) !== null && _this$callbacks !== void 0 && _this$callbacks.onAbort) {
          this.callbacks.onAbort(this.stats, this.context, this.response);
        }
      };

      _proto.load = function load(context, config, callbacks) {
        var _this = this;

        var stats = this.stats;

        if (stats.loading.start) {
          throw new Error('Loader can only be used once.');
        }

        stats.loading.start = self.performance.now();
        var initParams = getRequestParameters(context, this.controller.signal);
        var onProgress = callbacks.onProgress;
        var isArrayBuffer = context.responseType === 'arraybuffer';
        var LENGTH = isArrayBuffer ? 'byteLength' : 'length';
        this.context = context;
        this.config = config;
        this.callbacks = callbacks;
        this.request = this.fetchSetup(context, initParams);
        self.clearTimeout(this.requestTimeout);
        this.requestTimeout = self.setTimeout(function () {
          _this.abortInternal();

          callbacks.onTimeout(stats, context, _this.response);
        }, config.timeout);
        self.fetch(this.request).then(function (response) {
          _this.response = _this.loader = response;

          if (!response.ok) {
            var status = response.status,
                statusText = response.statusText;
            throw new FetchError(statusText || 'fetch, bad network response', status, response);
          }

          stats.loading.first = Math.max(self.performance.now(), stats.loading.start);
          stats.total = parseInt(response.headers.get('Content-Length') || '0');

          if (onProgress && Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(config.highWaterMark)) {
            return _this.loadProgressively(response, stats, context, config.highWaterMark, onProgress);
          }

          if (isArrayBuffer) {
            return response.arrayBuffer();
          }

          return response.text();
        }).then(function (responseData) {
          var response = _this.response;
          self.clearTimeout(_this.requestTimeout);
          stats.loading.end = Math.max(self.performance.now(), stats.loading.first);
          stats.loaded = stats.total = responseData[LENGTH];
          var loaderResponse = {
            url: response.url,
            data: responseData
          };

          if (onProgress && !Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(config.highWaterMark)) {
            onProgress(stats, context, responseData, response);
          }

          callbacks.onSuccess(loaderResponse, stats, context, response);
        }).catch(function (error) {
          self.clearTimeout(_this.requestTimeout);

          if (stats.aborted) {
            return;
          } // CORS errors result in an undefined code. Set it to 0 here to align with XHR's behavior


          var code = error.code || 0;
          callbacks.onError({
            code: code,
            text: error.message
          }, context, error.details);
        });
      };

      _proto.getCacheAge = function getCacheAge() {
        var result = null;

        if (this.response) {
          var ageHeader = this.response.headers.get('age');
          result = ageHeader ? parseFloat(ageHeader) : null;
        }

        return result;
      };

      _proto.loadProgressively = function loadProgressively(response, stats, context, highWaterMark, onProgress) {
        if (highWaterMark === void 0) {
          highWaterMark = 0;
        }

        var chunkCache = new _demux_chunk_cache__WEBPACK_IMPORTED_MODULE_2__["default"]();
        var reader = response.body.getReader();

        var pump = function pump() {
          return reader.read().then(function (data) {
            if (data.done) {
              if (chunkCache.dataLength) {
                onProgress(stats, context, chunkCache.flush(), response);
              }

              return Promise.resolve(new ArrayBuffer(0));
            }

            var chunk = data.value;
            var len = chunk.length;
            stats.loaded += len;

            if (len < highWaterMark || chunkCache.dataLength) {
              // The current chunk is too small to to be emitted or the cache already has data
              // Push it to the cache
              chunkCache.push(chunk);

              if (chunkCache.dataLength >= highWaterMark) {
                // flush in order to join the typed arrays
                onProgress(stats, context, chunkCache.flush(), response);
              }
            } else {
              // If there's nothing cached already, and the chache is large enough
              // just emit the progress event
              onProgress(stats, context, chunk, response);
            }

            return pump();
          }).catch(function () {
            /* aborted */
            return Promise.reject();
          });
        };

        return pump();
      };

      return FetchLoader;
    }();

    function getRequestParameters(context, signal) {
      var initParams = {
        method: 'GET',
        mode: 'cors',
        credentials: 'same-origin',
        signal: signal,
        headers: new self.Headers(_extends({}, context.headers))
      };

      if (context.rangeEnd) {
        initParams.headers.set('Range', 'bytes=' + context.rangeStart + '-' + String(context.rangeEnd - 1));
      }

      return initParams;
    }

    function getRequest(context, initParams) {
      return new self.Request(context.url, initParams);
    }

    var FetchError = /*#__PURE__*/function (_Error) {
      _inheritsLoose(FetchError, _Error);

      function FetchError(message, code, details) {
        var _this2;

        _this2 = _Error.call(this, message) || this;
        _this2.code = void 0;
        _this2.details = void 0;
        _this2.code = code;
        _this2.details = details;
        return _this2;
      }

      return FetchError;
    }( /*#__PURE__*/_wrapNativeSuper(Error));

    /* harmony default export */ __webpack_exports__["default"] = (FetchLoader);

    /***/ }),

    /***/ "./src/utils/imsc1-ttml-parser.ts":
    /*!****************************************!*\
      !*** ./src/utils/imsc1-ttml-parser.ts ***!
      \****************************************/
    /*! exports provided: IMSC1_CODEC, parseIMSC1 */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "IMSC1_CODEC", function() { return IMSC1_CODEC; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parseIMSC1", function() { return parseIMSC1; });
    /* harmony import */ var _mp4_tools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./mp4-tools */ "./src/utils/mp4-tools.ts");
    /* harmony import */ var _vttparser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./vttparser */ "./src/utils/vttparser.ts");
    /* harmony import */ var _vttcue__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./vttcue */ "./src/utils/vttcue.ts");
    /* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
    /* harmony import */ var _timescale_conversion__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./timescale-conversion */ "./src/utils/timescale-conversion.ts");
    /* harmony import */ var _webvtt_parser__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./webvtt-parser */ "./src/utils/webvtt-parser.ts");
    function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }







    var IMSC1_CODEC = 'stpp.ttml.im1t'; // Time format: h:m:s:frames(.subframes)

    var HMSF_REGEX = /^(\d{2,}):(\d{2}):(\d{2}):(\d{2})\.?(\d+)?$/; // Time format: hours, minutes, seconds, milliseconds, frames, ticks

    var TIME_UNIT_REGEX = /^(\d*(?:\.\d*)?)(h|m|s|ms|f|t)$/;
    var textAlignToLineAlign = {
      left: 'start',
      center: 'center',
      right: 'end',
      start: 'start',
      end: 'end'
    };
    function parseIMSC1(payload, initPTS, timescale, callBack, errorCallBack) {
      var results = Object(_mp4_tools__WEBPACK_IMPORTED_MODULE_0__["findBox"])(new Uint8Array(payload), ['mdat']);

      if (results.length === 0) {
        errorCallBack(new Error('Could not parse IMSC1 mdat'));
        return;
      }

      var mdat = results[0];
      var ttml = Object(_demux_id3__WEBPACK_IMPORTED_MODULE_3__["utf8ArrayToStr"])(new Uint8Array(payload, mdat.start, mdat.end - mdat.start));
      var syncTime = Object(_timescale_conversion__WEBPACK_IMPORTED_MODULE_4__["toTimescaleFromScale"])(initPTS, 1, timescale);

      try {
        callBack(parseTTML(ttml, syncTime));
      } catch (error) {
        errorCallBack(error);
      }
    }

    function parseTTML(ttml, syncTime) {
      var parser = new DOMParser();
      var xmlDoc = parser.parseFromString(ttml, 'text/xml');
      var tt = xmlDoc.getElementsByTagName('tt')[0];

      if (!tt) {
        throw new Error('Invalid ttml');
      }

      var defaultRateInfo = {
        frameRate: 30,
        subFrameRate: 1,
        frameRateMultiplier: 0,
        tickRate: 0
      };
      var rateInfo = Object.keys(defaultRateInfo).reduce(function (result, key) {
        result[key] = tt.getAttribute("ttp:" + key) || defaultRateInfo[key];
        return result;
      }, {});
      var trim = tt.getAttribute('xml:space') !== 'preserve';
      var styleElements = collectionToDictionary(getElementCollection(tt, 'styling', 'style'));
      var regionElements = collectionToDictionary(getElementCollection(tt, 'layout', 'region'));
      var cueElements = getElementCollection(tt, 'body', '[begin]');
      return [].map.call(cueElements, function (cueElement) {
        var cueText = getTextContent(cueElement, trim);

        if (!cueText || !cueElement.hasAttribute('begin')) {
          return null;
        }

        var startTime = parseTtmlTime(cueElement.getAttribute('begin'), rateInfo);
        var duration = parseTtmlTime(cueElement.getAttribute('dur'), rateInfo);
        var endTime = parseTtmlTime(cueElement.getAttribute('end'), rateInfo);

        if (startTime === null) {
          throw timestampParsingError(cueElement);
        }

        if (endTime === null) {
          if (duration === null) {
            throw timestampParsingError(cueElement);
          }

          endTime = startTime + duration;
        }

        var cue = new _vttcue__WEBPACK_IMPORTED_MODULE_2__["default"](startTime - syncTime, endTime - syncTime, cueText);
        cue.id = Object(_webvtt_parser__WEBPACK_IMPORTED_MODULE_5__["generateCueId"])(cue.startTime, cue.endTime, cue.text);
        var region = regionElements[cueElement.getAttribute('region')];
        var style = styleElements[cueElement.getAttribute('style')]; // TODO: Add regions to track and cue (origin and extend)
        // These values are hard-coded (for now) to simulate region settings in the demo

        cue.position = 10;
        cue.size = 80; // Apply styles to cue

        var styles = getTtmlStyles(region, style);
        var textAlign = styles.textAlign;

        if (textAlign) {
          // cue.positionAlign not settable in FF~2016
          var lineAlign = textAlignToLineAlign[textAlign];

          if (lineAlign) {
            cue.lineAlign = lineAlign;
          }

          cue.align = textAlign;
        }

        _extends(cue, styles);

        return cue;
      }).filter(function (cue) {
        return cue !== null;
      });
    }

    function getElementCollection(fromElement, parentName, childName) {
      var parent = fromElement.getElementsByTagName(parentName)[0];

      if (parent) {
        return [].slice.call(parent.querySelectorAll(childName));
      }

      return [];
    }

    function collectionToDictionary(elementsWithId) {
      return elementsWithId.reduce(function (dict, element) {
        var id = element.getAttribute('xml:id');

        if (id) {
          dict[id] = element;
        }

        return dict;
      }, {});
    }

    function getTextContent(element, trim) {
      return [].slice.call(element.childNodes).reduce(function (str, node, i) {
        var _node$childNodes;

        if (node.nodeName === 'br' && i) {
          return str + '\n';
        }

        if ((_node$childNodes = node.childNodes) !== null && _node$childNodes !== void 0 && _node$childNodes.length) {
          return getTextContent(node, trim);
        } else if (trim) {
          return str + node.textContent.trim().replace(/\s+/g, ' ');
        }

        return str + node.textContent;
      }, '');
    }

    function getTtmlStyles(region, style) {
      var ttsNs = 'http://www.w3.org/ns/ttml#styling';
      var styleAttributes = ['displayAlign', 'textAlign', 'color', 'backgroundColor', 'fontSize', 'fontFamily' // 'fontWeight',
      // 'lineHeight',
      // 'wrapOption',
      // 'fontStyle',
      // 'direction',
      // 'writingMode'
      ];
      return styleAttributes.reduce(function (styles, name) {
        var value = getAttributeNS(style, ttsNs, name) || getAttributeNS(region, ttsNs, name);

        if (value) {
          styles[name] = value;
        }

        return styles;
      }, {});
    }

    function getAttributeNS(element, ns, name) {
      return element.hasAttributeNS(ns, name) ? element.getAttributeNS(ns, name) : null;
    }

    function timestampParsingError(node) {
      return new Error("Could not parse ttml timestamp " + node);
    }

    function parseTtmlTime(timeAttributeValue, rateInfo) {
      if (!timeAttributeValue) {
        return null;
      }

      var seconds = Object(_vttparser__WEBPACK_IMPORTED_MODULE_1__["parseTimeStamp"])(timeAttributeValue);

      if (seconds === null) {
        if (HMSF_REGEX.test(timeAttributeValue)) {
          seconds = parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo);
        } else if (TIME_UNIT_REGEX.test(timeAttributeValue)) {
          seconds = parseTimeUnits(timeAttributeValue, rateInfo);
        }
      }

      return seconds;
    }

    function parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo) {
      var m = HMSF_REGEX.exec(timeAttributeValue);
      var frames = (m[4] | 0) + (m[5] | 0) / rateInfo.subFrameRate;
      return (m[1] | 0) * 3600 + (m[2] | 0) * 60 + (m[3] | 0) + frames / rateInfo.frameRate;
    }

    function parseTimeUnits(timeAttributeValue, rateInfo) {
      var m = TIME_UNIT_REGEX.exec(timeAttributeValue);
      var value = Number(m[1]);
      var unit = m[2];

      switch (unit) {
        case 'h':
          return value * 3600;

        case 'm':
          return value * 60;

        case 'ms':
          return value * 1000;

        case 'f':
          return value / rateInfo.frameRate;

        case 't':
          return value / rateInfo.tickRate;
      }

      return value;
    }

    /***/ }),

    /***/ "./src/utils/logger.ts":
    /*!*****************************!*\
      !*** ./src/utils/logger.ts ***!
      \*****************************/
    /*! exports provided: enableLogs, logger */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "enableLogs", function() { return enableLogs; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "logger", function() { return logger; });
    var noop = function noop() {};

    var fakeLogger = {
      trace: noop,
      debug: noop,
      log: noop,
      warn: noop,
      info: noop,
      error: noop
    };
    var exportedLogger = fakeLogger; // let lastCallTime;
    // function formatMsgWithTimeInfo(type, msg) {
    //   const now = Date.now();
    //   const diff = lastCallTime ? '+' + (now - lastCallTime) : '0';
    //   lastCallTime = now;
    //   msg = (new Date(now)).toISOString() + ' | [' +  type + '] > ' + msg + ' ( ' + diff + ' ms )';
    //   return msg;
    // }

    function consolePrintFn(type) {
      var func = self.console[type];

      if (func) {
        return func.bind(self.console, "[" + type + "] >");
      }

      return noop;
    }

    function exportLoggerFunctions(debugConfig) {
      for (var _len = arguments.length, functions = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {
        functions[_key - 1] = arguments[_key];
      }

      functions.forEach(function (type) {
        exportedLogger[type] = debugConfig[type] ? debugConfig[type].bind(debugConfig) : consolePrintFn(type);
      });
    }

    function enableLogs(debugConfig) {
      // check that console is available
      if (self.console && debugConfig === true || typeof debugConfig === 'object') {
        exportLoggerFunctions(debugConfig, // Remove out from list here to hard-disable a log-level
        // 'trace',
        'debug', 'log', 'info', 'warn', 'error'); // Some browsers don't allow to use bind on console object anyway
        // fallback to default if needed

        try {
          exportedLogger.log();
        } catch (e) {
          exportedLogger = fakeLogger;
        }
      } else {
        exportedLogger = fakeLogger;
      }
    }
    var logger = exportedLogger;

    /***/ }),

    /***/ "./src/utils/mediakeys-helper.ts":
    /*!***************************************!*\
      !*** ./src/utils/mediakeys-helper.ts ***!
      \***************************************/
    /*! exports provided: KeySystems, requestMediaKeySystemAccess */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "KeySystems", function() { return KeySystems; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "requestMediaKeySystemAccess", function() { return requestMediaKeySystemAccess; });
    /**
     * @see https://developer.mozilla.org/en-US/docs/Web/API/Navigator/requestMediaKeySystemAccess
     */
    var KeySystems;

    (function (KeySystems) {
      KeySystems["WIDEVINE"] = "com.widevine.alpha";
      KeySystems["PLAYREADY"] = "com.microsoft.playready";
    })(KeySystems || (KeySystems = {}));

    var requestMediaKeySystemAccess = function () {
      if (typeof self !== 'undefined' && self.navigator && self.navigator.requestMediaKeySystemAccess) {
        return self.navigator.requestMediaKeySystemAccess.bind(self.navigator);
      } else {
        return null;
      }
    }();



    /***/ }),

    /***/ "./src/utils/mediasource-helper.ts":
    /*!*****************************************!*\
      !*** ./src/utils/mediasource-helper.ts ***!
      \*****************************************/
    /*! exports provided: getMediaSource */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getMediaSource", function() { return getMediaSource; });
    /**
     * MediaSource helper
     */
    function getMediaSource() {
      return self.MediaSource || self.WebKitMediaSource;
    }

    /***/ }),

    /***/ "./src/utils/mp4-tools.ts":
    /*!********************************!*\
      !*** ./src/utils/mp4-tools.ts ***!
      \********************************/
    /*! exports provided: bin2str, readUint16, readUint32, writeUint32, findBox, parseSegmentIndex, parseInitSegment, getStartDTS, getDuration, computeRawDurationFromSamples, offsetStartDTS, segmentValidRange, appendUint8Array */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "bin2str", function() { return bin2str; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "readUint16", function() { return readUint16; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "readUint32", function() { return readUint32; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "writeUint32", function() { return writeUint32; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "findBox", function() { return findBox; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parseSegmentIndex", function() { return parseSegmentIndex; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parseInitSegment", function() { return parseInitSegment; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getStartDTS", function() { return getStartDTS; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getDuration", function() { return getDuration; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "computeRawDurationFromSamples", function() { return computeRawDurationFromSamples; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "offsetStartDTS", function() { return offsetStartDTS; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "segmentValidRange", function() { return segmentValidRange; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "appendUint8Array", function() { return appendUint8Array; });
    /* harmony import */ var _typed_array__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./typed-array */ "./src/utils/typed-array.ts");
    /* harmony import */ var _loader_fragment__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../loader/fragment */ "./src/loader/fragment.ts");


    var UINT32_MAX = Math.pow(2, 32) - 1;
    var push = [].push;
    function bin2str(data) {
      return String.fromCharCode.apply(null, data);
    }
    function readUint16(buffer, offset) {
      if ('data' in buffer) {
        offset += buffer.start;
        buffer = buffer.data;
      }

      var val = buffer[offset] << 8 | buffer[offset + 1];
      return val < 0 ? 65536 + val : val;
    }
    function readUint32(buffer, offset) {
      if ('data' in buffer) {
        offset += buffer.start;
        buffer = buffer.data;
      }

      var val = buffer[offset] << 24 | buffer[offset + 1] << 16 | buffer[offset + 2] << 8 | buffer[offset + 3];
      return val < 0 ? 4294967296 + val : val;
    }
    function writeUint32(buffer, offset, value) {
      if ('data' in buffer) {
        offset += buffer.start;
        buffer = buffer.data;
      }

      buffer[offset] = value >> 24;
      buffer[offset + 1] = value >> 16 & 0xff;
      buffer[offset + 2] = value >> 8 & 0xff;
      buffer[offset + 3] = value & 0xff;
    } // Find the data for a box specified by its path

    function findBox(input, path) {
      var results = [];

      if (!path.length) {
        // short-circuit the search for empty paths
        return results;
      }

      var data;
      var start;
      var end;

      if ('data' in input) {
        data = input.data;
        start = input.start;
        end = input.end;
      } else {
        data = input;
        start = 0;
        end = data.byteLength;
      }

      for (var i = start; i < end;) {
        var size = readUint32(data, i);
        var type = bin2str(data.subarray(i + 4, i + 8));
        var endbox = size > 1 ? i + size : end;

        if (type === path[0]) {
          if (path.length === 1) {
            // this is the end of the path and we've found the box we were
            // looking for
            results.push({
              data: data,
              start: i + 8,
              end: endbox
            });
          } else {
            // recursively search for the next box along the path
            var subresults = findBox({
              data: data,
              start: i + 8,
              end: endbox
            }, path.slice(1));

            if (subresults.length) {
              push.apply(results, subresults);
            }
          }
        }

        i = endbox;
      } // we've finished searching all of data


      return results;
    }
    function parseSegmentIndex(initSegment) {
      var moovBox = findBox(initSegment, ['moov']);
      var moov = moovBox[0];
      var moovEndOffset = moov ? moov.end : null; // we need this in case we need to chop of garbage of the end of current data

      var sidxBox = findBox(initSegment, ['sidx']);

      if (!sidxBox || !sidxBox[0]) {
        return null;
      }

      var references = [];
      var sidx = sidxBox[0];
      var version = sidx.data[0]; // set initial offset, we skip the reference ID (not needed)

      var index = version === 0 ? 8 : 16;
      var timescale = readUint32(sidx, index);
      index += 4; // TODO: parse earliestPresentationTime and firstOffset
      // usually zero in our case

      var earliestPresentationTime = 0;
      var firstOffset = 0;

      if (version === 0) {
        index += 8;
      } else {
        index += 16;
      } // skip reserved


      index += 2;
      var startByte = sidx.end + firstOffset;
      var referencesCount = readUint16(sidx, index);
      index += 2;

      for (var i = 0; i < referencesCount; i++) {
        var referenceIndex = index;
        var referenceInfo = readUint32(sidx, referenceIndex);
        referenceIndex += 4;
        var referenceSize = referenceInfo & 0x7fffffff;
        var referenceType = (referenceInfo & 0x80000000) >>> 31;

        if (referenceType === 1) {
          // eslint-disable-next-line no-console
          console.warn('SIDX has hierarchical references (not supported)');
          return null;
        }

        var subsegmentDuration = readUint32(sidx, referenceIndex);
        referenceIndex += 4;
        references.push({
          referenceSize: referenceSize,
          subsegmentDuration: subsegmentDuration,
          // unscaled
          info: {
            duration: subsegmentDuration / timescale,
            start: startByte,
            end: startByte + referenceSize - 1
          }
        });
        startByte += referenceSize; // Skipping 1 bit for |startsWithSap|, 3 bits for |sapType|, and 28 bits
        // for |sapDelta|.

        referenceIndex += 4; // skip to next ref

        index = referenceIndex;
      }

      return {
        earliestPresentationTime: earliestPresentationTime,
        timescale: timescale,
        version: version,
        referencesCount: referencesCount,
        references: references,
        moovEndOffset: moovEndOffset
      };
    }
    /**
     * Parses an MP4 initialization segment and extracts stream type and
     * timescale values for any declared tracks. Timescale values indicate the
     * number of clock ticks per second to assume for time-based values
     * elsewhere in the MP4.
     *
     * To determine the start time of an MP4, you need two pieces of
     * information: the timescale unit and the earliest base media decode
     * time. Multiple timescales can be specified within an MP4 but the
     * base media decode time is always expressed in the timescale from
     * the media header box for the track:
     * ```
     * moov > trak > mdia > mdhd.timescale
     * moov > trak > mdia > hdlr
     * ```
     * @param initSegment {Uint8Array} the bytes of the init segment
     * @return {InitData} a hash of track type to timescale values or null if
     * the init segment is malformed.
     */

    function parseInitSegment(initSegment) {
      var result = [];
      var traks = findBox(initSegment, ['moov', 'trak']);

      for (var i = 0; i < traks.length; i++) {
        var trak = traks[i];
        var tkhd = findBox(trak, ['tkhd'])[0];

        if (tkhd) {
          var version = tkhd.data[tkhd.start];

          var _index = version === 0 ? 12 : 20;

          var trackId = readUint32(tkhd, _index);
          var mdhd = findBox(trak, ['mdia', 'mdhd'])[0];

          if (mdhd) {
            version = mdhd.data[mdhd.start];
            _index = version === 0 ? 12 : 20;
            var timescale = readUint32(mdhd, _index);
            var hdlr = findBox(trak, ['mdia', 'hdlr'])[0];

            if (hdlr) {
              var hdlrType = bin2str(hdlr.data.subarray(hdlr.start + 8, hdlr.start + 12));
              var type = {
                soun: _loader_fragment__WEBPACK_IMPORTED_MODULE_1__["ElementaryStreamTypes"].AUDIO,
                vide: _loader_fragment__WEBPACK_IMPORTED_MODULE_1__["ElementaryStreamTypes"].VIDEO
              }[hdlrType];

              if (type) {
                // Parse codec details
                var stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];
                var codec = void 0;

                if (stsd) {
                  codec = bin2str(stsd.data.subarray(stsd.start + 12, stsd.start + 16)); // TODO: Parse codec details to be able to build MIME type.
                  // stsd.start += 8;
                  // const codecBox = findBox(stsd, [codec])[0];
                  // if (codecBox) {
                  //   TODO: Codec parsing support for avc1, mp4a, hevc, av01...
                  // }
                }

                result[trackId] = {
                  timescale: timescale,
                  type: type
                };
                result[type] = {
                  timescale: timescale,
                  id: trackId,
                  codec: codec
                };
              }
            }
          }
        }
      }

      var trex = findBox(initSegment, ['moov', 'mvex', 'trex']);
      trex.forEach(function (trex) {
        var trackId = readUint32(trex, 4);
        var track = result[trackId];

        if (track) {
          track.default = {
            duration: readUint32(trex, 12),
            flags: readUint32(trex, 20)
          };
        }
      });
      return result;
    }
    /**
     * Determine the base media decode start time, in seconds, for an MP4
     * fragment. If multiple fragments are specified, the earliest time is
     * returned.
     *
     * The base media decode time can be parsed from track fragment
     * metadata:
     * ```
     * moof > traf > tfdt.baseMediaDecodeTime
     * ```
     * It requires the timescale value from the mdhd to interpret.
     *
     * @param initData {InitData} a hash of track type to timescale values
     * @param fmp4 {Uint8Array} the bytes of the mp4 fragment
     * @return {number} the earliest base media decode start time for the
     * fragment, in seconds
     */

    function getStartDTS(initData, fmp4) {
      // we need info from two children of each track fragment box
      return findBox(fmp4, ['moof', 'traf']).reduce(function (result, traf) {
        var tfdt = findBox(traf, ['tfdt'])[0];
        var version = tfdt.data[tfdt.start];
        var start = findBox(traf, ['tfhd']).reduce(function (result, tfhd) {
          // get the track id from the tfhd
          var id = readUint32(tfhd, 4);
          var track = initData[id];

          if (track) {
            var baseTime = readUint32(tfdt, 4);

            if (version === 1) {
              baseTime *= Math.pow(2, 32);
              baseTime += readUint32(tfdt, 8);
            } // assume a 90kHz clock if no timescale was specified


            var scale = track.timescale || 90e3; // convert base time to seconds

            var startTime = baseTime / scale;

            if (isFinite(startTime) && (result === null || startTime < result)) {
              return startTime;
            }
          }

          return result;
        }, null);

        if (start !== null && isFinite(start) && (result === null || start < result)) {
          return start;
        }

        return result;
      }, null) || 0;
    }
    /*
      For Reference:
      aligned(8) class TrackFragmentHeaderBox
               extends FullBox(‘tfhd’, 0, tf_flags){
         unsigned int(32)  track_ID;
         // all the following are optional fields
         unsigned int(64)  base_data_offset;
         unsigned int(32)  sample_description_index;
         unsigned int(32)  default_sample_duration;
         unsigned int(32)  default_sample_size;
         unsigned int(32)  default_sample_flags
      }
     */

    function getDuration(data, initData) {
      var rawDuration = 0;
      var videoDuration = 0;
      var audioDuration = 0;
      var trafs = findBox(data, ['moof', 'traf']);

      for (var i = 0; i < trafs.length; i++) {
        var traf = trafs[i]; // There is only one tfhd & trun per traf
        // This is true for CMAF style content, and we should perhaps check the ftyp
        // and only look for a single trun then, but for ISOBMFF we should check
        // for multiple track runs.

        var tfhd = findBox(traf, ['tfhd'])[0]; // get the track id from the tfhd

        var id = readUint32(tfhd, 4);
        var track = initData[id];

        if (!track) {
          continue;
        }

        var trackDefault = track.default;
        var tfhdFlags = readUint32(tfhd, 0) | (trackDefault === null || trackDefault === void 0 ? void 0 : trackDefault.flags);
        var sampleDuration = trackDefault === null || trackDefault === void 0 ? void 0 : trackDefault.duration;

        if (tfhdFlags & 0x000008) {
          // 0x000008 indicates the presence of the default_sample_duration field
          if (tfhdFlags & 0x000002) {
            // 0x000002 indicates the presence of the sample_description_index field, which precedes default_sample_duration
            // If present, the default_sample_duration exists at byte offset 12
            sampleDuration = readUint32(tfhd, 12);
          } else {
            // Otherwise, the duration is at byte offset 8
            sampleDuration = readUint32(tfhd, 8);
          }
        } // assume a 90kHz clock if no timescale was specified


        var timescale = track.timescale || 90e3;
        var truns = findBox(traf, ['trun']);

        for (var j = 0; j < truns.length; j++) {
          rawDuration = computeRawDurationFromSamples(truns[j]);

          if (!rawDuration && sampleDuration) {
            var sampleCount = readUint32(truns[j], 4);
            rawDuration = sampleDuration * sampleCount;
          }

          if (track.type === _loader_fragment__WEBPACK_IMPORTED_MODULE_1__["ElementaryStreamTypes"].VIDEO) {
            videoDuration += rawDuration / timescale;
          } else if (track.type === _loader_fragment__WEBPACK_IMPORTED_MODULE_1__["ElementaryStreamTypes"].AUDIO) {
            audioDuration += rawDuration / timescale;
          }
        }
      }

      if (videoDuration === 0 && audioDuration === 0) {
        // If duration samples are not available in the traf use sidx subsegment_duration
        var sidx = parseSegmentIndex(data);

        if (sidx !== null && sidx !== void 0 && sidx.references) {
          return sidx.references.reduce(function (dur, ref) {
            return dur + ref.info.duration || 0;
          }, 0);
        }
      }

      if (videoDuration) {
        return videoDuration;
      }

      return audioDuration;
    }
    /*
      For Reference:
      aligned(8) class TrackRunBox
               extends FullBox(‘trun’, version, tr_flags) {
         unsigned int(32)  sample_count;
         // the following are optional fields
         signed int(32) data_offset;
         unsigned int(32)  first_sample_flags;
         // all fields in the following array are optional
         {
            unsigned int(32)  sample_duration;
            unsigned int(32)  sample_size;
            unsigned int(32)  sample_flags
            if (version == 0)
               { unsigned int(32)
            else
               { signed int(32)
         }[ sample_count ]
      }
     */

    function computeRawDurationFromSamples(trun) {
      var flags = readUint32(trun, 0); // Flags are at offset 0, non-optional sample_count is at offset 4. Therefore we start 8 bytes in.
      // Each field is an int32, which is 4 bytes

      var offset = 8; // data-offset-present flag

      if (flags & 0x000001) {
        offset += 4;
      } // first-sample-flags-present flag


      if (flags & 0x000004) {
        offset += 4;
      }

      var duration = 0;
      var sampleCount = readUint32(trun, 4);

      for (var i = 0; i < sampleCount; i++) {
        // sample-duration-present flag
        if (flags & 0x000100) {
          var sampleDuration = readUint32(trun, offset);
          duration += sampleDuration;
          offset += 4;
        } // sample-size-present flag


        if (flags & 0x000200) {
          offset += 4;
        } // sample-flags-present flag


        if (flags & 0x000400) {
          offset += 4;
        } // sample-composition-time-offsets-present flag


        if (flags & 0x000800) {
          offset += 4;
        }
      }

      return duration;
    }
    function offsetStartDTS(initData, fmp4, timeOffset) {
      findBox(fmp4, ['moof', 'traf']).forEach(function (traf) {
        findBox(traf, ['tfhd']).forEach(function (tfhd) {
          // get the track id from the tfhd
          var id = readUint32(tfhd, 4);
          var track = initData[id];

          if (!track) {
            return;
          } // assume a 90kHz clock if no timescale was specified


          var timescale = track.timescale || 90e3; // get the base media decode time from the tfdt

          findBox(traf, ['tfdt']).forEach(function (tfdt) {
            var version = tfdt.data[tfdt.start];
            var baseMediaDecodeTime = readUint32(tfdt, 4);

            if (version === 0) {
              writeUint32(tfdt, 4, baseMediaDecodeTime - timeOffset * timescale);
            } else {
              baseMediaDecodeTime *= Math.pow(2, 32);
              baseMediaDecodeTime += readUint32(tfdt, 8);
              baseMediaDecodeTime -= timeOffset * timescale;
              baseMediaDecodeTime = Math.max(baseMediaDecodeTime, 0);
              var upper = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1));
              var lower = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));
              writeUint32(tfdt, 4, upper);
              writeUint32(tfdt, 8, lower);
            }
          });
        });
      });
    } // TODO: Check if the last moof+mdat pair is part of the valid range

    function segmentValidRange(data) {
      var segmentedRange = {
        valid: null,
        remainder: null
      };
      var moofs = findBox(data, ['moof']);

      if (!moofs) {
        return segmentedRange;
      } else if (moofs.length < 2) {
        segmentedRange.remainder = data;
        return segmentedRange;
      }

      var last = moofs[moofs.length - 1]; // Offset by 8 bytes; findBox offsets the start by as much

      segmentedRange.valid = Object(_typed_array__WEBPACK_IMPORTED_MODULE_0__["sliceUint8"])(data, 0, last.start - 8);
      segmentedRange.remainder = Object(_typed_array__WEBPACK_IMPORTED_MODULE_0__["sliceUint8"])(data, last.start - 8);
      return segmentedRange;
    }
    function appendUint8Array(data1, data2) {
      var temp = new Uint8Array(data1.length + data2.length);
      temp.set(data1);
      temp.set(data2, data1.length);
      return temp;
    }

    /***/ }),

    /***/ "./src/utils/output-filter.ts":
    /*!************************************!*\
      !*** ./src/utils/output-filter.ts ***!
      \************************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return OutputFilter; });
    var OutputFilter = /*#__PURE__*/function () {
      function OutputFilter(timelineController, trackName) {
        this.timelineController = void 0;
        this.cueRanges = [];
        this.trackName = void 0;
        this.startTime = null;
        this.endTime = null;
        this.screen = null;
        this.timelineController = timelineController;
        this.trackName = trackName;
      }

      var _proto = OutputFilter.prototype;

      _proto.dispatchCue = function dispatchCue() {
        if (this.startTime === null) {
          return;
        }

        this.timelineController.addCues(this.trackName, this.startTime, this.endTime, this.screen, this.cueRanges);
        this.startTime = null;
      };

      _proto.newCue = function newCue(startTime, endTime, screen) {
        if (this.startTime === null || this.startTime > startTime) {
          this.startTime = startTime;
        }

        this.endTime = endTime;
        this.screen = screen;
        this.timelineController.createCaptionsTrack(this.trackName);
      };

      _proto.reset = function reset() {
        this.cueRanges = [];
        this.startTime = null;
      };

      return OutputFilter;
    }();



    /***/ }),

    /***/ "./src/utils/texttrack-utils.ts":
    /*!**************************************!*\
      !*** ./src/utils/texttrack-utils.ts ***!
      \**************************************/
    /*! exports provided: sendAddTrackEvent, addCueToTrack, clearCurrentCues, removeCuesInRange, getCuesInRange */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "sendAddTrackEvent", function() { return sendAddTrackEvent; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "addCueToTrack", function() { return addCueToTrack; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "clearCurrentCues", function() { return clearCurrentCues; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "removeCuesInRange", function() { return removeCuesInRange; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getCuesInRange", function() { return getCuesInRange; });
    /* harmony import */ var _logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./logger */ "./src/utils/logger.ts");

    function sendAddTrackEvent(track, videoEl) {
      var event;

      try {
        event = new Event('addtrack');
      } catch (err) {
        // for IE11
        event = document.createEvent('Event');
        event.initEvent('addtrack', false, false);
      }

      event.track = track;
      videoEl.dispatchEvent(event);
    }
    function addCueToTrack(track, cue) {
      // Sometimes there are cue overlaps on segmented vtts so the same
      // cue can appear more than once in different vtt files.
      // This avoid showing duplicated cues with same timecode and text.
      var mode = track.mode;

      if (mode === 'disabled') {
        track.mode = 'hidden';
      }

      if (track.cues && !track.cues.getCueById(cue.id)) {
        try {
          track.addCue(cue);

          if (!track.cues.getCueById(cue.id)) {
            throw new Error("addCue is failed for: " + cue);
          }
        } catch (err) {
          _logger__WEBPACK_IMPORTED_MODULE_0__["logger"].debug("[texttrack-utils]: " + err);
          var textTrackCue = new self.TextTrackCue(cue.startTime, cue.endTime, cue.text);
          textTrackCue.id = cue.id;
          track.addCue(textTrackCue);
        }
      }

      if (mode === 'disabled') {
        track.mode = mode;
      }
    }
    function clearCurrentCues(track) {
      // When track.mode is disabled, track.cues will be null.
      // To guarantee the removal of cues, we need to temporarily
      // change the mode to hidden
      var mode = track.mode;

      if (mode === 'disabled') {
        track.mode = 'hidden';
      }

      if (track.cues) {
        for (var i = track.cues.length; i--;) {
          track.removeCue(track.cues[i]);
        }
      }

      if (mode === 'disabled') {
        track.mode = mode;
      }
    }
    function removeCuesInRange(track, start, end) {
      var mode = track.mode;

      if (mode === 'disabled') {
        track.mode = 'hidden';
      }

      if (track.cues && track.cues.length > 0) {
        var cues = getCuesInRange(track.cues, start, end);

        for (var i = 0; i < cues.length; i++) {
          track.removeCue(cues[i]);
        }
      }

      if (mode === 'disabled') {
        track.mode = mode;
      }
    } // Find first cue starting after given time.
    // Modified version of binary search O(log(n)).

    function getFirstCueIndexAfterTime(cues, time) {
      // If first cue starts after time, start there
      if (time < cues[0].startTime) {
        return 0;
      } // If the last cue ends before time there is no overlap


      var len = cues.length - 1;

      if (time > cues[len].endTime) {
        return -1;
      }

      var left = 0;
      var right = len;

      while (left <= right) {
        var mid = Math.floor((right + left) / 2);

        if (time < cues[mid].startTime) {
          right = mid - 1;
        } else if (time > cues[mid].startTime && left < len) {
          left = mid + 1;
        } else {
          // If it's not lower or higher, it must be equal.
          return mid;
        }
      } // At this point, left and right have swapped.
      // No direct match was found, left or right element must be the closest. Check which one has the smallest diff.


      return cues[left].startTime - time < time - cues[right].startTime ? left : right;
    }

    function getCuesInRange(cues, start, end) {
      var cuesFound = [];
      var firstCueInRange = getFirstCueIndexAfterTime(cues, start);

      if (firstCueInRange > -1) {
        for (var i = firstCueInRange, len = cues.length; i < len; i++) {
          var cue = cues[i];

          if (cue.startTime >= start && cue.endTime <= end) {
            cuesFound.push(cue);
          } else if (cue.startTime > end) {
            return cuesFound;
          }
        }
      }

      return cuesFound;
    }

    /***/ }),

    /***/ "./src/utils/time-ranges.ts":
    /*!**********************************!*\
      !*** ./src/utils/time-ranges.ts ***!
      \**********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /**
     *  TimeRanges to string helper
     */
    var TimeRanges = {
      toString: function toString(r) {
        var log = '';
        var len = r.length;

        for (var i = 0; i < len; i++) {
          log += '[' + r.start(i).toFixed(3) + ',' + r.end(i).toFixed(3) + ']';
        }

        return log;
      }
    };
    /* harmony default export */ __webpack_exports__["default"] = (TimeRanges);

    /***/ }),

    /***/ "./src/utils/timescale-conversion.ts":
    /*!*******************************************!*\
      !*** ./src/utils/timescale-conversion.ts ***!
      \*******************************************/
    /*! exports provided: toTimescaleFromBase, toTimescaleFromScale, toMsFromMpegTsClock, toMpegTsClockFromTimescale */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "toTimescaleFromBase", function() { return toTimescaleFromBase; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "toTimescaleFromScale", function() { return toTimescaleFromScale; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "toMsFromMpegTsClock", function() { return toMsFromMpegTsClock; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "toMpegTsClockFromTimescale", function() { return toMpegTsClockFromTimescale; });
    var MPEG_TS_CLOCK_FREQ_HZ = 90000;
    function toTimescaleFromBase(value, destScale, srcBase, round) {
      if (srcBase === void 0) {
        srcBase = 1;
      }

      if (round === void 0) {
        round = false;
      }

      var result = value * destScale * srcBase; // equivalent to `(value * scale) / (1 / base)`

      return round ? Math.round(result) : result;
    }
    function toTimescaleFromScale(value, destScale, srcScale, round) {
      if (srcScale === void 0) {
        srcScale = 1;
      }

      if (round === void 0) {
        round = false;
      }

      return toTimescaleFromBase(value, destScale, 1 / srcScale, round);
    }
    function toMsFromMpegTsClock(value, round) {
      if (round === void 0) {
        round = false;
      }

      return toTimescaleFromBase(value, 1000, 1 / MPEG_TS_CLOCK_FREQ_HZ, round);
    }
    function toMpegTsClockFromTimescale(value, srcScale) {
      if (srcScale === void 0) {
        srcScale = 1;
      }

      return toTimescaleFromBase(value, MPEG_TS_CLOCK_FREQ_HZ, 1 / srcScale);
    }

    /***/ }),

    /***/ "./src/utils/typed-array.ts":
    /*!**********************************!*\
      !*** ./src/utils/typed-array.ts ***!
      \**********************************/
    /*! exports provided: sliceUint8 */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "sliceUint8", function() { return sliceUint8; });
    function sliceUint8(array, start, end) {
      // @ts-expect-error This polyfills IE11 usage of Uint8Array slice.
      // It always exists in the TypeScript definition so fails, but it fails at runtime on IE11.
      return Uint8Array.prototype.slice ? array.slice(start, end) : new Uint8Array(Array.prototype.slice.call(array, start, end));
    }

    /***/ }),

    /***/ "./src/utils/vttcue.ts":
    /*!*****************************!*\
      !*** ./src/utils/vttcue.ts ***!
      \*****************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /**
     * Copyright 2013 vtt.js Contributors
     *
     * Licensed under the Apache License, Version 2.0 (the 'License');
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     *   http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an 'AS IS' BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     */
    /* harmony default export */ __webpack_exports__["default"] = ((function () {
      if (typeof self !== 'undefined' && self.VTTCue) {
        return self.VTTCue;
      }

      var AllowedDirections = ['', 'lr', 'rl'];
      var AllowedAlignments = ['start', 'middle', 'end', 'left', 'right'];

      function isAllowedValue(allowed, value) {
        if (typeof value !== 'string') {
          return false;
        } // necessary for assuring the generic conforms to the Array interface


        if (!Array.isArray(allowed)) {
          return false;
        } // reset the type so that the next narrowing works well


        var lcValue = value.toLowerCase(); // use the allow list to narrow the type to a specific subset of strings

        if (~allowed.indexOf(lcValue)) {
          return lcValue;
        }

        return false;
      }

      function findDirectionSetting(value) {
        return isAllowedValue(AllowedDirections, value);
      }

      function findAlignSetting(value) {
        return isAllowedValue(AllowedAlignments, value);
      }

      function extend(obj) {
        for (var _len = arguments.length, rest = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {
          rest[_key - 1] = arguments[_key];
        }

        var i = 1;

        for (; i < arguments.length; i++) {
          var cobj = arguments[i];

          for (var p in cobj) {
            obj[p] = cobj[p];
          }
        }

        return obj;
      }

      function VTTCue(startTime, endTime, text) {
        var cue = this;
        var baseObj = {
          enumerable: true
        };
        /**
         * Shim implementation specific properties. These properties are not in
         * the spec.
         */
        // Lets us know when the VTTCue's data has changed in such a way that we need
        // to recompute its display state. This lets us compute its display state
        // lazily.

        cue.hasBeenReset = false;
        /**
         * VTTCue and TextTrackCue properties
         * http://dev.w3.org/html5/webvtt/#vttcue-interface
         */

        var _id = '';
        var _pauseOnExit = false;
        var _startTime = startTime;
        var _endTime = endTime;
        var _text = text;
        var _region = null;
        var _vertical = '';
        var _snapToLines = true;
        var _line = 'auto';
        var _lineAlign = 'start';
        var _position = 50;
        var _positionAlign = 'middle';
        var _size = 50;
        var _align = 'middle';
        Object.defineProperty(cue, 'id', extend({}, baseObj, {
          get: function get() {
            return _id;
          },
          set: function set(value) {
            _id = '' + value;
          }
        }));
        Object.defineProperty(cue, 'pauseOnExit', extend({}, baseObj, {
          get: function get() {
            return _pauseOnExit;
          },
          set: function set(value) {
            _pauseOnExit = !!value;
          }
        }));
        Object.defineProperty(cue, 'startTime', extend({}, baseObj, {
          get: function get() {
            return _startTime;
          },
          set: function set(value) {
            if (typeof value !== 'number') {
              throw new TypeError('Start time must be set to a number.');
            }

            _startTime = value;
            this.hasBeenReset = true;
          }
        }));
        Object.defineProperty(cue, 'endTime', extend({}, baseObj, {
          get: function get() {
            return _endTime;
          },
          set: function set(value) {
            if (typeof value !== 'number') {
              throw new TypeError('End time must be set to a number.');
            }

            _endTime = value;
            this.hasBeenReset = true;
          }
        }));
        Object.defineProperty(cue, 'text', extend({}, baseObj, {
          get: function get() {
            return _text;
          },
          set: function set(value) {
            _text = '' + value;
            this.hasBeenReset = true;
          }
        })); // todo: implement VTTRegion polyfill?

        Object.defineProperty(cue, 'region', extend({}, baseObj, {
          get: function get() {
            return _region;
          },
          set: function set(value) {
            _region = value;
            this.hasBeenReset = true;
          }
        }));
        Object.defineProperty(cue, 'vertical', extend({}, baseObj, {
          get: function get() {
            return _vertical;
          },
          set: function set(value) {
            var setting = findDirectionSetting(value); // Have to check for false because the setting an be an empty string.

            if (setting === false) {
              throw new SyntaxError('An invalid or illegal string was specified.');
            }

            _vertical = setting;
            this.hasBeenReset = true;
          }
        }));
        Object.defineProperty(cue, 'snapToLines', extend({}, baseObj, {
          get: function get() {
            return _snapToLines;
          },
          set: function set(value) {
            _snapToLines = !!value;
            this.hasBeenReset = true;
          }
        }));
        Object.defineProperty(cue, 'line', extend({}, baseObj, {
          get: function get() {
            return _line;
          },
          set: function set(value) {
            if (typeof value !== 'number' && value !== 'auto') {
              throw new SyntaxError('An invalid number or illegal string was specified.');
            }

            _line = value;
            this.hasBeenReset = true;
          }
        }));
        Object.defineProperty(cue, 'lineAlign', extend({}, baseObj, {
          get: function get() {
            return _lineAlign;
          },
          set: function set(value) {
            var setting = findAlignSetting(value);

            if (!setting) {
              throw new SyntaxError('An invalid or illegal string was specified.');
            }

            _lineAlign = setting;
            this.hasBeenReset = true;
          }
        }));
        Object.defineProperty(cue, 'position', extend({}, baseObj, {
          get: function get() {
            return _position;
          },
          set: function set(value) {
            if (value < 0 || value > 100) {
              throw new Error('Position must be between 0 and 100.');
            }

            _position = value;
            this.hasBeenReset = true;
          }
        }));
        Object.defineProperty(cue, 'positionAlign', extend({}, baseObj, {
          get: function get() {
            return _positionAlign;
          },
          set: function set(value) {
            var setting = findAlignSetting(value);

            if (!setting) {
              throw new SyntaxError('An invalid or illegal string was specified.');
            }

            _positionAlign = setting;
            this.hasBeenReset = true;
          }
        }));
        Object.defineProperty(cue, 'size', extend({}, baseObj, {
          get: function get() {
            return _size;
          },
          set: function set(value) {
            if (value < 0 || value > 100) {
              throw new Error('Size must be between 0 and 100.');
            }

            _size = value;
            this.hasBeenReset = true;
          }
        }));
        Object.defineProperty(cue, 'align', extend({}, baseObj, {
          get: function get() {
            return _align;
          },
          set: function set(value) {
            var setting = findAlignSetting(value);

            if (!setting) {
              throw new SyntaxError('An invalid or illegal string was specified.');
            }

            _align = setting;
            this.hasBeenReset = true;
          }
        }));
        /**
         * Other <track> spec defined properties
         */
        // http://www.whatwg.org/specs/web-apps/current-work/multipage/the-video-element.html#text-track-cue-display-state

        cue.displayState = undefined;
      }
      /**
       * VTTCue methods
       */


      VTTCue.prototype.getCueAsHTML = function () {
        // Assume WebVTT.convertCueToDOMTree is on the global.
        var WebVTT = self.WebVTT;
        return WebVTT.convertCueToDOMTree(self, this.text);
      }; // this is a polyfill hack


      return VTTCue;
    })());

    /***/ }),

    /***/ "./src/utils/vttparser.ts":
    /*!********************************!*\
      !*** ./src/utils/vttparser.ts ***!
      \********************************/
    /*! exports provided: parseTimeStamp, fixLineBreaks, VTTParser */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parseTimeStamp", function() { return parseTimeStamp; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "fixLineBreaks", function() { return fixLineBreaks; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VTTParser", function() { return VTTParser; });
    /* harmony import */ var _vttcue__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./vttcue */ "./src/utils/vttcue.ts");
    /*
     * Source: https://github.com/mozilla/vtt.js/blob/master/dist/vtt.js
     */


    var StringDecoder = /*#__PURE__*/function () {
      function StringDecoder() {}

      var _proto = StringDecoder.prototype;

      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      _proto.decode = function decode(data, options) {
        if (!data) {
          return '';
        }

        if (typeof data !== 'string') {
          throw new Error('Error - expected string data.');
        }

        return decodeURIComponent(encodeURIComponent(data));
      };

      return StringDecoder;
    }(); // Try to parse input as a time stamp.


    function parseTimeStamp(input) {
      function computeSeconds(h, m, s, f) {
        return (h | 0) * 3600 + (m | 0) * 60 + (s | 0) + parseFloat(f || 0);
      }

      var m = input.match(/^(?:(\d+):)?(\d{2}):(\d{2})(\.\d+)?/);

      if (!m) {
        return null;
      }

      if (parseFloat(m[2]) > 59) {
        // Timestamp takes the form of [hours]:[minutes].[milliseconds]
        // First position is hours as it's over 59.
        return computeSeconds(m[2], m[3], 0, m[4]);
      } // Timestamp takes the form of [hours (optional)]:[minutes]:[seconds].[milliseconds]


      return computeSeconds(m[1], m[2], m[3], m[4]);
    } // A settings object holds key/value pairs and will ignore anything but the first
    // assignment to a specific key.

    var Settings = /*#__PURE__*/function () {
      function Settings() {
        this.values = Object.create(null);
      }

      var _proto2 = Settings.prototype;

      // Only accept the first assignment to any key.
      _proto2.set = function set(k, v) {
        if (!this.get(k) && v !== '') {
          this.values[k] = v;
        }
      } // Return the value for a key, or a default value.
      // If 'defaultKey' is passed then 'dflt' is assumed to be an object with
      // a number of possible default values as properties where 'defaultKey' is
      // the key of the property that will be chosen; otherwise it's assumed to be
      // a single value.
      ;

      _proto2.get = function get(k, dflt, defaultKey) {
        if (defaultKey) {
          return this.has(k) ? this.values[k] : dflt[defaultKey];
        }

        return this.has(k) ? this.values[k] : dflt;
      } // Check whether we have a value for a key.
      ;

      _proto2.has = function has(k) {
        return k in this.values;
      } // Accept a setting if its one of the given alternatives.
      ;

      _proto2.alt = function alt(k, v, a) {
        for (var n = 0; n < a.length; ++n) {
          if (v === a[n]) {
            this.set(k, v);
            break;
          }
        }
      } // Accept a setting if its a valid (signed) integer.
      ;

      _proto2.integer = function integer(k, v) {
        if (/^-?\d+$/.test(v)) {
          // integer
          this.set(k, parseInt(v, 10));
        }
      } // Accept a setting if its a valid percentage.
      ;

      _proto2.percent = function percent(k, v) {
        if (/^([\d]{1,3})(\.[\d]*)?%$/.test(v)) {
          var percent = parseFloat(v);

          if (percent >= 0 && percent <= 100) {
            this.set(k, percent);
            return true;
          }
        }

        return false;
      };

      return Settings;
    }(); // Helper function to parse input into groups separated by 'groupDelim', and
    // interpret each group as a key/value pair separated by 'keyValueDelim'.


    function parseOptions(input, callback, keyValueDelim, groupDelim) {
      var groups = groupDelim ? input.split(groupDelim) : [input];

      for (var i in groups) {
        if (typeof groups[i] !== 'string') {
          continue;
        }

        var kv = groups[i].split(keyValueDelim);

        if (kv.length !== 2) {
          continue;
        }

        var _k = kv[0];
        var _v = kv[1];
        callback(_k, _v);
      }
    }

    var defaults = new _vttcue__WEBPACK_IMPORTED_MODULE_0__["default"](0, 0, ''); // 'middle' was changed to 'center' in the spec: https://github.com/w3c/webvtt/pull/244
    //  Safari doesn't yet support this change, but FF and Chrome do.

    var center = defaults.align === 'middle' ? 'middle' : 'center';

    function parseCue(input, cue, regionList) {
      // Remember the original input if we need to throw an error.
      var oInput = input; // 4.1 WebVTT timestamp

      function consumeTimeStamp() {
        var ts = parseTimeStamp(input);

        if (ts === null) {
          throw new Error('Malformed timestamp: ' + oInput);
        } // Remove time stamp from input.


        input = input.replace(/^[^\sa-zA-Z-]+/, '');
        return ts;
      } // 4.4.2 WebVTT cue settings


      function consumeCueSettings(input, cue) {
        var settings = new Settings();
        parseOptions(input, function (k, v) {
          var vals;

          switch (k) {
            case 'region':
              // Find the last region we parsed with the same region id.
              for (var i = regionList.length - 1; i >= 0; i--) {
                if (regionList[i].id === v) {
                  settings.set(k, regionList[i].region);
                  break;
                }
              }

              break;

            case 'vertical':
              settings.alt(k, v, ['rl', 'lr']);
              break;

            case 'line':
              vals = v.split(',');
              settings.integer(k, vals[0]);

              if (settings.percent(k, vals[0])) {
                settings.set('snapToLines', false);
              }

              settings.alt(k, vals[0], ['auto']);

              if (vals.length === 2) {
                settings.alt('lineAlign', vals[1], ['start', center, 'end']);
              }

              break;

            case 'position':
              vals = v.split(',');
              settings.percent(k, vals[0]);

              if (vals.length === 2) {
                settings.alt('positionAlign', vals[1], ['start', center, 'end', 'line-left', 'line-right', 'auto']);
              }

              break;

            case 'size':
              settings.percent(k, v);
              break;

            case 'align':
              settings.alt(k, v, ['start', center, 'end', 'left', 'right']);
              break;
          }
        }, /:/, /\s/); // Apply default values for any missing fields.

        cue.region = settings.get('region', null);
        cue.vertical = settings.get('vertical', '');
        var line = settings.get('line', 'auto');

        if (line === 'auto' && defaults.line === -1) {
          // set numeric line number for Safari
          line = -1;
        }

        cue.line = line;
        cue.lineAlign = settings.get('lineAlign', 'start');
        cue.snapToLines = settings.get('snapToLines', true);
        cue.size = settings.get('size', 100);
        cue.align = settings.get('align', center);
        var position = settings.get('position', 'auto');

        if (position === 'auto' && defaults.position === 50) {
          // set numeric position for Safari
          position = cue.align === 'start' || cue.align === 'left' ? 0 : cue.align === 'end' || cue.align === 'right' ? 100 : 50;
        }

        cue.position = position;
      }

      function skipWhitespace() {
        input = input.replace(/^\s+/, '');
      } // 4.1 WebVTT cue timings.


      skipWhitespace();
      cue.startTime = consumeTimeStamp(); // (1) collect cue start time

      skipWhitespace();

      if (input.substr(0, 3) !== '-->') {
        // (3) next characters must match '-->'
        throw new Error("Malformed time stamp (time stamps must be separated by '-->'): " + oInput);
      }

      input = input.substr(3);
      skipWhitespace();
      cue.endTime = consumeTimeStamp(); // (5) collect cue end time
      // 4.1 WebVTT cue settings list.

      skipWhitespace();
      consumeCueSettings(input, cue);
    }

    function fixLineBreaks(input) {
      return input.replace(/<br(?: \/)?>/gi, '\n');
    }
    var VTTParser = /*#__PURE__*/function () {
      function VTTParser() {
        this.state = 'INITIAL';
        this.buffer = '';
        this.decoder = new StringDecoder();
        this.regionList = [];
        this.cue = null;
        this.oncue = void 0;
        this.onparsingerror = void 0;
        this.onflush = void 0;
      }

      var _proto3 = VTTParser.prototype;

      _proto3.parse = function parse(data) {
        var _this = this; // If there is no data then we won't decode it, but will just try to parse
        // whatever is in buffer already. This may occur in circumstances, for
        // example when flush() is called.


        if (data) {
          // Try to decode the data that we received.
          _this.buffer += _this.decoder.decode(data, {
            stream: true
          });
        }

        function collectNextLine() {
          var buffer = _this.buffer;
          var pos = 0;
          buffer = fixLineBreaks(buffer);

          while (pos < buffer.length && buffer[pos] !== '\r' && buffer[pos] !== '\n') {
            ++pos;
          }

          var line = buffer.substr(0, pos); // Advance the buffer early in case we fail below.

          if (buffer[pos] === '\r') {
            ++pos;
          }

          if (buffer[pos] === '\n') {
            ++pos;
          }

          _this.buffer = buffer.substr(pos);
          return line;
        } // 3.2 WebVTT metadata header syntax


        function parseHeader(input) {
          parseOptions(input, function (k, v) {// switch (k) {
            // case 'region':
            // 3.3 WebVTT region metadata header syntax
            // console.log('parse region', v);
            // parseRegion(v);
            // break;
            // }
          }, /:/);
        } // 5.1 WebVTT file parsing.


        try {
          var line = '';

          if (_this.state === 'INITIAL') {
            // We can't start parsing until we have the first line.
            if (!/\r\n|\n/.test(_this.buffer)) {
              return this;
            }

            line = collectNextLine(); // strip of UTF-8 BOM if any
            // https://en.wikipedia.org/wiki/Byte_order_mark#UTF-8

            var m = line.match(/^(ï»¿)?WEBVTT([ \t].*)?$/);

            if (!m || !m[0]) {
              throw new Error('Malformed WebVTT signature.');
            }

            _this.state = 'HEADER';
          }

          var alreadyCollectedLine = false;

          while (_this.buffer) {
            // We can't parse a line until we have the full line.
            if (!/\r\n|\n/.test(_this.buffer)) {
              return this;
            }

            if (!alreadyCollectedLine) {
              line = collectNextLine();
            } else {
              alreadyCollectedLine = false;
            }

            switch (_this.state) {
              case 'HEADER':
                // 13-18 - Allow a header (metadata) under the WEBVTT line.
                if (/:/.test(line)) {
                  parseHeader(line);
                } else if (!line) {
                  // An empty line terminates the header and starts the body (cues).
                  _this.state = 'ID';
                }

                continue;

              case 'NOTE':
                // Ignore NOTE blocks.
                if (!line) {
                  _this.state = 'ID';
                }

                continue;

              case 'ID':
                // Check for the start of NOTE blocks.
                if (/^NOTE($|[ \t])/.test(line)) {
                  _this.state = 'NOTE';
                  break;
                } // 19-29 - Allow any number of line terminators, then initialize new cue values.


                if (!line) {
                  continue;
                }

                _this.cue = new _vttcue__WEBPACK_IMPORTED_MODULE_0__["default"](0, 0, '');
                _this.state = 'CUE'; // 30-39 - Check if self line contains an optional identifier or timing data.

                if (line.indexOf('-->') === -1) {
                  _this.cue.id = line;
                  continue;
                }

              // Process line as start of a cue.

              /* falls through */

              case 'CUE':
                // 40 - Collect cue timings and settings.
                if (!_this.cue) {
                  _this.state = 'BADCUE';
                  continue;
                }

                try {
                  parseCue(line, _this.cue, _this.regionList);
                } catch (e) {
                  // In case of an error ignore rest of the cue.
                  _this.cue = null;
                  _this.state = 'BADCUE';
                  continue;
                }

                _this.state = 'CUETEXT';
                continue;

              case 'CUETEXT':
                {
                  var hasSubstring = line.indexOf('-->') !== -1; // 34 - If we have an empty line then report the cue.
                  // 35 - If we have the special substring '-->' then report the cue,
                  // but do not collect the line as we need to process the current
                  // one as a new cue.

                  if (!line || hasSubstring && (alreadyCollectedLine = true)) {
                    // We are done parsing self cue.
                    if (_this.oncue && _this.cue) {
                      _this.oncue(_this.cue);
                    }

                    _this.cue = null;
                    _this.state = 'ID';
                    continue;
                  }

                  if (_this.cue === null) {
                    continue;
                  }

                  if (_this.cue.text) {
                    _this.cue.text += '\n';
                  }

                  _this.cue.text += line;
                }
                continue;

              case 'BADCUE':
                // 54-62 - Collect and discard the remaining cue.
                if (!line) {
                  _this.state = 'ID';
                }

            }
          }
        } catch (e) {
          // If we are currently parsing a cue, report what we have.
          if (_this.state === 'CUETEXT' && _this.cue && _this.oncue) {
            _this.oncue(_this.cue);
          }

          _this.cue = null; // Enter BADWEBVTT state if header was not parsed correctly otherwise
          // another exception occurred so enter BADCUE state.

          _this.state = _this.state === 'INITIAL' ? 'BADWEBVTT' : 'BADCUE';
        }

        return this;
      };

      _proto3.flush = function flush() {
        var _this = this;

        try {
          // Finish decoding the stream.
          // _this.buffer += _this.decoder.decode();
          // Synthesize the end of the current cue or region.
          if (_this.cue || _this.state === 'HEADER') {
            _this.buffer += '\n\n';

            _this.parse();
          } // If we've flushed, parsed, and we're still on the INITIAL state then
          // that means we don't have enough of the stream to parse the first
          // line.


          if (_this.state === 'INITIAL' || _this.state === 'BADWEBVTT') {
            throw new Error('Malformed WebVTT signature.');
          }
        } catch (e) {
          if (_this.onparsingerror) {
            _this.onparsingerror(e);
          }
        }

        if (_this.onflush) {
          _this.onflush();
        }

        return this;
      };

      return VTTParser;
    }();

    /***/ }),

    /***/ "./src/utils/webvtt-parser.ts":
    /*!************************************!*\
      !*** ./src/utils/webvtt-parser.ts ***!
      \************************************/
    /*! exports provided: generateCueId, parseWebVTT */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "generateCueId", function() { return generateCueId; });
    /* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parseWebVTT", function() { return parseWebVTT; });
    /* harmony import */ var _home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/polyfills/number */ "./src/polyfills/number.ts");
    /* harmony import */ var _vttparser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./vttparser */ "./src/utils/vttparser.ts");
    /* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
    /* harmony import */ var _timescale_conversion__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./timescale-conversion */ "./src/utils/timescale-conversion.ts");
    /* harmony import */ var _remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../remux/mp4-remuxer */ "./src/remux/mp4-remuxer.ts");








    var LINEBREAKS = /\r\n|\n\r|\n|\r/g; // String.prototype.startsWith is not supported in IE11

    var startsWith = function startsWith(inputString, searchString, position) {
      if (position === void 0) {
        position = 0;
      }

      return inputString.substr(position, searchString.length) === searchString;
    };

    var cueString2millis = function cueString2millis(timeString) {
      var ts = parseInt(timeString.substr(-3));
      var secs = parseInt(timeString.substr(-6, 2));
      var mins = parseInt(timeString.substr(-9, 2));
      var hours = timeString.length > 9 ? parseInt(timeString.substr(0, timeString.indexOf(':'))) : 0;

      if (!Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(ts) || !Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(secs) || !Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(mins) || !Object(_home_runner_work_hls_js_hls_js_src_polyfills_number__WEBPACK_IMPORTED_MODULE_0__["isFiniteNumber"])(hours)) {
        throw Error("Malformed X-TIMESTAMP-MAP: Local:" + timeString);
      }

      ts += 1000 * secs;
      ts += 60 * 1000 * mins;
      ts += 60 * 60 * 1000 * hours;
      return ts;
    }; // From https://github.com/darkskyapp/string-hash


    var hash = function hash(text) {
      var hash = 5381;
      var i = text.length;

      while (i) {
        hash = hash * 33 ^ text.charCodeAt(--i);
      }

      return (hash >>> 0).toString();
    }; // Create a unique hash id for a cue based on start/end times and text.
    // This helps timeline-controller to avoid showing repeated captions.


    function generateCueId(startTime, endTime, text) {
      return hash(startTime.toString()) + hash(endTime.toString()) + hash(text);
    }

    var calculateOffset = function calculateOffset(vttCCs, cc, presentationTime) {
      var currCC = vttCCs[cc];
      var prevCC = vttCCs[currCC.prevCC]; // This is the first discontinuity or cues have been processed since the last discontinuity
      // Offset = current discontinuity time

      if (!prevCC || !prevCC.new && currCC.new) {
        vttCCs.ccOffset = vttCCs.presentationOffset = currCC.start;
        currCC.new = false;
        return;
      } // There have been discontinuities since cues were last parsed.
      // Offset = time elapsed


      while ((_prevCC = prevCC) !== null && _prevCC !== void 0 && _prevCC.new) {
        var _prevCC;

        vttCCs.ccOffset += currCC.start - prevCC.start;
        currCC.new = false;
        currCC = prevCC;
        prevCC = vttCCs[currCC.prevCC];
      }

      vttCCs.presentationOffset = presentationTime;
    };

    function parseWebVTT(vttByteArray, initPTS, timescale, vttCCs, cc, timeOffset, callBack, errorCallBack) {
      var parser = new _vttparser__WEBPACK_IMPORTED_MODULE_1__["VTTParser"](); // Convert byteArray into string, replacing any somewhat exotic linefeeds with "\n", then split on that character.
      // Uint8Array.prototype.reduce is not implemented in IE11

      var vttLines = Object(_demux_id3__WEBPACK_IMPORTED_MODULE_2__["utf8ArrayToStr"])(new Uint8Array(vttByteArray)).trim().replace(LINEBREAKS, '\n').split('\n');
      var cues = [];
      var initPTS90Hz = Object(_timescale_conversion__WEBPACK_IMPORTED_MODULE_3__["toMpegTsClockFromTimescale"])(initPTS, timescale);
      var cueTime = '00:00.000';
      var timestampMapMPEGTS = 0;
      var timestampMapLOCAL = 0;
      var parsingError;
      var inHeader = true;
      var timestampMap = false;

      parser.oncue = function (cue) {
        // Adjust cue timing; clamp cues to start no earlier than - and drop cues that don't end after - 0 on timeline.
        var currCC = vttCCs[cc];
        var cueOffset = vttCCs.ccOffset; // Calculate subtitle PTS offset

        var webVttMpegTsMapOffset = (timestampMapMPEGTS - initPTS90Hz) / 90000; // Update offsets for new discontinuities

        if (currCC !== null && currCC !== void 0 && currCC.new) {
          if (timestampMapLOCAL !== undefined) {
            // When local time is provided, offset = discontinuity start time - local time
            cueOffset = vttCCs.ccOffset = currCC.start;
          } else {
            calculateOffset(vttCCs, cc, webVttMpegTsMapOffset);
          }
        }

        if (webVttMpegTsMapOffset) {
          // If we have MPEGTS, offset = presentation time + discontinuity offset
          cueOffset = webVttMpegTsMapOffset - vttCCs.presentationOffset;
        }

        if (timestampMap) {
          var duration = cue.endTime - cue.startTime;
          var startTime = Object(_remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_4__["normalizePts"])((cue.startTime + cueOffset - timestampMapLOCAL) * 90000, timeOffset * 90000) / 90000;
          cue.startTime = startTime;
          cue.endTime = startTime + duration;
        } //trim trailing webvtt block whitespaces


        var text = cue.text.trim(); // Fix encoding of special characters

        cue.text = decodeURIComponent(encodeURIComponent(text)); // If the cue was not assigned an id from the VTT file (line above the content), create one.

        if (!cue.id) {
          cue.id = generateCueId(cue.startTime, cue.endTime, text);
        }

        if (cue.endTime > 0) {
          cues.push(cue);
        }
      };

      parser.onparsingerror = function (error) {
        parsingError = error;
      };

      parser.onflush = function () {
        if (parsingError) {
          errorCallBack(parsingError);
          return;
        }

        callBack(cues);
      }; // Go through contents line by line.


      vttLines.forEach(function (line) {
        if (inHeader) {
          // Look for X-TIMESTAMP-MAP in header.
          if (startsWith(line, 'X-TIMESTAMP-MAP=')) {
            // Once found, no more are allowed anyway, so stop searching.
            inHeader = false;
            timestampMap = true; // Extract LOCAL and MPEGTS.

            line.substr(16).split(',').forEach(function (timestamp) {
              if (startsWith(timestamp, 'LOCAL:')) {
                cueTime = timestamp.substr(6);
              } else if (startsWith(timestamp, 'MPEGTS:')) {
                timestampMapMPEGTS = parseInt(timestamp.substr(7));
              }
            });

            try {
              // Convert cue time to seconds
              timestampMapLOCAL = cueString2millis(cueTime) / 1000;
            } catch (error) {
              timestampMap = false;
              parsingError = error;
            } // Return without parsing X-TIMESTAMP-MAP line.


            return;
          } else if (line === '') {
            inHeader = false;
          }
        } // Parse line by default.


        parser.parse(line + '\n');
      });
      parser.flush();
    }

    /***/ }),

    /***/ "./src/utils/xhr-loader.ts":
    /*!*********************************!*\
      !*** ./src/utils/xhr-loader.ts ***!
      \*********************************/
    /*! exports provided: default */
    /***/ (function(module, __webpack_exports__, __webpack_require__) {
    __webpack_require__.r(__webpack_exports__);
    /* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
    /* harmony import */ var _loader_load_stats__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../loader/load-stats */ "./src/loader/load-stats.ts");


    var AGE_HEADER_LINE_REGEX = /^age:\s*[\d.]+\s*$/m;

    var XhrLoader = /*#__PURE__*/function () {
      function XhrLoader(config
      /* HlsConfig */
      ) {
        this.xhrSetup = void 0;
        this.requestTimeout = void 0;
        this.retryTimeout = void 0;
        this.retryDelay = void 0;
        this.config = null;
        this.callbacks = null;
        this.context = void 0;
        this.loader = null;
        this.stats = void 0;
        this.xhrSetup = config ? config.xhrSetup : null;
        this.stats = new _loader_load_stats__WEBPACK_IMPORTED_MODULE_1__["LoadStats"]();
        this.retryDelay = 0;
      }

      var _proto = XhrLoader.prototype;

      _proto.destroy = function destroy() {
        this.callbacks = null;
        this.abortInternal();
        this.loader = null;
        this.config = null;
      };

      _proto.abortInternal = function abortInternal() {
        var loader = this.loader;
        self.clearTimeout(this.requestTimeout);
        self.clearTimeout(this.retryTimeout);

        if (loader) {
          loader.onreadystatechange = null;
          loader.onprogress = null;

          if (loader.readyState !== 4) {
            this.stats.aborted = true;
            loader.abort();
          }
        }
      };

      _proto.abort = function abort() {
        var _this$callbacks;

        this.abortInternal();

        if ((_this$callbacks = this.callbacks) !== null && _this$callbacks !== void 0 && _this$callbacks.onAbort) {
          this.callbacks.onAbort(this.stats, this.context, this.loader);
        }
      };

      _proto.load = function load(context, config, callbacks) {
        if (this.stats.loading.start) {
          throw new Error('Loader can only be used once.');
        }

        this.stats.loading.start = self.performance.now();
        this.context = context;
        this.config = config;
        this.callbacks = callbacks;
        this.retryDelay = config.retryDelay;
        this.loadInternal();
      };

      _proto.loadInternal = function loadInternal() {
        var config = this.config,
            context = this.context;

        if (!config) {
          return;
        }

        var xhr = this.loader = new self.XMLHttpRequest();
        var stats = this.stats;
        stats.loading.first = 0;
        stats.loaded = 0;
        var xhrSetup = this.xhrSetup;

        try {
          if (xhrSetup) {
            try {
              xhrSetup(xhr, context.url);
            } catch (e) {
              // fix xhrSetup: (xhr, url) => {xhr.setRequestHeader("Content-Language", "test");}
              // not working, as xhr.setRequestHeader expects xhr.readyState === OPEN
              xhr.open('GET', context.url, true);
              xhrSetup(xhr, context.url);
            }
          }

          if (!xhr.readyState) {
            xhr.open('GET', context.url, true);
          }

          var headers = this.context.headers;

          if (headers) {
            for (var header in headers) {
              xhr.setRequestHeader(header, headers[header]);
            }
          }
        } catch (e) {
          // IE11 throws an exception on xhr.open if attempting to access an HTTP resource over HTTPS
          this.callbacks.onError({
            code: xhr.status,
            text: e.message
          }, context, xhr);
          return;
        }

        if (context.rangeEnd) {
          xhr.setRequestHeader('Range', 'bytes=' + context.rangeStart + '-' + (context.rangeEnd - 1));
        }

        xhr.onreadystatechange = this.readystatechange.bind(this);
        xhr.onprogress = this.loadprogress.bind(this);
        xhr.responseType = context.responseType; // setup timeout before we perform request

        self.clearTimeout(this.requestTimeout);
        this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.timeout);
        xhr.send();
      };

      _proto.readystatechange = function readystatechange() {
        var context = this.context,
            xhr = this.loader,
            stats = this.stats;

        if (!context || !xhr) {
          return;
        }

        var readyState = xhr.readyState;
        var config = this.config; // don't proceed if xhr has been aborted

        if (stats.aborted) {
          return;
        } // >= HEADERS_RECEIVED


        if (readyState >= 2) {
          // clear xhr timeout and rearm it if readyState less than 4
          self.clearTimeout(this.requestTimeout);

          if (stats.loading.first === 0) {
            stats.loading.first = Math.max(self.performance.now(), stats.loading.start);
          }

          if (readyState === 4) {
            xhr.onreadystatechange = null;
            xhr.onprogress = null;
            var status = xhr.status; // http status between 200 to 299 are all successful

            if (status >= 200 && status < 300) {
              stats.loading.end = Math.max(self.performance.now(), stats.loading.first);
              var data;
              var len;

              if (context.responseType === 'arraybuffer') {
                data = xhr.response;
                len = data.byteLength;
              } else {
                data = xhr.responseText;
                len = data.length;
              }

              stats.loaded = stats.total = len;

              if (!this.callbacks) {
                return;
              }

              var onProgress = this.callbacks.onProgress;

              if (onProgress) {
                onProgress(stats, context, data, xhr);
              }

              if (!this.callbacks) {
                return;
              }

              var response = {
                url: xhr.responseURL,
                data: data
              };
              this.callbacks.onSuccess(response, stats, context, xhr);
            } else {
              // if max nb of retries reached or if http status between 400 and 499 (such error cannot be recovered, retrying is useless), return error
              if (stats.retry >= config.maxRetry || status >= 400 && status < 499) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_0__["logger"].error(status + " while loading " + context.url);
                this.callbacks.onError({
                  code: status,
                  text: xhr.statusText
                }, context, xhr);
              } else {
                // retry
                _utils_logger__WEBPACK_IMPORTED_MODULE_0__["logger"].warn(status + " while loading " + context.url + ", retrying in " + this.retryDelay + "..."); // abort and reset internal state

                this.abortInternal();
                this.loader = null; // schedule retry

                self.clearTimeout(this.retryTimeout);
                this.retryTimeout = self.setTimeout(this.loadInternal.bind(this), this.retryDelay); // set exponential backoff

                this.retryDelay = Math.min(2 * this.retryDelay, config.maxRetryDelay);
                stats.retry++;
              }
            }
          } else {
            // readyState >= 2 AND readyState !==4 (readyState = HEADERS_RECEIVED || LOADING) rearm timeout as xhr not finished yet
            self.clearTimeout(this.requestTimeout);
            this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.timeout);
          }
        }
      };

      _proto.loadtimeout = function loadtimeout() {
        _utils_logger__WEBPACK_IMPORTED_MODULE_0__["logger"].warn("timeout while loading " + this.context.url);
        var callbacks = this.callbacks;

        if (callbacks) {
          this.abortInternal();
          callbacks.onTimeout(this.stats, this.context, this.loader);
        }
      };

      _proto.loadprogress = function loadprogress(event) {
        var stats = this.stats;
        stats.loaded = event.loaded;

        if (event.lengthComputable) {
          stats.total = event.total;
        }
      };

      _proto.getCacheAge = function getCacheAge() {
        var result = null;

        if (this.loader && AGE_HEADER_LINE_REGEX.test(this.loader.getAllResponseHeaders())) {
          var ageHeader = this.loader.getResponseHeader('age');
          result = ageHeader ? parseFloat(ageHeader) : null;
        }

        return result;
      };

      return XhrLoader;
    }();

    /* harmony default export */ __webpack_exports__["default"] = (XhrLoader);

    /***/ })

    /******/ })["default"];
    });

    });

    var Hls = unwrapExports(hls);

    class HlsDecoder extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        player._opt;
        this.canVideoPlay = false;
        this.$videoElement = null;
        this.canvasRenderInterval = null;
        this.bandwidthEstimateInterval = null;
        this.fpsInterval = null;
        this.hlsFps = 0;
        this.hlsPrevFrams = 0;
        this.isInitInfo = false;
        this.eventsDestroy = [];

        if (Hls.isSupported()) {
          this.$videoElement = this.player.video.$videoElement;
          this.hls = new Hls({// levelLoadingTimeOut: _config.loadingTimeout * 1000,
            // levelLoadingMaxRetry: _config.loadingTimeoutReplayTimes,
            // maxBufferHole: 1,//
            // maxBufferLength: 2,
          });

          this._initHls();

          this._bindEvents();
        } else if (canPlayAppleMpegurl()) {
          this.$videoElement = this.player.video.$videoElement;
          this.canVideoPlay = true;
        } else {
          this.player.debug.error('HlsDecoder', 'init hls error ,not support ');
        }

        this.player.debug.log('HlsDecoder', 'init');
      }

      destroy() {
        if (this.hls) {
          this.hls.destroy();
          this.hls = null;
        }

        if (this.eventsDestroy.length) {
          this.eventsDestroy.forEach(event => event());
          this.eventsDestroy = [];
        }

        this.isInitInfo = false;

        this._stopCanvasRender();

        this._stopBandwidthEstimateInterval();

        this._stopFpsInterval();

        this.$videoElement = null;
        this.hlsFps = 0;
        this.player.debug.log('HlsDecoder', 'destroy');
      }

      checkHlsBufferedDelay() {
        const $video = this.$videoElement;
        let result = 0;
        const ranges = $video.buffered;
        const buffered = ranges.length ? ranges.end(ranges.length - 1) : 0;
        result = buffered - $video.currentTime;

        if (result < 0) {
          this.player.debug.warn('HlsDecoder', 'checkHlsBufferedDelay result < 0', result, buffered, $video.currentTime);
          result = 0;
        }

        return result;
      }

      getFps() {
        return this.hlsFps;
      }

      _startCanvasRender() {
        this._stopCanvasRender();

        this.canvasRenderInterval = setInterval(() => {
          this.player.video.render({
            $video: this.$videoElement,
            ts: 0
          });
        }, 1000 / 60);
      }

      _stopCanvasRender() {
        if (this.canvasRenderInterval) {
          clearInterval(this.canvasRenderInterval);
          this.canvasRenderInterval = null;
        }
      }

      _startBandwidthEstimateInterval() {
        this._stopBandwidthEstimateInterval();

        this.bandwidthEstimateInterval = setInterval(() => {
          let bandwidthEstimate = 0;

          if (this.hls.bandwidthEstimate) {
            bandwidthEstimate = this.hls.bandwidthEstimate; //console.log('bandwidthEstimate', bandwidthEstimate)
          }

          this.player.emit(EVENTS.kBps, (bandwidthEstimate / 1024 / 8 / 10).toFixed(2));
        }, 1 * 1000);
      }

      _stopBandwidthEstimateInterval() {
        if (this.bandwidthEstimateInterval) {
          clearInterval(this.bandwidthEstimateInterval);
          this.bandwidthEstimateInterval = null;
        }
      }

      _startFpsInterval() {
        this._stopCanvasRender();

        this.fpsInterval = setInterval(() => {
          const videoPlaybackQuality = this.$videoElement.getVideoPlaybackQuality();
          this.hlsFps = videoPlaybackQuality.totalVideoFrames - this.hlsPrevFrams;
          this.hlsPrevFrams = videoPlaybackQuality.totalVideoFrames;
        }, 1 * 1000);
      }

      _stopFpsInterval() {
        if (this.fpsInterval) {
          clearInterval(this.fpsInterval);
          this.fpsInterval = null;
        }
      }

      _initHls() {
        if (this.player._opt.useCanvasRender) {
          this.$videoElement = document.createElement('video');
          this.$videoElement.muted = true;

          if (isSafari()) {
            this.$videoElement.style.position = 'absolute';
          }

          this.initVideoEvents();
        }

        this.hls.attachMedia(this.$videoElement);
      }

      _bindEvents() {
        const player = this.player;
        const {
          proxy
        } = this.player.events;
        this.hls;
        const $videoElement = this.$videoElement;
        const timeUpdateDestroy = proxy($videoElement, VIDEO_ELEMENT_EVENTS.timeUpdate, event => {
          if (this.hls) {
            const timestamp = parseInt(event.timeStamp, 10);
            player.handleRender();
            player.updateStats({
              ts: timestamp,
              dts: timestamp
            }); //

            player.emit(EVENTS.videoTimeUpdate, timestamp);

            this._handleUpdatePlaybackRate();
          }
        }); // proxy($videoElement, VIDEO_ELEMENT_EVENTS.canplay, () => {
        //
        // })

        this.eventsDestroy.push(timeUpdateDestroy);

        this._startBandwidthEstimateInterval();

        this._startFpsInterval(); // error


        this.hls.on(Hls.Events.ERROR, (event, data) => {
          if (data.fatal) {
            switch (data.type) {
              case Hls.ErrorTypes.NETWORK_ERROR:
                // try to recover network error
                this.player.debug.error('HlsDecoder', 'fatal network error encountered, try to recover'); // 应调用以恢复网络错误。

                this.hls.startLoad();
                break;

              case Hls.ErrorTypes.MEDIA_ERROR:
                this.player.debug.error('HlsDecoder', 'fatal media error encountered, try to recover'); // 应调用以恢复媒体错误。

                this.hls.recoverMediaError();
                break;
            }
          }
        }); // 貌似没触发。。。

        this.hls.on(Hls.Events.MEDIA_ATTACHING, () => {// this.player.debug.log('HlsDecoder', 'MEDIA_ATTACHING');
        });
        this.hls.on(Hls.Events.MEDIA_ATTACHED, () => {// this.player.debug.log('HlsDecoder', 'MEDIA_ATTACHED');
        }); // 在媒体元素分解MediaSource之前被解雇

        this.hls.on(Hls.Events.MEDIA_DETACHING, () => {// this.player.debug.log('HlsDecoder', 'MEDIA_DETACHING');
        }); // 当MediaSource已经从媒体元素分离时触发

        this.hls.on(Hls.Events.MEDIA_DETACHED, () => {// this.player.debug.log('HlsDecoder', 'MEDIA_DETACHED');
        });
        this.hls.on(Hls.Events.BUFFER_RESET, () => {// this.player.debug.log('HlsDecoder', 'BUFFER_RESET');
        });
        this.hls.on(Hls.Events.BUFFER_CODECS, () => {// this.player.debug.log('HlsDecoder', 'BUFFER_CODECS');
        });
        this.hls.on(Hls.Events.BUFFER_CREATED, () => {// this.player.debug.log('HlsDecoder', 'BUFFER_CREATED');
        });
        this.hls.on(Hls.Events.BUFFER_APPENDING, (event, payload) => {
          this.player.debug.log('HlsDecoder', 'BUFFER_APPENDING', payload);
        });
        this.hls.on(Hls.Events.BUFFER_APPENDED, () => {// this.player.debug.log('HlsDecoder', 'BUFFER_APPENDED');
        });
        this.hls.on(Hls.Events.BUFFER_EOS, () => {// this.player.debug.log('HlsDecoder', 'fired when the stream is finished and we want to notify the media buffer that there will be no more data');
        });
        this.hls.on(Hls.Events.BUFFER_FLUSHING, () => {// this.player.debug.log('HlsDecoder', 'fired when the media buffer should be flushed');
        });
        this.hls.on(Hls.Events.BUFFER_FLUSHED, () => {// this.player.debug.log('HlsDecoder', 'fired when the media buffer has been flushed');
        }); // 开始加载playlist m3u8资源

        this.hls.on(Hls.Events.MANIFEST_LOADING, () => {
          this.player.debug.log('HlsDecoder', 'MANIFEST_LOADING 开始加载playlist m3u8资源');
        }); // playlist m3u8文件加载完成

        this.hls.on(Hls.Events.MANIFEST_LOADED, (event, data) => {
          this.player.debug.log('HlsDecoder', 'MANIFEST_LOADED playlist m3u8文件加载完成', data);
        }); // playlist m3u8解析完成

        this.hls.on(Hls.Events.MANIFEST_PARSED, () => {
          this.player.debug.log('HlsDecoder', 'MANIFEST_PARSED playlist m3u8解析完成'); // 模拟 demux 时间

          if (!player._times.demuxStart) {
            player._times.demuxStart = now$1();
          }
        }); // 加载特定码率的m3u8文件

        this.hls.on(Hls.Events.LEVEL_LOADING, () => {// this.player.debug.log('HlsDecoder', 'LEVEL_LOADING 加载特定码率的m3u8文件');
        }); // 特定码率的m3u8文件解析完成，拿到该码率对应的ts列表

        this.hls.on(Hls.Events.LEVEL_LOADED, (event, data) => {// this.player.debug.log('HlsDecoder', 'LEVEL_LOADED 特定码率的m3u8文件解析完成，拿到该码率对应的ts列表');
        }); //  开始加载某个ts分片文件，开始根据ts片下载时间预估带宽

        this.hls.on(Hls.Events.FRAG_LOADING, () => {// this.player.debug.log('HlsDecoder', 'FRAG_LOADING 开始加载某个ts分片文件，开始根据ts片下载时间预估带宽');
        }); // ts分片文件加载成功，开始转码

        this.hls.on(Hls.Events.FRAG_LOADED, (event, payload) => {
          // this.player.debug.log('HlsDecoder', 'FRAG_LOADED ts分片文件加载成功，开始转码');
          // 模拟 decode 时间
          if (!player._times.decodeStart) {
            player._times.decodeStart = now$1();
          } // this.player.debug.log('HlsDecoder', 'FRAG_LOADED', payload);
          // const frag = payload.frag || {}
          // const stats = payload.stats || {}
          // const buffering = stats.buffering || {};
          // this.player.debug.log('HlsDecoder', 'FRAG_LOADED buffering.end', buffering, buffering.end);
          // if (buffering.end) {
          //     this.player.updateStats({
          //         dts: buffering.end
          //     })
          // }

        }); // 视频流赋给video标签

        this.hls.on(Hls.Events.BUFFER_APPENDING, () => {
          // this.player.debug.log('HlsDecoder', 'BUFFER_APPENDING 视频流赋给video标签');
          if (!player._times.videoStart) {
            player._times.videoStart = now$1();
            player.handlePlayToRenderTimes();
          }
        });
        this.hls.on(Hls.Events.FRAG_DECRYPTED, () => {// this.player.debug.log('HlsDecoder', 'FRAG_DECRYPTED fired when a fragment decryption is completed');
        });
        this.hls.on(Hls.Events.KEY_LOADING, () => {// this.player.debug.log('HlsDecoder', 'KEY_LOADING fired when a decryption key loading starts');
        });
        this.hls.on(Hls.Events.KEY_LOADING, () => {// this.player.debug.log('HlsDecoder', 'KEY_LOADING fired when a fragment decryption is completed');
        });
        this.hls.on(Hls.Events.FPS_DROP, data => {// this.player.debug.log('HlsDecoder', 'FPS_DROP', data);
        });
        this.hls.on(Hls.Events.FPS_DROP_LEVEL_CAPPING, data => {// this.player.debug.log('HlsDecoder', 'FPS_DROP_LEVEL_CAPPING', data);
        }); // fired when Init Segment has been extracted from fragment

        this.hls.on(Hls.Events.FRAG_PARSING_INIT_SEGMENT, (id, payload) => {
          this.player.debug.log('HlsDecoder', 'FRAG_PARSING_INIT_SEGMENT', payload);
          const hasAudio = payload && payload.tracks && payload.tracks.audio ? true : false;
          const hasVideo = payload && payload.tracks && payload.tracks.video ? true : false;

          if (hasAudio && payload.tracks.audio) {
            let track = payload.tracks.audio;
            const audioChannelCount = track.metadata && track.metadata.channelCount ? track.metadata.channelCount : 0;
            const audioCodec = track.codec;
            this.player.audio && this.player.audio.updateAudioInfo({
              encType: audioCodec,
              channels: audioChannelCount,
              sampleRate: 44100 // default audioContext.sampleRate

            });
          }

          if (hasVideo && payload.tracks.video) {
            let track = payload.tracks.video;
            let videoCodec = track.codec;
            let width = track.metadata && track.metadata.width ? track.metadata.width : 0;
            let height = track.metadata && track.metadata.height ? track.metadata.height : 0;
            this.player.video && this.player.video.updateVideoInfo({
              encTypeCode: videoCodec.indexOf('avc') !== -1 ? VIDEO_ENC_CODE.h264 : VIDEO_ENC_CODE.h265,
              width,
              height
            });
          }
        });
      }

      initVideoPlay(url) {
        if (this.player._opt.useCanvasRender) {
          this.$videoElement = document.createElement('video');
          this.initVideoEvents();
        }

        this.$videoElement.muted = true;
        this.$videoElement.src = url;
      }

      initRenderSize() {
        if (!this.isInitInfo) {
          this.player.video.updateVideoInfo({
            width: this.$videoElement.videoWidth,
            height: this.$videoElement.videoHeight
          });
          this.player.video.initCanvasViewSize();
          this.isInitInfo = true;
        }
      }

      initVideoEvents() {
        const {
          proxy
        } = this.player.events;
        const canPlayDestroy = proxy(this.$videoElement, VIDEO_ELEMENT_EVENTS.canplay, () => {
          this.player.debug.log('HlsDecoder', 'video canplay');
          this.$videoElement.play().then(() => {
            this.player.debug.log('HlsDecoder', 'video play');

            this._startCanvasRender();

            this.initRenderSize();
          }).catch(e => {
            this.player.debug.warn('HlsDecoder', 'video play error ', e);
          });
        });
        const waitingDestroy = proxy(this.$videoElement, VIDEO_ELEMENT_EVENTS.waiting, () => {
          // this.player.emit(EVENTS.videoWaiting);
          this.player.debug.log('HlsDecoder', 'video waiting');
        });
        const timeUpdateDestroy = proxy(this.$videoElement, VIDEO_ELEMENT_EVENTS.timeUpdate, event => {
          const timeStamp = parseInt(event.timeStamp, 10);
          this.player.handleRender();
          this.player.updateStats({
            ts: timeStamp
          });
          this.player.emit(EVENTS.videoTimeUpdate, timeStamp);
        });
        const rateChangeDestroy = proxy(this.$videoElement, VIDEO_ELEMENT_EVENTS.ratechange, () => {
          this.player.debug.log('HlsDecoder', 'video playback Rate change', this.$videoElement && this.$videoElement.playbackRate);
        });
        this.eventsDestroy.push(canPlayDestroy, waitingDestroy, timeUpdateDestroy, rateChangeDestroy);
      }

      loadSource(url) {
        return new Promise((resolve, reject) => {
          if (this.canVideoPlay) {
            this.initVideoPlay(url);
            resolve();
          } else {
            this.hls.on(Hls.Events.MEDIA_ATTACHED, () => {
              this.hls.loadSource(url); // this.hls.on(Hls.Events.MANIFEST_PARSED, function () {
              //     resolve()
              // })

              resolve();
            });
          }
        });
      }

      _handleUpdatePlaybackRate() {
        if (!this.$videoElement) {
          return;
        }

        const $video = this.$videoElement;
        const videoBuffer = this.player._opt.videoBuffer;
        const videoBufferDelay = this.player._opt.videoBufferDelay;
        let maxDelay = (videoBuffer + videoBufferDelay) / 1000;
        const ranges = $video.buffered;
        ranges.length ? ranges.start(0) : 0;
        const buffered = ranges.length ? ranges.end(ranges.length - 1) : 0;
        let time = $video.currentTime;
        const buffer = buffered - time;
        const maxDelayTime = Math.max(MSE_MAX_DELAY_TIME, maxDelay + MSE_DELAY_INCREASE_TIME);

        if (buffer > maxDelayTime) {
          this.player.debug.warn('HlsDecoder', `handleUpdatePlaybackRate and delay buffer is more than ${maxDelayTime} is ${buffer} and new time is ${buffered} `);
          $video.currentTime = buffered;
          time = $video.currentTime;
        } else if (buffer < 0) {
          this.player.debug.warn('HlsDecoder', `handleUpdatePlaybackRate and delay buffer is less than 0 is ${buffer} and new time is ${buffered}`);
          $video.currentTime = buffered;
          time = $video.currentTime;
        }

        const rate = this._getPlaybackRate(buffered - time);

        if ($video.playbackRate !== rate) {
          $video.playbackRate = rate;
        }
      }

      _getPlaybackRate(buffer) {
        const $video = this.$videoElement;
        const videoBuffer = this.player._opt.videoBuffer;
        const videoBufferDelay = this.player._opt.videoBufferDelay;
        const maxDelay = videoBuffer + videoBufferDelay;
        buffer = buffer * 1000;

        switch ($video.playbackRate) {
          case 1:
            if (buffer > maxDelay) {
              return 1.2;
            }

            return 1;

          default:
            if (buffer <= videoBuffer) {
              return 1;
            }

            return $video.playbackRate;
        }
      }

      getDecodePlaybackRate() {
        let result = 0;
        const $video = this.$videoElement;

        if ($video) {
          result = $video.playbackRate;
        }

        return result;
      }

    }

    // a simple ajax
    var jsonType = 'application/json, text/javascript';
    var htmlType = 'text/html';
    var xmlTypeRE = /^(?:text|application)\/xml/i;
    var rheaders = /^(.*?):[ \t]*([^\r\n]*)\r?$/mg;
    var rurl = /^([\w.+-]+:)(?:\/\/(?:[^\/?#]*@|)([^\/?#:]*)(?::(\d+)|)|)/;
    var blankRE = /^\s*$/; // \s

    var lastModified = {};
    var etag = {};
    var responseHeadersString = '';
    var responseHeaders;
    /*
     * default setting
     * */

    var _settings = {
      type: "GET",
      beforeSend: noop,
      success: noop,
      error: noop,
      complete: noop,
      context: null,
      xhr: function () {
        return new window.XMLHttpRequest();
      },
      accepts: {
        json: jsonType,
        xml: 'application/xml, text/xml',
        html: htmlType,
        text: 'text/plain',
        '*': "*/".concat("*")
      },
      crossDomain: false,
      timeout: 0,
      username: null,
      password: null,
      processData: true,
      promise: noop,
      contentType: 'application/x-www-form-urlencoded; charset=UTF-8'
    };

    function noop() {}

    var ajax = function (url, options) {
      if (typeof url === 'object') {
        options = url;
        url = undefined;
      }

      options = options || {}; //

      var settings = extend({}, options); //

      for (var key in _settings) {
        if (settings[key] === undefined) {
          settings[key] = _settings[key];
        }
      } //


      try {
        var q = {};
        var promise = new Promise(function (resolve, reject) {
          q.resolve = resolve;
          q.reject = reject;
        });
        promise.resolve = q.resolve;
        promise.reject = q.reject;
        settings.promise = promise;
      } catch (e) {
        //
        settings.promise = {
          resolve: noop,
          reject: noop
        };
      } // url


      var ajaxLocParts = rurl.exec(window.location.href.toLowerCase()) || [];
      settings.url = ((url || settings.url || window.location.href) + '').replace(/#.*$/, '').replace(/^\/\//, ajaxLocParts[1] + "//");
      var cacheURL = settings.url; // cross domain

      if (!settings.crossDomain) {
        settings.crossDomain = /^([\w-]+:)?\/\/([^\/]+)/.test(settings.url) && RegExp.$2 !== window.location.href;
      } //


      var dataType = settings.dataType; // jsonp

      if (dataType === 'jsonp') {
        //
        var hasPlaceholder = /=\?/.test(settings.url);

        if (!hasPlaceholder) {
          var jsonpCallback = (settings.jsonp || 'callback') + '=?';
          settings.url = appendQuery(settings.url, jsonpCallback);
        }

        return JSONP(settings);
      } //


      serializeData(settings);
      var mime = settings.accepts[dataType] || settings.accepts['*']; // mime

      var baseHeader = {}; // header

      /^([\w-]+:)\/\//.test(settings.url) ? RegExp.$1 : window.location.protocol; // protocol

      var xhr = _settings.xhr();

      var abortTimeout; // X-Requested-With header
      // For cross-domain requests, seeing as conditions for a preflight are
      // akin to a jigsaw puzzle, we simply never set it to be sure.
      // (it can always be set on a per-request basis or even using ajaxSetup)
      // For same-domain requests, won't change header if already provided.

      if (!settings.crossDomain && !baseHeader['X-Requested-With']) {
        baseHeader['X-Requested-With'] = 'XMLHttpRequest';
      } // Set the If-Modified-Since and/or If-None-Match header, if in ifModified mode.


      if (settings.ifModified) {
        if (lastModified[cacheURL]) {
          baseHeader['If-Modified-Since'] = lastModified[cacheURL];
        }

        if (etag[cacheURL]) {
          baseHeader['If-None-Match'] = etag[cacheURL];
        }
      } // mime


      if (mime) {
        //
        baseHeader['Accept'] = mime;

        if (mime.indexOf(',') > -1) {
          mime = mime.split(',', 2)[0];
        } //


        xhr.overrideMimeType && xhr.overrideMimeType(mime);
      } // not get and not head


      var hasContent = !/^(?:GET|HEAD)$/.test(settings.type.toUpperCase()); //

      if (settings.data && hasContent && settings.contentType !== false || options.contentType) {
        baseHeader['Content-Type'] = settings.contentType;
      } // cache: default true


      if (settings.cache === false && !hasContent) {
        var rts = /([?&])_=[^&]*/;
        settings.url = rts.test(cacheURL) ? cacheURL.replace(rts, "$1_=" + now()) : cacheURL + (/\?/.test(cacheURL) ? "&" : "?") + "_=" + now();
      } // headers


      settings.headers = extend(baseHeader, settings.headers || {}); // on ready state change

      xhr.onreadystatechange = function () {
        // readystate
        if (xhr.readyState === 4) {
          clearTimeout(abortTimeout);
          var result;
          var error = false;
          var isSuccess = xhr.status >= 200 && xhr.status < 300 || xhr.status === 304; //

          if (isSuccess) {
            responseHeadersString = xhr.getAllResponseHeaders();

            if (settings.ifModified) {
              var modified = getResponseHeader('Last-Modified');

              if (modified) {
                lastModified[cacheURL] = modified;
              }

              modified = getResponseHeader('etag');

              if (modified) {
                etag[cacheURL] = modified;
              }
            }

            dataType = dataType || mimeToDataType(xhr.getResponseHeader('content-type'));
            result = xhr.responseText;

            try {
              // xml
              if (dataType === 'xml') {
                result = xhr.responseXML;
              } // json
              else if (dataType === 'json') {
                result = blankRE.test(result) ? null : JSON.parse(result);
              }
            } catch (e) {
              error = e;
            }

            if (error) {
              ajaxError(error, 'parseerror', xhr, settings);
            } else {
              ajaxSuccess(result, xhr, settings);
            }
          } else {
            ajaxError(null, 'error', xhr, settings);
          }
        }
      }; // async


      var async = 'async' in settings ? settings.async : true; // open

      xhr.open(settings.type, settings.url, async, settings.username, settings.password); // xhrFields

      if (settings.xhrFields) {
        for (var name in settings.xhrFields) {
          xhr[name] = settings.xhrFields[name];
        }
      } // Override mime type if needed


      if (settings.mimeType && xhr.overrideMimeType) {
        xhr.overrideMimeType(settings.mimeType);
      } // set request header


      for (var name in settings.headers) {
        // Support: IE<9
        // IE's ActiveXObject throws a 'Type Mismatch' exception when setting
        // request header to a null-value.
        //
        // To keep consistent with other XHR implementations, cast the value
        // to string and ignore `undefined`.
        if (settings.headers[name] !== undefined) {
          xhr.setRequestHeader(name, settings.headers[name] + "");
        }
      } // before send


      if (ajaxBeforeSend(xhr, settings) === false) {
        xhr.abort();
        return false;
      } // timeout


      if (settings.timeout > 0) {
        abortTimeout = window.setTimeout(function () {
          xhr.onreadystatechange = noop;
          xhr.abort();
          ajaxError(null, 'timeout', xhr, settings);
        }, settings.timeout);
      } // send


      xhr.send(settings.data ? settings.data : null); // abort method

      settings.promise.abort = function () {
        xhr.abort();
      }; //


      return settings.promise;
    };
    /*
     * method  get
     * */


    ajax.get = function (url, data, success, dataType) {
      if (isFunction(data)) {
        dataType = dataType || success;
        success = data;
        data = undefined;
      }

      return ajax({
        url: url,
        data: data,
        success: success,
        dataType: dataType
      });
    };
    /*
     * method post
     *
     * dataType:
     * */


    ajax.post = function (url, data, success, dataType) {
      if (isFunction(data)) {
        dataType = dataType || success;
        success = data;
        data = undefined;
      }

      return ajax({
        type: 'POST',
        url: url,
        data: data,
        success: success,
        dataType: dataType
      });
    };
    /*
     * method getJSON
     * */


    ajax.getJSON = function (url, data, success) {
      if (isFunction(data)) {
        success = data;
        data = undefined;
      }

      return ajax({
        url: url,
        data: data,
        success: success,
        dataType: 'json'
      });
    };
    /*
     * method  ajaxSetup
     * */


    ajax.ajaxSetup = function (target, settings) {
      return settings ? extend(extend(target, _settings), settings) : extend(_settings, target);
    };
    /*
     * utils
     *
     * */
    // triggers and extra global event ajaxBeforeSend that's like ajaxSend but cancelable


    function ajaxBeforeSend(xhr, settings) {
      var context = settings.context; //

      if (settings.beforeSend.call(context, xhr, settings) === false) {
        return false;
      }
    } // ajax success


    function ajaxSuccess(data, xhr, settings) {
      var context = settings.context;
      var status = 'success';
      settings.success.call(context, data, status, xhr);
      settings.promise.resolve(data, status, xhr);
      ajaxComplete(status, xhr, settings);
    } // status: "success", "notmodified", "error", "timeout", "abort", "parsererror"


    function ajaxComplete(status, xhr, settings) {
      var context = settings.context;
      settings.complete.call(context, xhr, status);
    } // type: "timeout", "error", "abort", "parsererror"


    function ajaxError(error, type, xhr, settings) {
      var context = settings.context;
      settings.error.call(context, xhr, type, error);
      settings.promise.reject(xhr, type, error);
      ajaxComplete(type, xhr, settings);
    }

    function getResponseHeader(key) {
      var match;

      if (!responseHeaders) {
        responseHeaders = {};

        while (match = rheaders.exec(responseHeadersString)) {
          responseHeaders[match[1].toLowerCase()] = match[2];
        }

        match = responseHeaders[key.toLowerCase()];
      }

      return match === null ? null : match;
    } // jsonp

    /*
     * tks: https://www.cnblogs.com/rubylouvre/archive/2011/02/13/1953087.html
     * */


    function JSONP(options) {
      //
      var callbackName = options.jsonpCallback || 'jsonp' + now();
      var script = window.document.createElement('script');

      var abort = function () {
        // 设置 window.xxx = noop
        if (callbackName in window) {
          window[callbackName] = noop;
        }
      };

      var xhr = {
        abort: abort
      };
      var abortTimeout;
      var head = window.document.getElementsByTagName('head')[0] || window.document.documentElement; // ie8+

      script.onerror = function (error) {
        _error(error);
      };

      function _error(error) {
        window.clearTimeout(abortTimeout);
        xhr.abort();
        ajaxError(error.type, xhr, error.type, options);

        _removeScript();
      }

      window[callbackName] = function (data) {
        window.clearTimeout(abortTimeout);
        ajaxSuccess(data, xhr, options);

        _removeScript();
      }; //


      serializeData(options);
      script.src = options.url.replace(/=\?/, '=' + callbackName); //

      script.src = appendQuery(script.src, '_=' + new Date().getTime()); //

      script.async = true; // script charset

      if (options.scriptCharset) {
        script.charset = options.scriptCharset;
      } //


      head.insertBefore(script, head.firstChild); //

      if (options.timeout > 0) {
        abortTimeout = window.setTimeout(function () {
          xhr.abort();
          ajaxError('timeout', xhr, 'timeout', options);

          _removeScript();
        }, options.timeout);
      } // remove script


      function _removeScript() {
        if (script.clearAttributes) {
          script.clearAttributes();
        } else {
          script.onload = script.onreadystatechange = script.onerror = null;
        }

        if (script.parentNode) {
          script.parentNode.removeChild(script);
        } //


        script = null;
        delete window[callbackName];
      } // add abort


      options.promise.abort = function () {
        xhr.abort();
      }; // add xhr


      options.promise.xhr = xhr;
      return options.promise;
    } //  mime to data type


    function mimeToDataType(mime) {
      return mime && (mime === htmlType ? 'html' : mime === jsonType ? 'json' : xmlTypeRE.test(mime) && 'xml') || 'text';
    } // append query


    function appendQuery(url, query) {
      return (url + '&' + query).replace(/[&?]{1,2}/, '?');
    } // serialize data


    function serializeData(options) {
      // formData
      if (isObject(options) && !isFormData(options.data) && options.processData) {
        options.data = param(options.data);
      }

      if (options.data && (!options.type || options.type.toUpperCase() === 'GET')) {
        options.url = appendQuery(options.url, options.data);
      }
    } // serialize


    function serialize(params, obj, traditional, scope) {
      var _isArray = isArray(obj);

      for (var key in obj) {
        var value = obj[key];

        if (scope) {
          key = traditional ? scope : scope + '[' + (_isArray ? '' : key) + ']';
        } // handle data in serializeArray format


        if (!scope && _isArray) {
          params.add(value.name, value.value);
        } else if (traditional ? _isArray(value) : isObject(value)) {
          serialize(params, value, traditional, key);
        } else {
          params.add(key, value);
        }
      }
    } // param


    function param(obj, traditional) {
      var params = []; //

      params.add = function (k, v) {
        this.push(encodeURIComponent(k) + '=' + encodeURIComponent(v));
      };

      serialize(params, obj, traditional);
      return params.join('&').replace('%20', '+');
    } // extend


    function extend(target) {
      var slice = Array.prototype.slice;
      var args = slice.call(arguments, 1); //

      for (var i = 0, length = args.length; i < length; i++) {
        var source = args[i] || {};

        for (var key in source) {
          if (source.hasOwnProperty(key) && source[key] !== undefined) {
            target[key] = source[key];
          }
        }
      }

      return target;
    } // is object


    function isObject(obj) {
      var type = typeof obj;
      return type === 'function' || type === 'object' && !!obj;
    } // is formData


    function isFormData(obj) {
      return obj instanceof FormData;
    } // is array


    function isArray(value) {
      return Object.prototype.toString.call(value) === "[object Array]";
    } // is function


    function isFunction(value) {
      return typeof value === "function";
    }

    function now() {
      return new Date().getTime();
    }

    function getWebRtcRemoteSdp(url, data) {
      // return ajax({
      //     url,
      //     type: 'POST',
      //     data,
      //     contentType: 'application/sdp',
      //     processData: false
      // })
      return fetch(url, {
        method: 'POST',
        mode: 'cors',
        // no-cors, *cors, same-origin
        cache: 'no-cache',
        // *default, no-cache, reload, force-cache, only-if-cached
        credentials: 'include',
        // include, *same-origin, omit
        redirect: 'follow',
        // manual, *follow, error
        referrerPolicy: 'no-referrer',
        headers: {
          'Content-Type': 'application/sdp'
        },
        body: data
      });
    }
    function getWebRtcRemoteSdpForZLM(url, data) {
      return ajax({
        url,
        type: 'POST',
        data,
        contentType: 'text/plain;charset=utf-8',
        processData: false,
        dataType: 'json'
      });
    }

    class WebrtcDecoder extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.rtcPeerConnection = null;
        this.videoStream = null;

        this._initRtcPeerConnection();

        this.player.debug.log('WebrtcDecoder', 'init');
      }

      destroy() {
        if (this.rtcPeerConnection) {
          this.rtcPeerConnection.close();
          this.rtcPeerConnection = null;
        }

        this.videoStream = null;
        this.player.video.$videoElement.srcObject = null;
        this.player.debug.log('WebrtcDecoder', 'destroy');
      }

      _initRtcPeerConnection() {
        const rtcPeerConnection = new RTCPeerConnection();
        const player = this.player;
        rtcPeerConnection.addTransceiver("video", {
          direction: "recvonly"
        });
        rtcPeerConnection.addTransceiver("audio", {
          direction: "recvonly"
        });

        rtcPeerConnection.onsignalingstatechange = e => {
          this.player.debug.log('WebrtcDecoder', "onsignalingstatechange", e);
        };

        rtcPeerConnection.oniceconnectionstatechange = e => {
          this.player.debug.log('WebrtcDecoder', "oniceconnectionstatechange", rtcPeerConnection.iceConnectionState);
        };

        rtcPeerConnection.onicecandidate = event => {
          this.player.debug.log('WebrtcDecoder', "onicecandidate", event);
        };

        rtcPeerConnection.ontrack = event => {
          const $video = player.video.$videoElement;

          if (event.track.kind === 'video') {
            let videoStream = event.streams[0];
            $video.srcObject = videoStream;
            this.videoStream = videoStream;
          }
        };

        rtcPeerConnection.onconnectionstatechange = event => {
          player.debug.log('WebrtcDecoder', `sdp connect status ${rtcPeerConnection.connectionState}`);

          switch (rtcPeerConnection.connectionState) {
            case "connected":
              break;

            case "disconnected":
              player.emit(EVENTS.webrtcDisconnect);
              break;

            case "failed":
              player.emit(EVENTS.webrtcFailed);
              break;

            case "closed":
              player.emit(EVENTS.webrtcClosed);
              break;
          }
        };

        this.rtcPeerConnection = rtcPeerConnection;
      }

      loadSource(url) {
        return new Promise((resolve, reject) => {
          const rtcPeerConnection = this.rtcPeerConnection;
          rtcPeerConnection.createOffer().then(res => {
            rtcPeerConnection.setLocalDescription(res);
            this.player.debug.log('WebrtcDecoder', `getWebRtcRemoteSdp loadSource`);
            getWebRtcRemoteSdp(url, res.sdp).then(response => {
              response.text().then(sdp => {
                this.player.debug.log('WebrtcDecoder', `getWebRtcRemoteSdp response`);
                rtcPeerConnection.setRemoteDescription(new RTCSessionDescription({
                  type: "answer",
                  sdp
                }));
                resolve();
              }).catch(e => {
                this.player.debug.error('WebrtcDecoder', `loadSource response.text() error`, e);
                reject(e);
              });
            }).catch(e => {
              this.player.debug.error('WebrtcDecoder', `loadSource getWebRtcRemoteSdp response error`, e);
              reject(e);
            });
          }).catch(e => {
            this.player.debug.error('WebrtcDecoder', `loadSource rtcPeerConnection.createOffer() error`, e);
            reject(e);
          });
        });
      }

    }

    class WebrtcForZLMDecoder extends Emitter {
      constructor(player) {
        super();
        this.tagName = 'WebrtcForZLMDecoder';
        this.player = player;
        this.rtcPeerConnection = null;
        this.videoStream = null;

        this._initRtcPeerConnection();

        this.player.debug.log(this.tagName, 'init');
      }

      destroy() {
        if (this.rtcPeerConnection) {
          this.rtcPeerConnection.close();
          this.rtcPeerConnection = null;
        }

        if (this.videoStream) {
          this.videoStream.getTracks().forEach(track => track.stop());
          this.videoStream = null;
        }

        this.videoStream = null;
        this.player.video.$videoElement.srcObject = null;
        this.player.debug.log(this.tagName, 'destroy');
      }

      _initRtcPeerConnection() {
        const rtcPeerConnection = new RTCPeerConnection();
        const player = this.player;
        rtcPeerConnection.addTransceiver("video", {
          direction: "recvonly"
        });
        rtcPeerConnection.addTransceiver("audio", {
          direction: "recvonly"
        });

        rtcPeerConnection.onsignalingstatechange = e => {
          console.log("onsignalingstatechange", e);
        };

        rtcPeerConnection.oniceconnectionstatechange = e => {
          console.log("oniceconnectionstatechange", rtcPeerConnection.iceConnectionState);
        };

        rtcPeerConnection.onicecandidate = event => {
          console.log("onicecandidate", event);
        };

        rtcPeerConnection.ontrack = event => {
          const $video = player.video.$videoElement;
          console.log("ontrack", event);

          if (event.track.kind === 'video') {
            let videoStream = event.streams[0];
            $video.srcObject = videoStream;
            this.videoStream = videoStream;
          }
        };

        this.rtcPeerConnection = rtcPeerConnection;
      }

      loadSource(url) {
        return new Promise((resolve, reject) => {
          const rtcPeerConnection = this.rtcPeerConnection;
          rtcPeerConnection.createOffer().then(res => {
            rtcPeerConnection.setLocalDescription(res);
            this.player.debug.log(this.tagName, `getWebRtcRemoteSdp loadSource`);
            getWebRtcRemoteSdpForZLM(url, res.sdp).then(response => {
              this.player.debug.log(this.tagName, `getWebRtcRemoteSdp response`);
              const ret = response.data;

              if (ret.code !== 0) {
                return reject(ret.msg);
              }

              rtcPeerConnection.setRemoteDescription(new RTCSessionDescription({
                type: "answer",
                sdp: ret.sdp
              }));
              resolve();
            }).catch(e => {
              this.player.debug.error(this.tagName, `loadSource getWebRtcRemoteSdp response error`, e);
              reject(e);
            });
          }).catch(e => {
            this.player.debug.error(this.tagName, `loadSource rtcPeerConnection.createOffer() error`, e);
            reject(e);
          });
        });
      }

    }

    class Playback extends Emitter {
      constructor(player, config) {
        super();
        this.player = player;
        this._showPrecision = null;
        this._startTime = null;
        this._playStartTime = null;
        this._playingTimestamp = null;
        this._fps = parseInt(config.fps, 10) || player._opt.playbackFps;
        this._isUseFpsRender = config.isUseFpsRender === true ? true : false;
        this._rate = 1; // 播放倍率

        this._audioTimestamp = 0;
        this._videoTimestamp = 0;
        this._currentLocalTimestamp = 0;
        this._localOneFrameTimestamp = config.localOneFrameTimestamp || 40;
        this._localCalculateTimeInterval = null;
        this._isUseLocalCalculateTime = config.isUseLocalCalculateTime === true ? true : false;
        this._startfpsTime = null;
        this._startFpsTimestamp = null;
        this._checkStatsInterval = null;
        this._playbackTs = 0;
        this._renderFps = 0; //

        if (this._isUseLocalCalculateTime) {
          this._startLocalCalculateTime();
        } else {
          this._listen();
        } //


        this.playbackList = [];
        this._totalDuration = 0;
        this.initPlaybackList(config.playList);
        this.player.on(EVENTS.playbackPause, flag => {
          if (flag) {
            this.pause();
          } else {
            this.resume();
          }
        });
        player.debug.log('Playback', 'init', {
          fps: this._fps,
          isUseFpsRender: this._isUseFpsRender,
          localOneFrameTimestamp: this._localOneFrameTimestamp,
          isUseLocalCalculateTime: this._isUseLocalCalculateTime,
          uiUsePlaybackPause: config.uiUsePlaybackPause,
          showControl: config.showControl
        });
      }

      destroy() {
        this._startTime = null;
        this._showPrecision = null;
        this._playStartTime = null;
        this._playingTimestamp = null;
        this._totalDuration = 0;
        this._audioTimestamp = 0;
        this._videoTimestamp = 0;
        this._fps = null;
        this._isUseFpsRender = false;
        this._rate = 1; // 播放倍率

        this.playbackList = [];
        this._localCalculateTimeInterval = null;
        this._currentLocalTimestamp = 0;
        this._startfpsTime = null;
        this._startFpsTimestamp = null;
        this._renderFps = 0;
        this._playbackTs = 0;

        this._stopLocalCalculateTime();

        this.clearStatsInterval();
        this.off();
        this.player.debug.log('Playback', 'destroy');
      }

      _listen() {
        //
        this.player.on(EVENTS.stats, stats => {
          const timestamp = stats.ts;

          if (!this._playStartTime) {
            this._playStartTime = timestamp;
          }

          let playingTimestamp = timestamp - this._playStartTime;
          this.setPlayingTimestamp(playingTimestamp);
        });
      }

      pause() {
        this.clearStatsInterval();
      }

      resume() {
        this.startCheckStatsInterval();
      }

      updateStats() {
        let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};

        if (!this._startFpsTimestamp) {
          this._startFpsTimestamp = now$1();
        }

        if (isNotEmpty(options.ts)) {
          this.player.updateStats({
            fps: true,
            ts: options.ts
          });
          this._playbackTs = options.ts;

          if (!this._startfpsTime) {
            this._startfpsTime = options.ts;
          }

          this._renderFps += 1;
        }

        const _now = now$1();

        const timestamp = _now - this._startFpsTimestamp; // update fps

        if (timestamp < 1 * 1000) {
          return;
        }

        let dataTimestamp = null;

        if (this._startfpsTime) {
          dataTimestamp = this._playbackTs - this._startfpsTime;
        }

        this.player.emit(EVENTS.playbackStats, {
          fps: this._renderFps,
          start: this._startfpsTime,
          end: this._playbackTs,
          timestamp: timestamp,
          dataTimestamp: dataTimestamp,
          audioBufferSize: this.player.audio ? this.player.audio.bufferSize : 0,
          videoBufferSize: this.player.video ? this.player.video.bufferSize : 0,
          ts: this._playbackTs
        });
        this._renderFps = 0;
        this._startfpsTime = this._playbackTs;
        this._startFpsTimestamp = _now;
      }

      _startLocalCalculateTime() {
        this._stopLocalCalculateTime();

        this._localCalculateTimeInterval = setInterval(() => {
          const timestamp = this._currentLocalTimestamp;

          if (!this._playStartTime) {
            this._playStartTime = timestamp;
          }

          let playingTimestamp = timestamp - this._playStartTime;
          this.setPlayingTimestamp(playingTimestamp);
        }, 1000);
      }

      startCheckStatsInterval() {
        this.clearStatsInterval();
        this._checkStatsInterval = setInterval(() => {
          this.updateStats();
        }, 1000);
      }

      _stopLocalCalculateTime() {
        if (this._localCalculateTimeInterval) {
          clearInterval(this._localCalculateTimeInterval);
          this._localCalculateTimeInterval = null;
        }
      }

      clearStatsInterval() {
        if (this._checkStatsInterval) {
          clearInterval(this._checkStatsInterval);
          this._checkStatsInterval = null;
        }
      } //


      increaseLocalTimestamp() {
        if (this._isUseLocalCalculateTime) {
          this._currentLocalTimestamp += this._localOneFrameTimestamp;
        }
      } //


      initPlaybackList(playList) {
        this.playbackList = playList || [];
        let totalDuration = 0;
        this.playbackList.forEach((playItem, index) => {
          if (getStrLength(playItem.start) === 10) {
            playItem.startTimestamp = playItem.start * 1000;
            playItem.startTime = parseTime(playItem.startTimestamp);
          }

          if (getStrLength(playItem.end) === 10) {
            playItem.endTimestamp = playItem.end * 1000;
            playItem.endTime = parseTime(playItem.endTimestamp);
          }

          playItem.duration = playItem.end - playItem.start;
          totalDuration += playItem.duration;
        });
        this._totalDuration = totalDuration;
        this.player.debug.log('Playback', this.playbackList);

        if (this.playbackList.length > 0) {
          // 设置时分秒
          this.setStartTime(this.playbackList[0].startTimestamp);
        } // init...


        this.setShowPrecision(PLAYBACK_CONTROL_TIME_PRECISION.oneHour);
      }

      get startTime() {
        return this._startTime || 0;
      } // set start time 开始时间，默认是 某一天的00:00:00


      setStartTime(time) {
        this._startTime = time;
        this._playStartTime = null;
      }

      setRate(rate) {
        this._rate = rate;
      }

      get fps() {
        return this._fps;
      }

      get rate() {
        return this._rate;
      }

      get isUseFpsRender() {
        return this._isUseFpsRender;
      }

      get isUseLocalCalculateTime() {
        return this._isUseLocalCalculateTime;
      }

      get showPrecision() {
        return this._showPrecision;
      }

      get is60Min() {
        return this.showPrecision === PLAYBACK_CONTROL_TIME_PRECISION.oneHour;
      }

      get is30Min() {
        return this.showPrecision === PLAYBACK_CONTROL_TIME_PRECISION.halfHour;
      }

      get is10Min() {
        return this.showPrecision === PLAYBACK_CONTROL_TIME_PRECISION.tenMin;
      }

      get is5Min() {
        return this.showPrecision === PLAYBACK_CONTROL_TIME_PRECISION.fiveMin;
      }

      get is1Min() {
        return this.showPrecision === PLAYBACK_CONTROL_TIME_PRECISION.fiveMin;
      }

      setShowPrecision(type) {
        if (this._showPrecision && this._showPrecision === type) {
          return;
        }

        this._showPrecision = type;
        this.player.emit(EVENTS.playbackPrecision, this._showPrecision, this.playbackList);
      }

      setPlayingTimestamp(ts) {
        const timestamp = this.startTime + ts;
        this._playingTimestamp = timestamp;
        this.player.emit(EVENTS.playbackTime, timestamp);
        const timeDay = new Date(timestamp);
        this.player.emit(EVENTS.playbackTimestamp, {
          ts: timestamp,
          hour: timeDay.getHours(),
          min: timeDay.getMinutes(),
          second: timeDay.getSeconds()
        });
      }

      get playingTimestamp() {
        return this._playingTimestamp;
      }
      /**
       *
       */


      narrowPrecision() {
        const index = PLAYBACK_CONTROL_TIME_PRECISION_ARRAY.indexOf(this.showPrecision);
        const prev = index - 1;

        if (prev >= 0) {
          const item = PLAYBACK_CONTROL_TIME_PRECISION_ARRAY[prev];
          this.setShowPrecision(item);
        }
      }
      /**
       *
       */


      expandPrecision() {
        const index = PLAYBACK_CONTROL_TIME_PRECISION_ARRAY.indexOf(this.showPrecision);
        const next = index + 1;

        if (next <= PLAYBACK_CONTROL_TIME_PRECISION_ARRAY.length - 1) {
          const item = PLAYBACK_CONTROL_TIME_PRECISION_ARRAY[next];
          this.setShowPrecision(item);
        }
      }
      /**
       *
       * @param obj
       */


      seek(obj) {
        console.log(obj);

        if (obj.hasRecord === 'true') {
          let seconds = obj.time;

          if (obj.type === 'min') {
            seconds = obj.time * 60;
          } // console.log(formatSecondTime(seconds));


          this.player.emit(EVENTS.playbackSeek, formatSecondTime(seconds));
        }
      }

    }

    class Zoom extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.bindEvents = [];
        this.isDragging = false;
        this.currentZoom = 1;
        this.prevVideoElementStyleTransform = null;
        this.prevVideoElementStyleScale = null;
        this.tempPosition = {
          x: 0,
          y: 0
        };
        this.videoPosition = {
          left: 0,
          top: 0
        };
        const {
          events: {
            proxy
          },
          debug
        } = this.player;
        this.player.on(EVENTS.zooming, isZooming => {
          if (isZooming) {
            this.player.$container.classList.add('jessibuca-zoom-control');

            this._bindEvents();

            const styleTransform = this.player.video.$videoElement.style.transform;
            let left = this.player.video.$videoElement.style.left;
            let top = this.player.video.$videoElement.style.top;
            left = parseFloat(left);
            top = parseFloat(top);

            if (left) {
              this.videoPosition.left = left;
            }

            if (top) {
              this.videoPosition.top = top;
            }

            this.prevVideoElementStyleTransform = styleTransform;
            let scaleStyleMatch = styleTransform.match(/scale\([0-9., ]*\)/g);

            if (scaleStyleMatch && scaleStyleMatch[0]) {
              let scaleStyle = scaleStyleMatch[0].replace('scale(', '').replace(')', '');
              this.prevVideoElementStyleScale = scaleStyle.split(',');
            }
          } else {
            this.player.$container.classList.remove('jessibuca-zoom-control');

            this._unbindEvents();

            this._resetVideoPosition();

            this.player.$container.style.cursor = 'auto';
            this.player.video.$videoElement.style.transform = this.prevVideoElementStyleTransform;
            this.prevVideoElementStyleTransform = null;
            this.prevVideoElementStyleScale = null;
          }
        });
        proxy(window, 'mouseup', event => {
          this.handleMouseUp(event);
        });
        player.debug.log('zoom', 'init');
      }

      destroy() {
        this.bindEvents = [];
        this.isDragging = false;
        this.currentZoom = 1;
        this.prevVideoElementStyleTransform = null;
        this.prevVideoElementStyleScale = null;
        this.tempPosition = {
          x: 0,
          y: 0
        };
        this.videoPosition = {
          left: 0,
          top: 0
        };
        this.off();
        this.player.debug.log('zoom', 'destroy');
      }

      _bindEvents() {
        const {
          events: {
            proxy
          },
          debug
        } = this.player;
        const mouseMoveDestroy = proxy(this.player.$container, 'mousemove', e => {
          this.handleMouseMove(e);
        });
        this.bindEvents.push(mouseMoveDestroy);
        const mouseDownDestroy = proxy(this.player.$container, 'mousedown', e => {
          this.handleMouseDown(e);
        });
        this.bindEvents.push(mouseDownDestroy);
      }

      _unbindEvents() {
        this.bindEvents.forEach(fn => {
          fn && fn();
        });
      }

      handleMouseMove(event) {
        event.stopPropagation();

        if (this.isDragging && this.player.zooming) {
          const {
            posX,
            posY
          } = getMousePosition(event);
          const tempX = this.tempPosition.x - posX;
          const tempY = this.tempPosition.y - posY;
          this.videoPosition.left = this.videoPosition.left - tempX;
          this.videoPosition.top = this.videoPosition.top - tempY;
          this.tempPosition.x = posX;
          this.tempPosition.y = posY;
          this.updateVideoPosition();
        }
      }

      handleMouseDown(event) {
        event.stopPropagation();
        const target = getTarget(event);

        if (!this.player.zooming) {
          return;
        }

        if (target.matches('video') || target.matches('canvas')) {
          const {
            posX,
            posY
          } = getMousePosition(event);
          this.player.$container.style.cursor = 'grabbing';
          this.tempPosition.x = posX;
          this.tempPosition.y = posY;
          this.isDragging = true;
          this.player.debug.log('zoom', 'handleMouseDown is dragging true');
        }
      }

      handleMouseUp(event) {
        event.stopPropagation();

        if (this.isDragging && this.player.zooming) {
          this.tempPosition = {
            x: 0,
            y: 0
          };
          this.isDragging = false;
          this.player.$container.style.cursor = 'grab';
          this.player.debug.log('zoom', 'handleMouseUp is dragging false');
        }
      } //


      updateVideoPosition() {
        const $videoElement = this.player.video.$videoElement;
        $videoElement.style.left = this.videoPosition.left + 'px';
        $videoElement.style.top = this.videoPosition.top + 'px';
      } //


      _resetVideoPosition() {
        // const $videoElement = this.player.video.$videoElement;
        // $videoElement.style.left = 0 + 'px';
        // $videoElement.style.top = 0 + 'px';
        this.player.resize();
        this.tempPosition = {
          x: 0,
          y: 0
        };
        this.videoPosition = {
          left: 0,
          top: 0
        };
        this.currentZoom = 1;
      } // narrow


      narrowPrecision() {
        if (this.currentZoom <= 1) {
          return;
        }

        this.currentZoom -= 1;
        this.updateVideoElementScale();
      } // expand


      expandPrecision() {
        if (this.currentZoom >= 5) {
          return;
        }

        this.currentZoom += 1;
        this.updateVideoElementScale();
      }

      updateVideoElementScale() {
        const $videoElement = this.player.video.$videoElement;
        let styleTransform = $videoElement.style.transform;
        let scaleX = 1;
        let scaleY = 1;

        if (this.prevVideoElementStyleScale) {
          const x = this.prevVideoElementStyleScale[0];

          if (x !== undefined) {
            scaleX = x;
            scaleY = x;
          }

          const y = this.prevVideoElementStyleScale[1];

          if (y !== undefined) {
            scaleY = y;
          }
        }

        scaleY = toNumber(scaleY);
        scaleX = toNumber(scaleX);
        const endScaleX = 0.5 * scaleX * (this.currentZoom - 1) + scaleX;
        const endScaleY = 0.5 * scaleY * (this.currentZoom - 1) + scaleY;
        let endStyleTransform;

        if (styleTransform.indexOf('scale(') === -1) {
          endStyleTransform = styleTransform + ` scale(${endScaleX},${endScaleY})`;
        } else {
          endStyleTransform = styleTransform.replace(/scale\([0-9., ]*\)/, `scale(${endScaleX},${endScaleY})`);
        }

        this.player.debug.log('zoom', `updateVideoElementScale end is ${endScaleX}, ${endScaleY} style is ${endStyleTransform}`);
        $videoElement.style.transform = endStyleTransform;
      }

    }

    class AiLoader extends Emitter {
      constructor(player) {
        super();
        this.player = player;
        this.faceDetector = null;
        this.initFaceDetector();
        this.player.debug.log('AiLoader', 'init');
      }

      initFaceDetector() {
        if (this.player._opt.useFaceDetector && window.JessibucaProFaceDetector) {
          const faceDetector = new JessibucaProFaceDetector();
          faceDetector.load().then(() => {
            this.player.debug.log('AiLoader', 'init face detector success');
            this.faceDetector = faceDetector;
          });
        }
      }

      destroy() {
        if (this.faceDetector) {
          this.faceDetector.destroy();
          this.faceDetector = null;
        }

        this.off();
      }

    }

    class Player extends Emitter {
      constructor(container, options) {
        super();
        this.$container = container;
        this._opt = Object.assign({}, DEFAULT_PLAYER_OPTIONS, options);
        this.debug = new Debug(this); // 禁用 离屏渲染。

        this._opt.forceNoOffscreen = true; // for demo

        {
          this._opt.watermarkConfig = {
            image: {
              src: 'data:image/png;base64,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',
              width: 75,
              height: 24
            },
            opacity: 0.1,
            right: 10,
            top: 10
          };
        }

        if (!this._opt.forceNoOffscreen) {
          if (!supportOffscreenV2()) {
            this._opt.forceNoOffscreen = true;
            this._opt.useOffscreen = false;
          } else {
            this._opt.useOffscreen = true;
          }
        }

        if (this._opt.isHls || this._opt.isWebrtc) {
          this._opt.useWCS = false;
          this._opt.useMSE = false;
          this._opt.isNakedFlow = false;
        }

        if (this._opt.isNakedFlow) {
          // this._opt.hasAudio = false;
          this._opt.videoBufferDelay = 10 * 60 * 1000;
        } // 排除hls 和 webrtc 协议


        if (!this._opt.isHls && !this._opt.isWebrtc) {
          if (this._opt.useWCS) {
            this._opt.useWCS = supportWCS();

            if (this._opt.useWCS) {
              if (this._opt.useOffscreen) {
                this._opt.wcsUseVideoRender = false;
              } else {
                if (this._opt.wcsUseVideoRender) {
                  this._opt.wcsUseVideoRender = supportMediaStreamTrack();
                }
              }
            }
          }

          if (this._opt.useMSE) {
            this._opt.useMSE = supportMSE();
          }
        } // 如果使用mse则强制不允许 webcodecs


        if (this._opt.useMSE) {
          if (this._opt.useWCS) {
            this.debug.log('Player', 'useWCS set true->false');
          }

          if (!this._opt.forceNoOffscreen) {
            this.debug.log('Player', 'forceNoOffscreen set false->true');
          }

          this._opt.useWCS = false;
          this._opt.forceNoOffscreen = true;
        } else if (this._opt.useWCS) ; // check simd


        if (this._opt.useSIMD || this._opt.decoder.indexOf('-simd') !== -1) {
          this._opt.useSIMD = isSupportSIMD();
        }

        if (this._opt.useSIMD) {
          if (this._opt.decoder.indexOf('-simd') === -1) {
            this._opt.decoder = this._opt.decoder.replace('decoder-pro', 'decoder-pro-simd');
          }
        } else {
          if (this._opt.decoder.indexOf('-simd') !== -1) {
            this._opt.decoder = this._opt.decoder.replace('decoder-pro-simd', 'decoder-pro');
          }
        }

        if (!this._opt.hasAudio) {
          this._opt.operateBtns.audio = false;
        }

        if (!this._opt.hasVideo) {
          this._opt.operateBtns.fullscreen = false;
          this._opt.operateBtns.screenshot = false;
          this._opt.operateBtns.record = false;
          this._opt.operateBtns.ptz = false;
          this._opt.operateBtns.quality = false;
          this._opt.operateBtns.zoom = false;
        }

        this._opt.hasControl = this._hasControl(); //

        this._loading = false;
        this._playing = false;
        this._playbackPause = false;
        this._hasLoaded = false;
        this._zooming = false; //

        this._checkHeartTimeout = null;
        this._checkLoadingTimeout = null;
        this._checkStatsInterval = null; //

        this._startBpsTime = null; //

        this._isPlayingBeforePageHidden = false;
        this._stats = {
          buf: 0,
          // 当前缓冲区时长，单位毫秒,
          netBuf: 0,
          // 网络延迟时长，单位毫秒，
          fps: 0,
          // 当前视频帧率
          dfps: 0,
          // 当前解码器的帧率
          abps: 0,
          // 当前音频码率，单位bit
          vbps: 0,
          // 当前视频码率，单位bit
          ts: 0,
          // 当前视频帧pts，单位毫秒
          pTs: 0,
          // 播放时间戳 单位 秒
          dts: 0 // 当前最新的dts

        };
        this._allStatsData = {};
        this._faceDetectActive = false; // 各个步骤的时间统计

        this._times = initPlayTimes(); //

        this._videoTimestamp = 0;
        this._audioTimestamp = 0;
        this._videoIframeIntervalTs = 0; // i 帧间隔时间。

        this._streamQuality = this._opt.defaultStreamQuality || '';
        this._visibility = true;
        this._lastestVisibilityChangeTimestamp = null;
        this._tempWorkerStats = null;

        if (this._isPlayback()) {
          this._opt.useMSE = false;
          this._opt.useWCS = false;
        }

        if (this._opt.useMSE === false && this._opt.useWCS === false && !this._opt.isWebrtc && !this._opt.isHls) {
          this._opt.useWasm = true;
        }

        if (this._opt.isHls || this._opt.isWebrtc) {
          this._opt.hasVideo = true;
          this._opt.hasAudio = true;
        }

        if (!this._opt.hasVideo) {
          this._opt.useMSE = false;
          this._opt.useWCS = false;
        }

        if (this._opt.useWasm) {
          // offscreen 模式下，不支持 video 渲染。
          if (this._opt.useOffscreen) {
            this._opt.wasmUseVideoRender = false;
          } else {
            if (this._opt.wasmUseVideoRender) {
              this._opt.wasmUseVideoRender = supportWasmUseVideoRender();
            }
          }

          if (this._opt.useSIMD) {
            this.debug.log('Player', 'use simd wasm');
          } else {
            this.debug.log('Player', 'use wasm');
          }
        }

        if (this._opt.useWasm && this._opt.useFaceDetector && window.JessibucaProFaceDetector) {
          this.ai = new AiLoader(this);
        } else {
          this._opt.operateBtns.face = false;
        } // maybe useVideoRender and useCanvasRender all is true


        if (this._opt.useVideoRender) {
          if (this._opt.useWasm && !this._opt.useOffscreen) {
            this._opt.wasmUseVideoRender = supportWasmUseVideoRender();
          } else if (this._opt.useWCS && !this._opt.useOffscreen) {
            this._opt.wcsUseVideoRender = supportMediaStreamTrack();
          }
        }

        if (this._opt.useCanvasRender) {
          if (this._opt.useMSE) {
            this._opt.mseUseCanvasRender = true;
          }

          if (this._opt.isHls && !isSafari()) {
            this._opt.hlsUseCanvasRender = true;
          }
        } // 反推下 usexxx 为true 或者 false


        this._opt.useVideoRender = false;
        this._opt.useCanvasRender = false;

        if (this._opt.useWasm) {
          if (this._opt.wasmUseVideoRender) {
            this._opt.useVideoRender = true;
          } else {
            this._opt.useCanvasRender = true;
          }
        } else if (this._opt.useWCS) {
          if (this._opt.wcsUseVideoRender) {
            this._opt.useVideoRender = true;
          } else {
            this._opt.useCanvasRender = true;
          }
        } else if (this._opt.useMSE) {
          if (this._opt.mseUseCanvasRender) {
            this._opt.useCanvasRender = true;
          } else {
            this._opt.useVideoRender = true;
          }
        } else if (this._opt.isHls) {
          if (this._opt.hlsUseCanvasRender) {
            this._opt.useCanvasRender = true;
          } else {
            this._opt.useVideoRender = true;
          }
        } else if (this._opt.isWebrtc) {
          this._opt.useVideoRender = true;
        }

        property$1(this);
        this.events = new Events(this);

        if (this._opt.hasVideo) {
          this.video = new Video(this);
          this.recorder = new Recorder(this);
        }

        if (this._opt.isHls) {
          this.hlsDecoder = new HlsDecoder(this);
          this.loaded = true;
        } else if (this._opt.isWebrtc) {
          if (this._opt.isWebrtcForZLM) {
            this.webrtc = new WebrtcForZLMDecoder(this);
          } else {
            this.webrtc = new WebrtcDecoder(this);
          }

          this.loaded = true;
        } else {
          if (!onlyMseOrWcsVideo(this._opt)) {
            this.decoderWorker = new DecoderWorker(this);
          } else {
            this.loaded = true;
          }
        }

        if (this._opt.hasAudio) {
          this.audio = new Audio(this);
        }

        this.stream = null;
        this.demux = null;
        this._lastVolume = null;
        this._isInZoom = false;
        this._playingStartTimestamp = null;

        if (this._opt.useWCS) {
          this.webcodecsDecoder = new WebcodecsDecoder(this);

          if (!this._opt.hasAudio) {
            this.loaded = true;
          }
        }

        if (this._opt.useMSE) {
          this.mseDecoder = new MseDecoder(this);

          if (!this._opt.hasAudio) {
            this.loaded = true;
          }
        } //


        this.control = new Control(this);

        if (this._isPlayback()) {
          this.playback = new Playback(this, this._opt.playbackConfig);
          this.$container.classList.add('jessibuca-container-playback');
        }

        if (this._opt.operateBtns.zoom) {
          this.zoom = new Zoom(this);
        }

        if (isMobile()) {
          this.keepScreenOn = new NoSleep(this);
        }

        events$1(this);
        observer(this);

        if (isNotEmptyObject(this._opt.watermarkConfig)) {
          const config = Object.assign(this._opt.watermarkConfig, {
            container: this.$container
          });
          this._removeWatermarkFn = createWatermark(config);
        }

        if (this._opt.useWCS) {
          this.debug.log('Player', 'use WCS');
        }

        if (this._opt.useMSE) {
          this.debug.log('Player', 'use MSE');
        }

        if (this._opt.useOffscreen) {
          this.debug.log('Player', 'use offscreen');
        }

        if (this._opt.isHls) {
          this.debug.log('Player', 'use hls');
        }

        if (this._opt.isWebrtc) {
          this.debug.log('Player', 'use webrtc');
        }

        if (this._isPlayback()) {
          this.debug.log('Player', 'use playback');
        }

        this.debug.log('Player options', this._opt);
      }

      destroy() {
        this._loading = false;
        this._playing = false;
        this._playbackPause = false;
        this._hasLoaded = false;
        this._lastVolume = null;
        this._zooming = false;
        this._faceDetectActive = false;
        this._times = initPlayTimes();
        this._opt = DEFAULT_PLAYER_OPTIONS;

        if (this.decoderWorker) {
          this.decoderWorker.destroy();
          this.decoderWorker = null;
        }

        if (this.video) {
          this.video.destroy();
          this.video = null;
        }

        if (this.audio) {
          this.audio.destroy();
          this.audio = null;
        }

        if (this.stream) {
          this.stream.destroy();
          this.stream = null;
        }

        if (this.recorder) {
          this.recorder.destroy();
          this.recorder = null;
        }

        if (this.control) {
          this.control.destroy();
          this.control = null;
        }

        if (this.webcodecsDecoder) {
          this.webcodecsDecoder.destroy();
          this.webcodecsDecoder = null;
        }

        if (this.mseDecoder) {
          this.mseDecoder.destroy();
          this.mseDecoder = null;
        }

        if (this.demux) {
          this.demux.destroy();
          this.demux = null;
        }

        if (this.hlsDecoder) {
          this.hlsDecoder.destroy();
          this.hlsDecoder = null;
        }

        if (this.events) {
          this.events.destroy();
          this.events = null;
        }

        if (this.playback) {
          this.playback.destroy();
          this.playback = null;
        }

        if (this.zoom) {
          this.zoom.destroy();
          this.zoom = null;
        }

        if (this.ai) {
          this.ai.destroy();
          this.ai = null;
        }

        this.clearCheckHeartTimeout();
        this.clearCheckLoadingTimeout();
        this.clearStatsInterval(); //

        this.releaseWakeLock();
        this.keepScreenOn = null; // reset stats

        this.resetStats();
        this._audioTimestamp = 0;
        this._videoTimestamp = 0;
        this._streamQuality = '';
        this._visibility = true;
        this._isInZoom = false;
        this._playingStartTimestamp = null;
        this._lastestVisibilityChangeTimestamp = null;
        this._videoIframeIntervalTs = null;
        this._tempWorkerStats = null; // 移除水印

        if (this._removeWatermarkFn) {
          this._removeWatermarkFn();

          this._removeWatermarkFn = null;
        } // 其他没法解耦的，通过 destroy 方式


        this.emit('destroy'); // 接触所有绑定事件

        this.off();
        this.debug.log('play', 'destroy end');
      }

      set fullscreen(value) {
        if (isMobile()) {
          this.emit(EVENTS.webFullscreen, value);
          setTimeout(() => {
            this.updateOption({
              rotate: value ? 270 : 0
            });
            this.resize();
          }, 10);
        } else {
          this.emit(EVENTS.fullscreen, value);
        }
      }

      get fullscreen() {
        return isFullScreen() || this.webFullscreen;
      }

      set webFullscreen(value) {
        this.emit(EVENTS.webFullscreen, value);
      }

      get webFullscreen() {
        return this.$container.classList.contains('jessibuca-fullscreen-web');
      }

      set loaded(value) {
        this._hasLoaded = value;
      } //


      get loaded() {
        return this._hasLoaded || this._opt.isHls || this._opt.isWebrtc || this._opt.useMSE && !this._opt.hasAudio || this._opt.useWCS && !this._opt.hasAudio;
      } //


      set playing(value) {
        if (value) {
          // 将loading 设置为 false
          this.loading = false;
        }

        if (this.playing !== value) {
          this._playing = value;
          this.emit(EVENTS.playing, value);
          this.emit(EVENTS.volumechange, this.volume);

          if (value) {
            this.emit(EVENTS.play);
          } else {
            this.emit(EVENTS.pause);
          }
        }
      }

      get playing() {
        return this._playing;
      }

      get volume() {
        return this.audio && this.audio.volume || 0;
      }

      set volume(value) {
        if (value !== this.volume) {
          if (this.audio) {
            this.audio.setVolume(value);
            this._lastVolume = this.volume;
          } else {
            this.debug.error('Player', 'set volume error, audio is null');
          }
        }
      }

      get lastVolume() {
        return this._lastVolume;
      }

      set loading(value) {
        if (this.loading !== value) {
          this._loading = value;
          this.emit(EVENTS.loading, this._loading);
        }
      }

      get loading() {
        return this._loading;
      }

      set zooming(value) {
        if (this.zooming !== value) {
          if (!this.zoom) {
            this.zoom = new Zoom(this);
          }

          this._zooming = value;
          this.emit(EVENTS.zooming, this.zooming);
        }
      }

      get zooming() {
        return this._zooming;
      }

      set recording(value) {
        if (value) {
          if (this.playing && !this.recording) {
            this.recorder && this.recorder.startRecord();

            if (this._opt.useWasm) {
              this.decoderWorker.updateWorkConfig({
                key: 'isRecording',
                value: true
              });
            }
          }
        } else {
          if (this.recording) {
            if (this._opt.useWasm) {
              this.decoderWorker.updateWorkConfig({
                key: 'isRecording',
                value: false
              });
            }

            this.recorder && this.recorder.stopRecordAndSave().then(() => {}).catch(e => {});
          }
        }
      }

      get recording() {
        return this.recorder ? this.recorder.isRecording : false;
      }

      set audioTimestamp(value) {
        if (value === null) {
          return;
        }

        this._audioTimestamp = value;
      } //


      get audioTimestamp() {
        return this._audioTimestamp;
      } //


      set videoTimestamp(value) {
        if (value === null) {
          return;
        }

        this._videoTimestamp = value; // just for wasm

        if (!this._opt.useWCS && !this._opt.useMSE) {
          if (this.audioTimestamp && this.videoTimestamp) {
            this.audio && this.audio.emit(EVENTS.videoSyncAudio, {
              audioTimestamp: this.audioTimestamp,
              videoTimestamp: this.videoTimestamp,
              diff: this.audioTimestamp - this.videoTimestamp
            });
          }
        }
      }

      set streamQuality(value) {
        if (this.streamQuality !== value) {
          this._streamQuality = value;
          this.emit(EVENTS.streamQualityChange, value);
        }
      }

      get streamQuality() {
        return this._streamQuality;
      } //


      get videoTimestamp() {
        return this._videoTimestamp;
      }

      get isDebug() {
        return this._opt.debug === true;
      }

      get scaleType() {
        const opt = this._opt;
        const isResize = opt.isResize;
        const isFullResize = opt.isFullResize;
        let result = SCALE_MODE_TYPE.full;

        if (isFullResize === false && isResize === false) {
          result = SCALE_MODE_TYPE.full;
        } else if (isFullResize === false && isResize === true) {
          result = SCALE_MODE_TYPE.auto;
        } else if (isFullResize === true && isResize === true) {
          result = SCALE_MODE_TYPE.fullAuto;
        }

        return result;
      } //


      set visibility(value) {
        if (this._visibility !== value) {
          this._visibility = value;
          this.emit(EVENTS.visibilityChange, value);
          this._lastestVisibilityChangeTimestamp = now$1();
        }
      } //


      get visibility() {
        return this._visibility;
      }

      set playbackPause(value) {
        if (this._playbackPause !== value) {
          this._playbackPause = value;
          this.emit(EVENTS.playbackPause, value);
        }
      }

      get playbackPause() {
        return this._playbackPause;
      }

      set videoIframeIntervalTs(ts) {
        this._videoIframeIntervalTs = ts;
      }

      get videoIframeIntervalTs() {
        return this._videoIframeIntervalTs;
      }

      set faceDetectActive(value) {
        if (this._faceDetectActive !== value) {
          this._faceDetectActive = value;
          this.emit(EVENTS.faceDetectActive, value);
        }
      }

      get faceDetectActive() {
        return this._faceDetectActive;
      }
      /**
       *
       * @param options
       */


      updateOption(options) {
        this._opt = Object.assign({}, this._opt, options);
      }
      /**
       *
       * @returns {Promise<unknown>}
       */


      init() {
        return new Promise((resolve, reject) => {
          if (!this.video) {
            if (this._opt.hasVideo) {
              this.video = new Video(this);
            }
          }

          if (!this.audio) {
            if (this._opt.hasAudio) {
              this.audio = new Audio(this);
            }
          }

          if (!this.stream) {
            this.stream = new Stream(this);
          }

          if (this._opt.isHls) {
            if (!this.hlsDecoder) {
              this.hlsDecoder = new HlsDecoder(this);
              this.loaded = true;
            }

            resolve();
          } else if (this._opt.isWebrtc) {
            if (!this.webrtc) {
              if (this._opt.isWebrtcForZLM) {
                this.webrtc = new WebrtcForZLMDecoder(this);
              } else {
                this.webrtc = new WebrtcDecoder(this);
              }

              this.loaded = true;
            }

            resolve();
          } else {
            if (!this.demux) {
              this.demux = new Demux(this);
            }

            if (this._opt.useWCS) {
              if (!this.webcodecsDecoder) {
                this.webcodecsDecoder = new WebcodecsDecoder(this);
              }
            }

            if (this._opt.useMSE) {
              if (!this.mseDecoder) {
                this.mseDecoder = new MseDecoder(this);
              }
            }

            if (this.decoderWorker) {
              if (this.loaded) {
                resolve();
              } else {
                this.once(EVENTS.decoderWorkerInit, () => {
                  resolve();
                });
              }
            } else {
              if (!onlyMseOrWcsVideo(this._opt)) {
                this.decoderWorker = new DecoderWorker(this);
                this.once(EVENTS.decoderWorkerInit, () => {
                  resolve();
                });
              } else {
                resolve();
              }
            }
          }
        });
      }
      /**
       *
       * @param url
       * @returns {Promise<unknown>}
       */


      play(url, options) {
        return new Promise((resolve, reject) => {
          if (!url && !this._opt.url) {
            return reject("url is empty");
          }

          this.loading = true;
          this.playing = false;
          this._times.playInitStart = now$1();

          if (!url) {
            url = this._opt.url;
          }

          this._opt.url = url;
          this.clearCheckHeartTimeout();
          this.init().then(() => {
            this._times.playStart = now$1(); //

            if (this._opt.isNotMute) {
              this.mute(false);
            }

            if (this.webcodecsDecoder) {
              this.webcodecsDecoder.once(EVENTS_ERROR.webcodecsH265NotSupport, () => {
                this.emit(EVENTS_ERROR.webcodecsH265NotSupport);

                if (!this._opt.autoWasm) {
                  this.emit(EVENTS.error, EVENTS_ERROR.webcodecsH265NotSupport);
                }
              });
            }

            if (this.mseDecoder) {
              this.mseDecoder.once(EVENTS_ERROR.mediaSourceH265NotSupport, () => {
                this.emit(EVENTS_ERROR.mediaSourceH265NotSupport);

                if (!this._opt.autoWasm) {
                  this.emit(EVENTS.error, EVENTS_ERROR.mediaSourceH265NotSupport);
                }
              }); //

              this.mseDecoder.once(EVENTS_ERROR.mediaSourceFull, () => {
                this.emit(EVENTS_ERROR.mediaSourceFull);
              });
              this.mseDecoder.once(EVENTS_ERROR.mediaSourceAppendBufferError, () => {
                this.emit(EVENTS_ERROR.mediaSourceAppendBufferError);
              });
              this.mseDecoder.once(EVENTS_ERROR.mediaSourceBufferListLarge, () => {
                this.emit(EVENTS_ERROR.mediaSourceBufferListLarge);
              });
              this.mseDecoder.once(EVENTS_ERROR.mediaSourceAppendBufferEndTimeout, () => {
                this.emit(EVENTS_ERROR.mediaSourceAppendBufferEndTimeout);
              });
            }

            this.enableWakeLock(); //

            this.checkLoadingTimeout(); // fetch error

            this.stream.once(EVENTS_ERROR.fetchError, error => {
              // reject(error)
              this.emit(EVENTS_ERROR.fetchError, error);
            }); // ws

            this.stream.once(EVENTS_ERROR.websocketError, error => {
              reject(error);
            }); // stream end

            this.stream.once(EVENTS.streamEnd, () => {
              reject();
            }); // hls

            this.stream.once(EVENTS_ERROR.hlsError, error => {
              reject(error);
            }); // webrtc

            this.stream.once(EVENTS_ERROR.webrtcError, error => {
              reject(error);
            }); // success

            this.stream.once(EVENTS.streamSuccess, () => {
              resolve();
              this._times.streamResponse = now$1();
              this.video && this.video.play();
              this.checkStatsInterval();

              if (this.isPlayback() && this.playback) {
                this.playback.startCheckStatsInterval();
              }

              {
                setTimeout(() => {
                  this.destroy();
                  console.error('jessibuca pro 体验结束,请刷新页面再次体验');
                  alert('jessibuca pro 体验结束,请刷新页面再次体验，如需要购买商业授权，可以联系微信：bosswancheng');
                  window.location.reload();
                }, 1 * 60 * 60 * 1000);
              }
            });
            this.stream.fetchStream(url, options);
          }).catch(e => {
            reject(e);
          });
        });
      }
      /**
       *
       */


      close() {
        return new Promise((resolve, reject) => {
          this._close().then(() => {
            this.video && this.video.clearView();
            resolve();
          });
        });
      }

      resumeAudioAfterPause() {
        if (this.lastVolume) {
          this.volume = this.lastVolume;
        }
      }

      _close() {
        return new Promise((resolve, reject) => {
          //
          if (this.stream) {
            this.stream.destroy();
            this.stream = null;
          }

          if (this.demux) {
            this.demux.destroy();
            this.demux = null;
          } //


          if (this.decoderWorker) {
            this.decoderWorker.destroy();
            this.decoderWorker = null;
          }

          if (this.webcodecsDecoder) {
            this.webcodecsDecoder.destroy();
            this.webcodecsDecoder = null;
          } //


          if (this.mseDecoder) {
            this.mseDecoder.destroy();
            this.mseDecoder = null;
          } //


          if (this.hlsDecoder) {
            this.hlsDecoder.destroy();
            this.hlsDecoder = null;
          }

          if (this.webrtc) {
            this.webrtc.destroy();
            this.webrtc = null;
          }

          if (this.audio) {
            this.audio.destroy();
            this.audio = null;
          }

          this.clearCheckHeartTimeout();
          this.clearCheckLoadingTimeout();
          this.clearStatsInterval();

          if (this.isPlayback() && this.playback) {
            this.playback.clearStatsInterval();
          }

          this.loading = false;
          this.recording = false;
          this.zooming = false;
          this.playing = false; // if (this.audio) {
          //     this.audio.resetInit();
          //     this.audio.pause();
          // }

          if (this.video) {
            this.video.resetInit();
            this.video.pause(true);
          } // release lock


          this.releaseWakeLock(); // reset stats

          this.resetStats(); //

          this._audioTimestamp = 0;
          this._videoTimestamp = 0; //

          this._times = initPlayTimes(); //

          setTimeout(() => {
            resolve();
          }, 0);
        });
      }
      /**
       *
       * @param flag {boolean} 是否清除画面
       * @returns {Promise<unknown>}
       */


      pause() {
        let flag = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;

        if (flag) {
          return this.close();
        } else {
          return this._close();
        }
      }

      isAudioMute() {
        let result = true;

        if (this.audio) {
          result = this.audio.isMute;
        }

        return result;
      }

      isAudioNotMute() {
        return !this.isAudioMute();
      }
      /**
       *
       * @param flag
       */


      mute(flag) {
        this.audio && this.audio.mute(flag);
      }
      /**
       *
       */


      resize() {
        this.video && this.video.resize();
      }
      /**
       *
       * @param fileName
       * @param fileType
       */


      startRecord(fileName, fileType) {
        if (this.recording) {
          return;
        }

        this.recorder.setFileName(fileName, fileType);
        this.recording = true;
      }
      /**
       *
       */


      stopRecordAndSave(type, fileName) {
        // if (this.recording) {
        //     this.recording = false;
        // }
        return new Promise((resolve, reject) => {
          if (!this.recorder) {
            reject('recorder is null');
          }

          if (this.recording) {
            if (this._opt.useWasm) {
              this.decoderWorker.updateWorkConfig({
                key: 'isRecording',
                value: true
              });
            }

            this.recorder.stopRecordAndSave(type, fileName).then(blob => {
              resolve(blob);
            }).catch(e => {
              reject(e);
            });
          } else {
            reject('recorder is not recording');
          }
        });
      }

      _hasControl() {
        let result = false;
        let hasBtnShow = false;
        Object.keys(this._opt.operateBtns).forEach(key => {
          if (this._opt.operateBtns[key]) {
            hasBtnShow = true;
          }
        });

        if (this._opt.showBandwidth || this._opt.text || hasBtnShow) {
          result = true;
        }

        if (this._isPlayback() && this._opt.playbackConfig.showControl) {
          result = true;
        }

        return result;
      }

      _isPlayback() {
        return this._opt.playType === PLAY_TYPE.playbackTF;
      } // wasm 解码


      useWasmDecode() {
        return this._opt.useMSE === false && this._opt.useWCS === false;
      } // wasm 或者webcodecs解码 用video 标签渲染


      canVideoTrackWritter() {
        const _opt = this._opt;
        return !_opt.isHls && !_opt.isWebrtc && !_opt.useMSE && (_opt.useWCS && !_opt.useOffscreen && _opt.wcsUseVideoRender || this.useWasmDecode());
      }

      checkHeart() {
        this.clearCheckHeartTimeout();
        this.checkHeartTimeout();
      } // 心跳检查，如果渲染间隔暂停了多少时间之后，就会抛出异常


      checkHeartTimeout() {
        this._checkHeartTimeout = setTimeout(() => {
          // if page is visibility and playback pause is false
          if (this.visibility && this.playbackPause === false && this.playing) {
            // check again
            if (this._stats.fps !== 0) {
              this.player.debug('player', `checkHeartTimeout but fps is ${this._stats.fps}`);
              return;
            }

            this.debug.warn('player', `checkHeartTimeout and pause and emit delayTimeout event`);
            this.pause(false).then(() => {
              this.emit(EVENTS.timeout, EVENTS.delayTimeout);
              this.emit(EVENTS.delayTimeout);
            });
          }
        }, this._opt.heartTimeout * 1000);
      }

      checkStatsInterval() {
        this._checkStatsInterval = setInterval(() => {
          this.updateStats();
        }, 1000);
      } //


      clearCheckHeartTimeout() {
        if (this._checkHeartTimeout) {
          clearTimeout(this._checkHeartTimeout);
          this._checkHeartTimeout = null;
        }
      } // loading 等待时间


      checkLoadingTimeout() {
        this._checkLoadingTimeout = setTimeout(() => {
          // check again
          if (this.playing) {
            this.debug.warn('player', `checkLoadingTimeout but loading is ${this.loading} and playing is ${this.playing}`);
            return;
          }

          this.debug.warn('player', `checkLoadingTimeout and pause and emit loadingTimeout event`);
          this.pause(false).then(() => {
            this.emit(EVENTS.timeout, EVENTS.loadingTimeout);
            this.emit(EVENTS.loadingTimeout);
          });
        }, this._opt.loadingTimeout * 1000);
      }

      clearCheckLoadingTimeout() {
        if (this._checkLoadingTimeout) {
          this.debug.log('player', `clearCheckLoadingTimeout`);
          clearTimeout(this._checkLoadingTimeout);
          this._checkLoadingTimeout = null;
        }
      }

      clearStatsInterval() {
        if (this._checkStatsInterval) {
          clearInterval(this._checkStatsInterval);
          this._checkStatsInterval = null;
        }
      }

      handleRender() {
        if (this.loading) {
          //
          this.clearCheckLoadingTimeout();
          this.emit(EVENTS.start);
          this.loading = false;
        }

        if (!this.playing) {
          this.playing = true;
        }

        this.checkHeart();
      } //


      updateStats(options) {
        options = options || {};

        if (!this._startBpsTime) {
          this._startBpsTime = now$1();
        }

        if (isNotEmpty(options.ts)) {
          this._stats.ts = options.ts;

          if (this._playingStartTimestamp === null && options.ts > 0) {
            this._playingStartTimestamp = options.ts;
          }
        }

        if (isNotEmpty(options.dts)) {
          this._stats.dts = options.dts;
        }

        if (isNotEmpty(options.buf)) {
          this._stats.buf = options.buf;
        }

        if (isNotEmpty(options.netBuf)) {
          this._stats.netBuf = options.netBuf;
        }

        if (options.fps) {
          this._stats.fps += 1;
        }

        if (options.dfps) {
          this._stats.dfps += 1;
        }

        if (options.abps) {
          this._stats.abps += options.abps;
        }

        if (options.vbps) {
          this._stats.vbps += options.vbps;
        }

        if (options.workerStats) {
          this._tempWorkerStats = options.workerStats;
        }

        const _nowTime = now$1();

        const timestamp = _nowTime - this._startBpsTime;

        if (timestamp < 1 * 1000) {
          return;
        }

        if (this._playingStartTimestamp !== null) {
          this._stats.pTs += 1;
        }

        let sourceBufferDelay = 0;
        let decodeDiffTimes = 0;
        let decodePlaybackRate = 0; // just for mse

        if (this._opt.useMSE && this.mseDecoder) {
          sourceBufferDelay = this.mseDecoder.checkSourceBufferDelay();
          sourceBufferDelay = parseInt(sourceBufferDelay * 1000, 10);
          decodeDiffTimes = this.mseDecoder.getDecodeDiffTimes();
          decodePlaybackRate = this.mseDecoder.getDecodePlaybackRate();
        }

        if (this._opt.useWCS && this.webcodecsDecoder) {
          decodeDiffTimes = this.webcodecsDecoder.getDecodeDiffTimes();
        } // just for hls


        if (this._opt.isHls && this.hlsDecoder) {
          sourceBufferDelay = this.hlsDecoder.checkHlsBufferedDelay();
          sourceBufferDelay = parseInt(sourceBufferDelay * 1000, 10);
          decodePlaybackRate = this.hlsDecoder.getDecodePlaybackRate();
        } // just for wasm


        let flvBufferByteLength = 0;

        if (this._opt.useWasm) {
          //wasm
          if (this._tempWorkerStats) {
            flvBufferByteLength = this._tempWorkerStats.flvBufferByteLength;
          }
        } else {
          // mse or wcs
          if (this.demux) {
            flvBufferByteLength = this.demux.getInputByteLength();
          }
        }

        let audioBufferDelay = 0;

        if (this.audio && this.audio.bufferList) {
          audioBufferDelay = this.audio.bufferList.length;
        }

        let demuxBufferDelay = 0;
        let audioDemuxBufferDelay = 0;

        if (this._opt.useWasm) {
          //    for wasm
          if (this._tempWorkerStats) {
            demuxBufferDelay = this._tempWorkerStats.demuxBufferDelay;
            audioDemuxBufferDelay = this._tempWorkerStats.audioDemuxBufferDelay;
          }
        } else {
          // just for mse or wcs
          if (this.demux && this.demux.bufferList) {
            demuxBufferDelay = this.demux.bufferList.length;
          }
        }

        let playbackVideoBufferDelay = 0;
        let playbackVideoWaitingBufferDelay = 0;
        let playbackAudioWaitingBufferDelay = 0;

        if (this.isPlayback()) {
          if (this._opt.playbackConfig.isUseFpsRender && this.video) {
            playbackVideoBufferDelay = this.video.bufferList && this.video.bufferList.length || 0;
          }
        }

        const delayTs = this._stats.dts - this._stats.ts;
        const totalDelayTs = delayTs + this._stats.netBuf;

        if (this._opt.isHls) {
          this._stats.fps = this.hlsDecoder.getFps();
        }

        let isDropping = false;

        if (this.demux) {
          isDropping = this.demux.isDropping();
        }

        this._allStatsData = Object.assign(this._stats, {
          audioBuffer: audioBufferDelay,
          audioTs: this.audioTimestamp,
          playbackVideoBuffer: playbackVideoBufferDelay,
          playbackVideoWaitingBuffer: playbackVideoWaitingBufferDelay,
          playbackAudioWaitingBuffer: playbackAudioWaitingBufferDelay,
          demuxBuffer: demuxBufferDelay,
          audioDemuxBuffer: audioDemuxBufferDelay,
          flvBuffer: flvBufferByteLength,
          mseDelay: sourceBufferDelay,
          mseDecodeDiffTimes: decodeDiffTimes,
          mseDecodePlaybackRate: decodePlaybackRate,
          wcsDecodeDiffTimes: decodeDiffTimes,
          hlsDelay: sourceBufferDelay,
          hlsDecodePlaybackRate: decodePlaybackRate,
          delayTs,
          totalDelayTs,
          isDropping
        });
        this.emit(EVENTS.stats, this._allStatsData);
        this.emit(EVENTS.performance, fpsStatus(this._stats.fps));
        this._stats.fps = 0;
        this._stats.dfps = 0;
        this._stats.abps = 0;
        this._stats.vbps = 0;
        this._startBpsTime = _nowTime;
      }

      resetStats() {
        this._startBpsTime = null;
        this._playingStartTimestamp = null;
        this._stats = {
          buf: 0,
          //ms
          netBuf: 0,
          fps: 0,
          dfps: 0,
          abps: 0,
          vbps: 0,
          ts: 0,
          pTs: 0,
          dts: 0
        };
        this._allStatsData = {};
      }

      enableWakeLock() {
        if (this._opt.keepScreenOn) {
          this.keepScreenOn && this.keepScreenOn.enable();
        }
      }

      releaseWakeLock() {
        if (this._opt.keepScreenOn) {
          this.keepScreenOn && this.keepScreenOn.disable();
        }
      }

      clearBufferDelay() {
        if (this._opt.useWasm) {
          if (this.decoderWorker) {
            this.decoderWorker.clearWorkBuffer(true);
          }
        } else {
          if (this.demux) {
            this.demux.clearBuffer(true);
          }
        }
      }

      doDestroy() {
        this.emit(EVENTS.beforeDestroy);
      }

      handlePlayToRenderTimes() {
        const _times = this.getPlayToRenderTimes();

        this.emit(EVENTS.playToRenderTimes, _times);
      }

      getPlayToRenderTimes() {
        const _times = this._times; // play init time

        _times.playTimestamp = _times.playStart - _times.playInitStart; // stream start time

        _times.streamTimestamp = _times.streamStart - _times.playStart; // stream response time

        _times.streamResponseTimestamp = _times.streamResponse - _times.streamStart; // demux time

        _times.demuxTimestamp = _times.demuxStart - _times.streamResponse; // decode times

        _times.decodeTimestamp = _times.decodeStart - _times.demuxStart; // start render time

        _times.videoTimestamp = _times.videoStart - _times.decodeStart; // all time

        _times.allTimestamp = _times.videoStart - _times.playInitStart;
        return _times;
      }

      getOption() {
        return this._opt;
      }

      isPlayer() {
        return this._opt.playType === PLAY_TYPE.player;
      }

      isPlayback() {
        return this._opt.playType === PLAY_TYPE.playbackTF;
      }

      isDemuxSetCodecInit() {
        let result = true;
        let _opt = this._opt;

        if (_opt.useWCS && !_opt.useOffscreen) {
          result = this.webcodecsDecoder.hasInit;
        } else if (_opt.useMSE) {
          result = this.mseDecoder.hasInit;
        }

        return result;
      }

      isDemuxDecodeFirstIIframeInit() {
        let result = true;
        let _opt = this._opt;

        if (_opt.useWCS && !_opt.useOffscreen) {
          result = this.webcodecsDecoder.isDecodeFirstIIframe;
        } else if (_opt.useMSE) {
          result = this.mseDecoder.isDecodeFirstIIframe;
        }

        return result;
      }

      isAudioPlaybackRateSpeed() {
        let result = false;

        if (this.audio) {
          result = this.audio.isPlaybackRateSpeed();
        }

        return result;
      }

      getPlayingTimestamp() {
        return this._stats.pTs;
      }

      getRecordingType() {
        let result = null;

        if (this.recorder) {
          result = this.recorder.getType();
        }

        return result;
      }

      getRecordingByteLength() {
        let result = 0;

        if (this.recording) {
          result = this.recorder.getToTalByteLength();
        }

        return result;
      }

      getRecordingDuration() {
        let result = 0;

        if (this.recording) {
          result = this.recorder.getTotalDuration();
        }

        return result;
      }

      getDecodeType() {
        let result = '';
        const options = this.getOption();

        if (options.useMSE) {
          result += DECODE_TYPE.mse + ' ';
        }

        if (options.useWCS) {
          result += DECODE_TYPE.wcs + ' ';
        }

        if (options.useWasm) {
          result += DECODE_TYPE.wasm + ' ';
        }

        if (options.useSIMD) {
          result += DECODE_TYPE.simd + ' ';
        }

        if (options.useOffscreen) {
          result += DECODE_TYPE.offscreen + ' ';
        }

        return result;
      }

      getDemuxType() {
        let result = '';
        const options = this.getOption();
        result = options.demuxType;
        return result;
      }

      getRenderType() {
        let result = '';

        if (this.video) {
          result = this.video.getType();
        }

        return result;
      }

      getAudioEngineType() {
        let result = '';

        if (this.audio) {
          result = this.audio.getEngineType();
        }

        return result;
      }

      getAllStatsData() {
        return this._allStatsData;
      }

      togglePerformancePanel(toggle) {
        this.updateOption({
          showPerformance: toggle
        });
        this.emit(EVENTS.togglePerformancePanel, toggle);
      }

      setScaleMode(type) {
        type = Number(type);
        let options = {
          isFullResize: false,
          isResize: false
        };

        switch (type) {
          case SCALE_MODE_TYPE.full:
            options.isFullResize = false;
            options.isResize = false;
            break;

          case SCALE_MODE_TYPE.auto:
            options.isFullResize = false;
            options.isResize = true;
            break;

          case SCALE_MODE_TYPE.fullAuto:
            options.isFullResize = true;
            options.isResize = true;
            break;
        }

        this.updateOption(options);
        this.resize();
        this.emit(EVENTS.viewResizeChange, type);
      }

      faceDetect(toggle) {
        this.faceDetectActive = toggle;
      }

      downloadNakedFlowFile() {
        if (this.demux && this.demux.downloadNakedFlowFile) {
          this.demux.downloadNakedFlowFile();
        }
      }

    }

    class Resampler {
      constructor(options) {
        const {
          fromSampleRate,
          toSampleRate,
          channels,
          inputBufferSize
        } = options;

        if (!fromSampleRate || !toSampleRate || !channels) {
          throw new Error("Invalid settings specified for the resampler.");
        }

        this.resampler = null;
        this.fromSampleRate = fromSampleRate;
        this.toSampleRate = toSampleRate;
        this.channels = channels || 0;
        this.inputBufferSize = inputBufferSize;
        this.initialize();
      }

      initialize() {
        if (this.fromSampleRate == this.toSampleRate) {
          // Setup resampler bypass - Resampler just returns what was passed through
          this.resampler = buffer => {
            return buffer;
          };

          this.ratioWeight = 1;
        } else {
          if (this.fromSampleRate < this.toSampleRate) {
            // Use generic linear interpolation if upsampling,
            // as linear interpolation produces a gradient that we want
            // and works fine with two input sample points per output in this case.
            this.linearInterpolation();
            this.lastWeight = 1;
          } else {
            // Custom resampler I wrote that doesn't skip samples
            // like standard linear interpolation in high downsampling.
            // This is more accurate than linear interpolation on downsampling.
            this.multiTap();
            this.tailExists = false;
            this.lastWeight = 0;
          } // Initialize the internal buffer:


          this.initializeBuffers();
          this.ratioWeight = this.fromSampleRate / this.toSampleRate;
        }
      }

      bufferSlice(sliceAmount) {
        //Typed array and normal array buffer section referencing:
        try {
          return this.outputBuffer.subarray(0, sliceAmount);
        } catch (error) {
          try {
            //Regular array pass:
            this.outputBuffer.length = sliceAmount;
            return this.outputBuffer;
          } catch (error) {
            //Nightly Firefox 4 used to have the subarray function named as slice:
            return this.outputBuffer.slice(0, sliceAmount);
          }
        }
      }

      initializeBuffers() {
        this.outputBufferSize = Math.ceil(this.inputBufferSize * this.toSampleRate / this.fromSampleRate / this.channels * 1.000000476837158203125) + this.channels + this.channels;

        try {
          this.outputBuffer = new Float32Array(this.outputBufferSize);
          this.lastOutput = new Float32Array(this.channels);
        } catch (error) {
          this.outputBuffer = [];
          this.lastOutput = [];
        }
      }

      linearInterpolation() {
        this.resampler = buffer => {
          let bufferLength = buffer.length,
              channels = this.channels,
              outLength,
              ratioWeight,
              weight,
              firstWeight,
              secondWeight,
              sourceOffset,
              outputOffset,
              outputBuffer,
              channel;

          if (bufferLength % channels !== 0) {
            throw new Error("Buffer was of incorrect sample length.");
          }

          if (bufferLength <= 0) {
            return [];
          }

          outLength = this.outputBufferSize;
          ratioWeight = this.ratioWeight;
          weight = this.lastWeight;
          firstWeight = 0;
          secondWeight = 0;
          sourceOffset = 0;
          outputOffset = 0;
          outputBuffer = this.outputBuffer;

          for (; weight < 1; weight += ratioWeight) {
            secondWeight = weight % 1;
            firstWeight = 1 - secondWeight;
            this.lastWeight = weight % 1;

            for (channel = 0; channel < this.channels; ++channel) {
              outputBuffer[outputOffset++] = this.lastOutput[channel] * firstWeight + buffer[channel] * secondWeight;
            }
          }

          weight -= 1;

          for (bufferLength -= channels, sourceOffset = Math.floor(weight) * channels; outputOffset < outLength && sourceOffset < bufferLength;) {
            secondWeight = weight % 1;
            firstWeight = 1 - secondWeight;

            for (channel = 0; channel < this.channels; ++channel) {
              outputBuffer[outputOffset++] = buffer[sourceOffset + (channel > 0 ? channel : 0)] * firstWeight + buffer[sourceOffset + (channels + channel)] * secondWeight;
            }

            weight += ratioWeight;
            sourceOffset = Math.floor(weight) * channels;
          }

          for (channel = 0; channel < channels; ++channel) {
            this.lastOutput[channel] = buffer[sourceOffset++];
          }

          return this.bufferSlice(outputOffset);
        };
      }

      multiTap() {
        this.resampler = buffer => {
          let bufferLength = buffer.length,
              outLength,
              output_variable_list,
              channels = this.channels,
              ratioWeight,
              weight,
              channel,
              actualPosition,
              amountToNext,
              alreadyProcessedTail,
              outputBuffer,
              outputOffset,
              currentPosition;

          if (bufferLength % channels !== 0) {
            throw new Error("Buffer was of incorrect sample length.");
          }

          if (bufferLength <= 0) {
            return [];
          }

          outLength = this.outputBufferSize;
          output_variable_list = [];
          ratioWeight = this.ratioWeight;
          weight = 0;
          actualPosition = 0;
          amountToNext = 0;
          alreadyProcessedTail = !this.tailExists;
          this.tailExists = false;
          outputBuffer = this.outputBuffer;
          outputOffset = 0;
          currentPosition = 0;

          for (channel = 0; channel < channels; ++channel) {
            output_variable_list[channel] = 0;
          }

          do {
            if (alreadyProcessedTail) {
              weight = ratioWeight;

              for (channel = 0; channel < channels; ++channel) {
                output_variable_list[channel] = 0;
              }
            } else {
              weight = this.lastWeight;

              for (channel = 0; channel < channels; ++channel) {
                output_variable_list[channel] = this.lastOutput[channel];
              }

              alreadyProcessedTail = true;
            }

            while (weight > 0 && actualPosition < bufferLength) {
              amountToNext = 1 + actualPosition - currentPosition;

              if (weight >= amountToNext) {
                for (channel = 0; channel < channels; ++channel) {
                  output_variable_list[channel] += buffer[actualPosition++] * amountToNext;
                }

                currentPosition = actualPosition;
                weight -= amountToNext;
              } else {
                for (channel = 0; channel < channels; ++channel) {
                  output_variable_list[channel] += buffer[actualPosition + (channel > 0 ? channel : 0)] * weight;
                }

                currentPosition += weight;
                weight = 0;
                break;
              }
            }

            if (weight === 0) {
              for (channel = 0; channel < channels; ++channel) {
                outputBuffer[outputOffset++] = output_variable_list[channel] / ratioWeight;
              }
            } else {
              this.lastWeight = weight;

              for (channel = 0; channel < channels; ++channel) {
                this.lastOutput[channel] = output_variable_list[channel];
              }

              this.tailExists = true;
              break;
            }
          } while (actualPosition < bufferLength && outputOffset < outLength);

          return this.bufferSlice(outputOffset);
        };
      }

      resample(buffer) {
        if (this.fromSampleRate == this.toSampleRate) {
          this.ratioWeight = 1;
        } else {
          if (this.fromSampleRate < this.toSampleRate) {
            this.lastWeight = 1;
          } else {
            this.tailExists = false;
            this.lastWeight = 0;
          }

          this.initializeBuffers();
          this.ratioWeight = this.fromSampleRate / this.toSampleRate;
        }

        return this.resampler(buffer);
      }

    }

    /**
     * 将无符号Float32Array数组转化成有符号的Int16Array数组
     * @param {Float32Array} input unsinged Float32Array
     * @return {Int16Array} singed int16
     */
    function floatTo16BitPCM(input) {
      let i = input.length;
      let output = new Int16Array(i);

      while (i--) {
        let s = Math.max(-1, Math.min(1, input[i]));
        output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
      }

      return output;
    }
    /**
     * 将无符号Float32Array数组转化成有符号的Int8Array数组
     * @param {Float32Array} input unsinged Float32Array
     * @return {Int8Array} singed int8
     */

    function floatTo8BitPCM(input) {
      let i = input.length;
      let output = new Int8Array(i);

      while (i--) {
        let s = Math.max(-1, Math.min(1, input[i]));
        const temp = s < 0 ? s * 0x8000 : s * 0x7FFF;
        output[i] = parseInt(255 / (65535 / (32768 + temp)), 10);
      }

      return output;
    }

    const QUANT_MASK = 0xf;
    const SEG_SHIFT = 4;
    const BIAS = 0x84;
    const segEnd = [0xFF, 0x1FF, 0x3FF, 0x7FF, 0xFFF, 0x1FFF, 0x3FFF, 0x7FFF];

    function _search(val, table, size) {
      for (let i = 0; i < size; i++) {
        if (val <= table[i]) {
          return i;
        }
      }

      return size;
    } // alaw


    function _linear2alaw(pcmVal) {
      let mask;
      let seg;
      let aval;

      if (pcmVal >= 0) {
        mask = 0xD5;
      } else {
        mask = 0x55; // pcmVal = -pcmVal - 8;

        pcmVal = -pcmVal - 1;

        if (pcmVal < 0) {
          pcmVal = 32767;
        }
      }
      /* Convert the scaled magnitude to segment number. */


      seg = _search(pcmVal, segEnd, 8);

      if (seg >= 8) {
        return 0x7F ^ mask;
      } else {
        aval = seg << SEG_SHIFT;

        if (seg < 2) {
          aval |= pcmVal >> 4 & QUANT_MASK;
        } else {
          aval |= pcmVal >> seg + 3 & QUANT_MASK;
        }

        return aval ^ mask;
      }
    }


    function _linear2ulaw(pcmVal) {
      let mask = 0;

      if (pcmVal < 0) {
        pcmVal = BIAS - pcmVal;
        mask = 0x7F;
      } else {
        pcmVal += BIAS;
        mask = 0xFF;
      }

      let seg = _search(pcmVal, segEnd, 8);

      if (seg >= 8) {
        return 0x7F ^ mask;
      } else {
        let uval = seg << 4 | pcmVal >> seg + 3 & 0xF;
        return uval ^ mask;
      }
    }


    function g711aEncoder(typedArray) {
      const g711Array = [];
      const tempArray = Array.prototype.slice.call(typedArray);
      tempArray.forEach((i, index) => {
        g711Array[index] = _linear2alaw(i);
      });
      return g711Array;
    } // g711a to pcm(float32Array)

    function g711uEncoder(typedArray) {
      const g711Array = [];
      const tempArray = Array.prototype.slice.call(typedArray);
      tempArray.forEach((i, index) => {
        g711Array[index] = _linear2ulaw(i);
      });
      return g711Array;
    } // g711u

    class Talk extends Emitter {
      constructor(player) {
        let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
        super();

        if (player) {
          this.player = player;
        }

        this.tag = 'talk';
        this._opt = Object.assign({}, DEFAULT_TALK_OPTIONS, options);
        this._opt.sampleRate = parseInt(this._opt.sampleRate, 10);
        this._opt.sampleBitsWidth = parseInt(this._opt.sampleBitsWidth, 10);
        this.audioContext = null;
        this.gainNode = null;
        this.recorder = null;
        this.workletRecorder = null;
        this.biquadFilter = null;
        this.userMediaStream = null; // buffersize

        this.bufferSize = 512;
        this._opt.audioBufferLength = this.calcAudioBufferLength();
        this.audioBufferList = []; // socket

        this.socket = null;
        this.socketStatus = WEBSOCKET_STATUS.notConnect; //

        this.mediaStreamSource = null;
        this.heartInterval = null;
        this.checkGetUserMediaTimeout = null;
        this.wsUrl = null;
        this.startTimestamp = 0; // 报文数据

        this.sequenceId = 0;
        this.tempTimestamp = null;
        this.tempRtpBufferList = [];
        this.events = new Events(this);

        this._initTalk(); //


        if (!this.player) {
          this.debug = new Debug(this);
        }

        this.log(this.tag, 'init', this._opt);
      }

      destroy() {
        //
        if (this.userMediaStream) {
          this.userMediaStream.getTracks && this.userMediaStream.getTracks().forEach(track => {
            track.stop();
          });
          this.userMediaStream = null;
        }

        if (this.mediaStreamSource) {
          this.mediaStreamSource.disconnect();
          this.mediaStreamSource = null;
        }

        if (this.recorder) {
          this.recorder.disconnect();
          this.recorder.onaudioprocess = null;
        }

        if (this.biquadFilter) {
          this.biquadFilter.disconnect();
          this.biquadFilter = null;
        }

        if (this.gainNode) {
          this.gainNode.disconnect();
          this.gainNode = null;
        }

        if (this.workletRecorder) {
          this.workletRecorder.disconnect();
          this.workletRecorder = null;
        }

        if (this.socket) {
          if (this.socketStatus === WEBSOCKET_STATUS.open) {
            this._sendClose();
          }

          this.socket.close();
          this.socket = null;
        }

        this._stopHeartInterval();

        this._stopCheckGetUserMediaTimeout();

        this.audioContext = null;
        this.gainNode = null;
        this.recorder = null;
        this.audioBufferList = [];
        this.sequenceId = 0;
        this.wsUrl = null;
        this.tempTimestamp = null;
        this.tempRtpBufferList = [];
        this.startTimestamp = 0;
        this.log('talk', 'destroy');
      }

      addRtpToBuffer(rtp) {
        const len = rtp.length + this.tempRtpBufferList.length;
        const buffer = new Uint8Array(len);
        buffer.set(this.tempRtpBufferList, 0);
        buffer.set(rtp, this.tempRtpBufferList.length);
        this.tempRtpBufferList = buffer; //console.log('addRtpToBuffer length and byteLength ', this.tempRtpBufferList.length, this.tempRtpBufferList.byteLength)
      }

      downloadRtpFile() {
        const blob = new Blob([this.tempRtpBufferList]);

        try {
          const oa = document.createElement('a');
          oa.href = window.URL.createObjectURL(blob);
          oa.download = Date.now() + '.rtp';
          oa.click();
        } catch (e) {
          console.error('downloadRtpFile', e);
        }
      }

      calcAudioBufferLength() {
        const {
          sampleRate,
          sampleBitsWidth
        } = this._opt;
        return sampleRate * 8 * (20 / 1000) / 8;
      }

      get socketStatusOpen() {
        return this.socketStatus === WEBSOCKET_STATUS.open;
      }

      log() {
        for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {
          args[_key] = arguments[_key];
        }

        this._log('log', ...args);
      }

      warn() {
        for (var _len2 = arguments.length, args = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {
          args[_key2] = arguments[_key2];
        }

        this._log('warn', ...args);
      }

      error() {
        for (var _len3 = arguments.length, args = new Array(_len3), _key3 = 0; _key3 < _len3; _key3++) {
          args[_key3] = arguments[_key3];
        }

        this._log('error', ...args);
      }

      _log(type) {
        for (var _len4 = arguments.length, args = new Array(_len4 > 1 ? _len4 - 1 : 0), _key4 = 1; _key4 < _len4; _key4++) {
          args[_key4 - 1] = arguments[_key4];
        }

        if (this.player) {
          this.player.debug[type](...args);
        } else if (this.debug) {
          this.debug[type](...args);
        } else {
          console[type](...args);
        }
      }

      _getSequenceId() {
        return ++this.sequenceId;
      }

      _createWebSocket() {
        return new Promise((resolve, reject) => {
          const proxy = this.events.proxy;
          this.socket = new WebSocket(this.wsUrl);
          this.socket.binaryType = 'arraybuffer';
          this.emit(EVENTS.talkStreamStart);
          proxy(this.socket, WEBSOCKET_EVENTS.open, () => {
            this.socketStatus = WEBSOCKET_STATUS.open;
            this.log(this.tag, 'websocket open -> do talk');
            this.emit(EVENTS.talkStreamOpen);
            resolve();

            this._doTalk();
          });
          proxy(this.socket, WEBSOCKET_EVENTS.message, event => {
            this.log(this.tag, 'websocket message', event.data);
          });
          proxy(this.socket, WEBSOCKET_EVENTS.close, e => {
            this.socketStatus = WEBSOCKET_STATUS.close;
            this.log(this.tag, 'websocket close');
            this.emit(EVENTS.talkStreamClose);
            reject(e);
          });
          proxy(this.socket, WEBSOCKET_EVENTS.error, error => {
            this.socketStatus = WEBSOCKET_STATUS.error;
            this.error(this.tag, 'websocket error', error);
            this.emit(EVENTS.talkStreamError, error);
            reject(error);
          });
        });
      }

      _sendClose() {}

      _initTalk() {
        this._initMethods();

        if (this._opt.engine === TALK_ENGINE.worklet) {
          this._initWorklet();
        } else if (this._opt.engine === TALK_ENGINE.script) {
          this._initScriptProcessor();
        }

        this.log(this.tag, 'audioContext samplerate', this.audioContext.sampleRate);
      }

      _initMethods() {
        //
        this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
          sampleRate: 48000
        });
        this.gainNode = this.audioContext.createGain(); // default 1

        this.gainNode.gain.value = 1; // 消音器

        this.biquadFilter = this.audioContext.createBiquadFilter();
        this.biquadFilter.type = "lowpass";
        this.biquadFilter.frequency.value = 3000;
        this.resampler = new Resampler({
          fromSampleRate: this.audioContext.sampleRate,
          toSampleRate: this._opt.sampleRate,
          channels: this._opt.numberChannels,
          inputBufferSize: this.bufferSize
        });
      }

      _initScriptProcessor() {
        //
        const createScript = this.audioContext.createScriptProcessor || this.audioContext.createJavaScriptNode;
        this.recorder = createScript.apply(this.audioContext, [this.bufferSize, this._opt.numberChannels, this._opt.numberChannels]);

        this.recorder.onaudioprocess = e => this._onaudioprocess(e);
      }

      _initWorklet() {
        function workletProcess() {
          class TalkProcessor extends AudioWorkletProcessor {
            constructor(options) {
              super();
              this._cursor = 0;
              this._bufferSize = options.processorOptions.bufferSize;
              this._buffer = new Float32Array(this._bufferSize);
            }

            process(inputs, outputs, parameters) {
              if (!inputs.length || !inputs[0].length) {
                return true;
              }

              for (let i = 0; i < inputs[0][0].length; i++) {
                this._cursor += 1;

                if (this._cursor === this._bufferSize) {
                  this._cursor = 0;
                  this.port.postMessage({
                    eventType: 'data',
                    buffer: this._buffer
                  });
                }

                this._buffer[this._cursor] = inputs[0][0][i];
              }

              return true;
            }

          }

          registerProcessor('talk-processor', TalkProcessor);
        }

        this.audioContext.audioWorklet.addModule(createWorkletModuleUrl(workletProcess)).then(() => {
          const workletNode = new AudioWorkletNode(this.audioContext, 'talk-processor', {
            processorOptions: {
              bufferSize: this.bufferSize
            }
          });
          workletNode.connect(this.gainNode);

          workletNode.port.onmessage = e => {
            if (e.data.eventType === 'data') {
              this._encodeAudioData(e.data.buffer);
            }
          };

          this.workletRecorder = workletNode;
        });
      }

      _onaudioprocess(e) {
        // 数组里的每个数字都是32位的单精度浮点数
        // 默认是单精度
        const float32Array = e.inputBuffer.getChannelData(0); // send 出去。

        this._encodeAudioData(new Float32Array(float32Array));
      }

      _encodeAudioData(float32Array) {
        // 没有说话
        if (float32Array[0] === 0 && float32Array[1] === 0) {
          this.log(this.tag, 'empty audio data');
          return;
        }

        const resampleBuffer = this.resampler.resample(float32Array); // default 32Bit

        let tempArrayBuffer = resampleBuffer;

        if (this._opt.sampleBitsWidth === 16) {
          tempArrayBuffer = floatTo16BitPCM(resampleBuffer);
        } else if (this._opt.sampleBitsWidth === 8) {
          tempArrayBuffer = floatTo8BitPCM(resampleBuffer);
        }

        if (tempArrayBuffer.buffer !== null) {
          let typedArray = null;

          if (this._opt.encType === TALK_ENC_TYPE.g711a) {
            typedArray = g711aEncoder(tempArrayBuffer);
          } else if (this._opt.encType === TALK_ENC_TYPE.g711u) {
            typedArray = g711uEncoder(tempArrayBuffer);
          } //


          const unit8Array = Uint8Array.from(typedArray);

          for (let i = 0; i < unit8Array.length; i++) {
            let audioBufferLength = this.audioBufferList.length;
            this.audioBufferList[audioBufferLength++] = unit8Array[i]; //

            if (this.audioBufferList.length === this._opt.audioBufferLength) {
              this._sendTalkMsg(new Uint8Array(this.audioBufferList));

              this.audioBufferList = [];
            }
          }
        }
      }

      _parseAudioMsg(typedArray) {
        let typeArray2 = null; // rtp reumx just support g711a or g711u

        if (this._opt.packetType === TALK_PACKET_TYPE.rtp && (this._opt.encType === TALK_ENC_TYPE.g711a || this._opt.encType === TALK_ENC_TYPE.g711u)) {
          typeArray2 = this.rtpPacket(typedArray);
        } else if (this._opt.packetType === TALK_PACKET_TYPE.opus) {
          typeArray2 = this.opusPacket(typedArray);
        }

        return typeArray2;
      }

      rtpPacket(typedArray) {
        const rtpHeader = []; //2 bits RTP的版本，这里统一为2

        const version = 2; //1 bit 如果置1，在packet的末尾被填充，填充有时是方便一些针对固定长度的算法的封装

        const padding = 0; //1 bit 如果置1，在RTP Header会跟着一个header extension

        const extension = 0; //4 bits 表示头部后 特约信源 的个数

        const csrcCount = 0; //1 bit 不同的有效载荷有不同的含义，marker=1; 对于视频，标记一帧的结束；对于音频，标记会话的开始。

        const marker = 1; //7 bits 表示所传输的多媒体的类型，

        let playloadType = 0; //16 bits 每个RTP packet的sequence number会自动加一，以便接收端检测丢包情况

        let sequenceNumber = 0; //32 bits 时间戳

        let timestamp = 0; //32 bits 同步源的id，每两个同步源的id不能相同

        const ssrc = this._opt.rtpSsrc; //

        const frameLen = typedArray.length;

        if (this._opt.encType === TALK_ENC_TYPE.g711a) {
          playloadType = RTP_PAYLOAD_TYPE.g711a;
        } else if (this._opt.encType === TALK_ENC_TYPE.g711u) {
          playloadType = RTP_PAYLOAD_TYPE.g711u;
        }

        if (!this.startTimestamp) {
          this.startTimestamp = now$1();
        }

        timestamp = now$1() - this.startTimestamp;
        sequenceNumber = this._getSequenceId(); // frame length
        // 需要在rtp头前面加两个字节，表示数据包长度（整个rtp包长度）
        // 国标流udp不需要两个字节长度
        // 国标流tcp需要两个字节长度
        // websocket目前是按照tcp的做法做的

        const rtpFrameLen = frameLen + 12;
        rtpHeader[0] = 0xFF & rtpFrameLen >> 8;
        rtpHeader[1] = 0xFF & rtpFrameLen >> 0;
        rtpHeader[2] = (version << 6) + (padding << 5) + (extension << 4) + csrcCount;
        rtpHeader[3] = (marker << 7) + playloadType;
        rtpHeader[4] = sequenceNumber / (0xff + 1);
        rtpHeader[5] = sequenceNumber % (0xff + 1);
        rtpHeader[6] = timestamp / (0xffff + 1) / (0xff + 1);
        rtpHeader[7] = timestamp / (0xffff + 1) % (0xff + 1);
        rtpHeader[8] = timestamp % (0xffff + 1) / (0xff + 1);
        rtpHeader[9] = timestamp % (0xffff + 1) % (0xff + 1);
        rtpHeader[10] = ssrc / (0xffff + 1) / (0xff + 1);
        rtpHeader[11] = ssrc / (0xffff + 1) % (0xff + 1);
        rtpHeader[12] = ssrc % (0xffff + 1) / (0xff + 1);
        rtpHeader[13] = ssrc % (0xffff + 1) % (0xff + 1);
        let typeArray2 = rtpHeader.concat([...typedArray]);
        let binary = new Uint8Array(typeArray2.length);

        for (let ii = 0; ii < typeArray2.length; ii++) {
          binary[ii] = typeArray2[ii];
        }

        return binary;
      }

      opusPacket(typedArray) {
        //TODO:待完成
        return typedArray;
      }

      _sendTalkMsg(typedArray) {
        if (this.tempTimestamp === null) {
          this.tempTimestamp = now$1();
        }

        const timestamp = now$1();
        const diff = timestamp - this.tempTimestamp;

        const typedArray2 = this._parseAudioMsg(typedArray);

        this.log(this.tag, `'send talk msg and diff is ${diff} and byteLength is ${typedArray2.byteLength} and length is ${typedArray2.length}, and g711 length is ${typedArray.length}`);
        this.addRtpToBuffer(typedArray2);

        if (typedArray2) {
          if (this.socketStatusOpen) {
            this.socket.send(typedArray2.buffer);
          } else {
            this.emit(EVENTS_ERROR.tallWebsocketClosedByError);
          }
        }

        this.tempTimestamp = timestamp;
      }

      _doTalk() {
        this._getUserMedia(); // this._getUserMedia2();
        // this._getUserMedia3();

      }

      _getUserMedia() {
        this.log(this.tag, 'getUserMedia'); // 老的浏览器可能根本没有实现 mediaDevices，所以我们可以先设置一个空的对象

        if (window.navigator.mediaDevices === undefined) {
          window.navigator.mediaDevices = {};
        } // 一些浏览器部分支持 mediaDevices。我们不能直接给对象设置 getUserMedia
        // 因为这样可能会覆盖已有的属性。这里我们只会在没有 getUserMedia 属性的时候添加它。


        if (window.navigator.mediaDevices.getUserMedia === undefined) {
          this.log(this.tag, 'window.navigator.mediaDevices.getUserMedia is undefined and init function');

          window.navigator.mediaDevices.getUserMedia = function (constraints) {
            // 首先，如果有 getUserMedia 的话，就获得它
            var getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia; // 一些浏览器根本没实现它 - 那么就返回一个 error 到 promise 的 reject 来保持一个统一的接口
            // 由于受浏览器的限制，navigator.mediaDevices.getUserMedia在https协议下是可以正常使用的，
            // 而在http协议下只允许localhost/127.0.0.1这两个域名访问，
            // 因此在开发时应做好容灾处理，上线时则需要确认生产环境是否处于https协议下。

            if (!getUserMedia) {
              return Promise.reject(new Error('getUserMedia is not implemented in this browser'));
            } // 否则，为老的 navigator.getUserMedia 方法包裹一个 Promise


            return new Promise(function (resolve, reject) {
              getUserMedia.call(navigator, constraints, resolve, reject);
            });
          };
        }

        if (this._opt.checkGetUserMediaTimeout) {
          this._startCheckGetUserMediaTimeout();
        }

        window.navigator.mediaDevices.getUserMedia({
          audio: {
            latency: true,
            noiseSuppression: true,
            autoGainControl: true,
            echoCancellation: true,
            sampleRate: 48000,
            channelCount: 1
          },
          video: false
        }).then(stream => {
          this.log(this.tag, 'getUserMedia success');
          this.userMediaStream = stream;
          this.mediaStreamSource = this.audioContext.createMediaStreamSource(stream);
          this.mediaStreamSource.connect(this.biquadFilter);

          if (this.recorder) {
            this.biquadFilter.connect(this.recorder);
            this.recorder.connect(this.gainNode);
          } else if (this.workletRecorder) {
            this.biquadFilter.connect(this.workletRecorder);
            this.workletRecorder.connect(this.gainNode);
          }

          this.gainNode.connect(this.audioContext.destination);
          this.emit(EVENTS.talkGetUserMediaSuccess); // check stream inactive

          if (stream.oninactive === null) {
            stream.oninactive = e => {
              this._handleStreamInactive(e);
            };
          }
        }).catch(e => {
          this.error(this.tag, 'getUserMedia error', e.toString());
          this.emit(EVENTS.talkGetUserMediaFail, e.toString());
        }).finally(() => {
          this.log(this.tag, 'getUserMedia finally');

          this._stopCheckGetUserMediaTimeout();
        });
      }

      _getUserMedia2() {
        this.log(this.tag, 'getUserMedia');
        navigator.mediaDevices ? navigator.mediaDevices.getUserMedia({
          audio: true
        }).then(stream => {
          this.log(this.tag, 'getUserMedia2 success');
        }) : navigator.getUserMedia({
          audio: true
        }, this.log(this.tag, 'getUserMedia2 success'), this.log(this.tag, 'getUserMedia2 fail'));
      }

      async _getUserMedia3() {
        this.log(this.tag, 'getUserMedia3');

        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              latency: true,
              noiseSuppression: true,
              autoGainControl: true,
              echoCancellation: true,
              sampleRate: 48000,
              channelCount: 1
            },
            video: false
          });
          console.log('getUserMedia() got stream:', stream);
          this.log(this.tag, 'getUserMedia3 success');
        } catch (e) {
          this.log(this.tag, 'getUserMedia3 fail');
        }
      }

      _handleStreamInactive(e) {
        if (this.userMediaStream) {
          this.error(this.tag, 'stream oninactive');
          this.emit(EVENTS.talkStreamInactive);
        }
      }

      _startCheckGetUserMediaTimeout() {
        this._stopCheckGetUserMediaTimeout();

        this.checkGetUserMediaTimeout = setTimeout(() => {
          this.log(this.tag, 'check getUserMedia timeout');
          this.emit(EVENTS.talkGetUserMediaTimeout);
        }, this._opt.getUserMediaTimeout);
      }

      _stopCheckGetUserMediaTimeout() {
        if (this.checkGetUserMediaTimeout) {
          this.log(this.tag, 'stop checkGetUserMediaTimeout');
          clearTimeout(this.checkGetUserMediaTimeout);
          this.checkGetUserMediaTimeout = null;
        }
      }

      _startHeartInterval() {
        // 定时发送心跳，
        this.heartInterval = setInterval(() => {
          this.log(this.tag, 'heart interval');
          let data = [0x23, 0x24, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00];
          data = new Uint8Array(data);
          this.socket.send(data.buffer);
        }, 15 * 1000);
      }

      _stopHeartInterval() {
        if (this.heartInterval) {
          this.log(this.tag, 'stop heart interval');
          clearInterval(this.heartInterval);
          this.heartInterval = null;
        }
      }

      startTalk(wsUrl) {
        return new Promise((resolve, reject) => {
          if (!isSupportGetUserMedia()) {
            return reject('not support getUserMedia');
          }

          this.wsUrl = wsUrl;

          if (this._opt.testMicrophone) {
            this._doTalk();

            return resolve();
          }

          this._createWebSocket().catch(e => {
            reject(e);
          }); // reject


          this.once(EVENTS.talkGetUserMediaFail, () => {
            reject('getUserMedia fail');
          }); // only get user media success and resolve

          this.once(EVENTS.talkGetUserMediaSuccess, () => {
            resolve();
          });
        });
      }

      setVolume(volume) {
        volume = parseFloat(volume).toFixed(2);

        if (isNaN(volume)) {
          return;
        }

        volume = clamp(volume, 0, 1);
        this.gainNode.gain.value = volume;
      }

      getOption() {
        return this._opt;
      }

      get volume() {
        return this.gainNode ? parseFloat(this.gainNode.gain.value * 100).toFixed(0) : null;
      }

    }

    class JessibucaPro extends Emitter {
      constructor(options) {
        super();

        let _opt = Object.assign({}, DEFAULT_JESSIBUCA_OPTIONS, options);

        let $container = options.container;

        if (typeof options.container === 'string') {
          $container = document.querySelector(options.container);
        }

        if (!$container) {
          throw new Error('Jessibuca-pro need container option');
        } // check container node name


        if ($container.nodeName === 'CANVAS' || $container.nodeName === 'VIDEO') {
          throw new Error(`Jessibuca-pro container type can not be ${$container.nodeName} type`);
        }

        if (_opt.videoBuffer >= _opt.heartTimeout) {
          throw new Error(`Jessibuca-pro videoBuffer ${_opt.videoBuffer}s must be less than heartTimeout ${_opt.heartTimeout}s`);
        }

        $container.classList.add('jessibuca-container');

        if (_opt.isLive === false) {
          const $videoElement = document.createElement('video');
          $videoElement.muted = true;
          $videoElement.setAttribute("controlsList", "nodownload");
          $videoElement.disablePictureInPicture = 'disablePictureInPicture';
          $videoElement.style.position = "absolute";
          $videoElement.style.top = 0;
          $videoElement.style.left = 0;
          $videoElement.style.height = "100%";
          $videoElement.style.width = '100%';
          $container.appendChild($videoElement);
          this.$videoElement = $videoElement;
          this.$container = $container;
          this._opt = _opt;
          return;
        }

        delete _opt.container; // s -> ms

        if (isNotEmpty(_opt.videoBuffer)) {
          _opt.videoBuffer = Number(_opt.videoBuffer) * 1000;
        } // s -> ms


        if (isNotEmpty(_opt.videoBufferDelay)) {
          _opt.videoBufferDelay = Number(_opt.videoBufferDelay) * 1000;
        } // s -> ms


        if (isNotEmpty(_opt.networkDelay)) {
          _opt.networkDelay = Number(_opt.networkDelay) * 1000;
        } // setting


        if (isNotEmpty(_opt.timeout)) {
          if (isEmpty(_opt.loadingTimeout)) {
            _opt.loadingTimeout = _opt.timeout;
          }

          if (isEmpty(_opt.heartTimeout)) {
            _opt.heartTimeout = _opt.timeout;
          }
        }

        this._opt = _opt;
        this.$container = $container;
        this._loadingTimeoutReplayTimes = 0;
        this._heartTimeoutReplayTimes = 0;
        this.events = new Events(this);
        this.debug = new Debug(this);

        this._initPlayer($container, _opt);
      }
      /**
       *
       */


      destroy() {
        if (this.$videoElement) {
          this.$videoElement.pause();
          this.$videoElement.currentTime = 0;
          this.$videoElement.src = '';
          this.$container.removeChild(this.$videoElement);
          this.$videoElement = null;
        }

        if (this.events) {
          this.events.destroy();
          this.events = null;
        }

        if (this.player) {
          this.player.destroy();
          this.player = null;
        }

        if (this.talk) {
          this.talk.destroy();
          this.talk = null;
        }

        this.$container = null;

        this._resetOpt();

        this._loadingTimeoutReplayTimes = 0;
        this._heartTimeoutReplayTimes = 0;
        this.off();
        this.debug && this.debug.log('jessibuca', 'destroy');
      }

      _resetOpt() {
        this._opt = DEFAULT_JESSIBUCA_OPTIONS;
      }

      _initPlayer($container, options) {
        this.player = new Player($container, options);
        this.debug.log('jessibuca', '_initPlayer', this.player.getOption());

        this._bindEvents();
      }

      _initTalk() {
        let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};

        if (this.talk) {
          this.talk.destroy();
          this.talk = null;
        }

        if (this.player) {
          options.debug = this.player._opt.debug;
        }

        this.talk = new Talk(this.player, options);
        this.debug.log('jessibuca', '_initTalk', this.talk.getOption());

        this._bindTalkEvents();
      }

      _resetPlayer() {
        let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};

        if (this.player) {
          this.player.destroy();
          this.player = null;
        }

        this._opt = Object.assign(this._opt, options);
        this._opt.url = ''; // reset url

        this._initPlayer(this.$container, this._opt);
      }

      _bindEvents() {
        // 对外的事件
        Object.keys(JESSIBUCA_EVENTS).forEach(key => {
          this.player.on(JESSIBUCA_EVENTS[key], value => {
            this.emit(key, value);
          });
        });
        this.player.once(EVENTS.beforeDestroy, () => {
          this.emit(EVENTS.close);
          this.destroy();
        });
      }

      _bindTalkEvents() {
        // 对外的事件
        Object.keys(TALK_EVENTS).forEach(key => {
          this.player.on(TALK_EVENTS[key], value => {
            this.emit(key, value);
          });
        });
      }
      /**
       *
       * @returns {{}|({rotate: number, isResize: boolean, playbackForwardMaxRateDecodeIFrame: number, loadingTimeoutReplayTimes: number, wasmDecodeErrorReplay: boolean, demuxType: string, useWCS: boolean, useOffscreen: boolean, loadingTimeout: number, playbackConfig: {playList: [], fps: string}, timeout: number, wasmUseVideoRender: boolean, heartTimeoutReplay: boolean, isNotMute: boolean, protocol: number, useMSE: boolean, operateBtns: {play: boolean, fullscreen: boolean, record: boolean, screenshot: boolean, audio: boolean}, isHls: boolean, hotKey: boolean, heartTimeout: number, isFlv: boolean, openWebglAlignment: boolean, hasVideo: boolean, loadingTimeoutReplay: boolean, hasAudio: boolean, debug: boolean, loadingText: string, useWasm: boolean, keepScreenOn: boolean, isFullResize: boolean, watermarkConfig: {}, forceNoOffscreen: boolean, videoBuffer: number, decoder: string, isWebrtc: boolean, url: string, showBandwidth: boolean, hiddenAutoPause: boolean, autoWasm: boolean, heartTimeoutReplayTimes: number, playType: string, background: string, hasControl: boolean, controlAutoHide: boolean, playbackDelayTime: number, playbackFps: number, supportDblclickFullscreen: boolean, wcsUseVideoRender: boolean} & *)}
       */


      getOption() {
        if (this.player) {
          return this.player.getOption();
        }

        return {};
      }
      /**
       * 是否开启控制台调试打印
       * @param value {Boolean}
       */


      setDebug(value) {
        this.player && this.player.updateOption({
          debug: !!value
        });
      }
      /**
       *
       */


      mute() {
        this.player && this.player.mute(true);
      }
      /**
       *
       */


      cancelMute() {
        this.player && this.player.mute(false);
      }
      /**
       *
       * @param value {number}
       */


      setVolume(value) {
        this.player && (this.player.volume = value);
      }
      /**
       *
       */


      audioResume() {
        this.player && this.player.audio && this.player.audio.audioEnabled(true);
      }
      /**
       * 设置超时时长, 单位秒 在连接成功之前和播放中途,如果超过设定时长无数据返回,则回调timeout事件
       * @param value {number}
       */


      setTimeout(time) {
        time = Number(time);
        this.player && this.player.updateOption({
          timeout: time,
          loadingTimeout: time,
          heartTimeout: time
        });
      }
      /**
       *
       * @param type {number}: 0,1,2
       */


      setScaleMode(type) {
        if (this.player) {
          this.player.setScaleMode(type);
        }
      }
      /**
       *
       * @returns {Promise<commander.ParseOptionsResult.unknown>}
       */


      pause() {
        return this.player && this.player.pause();
      }
      /**
       *
       */


      close() {
        // clear url
        this._resetOpt();

        return this.player && this.player.close();
      }
      /**
       *
       */


      clearView() {
        this.player && this.player.video && this.player.video.clearView();
      }
      /**
       *
       * @param url {string}
       * @returns {Promise<unknown>}
       */


      play(url) {
        let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
        return new Promise((resolve, reject) => {
          if (!url && !this._opt.url) {
            this.emit(EVENTS.error, EVENTS_ERROR.playError);
            reject();
            return;
          } //


          if (url) {
            url = ('' + url).trim();
          }

          if (this._opt.isLive === false) {
            this.$videoElement.controls = 'controls';
            this.$videoElement.muted = false;
            this.$videoElement.src = url;
            this.$videoElement.play();
            resolve(this.$videoElement);
            return;
          }

          if (this.player) {
            if (url) {
              // url 相等的时候。
              if (this._opt.url) {
                // 存在相同的 url
                if (url === this._opt.url) {
                  // 正在播放
                  if (this.player.playing) {
                    resolve();
                  } else {
                    // pause ->  play
                    this.clearView();
                    this.player.play(this._opt.url, this._opt.playOptions).then(() => {
                      resolve(); // 恢复下之前的音量

                      this.player.resumeAudioAfterPause();
                    }).catch(e => {
                      this.debug.error('Jessibuca', 'this.player.play error', e);
                      this.emit(EVENTS.crashLog, this.getCrashLog(e));
                      this.player.pause().then(() => {
                        reject(e);
                      });
                    });
                  }
                } else {
                  // url 发生改变了
                  this.player.pause().then(() => {
                    // 清除 画面
                    this.clearView();

                    this._play(url, options).then(() => {
                      resolve();
                    }).catch(e => {
                      this.debug.error('Jessibuca', '_play error', e);
                      reject(e);
                    });
                  }).catch(e => {
                    this.debug.error('Jessibuca', 'this.player.pause error', e);
                    reject(e);
                  });
                }
              } else {
                this._play(url, options).then(() => {
                  resolve();
                }).catch(e => {
                  this.debug.error('Jessibuca', '_play error', e);
                  reject(e);
                });
              }
            } else {
              //  url 不存在的时候
              //  就是从 play -> pause -> play
              this.player.play(this._opt.url, this._opt.playOptions).then(() => {
                resolve(); // 恢复下之前的音量

                this.player.resumeAudioAfterPause();
              }).catch(e => {
                this.debug.error('Jessibuca', 'this.player.play error', e);
                this.emit(EVENTS.crashLog, this.getCrashLog(e));
                this.player.pause().then(() => {
                  reject(e);
                });
              });
            }
          } else {
            if (url) {
              this._play(url, options).then(() => {
                resolve();
              }).catch(e => {
                this.debug.error('Jessibuca', '_play error', e);
                reject(e);
              });
            } else {
              this._play(this._opt.url, options).then(() => {
                resolve();
              }).catch(e => {
                this.debug.error('Jessibuca', '_play error', e);
                reject(e);
              });
            }
          }
        });
      }
      /**
       * playback 录像回放
       * @param url {string}
       */


      playback(url) {
        let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};

        if (this._opt.isLive === false) {
          return Promise.reject();
        }

        const playbackConfig = Object.assign({}, DEFAULT_PLAYER_OPTIONS.playbackConfig, this._opt.playbackConfig, options);

        if (!playbackConfig.isUseFpsRender) {
          if (playbackConfig.isCacheBeforeDecodeForFpsRender) {
            playbackConfig.isCacheBeforeDecodeForFpsRender = false;
            this.debug.error('Jessibuca', 'playbackConfig.isUseFpsRender is false, isCacheBeforeDecodeForFpsRender can not be ture, isCacheBeforeDecodeForFpsRender is set to false');
          }
        }

        this._resetPlayer({
          videoBuffer: 0,
          // 录播的时候不缓存。
          playbackConfig,
          playType: PLAY_TYPE.playbackTF,
          useMSE: false,
          //
          useWCS: false //

        });

        return this.play(url);
      } // playback pause


      playbackPause() {
        if (this._opt.playType === PLAY_TYPE.player) {
          return Promise.reject();
        }

        return new Promise((resolve, reject) => {
          if (!this.player) {
            return reject();
          }

          this.player.playbackPause = true;
          resolve();
        });
      } // playback pause - > resume


      playbackResume() {
        if (this._opt.playType === PLAY_TYPE.player) {
          return Promise.reject();
        }

        return new Promise((resolve, reject) => {
          if (!this.player) {
            return reject();
          }

          this.player.playbackPause = false;
          resolve();
        });
      }
      /**
       * 快放 1倍，2倍，4倍，8倍,支持范围 0.1 - 8
       * @param rate
       * @returns {Promise<unknown>}
       */


      forward(rate) {
        if (this._opt.isLive === false || this._opt.playType === PLAY_TYPE.player) {
          return Promise.reject('forward() method only just for playback type');
        }

        if (!isNumber(Number(rate))) {
          return Promise.reject(`forward() params "rate": ${rate} must be number type`);
        }

        return new Promise((resolve, reject) => {
          if (this.player && this.player.playing) {
            rate = clamp(Number(rate), 0.1, 8);
            this.player.playback.setRate(rate);
            this.player.video && this.player.video.setRate(rate);
            this.player.audio && this.player.audio.setRate(rate);
            this.player.decoderWorker.clearWorkBuffer(true); // update config

            this.player.decoderWorker && this.player.decoderWorker.updateWorkConfig({
              key: 'playbackRate',
              value: rate
            });
            resolve();
          } else {
            reject();
          }
        });
      }
      /**
       * playback 快放->恢复
       * @returns {Promise<unknown>}
       */


      normal() {
        return this.forward(1);
      }
      /**
       * playback 更新TF卡流只解码i帧播放倍率，支持playback()之前调用。
       * @param rate
       */


      updatePlaybackForwardMaxRateDecodeIFrame(rate) {
        rate = clamp(Number(rate), 1, 8);

        if (this.player) {
          this.player.updateOption({
            playbackForwardMaxRateDecodeIFrame: rate
          });
        } else {
          this._opt.playbackForwardMaxRateDecodeIFrame = rate;
        }
      }
      /**
       * playback set playback start time  and clear buffer
       * for seek callback
       * @param timestamp
       */


      setPlaybackStartTime(timestamp) {
        const strLength = getStrLength(timestamp);

        if (!this.player) {
          return;
        }

        if (!this.player.isPlayback()) {
          return;
        }

        if (strLength < 10 && timestamp !== 0) {
          return;
        }

        if (this.player.playing) {
          if (strLength === 10) {
            timestamp = timestamp * 1000;
          }

          this.player.playback.setStartTime(timestamp);
          this.playbackClearCacheBuffer();
        }
      }
      /**
       *
       */


      playbackClearCacheBuffer() {
        if (!this.player) {
          return;
        }

        if (!this.player.isPlayback()) {
          return;
        }

        this.player.video && this.player.video.clear();
        this.player.audio && this.player.audio.clear();
        this.player.decoderWorker.clearWorkBuffer(true);
      }
      /**
       *
       * @param quality
       */


      setStreamQuality(quality) {
        if (!this.player) {
          return;
        }

        if (!this.player._opt.operateBtns.quality) {
          return;
        }

        const qualityList = this.player._opt.qualityConfig || [];

        if (qualityList.includes(quality)) {
          this.player.streamQuality = quality;
        }
      }
      /**
       *
       * @param url {string}
       * @returns {Promise<unknown>}
       * @private
       */


      _play(url) {
        let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
        return new Promise((resolve, reject) => {
          // check need reset player
          let needResetPlayer = false;

          if (this._opt.url && this._opt.url !== url) {
            needResetPlayer = true;
          }

          this._opt.url = url; //  新的url

          const isHttp = url.indexOf("http") === 0;
          const isWebrtc = url.indexOf('webrtc') === 0;
          const isWebTransport = url.indexOf('wt') === 0;
          const isHls = !isWebrtc && url.indexOf('.m3u8') !== -1;
          const isFlv = !isWebrtc && url.indexOf(".flv") !== -1; //

          let protocol = null;
          let demuxType = null;

          if (isHttp) {
            if (isHls) {
              protocol = PLAYER_PLAY_PROTOCOL.hls;
            } else {
              protocol = PLAYER_PLAY_PROTOCOL.fetch;
            }
          } else if (isWebTransport) {
            protocol = PLAYER_PLAY_PROTOCOL.webTransport;
          } else {
            if (isWebrtc) {
              protocol = PLAYER_PLAY_PROTOCOL.webrtc;
            } else {
              protocol = PLAYER_PLAY_PROTOCOL.websocket;
            }
          }

          if (this._opt.isNakedFlow) {
            demuxType = DEMUX_TYPE.nakedFlow;
          } else if (isHttp && !isHls || isFlv || this._opt.isFlv) {
            demuxType = DEMUX_TYPE.flv;
          } else {
            if (isHls) {
              demuxType = DEMUX_TYPE.hls;
            } else if (isWebrtc) {
              demuxType = DEMUX_TYPE.webrtc;
            } else if (isWebTransport) {
              demuxType = DEMUX_TYPE.webTransport;
            } else {
              demuxType = DEMUX_TYPE.m7s;
            }
          }

          if (isFlv && !this._opt.isFlv) {
            this._opt.isFlv = true;
          }

          if (!(protocol && demuxType)) {
            // this.debug.log('Jessibuca', `play protocol is ${protocol}, demuxType is ${demuxType}`)
            return reject(`play protocol is ${protocol}, demuxType is ${demuxType}`);
          } //


          if (isHls || isWebrtc || needResetPlayer) {
            this._resetPlayer({
              protocol,
              demuxType,
              isHls,
              isWebrtc
            });
          } else {
            this.player.updateOption({
              protocol,
              demuxType,
              isFlv: this._opt.isFlv
            });
          } // webgl


          this.player.once(EVENTS_ERROR.webglAlignmentError, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.webglAlignmentError));
            this.pause().then(() => {
              this.debug.log('Jessibuca', 'webglAlignmentError');

              this._resetPlayer({
                openWebglAlignment: true
              });

              this.play(url).then(() => {
                // resolve();
                this.debug.log('Jessibuca', 'webglAlignmentError and play success');
              }).catch(e => {
                // reject();
                this.debug.error('Jessibuca', 'webglAlignmentError and play error', e);
              });
            });
          }); // MSE

          this.player.once(EVENTS_ERROR.mediaSourceH265NotSupport, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.mediaSourceH265NotSupport));
            this.pause().then(() => {
              if (this.player._opt.autoWasm) {
                this.debug.log('Jessibuca', 'auto wasm [mse-> wasm] reset player and play');

                this._resetPlayer({
                  useMSE: false
                });

                this.play(url).then(() => {
                  // resolve();
                  this.debug.log('Jessibuca', 'auto wasm [mse-> wasm] reset player and play success');
                }).catch(e => {
                  // reject();
                  this.debug.error('Jessibuca', 'auto wasm [mse-> wasm] reset player and play error', e);
                });
              }
            });
          }); // MSE

          this.player.once(EVENTS_ERROR.mediaSourceFull, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.mediaSourceFull));
            this.pause().then(() => {
              this.debug.log('Jessibuca', 'media source full');

              this._resetPlayer();

              this.play(url).then(() => {
                // resolve();
                this.debug.log('Jessibuca', 'media source full and reset player and play success');
              }).catch(e => {
                // reject();
                this.debug.error('Jessibuca', 'media source full and reset player and play error', e);
              });
            });
          }); // MSE

          this.player.once(EVENTS_ERROR.mediaSourceAppendBufferError, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.mediaSourceAppendBufferError));
            this.pause().then(() => {
              this.debug.log('Jessibuca', 'media source append buffer error');

              this._resetPlayer();

              this.play(url).then(() => {
                // resolve();
                this.debug.log('Jessibuca', 'media source append buffer error and reset player and play success');
              }).catch(e => {
                // reject();
                this.debug.error('Jessibuca', 'media source append buffer error and reset player and play error', e);
              });
            });
          }); // MSE

          this.player.once(EVENTS_ERROR.mediaSourceBufferListLarge, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.mediaSourceBufferListLarge));
            this.pause().then(() => {
              this.debug.log('Jessibuca', 'media source buffer list large');

              this._resetPlayer();

              this.play(url).then(() => {
                // resolve();
                this.debug.log('Jessibuca', 'media source buffer list large and reset player and play success');
              }).catch(e => {
                // reject();
                this.debug.error('Jessibuca', 'media source buffer list large and reset player and play error', e);
              });
            });
          }); // MSE

          this.player.once(EVENTS_ERROR.mediaSourceAppendBufferEndTimeout, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.mediaSourceAppendBufferEndTimeout));
            this.pause().then(() => {
              this.debug.log('Jessibuca', 'media source append buffer end timeout');

              this._resetPlayer();

              this.play(url).then(() => {
                // resolve();
                this.debug.log('Jessibuca', 'media source append buffer end timeout and reset player and play success');
              }).catch(e => {
                // reject();
                this.debug.error('Jessibuca', 'media source append buffer end timeout and reset player and play error', e);
              });
            });
          }); // MSE

          this.player.once(EVENTS_ERROR.mseSourceBufferError, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.mseSourceBufferError));
            this.pause().then(() => {
              if (this.player._opt.autoWasm) {
                this.debug.log('Jessibuca', 'mseSourceBufferError auto wasm [mse-> wasm] reset player and play');

                this._resetPlayer({
                  useMSE: false
                });

                this.play(url).then(() => {
                  // resolve();
                  this.debug.log('Jessibuca', 'mseSourceBufferError auto wasm [mse-> wasm] reset player and play success');
                }).catch(e => {
                  // reject();
                  this.debug.error('Jessibuca', 'mseSourceBufferError auto wasm [mse-> wasm] reset player and play error', e);
                });
              }
            });
          }); // webcodecs

          this.player.once(EVENTS_ERROR.webcodecsH265NotSupport, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.webcodecsH265NotSupport));
            this.pause().then(() => {
              if (this.player._opt.autoWasm) {
                this.debug.log('Jessibuca', 'auto wasm [wcs-> wasm] reset player and play');

                this._resetPlayer({
                  useWCS: false
                });

                this.play(url).then(() => {
                  // resolve();
                  this.debug.log('Jessibuca', 'auto wasm [wcs-> wasm] reset player and play success');
                }).catch(e => {
                  // reject();
                  this.debug.error('Jessibuca', 'auto wasm [wcs-> wasm] reset player and play error', e);
                });
              }
            });
          }); // webcodecs

          this.player.once(EVENTS_ERROR.webcodecsWidthOrHeightChange, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.webcodecsWidthOrHeightChange));
            this.pause().then(() => {
              this.debug.log('Jessibuca', 'webcodecs Width Or Height Change reset player and play');

              this._resetPlayer({
                useWCS: true
              });

              this.play(url).then(() => {
                // resolve();
                this.debug.log('Jessibuca', 'webcodecs Width Or Height Change reset player and play success');
              }).catch(e => {
                // reject();
                this.debug.warn('Jessibuca', 'webcodecs Width Or Height Change reset player and play error', e);
              });
            });
          }); // webcodecs

          this.player.once(EVENTS_ERROR.webcodecsDecodeError, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.webcodecsDecodeError));
            this.pause().then(() => {
              if (this.player._opt.autoWasm) {
                this.debug.log('Jessibuca', 'webcodecs decode error reset player and play');

                this._resetPlayer({
                  useWCS: false
                });

                this.play(url).then(() => {
                  // resolve();
                  this.debug.log('Jessibuca', 'webcodecs decode error  reset player and play success');
                }).catch(e => {
                  // reject();
                  this.debug.error('Jessibuca', 'webcodecs decode error reset player and play error', e);
                });
              }
            });
          }); // wasm。

          this.player.once(EVENTS_ERROR.wasmDecodeError, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.wasmDecodeError));

            if (this.player._opt.wasmDecodeErrorReplay) {
              this.pause().then(() => {
                this.debug.log('Jessibuca', 'wasm decode error and reset player and play');
                this.play(url, options).then(() => {
                  // resolve();
                  this.debug.log('Jessibuca', 'wasm decode error and reset player and play success');
                }).catch(e => {
                  // reject();
                  this.debug.error('Jessibuca', 'wasm decode error and reset player and play error', e);
                });
              });
            }
          }); // 网络超时

          this.player.once(EVENTS.networkDelayTimeout, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS.networkDelayTimeout));

            if (this.player._opt.networkDelayTimeoutReplay) {
              this.pause().then(() => {
                this.debug.log('Jessibuca', `network delay time out and reset player and play`);
                this.play(url, options).then(() => {
                  // resolve();
                  this.debug.log('Jessibuca', 'wasm decode error and reset player and play success');
                }).catch(e => {
                  // reject();
                  this.debug.error('Jessibuca', 'wasm decode error and reset player and play error', e);
                });
              });
            }
          }); // stream fetch error

          this.player.once(EVENTS_ERROR.fetchError, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS_ERROR.fetchError));
            this.debug.log('Jessibuca', 'fetch error and reset player');
            this.pause().then(() => {
              this._resetPlayer();
            }).catch(e => {
              this.debug.error('Jessibuca', 'fetch error', e);
            });
          }); // 监听 delay timeout

          this.player.on(EVENTS.delayTimeout, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS.delayTimeout));

            if (this.player._opt.heartTimeoutReplay && (this._heartTimeoutReplayTimes < this.player._opt.heartTimeoutReplayTimes || this.player._opt.heartTimeoutReplayTimes === -1)) {
              this.debug.log('Jessibuca', `delay timeout replay time is ${this._heartTimeoutReplayTimes}`);
              this._heartTimeoutReplayTimes += 1;
              this.play(url, options).then(() => {
                // resolve();
                this._heartTimeoutReplayTimes = 0;
              }).catch(e => {
                // reject();
                this.debug.error('Jessibuca', 'delay timeout replay error', e);
              });
            }
          }); // 监听 loading timeout

          this.player.on(EVENTS.loadingTimeout, () => {
            this.emit(EVENTS.crashLog, this.getCrashLog(EVENTS.loadingTimeout));

            if (this.player._opt.loadingTimeoutReplay && (this._loadingTimeoutReplayTimes < this.player._opt.loadingTimeoutReplayTimes || this.player._opt.loadingTimeoutReplayTimes === -1)) {
              this.debug.log('Jessibuca', `loading timeout replay time is ${this._loadingTimeoutReplayTimes}`);
              this._loadingTimeoutReplayTimes += 1;
              this.play(url, options).then(() => {
                // resolve();
                this._loadingTimeoutReplayTimes = 0;
              }).catch(e => {
                // reject();
                this.debug.error('Jessibuca', 'loading timeout replay error', e);
              });
            }
          });

          if (this.hasLoaded()) {
            this.player.play(url, options).then(() => {
              resolve();
            }).catch(e => {
              this.debug.error('Jessibuca', 'hasLoaded and play error', e);
              this.emit(EVENTS.crashLog, this.getCrashLog(e));
              this.player.pause().then(() => {
                reject(e);
              });
            });
          } else {
            this.player.once(EVENTS.decoderWorkerInit, () => {
              this.player.play(url, options).then(() => {
                resolve();
              }).catch(e => {
                this.debug.error('Jessibuca', 'decoderWorkerInit and play error', e);
                this.emit(EVENTS.crashLog, this.getCrashLog(e));
                this.player.pause().then(() => {
                  reject(e);
                });
              });
            });
          }
        });
      }
      /**
       *
       */


      resize() {
        this.player && this.player.resize();
      }
      /**
       *
       * @param time {number} s
       */


      setBufferTime(time) {
        time = Number(time);

        if (!this.player) {
          return;
        }

        if (time > 10) {
          console.warn(`Jessibuca buffer time is ${time} second, is too large, video will show blank screen until cache ${time} second buffer data`);
        } // s -> ms


        this.player.updateOption({
          videoBuffer: time * 1000
        }); // update worker config

        this.player.decoderWorker && this.player.decoderWorker.updateWorkConfig({
          key: 'videoBuffer',
          value: time * 1000
        });
      }
      /**
       *
       * @param time
       */


      setBufferDelayTime(time) {
        time = Number(time);

        if (!this.player) {
          return;
        }

        if (time < 0.2) {
          console.warn(`Jessibuca buffer time delay is ${time} second, is too small`);
        }

        time = clamp(time, 0.2, 100); // s -> ms

        this.player.updateOption({
          videoBufferDelay: time * 1000
        }); // update worker config

        this.player.decoderWorker && this.player.decoderWorker.updateWorkConfig({
          key: 'videoBufferDelay',
          value: time * 1000
        });
      }
      /**
       *
       * @param deg {number}
       */


      setRotate(deg) {
        deg = parseInt(deg, 10);
        const list = [0, 90, 180, 270];

        if (!this.player) {
          return;
        }

        if (this._opt.rotate === deg || list.indexOf(deg) === -1) {
          return;
        }

        this.player.updateOption({
          rotate: deg
        });
        this.resize();
      }
      /**
       * 设置镜像翻转
       * @param type
       */


      setMirrorRotate(mirrorRotate) {
        const list = ['none', 'level', 'vertical'];

        if (!this.player) {
          return;
        }

        if (this._opt.mirrorRotate === mirrorRotate || list.indexOf(mirrorRotate) === -1) {
          return;
        }

        this.player.updateOption({
          mirrorRotate
        });
        this.resize();
      }
      /**
       *
       * @returns {boolean}
       */


      hasLoaded() {
        return this.player && this.player.loaded || false;
      }
      /**
       *
       */


      setKeepScreenOn() {
        this.player && this.player.updateOption({
          keepScreenOn: true
        });
      }
      /**
       *
       * @param flag {Boolean}
       */


      setFullscreen(flag) {
        const fullscreen = !!flag;

        if (!this.player) {
          return;
        }

        if (this.player.fullscreen !== fullscreen) {
          this.player.fullscreen = fullscreen;
        }
      }
      /**
       *
       * @param filename {string}
       * @param format {string}
       * @param quality {number}
       * @param type {string} download,base64,blob
       */


      screenshot(filename, format, quality, type) {
        if (this.player && this.player.video) {
          return this.player.video.screenshot(filename, format, quality, type);
        }

        return null;
      }
      /**
       *
       * @param options
       * @returns Promise
       */


      screenshotWatermark(options) {
        if (this.player && this.player.video) {
          return this.player.video.screenshotWatermark(options);
        }

        return null;
      }
      /**
       *
       * @param fileName {string}
       * @param fileType {string}
       * @returns {Promise<unknown>}
       */


      startRecord(fileName, fileType) {
        return new Promise((resolve, reject) => {
          if (!this.player) {
            return reject();
          }

          if (this.player.playing) {
            this.player.startRecord(fileName, fileType);
            resolve();
          } else {
            reject();
          }
        });
      }

      stopRecordAndSave(type, fileName) {
        return new Promise((resolve, reject) => {
          if (this.player && this.player.recording) {
            this.player.stopRecordAndSave(type, fileName).then(blob => {
              resolve(blob);
            }).catch(e => {
              reject(e);
            });
          } else {
            reject('not recording');
          }
        });
      }
      /**
       *
       * @returns {Boolean}
       */


      isPlaying() {
        return this.player ? this.player.playing : false;
      }
      /**
       *
       * @returns {boolean}
       */


      isLoading() {
        return this.player ? this.player.loading : false;
      }
      /**
       *
       * @returns {boolean}
       */


      isPause() {
        let result = false;

        if (this._opt.playType === PLAY_TYPE.player) {
          result = !this.isPlaying() && !this.isLoading();
        } else if (this._opt.playType === PLAY_TYPE.playbackTF && this.player) {
          result = this.player.playbackPause;
        }

        return result;
      }
      /**
       *
       * @returns {boolean}
       */


      isPlaybackPause() {
        let result = false;

        if (this._opt.playType === PLAY_TYPE.playbackTF && this.player) {
          result = this.player.playbackPause;
        }

        return result;
      }
      /**
       * 是否静音状态
       * @returns {Boolean}
       */


      isMute() {
        let result = true;

        if (this.player) {
          result = this.player.isAudioMute();
        }

        return result;
      }
      /**
       * 是否在录制视频
       * @returns {*}
       */


      isRecording() {
        return this.player && this.player.recorder && this.player.recorder.recording || false;
      }
      /**
       * 清除延迟
       */


      clearBufferDelay() {
        if (this.player) {
          this.player.clearBufferDelay();
        }
      }

      setNetworkDelayTime(time) {
        time = Number(time);

        if (!this.player) {
          return;
        }

        if (time < 1) {
          console.warn(`Jessibuca network delay is ${time} second, is too small`);
        }

        time = clamp(time, 1, 100); // s -> ms

        this.player.updateOption({
          networkDelay: time * 1000
        }); // update worker config

        this.player.decoderWorker && this.player.decoderWorker.updateWorkConfig({
          key: 'networkDelay',
          value: time * 1000
        });
      }
      /**
       * 获取解码方式
       */


      getDecodeType() {
        let result = '';

        if (this.player) {
          result = this.player.getDecodeType();
        }

        return result;
      }

      getRenderType() {
        let result = '';

        if (this.player) {
          result = this.player.getRenderType();
        }

        return result;
      }

      getAudioEngineType() {
        let result = '';

        if (this.player) {
          result = this.player.getAudioEngineType();
        }

        return result;
      }
      /**
       * get playing timestamp
       * @returns {number}
       */


      getPlayingTimestamp() {
        let result = 0;

        if (this.player) {
          result = this.player.getPlayingTimestamp();
        }

        return result;
      }
      /**
       * get player now status
       * @returns {string}
       */


      getStatus() {
        let result = PLAYER_STATUS.destroy;

        if (this.player) {
          if (this.player.loading) {
            result = PLAYER_STATUS.loading;
          } else {
            if (this.player.playing) {
              result = PLAYER_STATUS.playing;
            } else {
              result = PLAYER_STATUS.paused;
            }
          }
        }

        return result;
      }

      getPlayType() {
        return this.player ? this.player._opt.playType : PLAY_TYPE.player;
      }

      togglePerformancePanel(flag) {
        const prev = this.player._opt.showPerformance;
        let toggleResult = !prev;

        if (isBoolean(flag)) {
          toggleResult = flag;
        }

        if (toggleResult === prev) {
          return;
        }

        if (this.player) {
          this.player.togglePerformancePanel(toggleResult);
        }
      }
      /**
       *
       */


      openZoom() {
        if (this.player) {
          this.player.zooming = true;
        }
      }
      /**
       *
       */


      closeZoom() {
        if (this.player) {
          this.player.zooming = false;
        }
      }
      /**
       *
       * @returns {boolean}
       */


      isZoomOpen() {
        let result = false;

        if (this.player) {
          result = this.player.zooming;
        }

        return result;
      }
      /**
       *
       */


      expandZoom() {
        if (this.player && this.player.zoom && this.player.zooming) {
          this.player.zoom.expandPrecision();
        }
      }
      /**
       *
       */


      narrowZoom() {
        if (this.player && this.player.zoom && this.player.zooming) {
          this.player.zoom.narrowPrecision();
        }
      }
      /**
       *
       * @returns {number}
       */


      getCurrentZoomIndex() {
        let result = 1;

        if (this.player && this.player.zoom) {
          result = this.player.zoom.currentZoom;
        }

        return result;
      }
      /**
       *
       * @param wsUrl
       * @param options
       * @returns {Promise<unknown>}
       */


      startTalk(wsUrl) {
        let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
        return new Promise((resolve, reject) => {
          this._initTalk(options);

          this.talk.startTalk(wsUrl).then(() => {
            resolve();
            this.talk.once(EVENTS.talkStreamClose, () => {
              this.stopTalk().catch(e => {});
            });
            this.talk.once(EVENTS.talkStreamError, () => {
              this.stopTalk().catch(e => {});
            });
            this.talk.once(EVENTS.talkStreamInactive, () => {
              this.stopTalk().catch(e => {});
            });
          }).catch(e => {
            reject(e);
          });
        });
      }
      /**
       *
       * @returns {Promise<unknown>}
       */


      stopTalk() {
        return new Promise((resolve, reject) => {
          if (!this.talk) {
            reject('talk is not init');
          }

          this.talk.destroy();
          resolve();
        });
      }
      /**
       *
       * @returns {Promise<unknown>}
       */


      getTalkVolume() {
        return new Promise((resolve, reject) => {
          if (!this.talk) {
            reject('talk is not init');
          }

          let result = this.talk.volume;
          resolve(result);
        });
      }
      /**
       *
       * @param volume
       * @returns {Promise<unknown>}
       */


      setTalkVolume(volume) {
        return new Promise((resolve, reject) => {
          if (!this.talk) {
            reject('talk is not init');
          }

          this.talk.setVolume(volume / 100);
          resolve();
        });
      }

      setNakedFlowFps(fps) {
        return new Promise((resolve, reject) => {
          if (!this.player) {
            return reject('player is not init');
          }

          if (isEmpty(fps)) {
            return reject('fps is empty');
          }

          let _fps = Number(fps);

          _fps = clamp(_fps, 1, 100);
          this.player.updateOption({
            nakedFlowFps: _fps
          });
        });
      }

      getCrashLog(error) {
        if (!this.player) {
          return;
        }

        const statsData = this.player.getAllStatsData();
        const player = this.player;
        let result = {
          url: this._opt.url,
          playType: player.isPlayback() ? 'playback' : 'live',
          demuxType: player.getDemuxType(),
          decoderType: player.getDecodeType(),
          renderType: player.getRenderType(),
          videoInfo: player.video ? player.video.videoInfo : {},
          audioInfo: player.audio ? player.audio.audioInfo : {},
          audioEngine: player.getAudioEngineType(),
          allTimes: statsData.pTs,
          error: errorToString(error)
        };
        return result;
      }

      faceDetectOpen() {
        if (this.player) {
          this.player.faceDetect(true);
        }
      }

      faceDetectClose() {
        if (this.player) {
          this.player.faceDetect(false);
        }
      }

      downloadTempNakedFlowFile() {
        return new Promise((resolve, reject) => {
          if (this.player) {
            this.player.downloadNakedFlowFile();
            resolve();
          } else {
            reject('player is not init');
          }
        });
      }

      downloadTempRtpFile() {
        return new Promise((resolve, reject) => {
          if (this.talk) {
            this.talk.downloadRtpFile();
            resolve();
          } else {
            reject('talk is not init');
          }
        });
      }

    } //


    JessibucaPro.ERROR = EVENTS_ERROR; //

    JessibucaPro.EVENTS = JESSIBUCA_EVENTS;
    window.JessibucaPro = JessibucaPro;

    return JessibucaPro;

}));
//# sourceMappingURL=jessibuca-pro-demo.js.map
